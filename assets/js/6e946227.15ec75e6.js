"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[786],{8453:(i,e,n)=>{n.d(e,{R:()=>t,x:()=>o});var r=n(6540);const s={},a=r.createContext(s);function t(i){const e=r.useContext(a);return r.useMemo(function(){return"function"==typeof i?i(e):{...e,...i}},[e,i])}function o(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(s):i.components||s:t(i.components),r.createElement(a.Provider,{value:e},i.children)}},9880:(i,e,n)=>{n.r(e),n.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"daily/20260112-20260118","title":"20260112-20260118","description":"2026-01-12","source":"@site/docs/daily/20260112-20260118.md","sourceDirName":"daily","slug":"/daily/20260112-20260118","permalink":"/daily/20260112-20260118","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1772076407000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"20260105-20260111","permalink":"/daily/20260105-20260111"},"next":{"title":"20260119-20260125","permalink":"/daily/20260119-20260125"}}');var s=n(4848),a=n(8453);const t={},o="20260112-20260118",l={},d=[{value:"2026-01-12",id:"2026-01-12",level:2},{value:"2026-01-13",id:"2026-01-13",level:2},{value:"2026-01-14",id:"2026-01-14",level:2},{value:"2026-01-15",id:"2026-01-15",level:2},{value:"2026-01-16",id:"2026-01-16",level:2}];function c(i){const e={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...i.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"20260112-20260118",children:"20260112-20260118"})}),"\n",(0,s.jsx)(e.h2,{id:"2026-01-12",children:"2026-01-12"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 5"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260112] LACIN: Linearly Arranged Complete Interconnection Networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [interconnection networks], [complete graph, isoport, wiring, routing, Dragonfly, HyperX]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Ram\xf3n Beivide, Crist\xf3bal Camarero, Carmen Mart\xednez, Enrique Vallejo, Mateo Valero"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Universidad de Cantabria, Barcelona Supercomputing Center"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05668",children:"https://arxiv.org/pdf/2601.05668"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces LACIN, a method for implementing Complete Interconnection Networks (CINs) by connecting switches using identically indexed ports (isoport). This approach simplifies network cabling and routing complexity. It facilitates the deployment of scalable networks from VLSI systems to large supercomputers."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260112] MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm training], [mixture-of-experts, memory wall, activation checkpointing, kernel co-design, token dispatch, memory-efficient training]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jiyuan Zhang, Yining Liu, Siqi Yan, Lisen Deng, Jennifer Cao, Shuqi Yang, Min Ni, Bi Xue, Shen Li"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Meta Platforms Inc, Thinking Machines Lab"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05296",children:"https://arxiv.org/pdf/2601.05296"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces MoEBlaze, a memory-efficient training framework for Mixture-of-Experts models that co-designs an end-to-end token dispatch method and optimized kernels to eliminate intermediate activation buffers and reduce memory footprint. The system achieves significant performance gains and memory savings, demonstrating over 4x speedups and over 50% memory reduction compared to existing frameworks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260112] Self-Evolving Distributed Memory Architecture for Scalable AI Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [distributed memory architecture, dual memory system, memory-guided matrix processing, memory-aware peer selection, runtime-adaptive deployment]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zixuan Li, Chuanzhen Wang, Haotian Sun"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Tongji University, Pacific Coast University, Northern Research Laboratory"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05569",children:"https://arxiv.org/pdf/2601.05569"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a Self-Evolving Distributed Memory Architecture, a three-layer framework that unifies memory management across computation, communication, and deployment layers using techniques like dynamic partitioning and a dual memory system. The experiments show it outperforms baselines like Ray Distributed in memory utilization, operational speed, and communication latency. The main conclusion is that coordinated, adaptive memory management across architectural layers is crucial for scalable and efficient distributed AI systems."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260112] Multi-Modal Style Transfer-based Prompt Tuning for Efficient Federated Domain Generalization"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [multi-modal training], [federated domain generalization, multi-modal style transfer, prompt tuning, dual-prompt module, domain-aware prompt generation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yuliang Chen, Xi Lin, Jun Wu, Xiangrui Cai, Qiaolun Zhang, Xichun Fan, Jiapeng Xu, Xiu Su"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Shanghai Jiao Tong University, Nankai University, Polytechnic Institute of Milan, New York University Shanghai, Central South University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05955",children:"https://arxiv.org/pdf/2601.05955"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes FaST-PT, a federated domain generalization framework that uses a lightweight Multi-Modal Style Transfer method for local feature augmentation and a dual-prompt module with Domain-aware Prompt Generation for efficient unseen domain adaptation. The method demonstrates superior performance over state-of-the-art FDG methods on benchmark datasets like PACS and DomainNet, validating its effectiveness and efficiency."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260112] Performance-Portable Optimization and Analysis of Multiple Right-Hand Sides in a Lattice QCD Solver"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [high-performance computing], [multiple right-hand sides, SIMD, data layout, auto-vectorization, GMRES, performance portability, SME]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Shiting Long, Gustavo Ramirez-Hidalgo, Stepan Nassyr, Jose Jimenez-Merchan, Andreas Frommer, Dirk Pleiter"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," KTH Royal Institute of Technology, Forschungszentrum J\xfclich GmbH, University of Wuppertal, University of Groningen"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05816",children:"https://arxiv.org/pdf/2601.05816"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper extends a lattice QCD solver to support multiple right-hand sides and optimizes it with a flexible data layout interface for better SIMD utilization. The optimizations are evaluated on x86 and Arm clusters, demonstrating performance portability and revealing insights into architectural constraints and compiler behavior. An early assessment of the Arm SME instruction set is also provided."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 19'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] WildSci: Advancing Scientific Reasoning from In-the-Wild Literature ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05567",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] On the Limits of Self-Improving in LLMs and Why AGI, ASI and the Singularity Are Not Near Without Symbolic Model Synthesis ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05280",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05836",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05475",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05257",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05870",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Do LLMs Need Inherent Reasoning Before Reinforcement Learning? A Study in Korean Self-Correction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05459",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05890",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05432",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05899",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05607",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05593",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Sequential Bayesian Optimal Experimental Design in Infinite Dimensions via Policy Gradient Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05868",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Autonomous Discovery of the Ising Model's Critical Parameters with Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05577",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05578",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05465",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05787",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Dual-Phase LLM Reasoning: Self-Evolved Mathematical Frameworks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05616",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05808",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 9'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05684",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05593",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05407",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05732",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] DNATokenizer: A GPU-First Byte-to-Identifier Tokenizer for High-Throughput DNA Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05531",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Influence of Parallelism in Vector-Multiplication Units on Correlation Power Analysis ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05828",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Tracing Stereotypes in Pre-trained Transformers: From Biased Neurons to Fairer Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05663",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] A Survey of Agentic AI and Cybersecurity: Challenges, Opportunities and Use-case Prototypes ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05293",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Can We Predict Before Executing Machine Learning Agents? ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05930",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2026-01-13",children:"2026-01-13"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 18"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Behavioral Analytics for Continuous Insider Threat Detection in Zero-Trust Architectures"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [AdaBoost, SMOTE, PCA, SVM, ANN, Bayesian Network, behavioral analytics, insider threat detection]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Gaurav Sarraf"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Independent researcher"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06708",children:"https://arxiv.org/pdf/2601.06708"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a framework using behavioral analytics and machine learning for continuous insider threat detection in zero-trust architectures. It employs data preprocessing (SMOTE, PCA) and benchmarks classifiers, finding that an AdaBoost model achieves the highest performance (98% accuracy). The results demonstrate the effectiveness of AdaBoost-based analytics for reinforcing security in zero-trust settings."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] BlazeAIoT: A Modular Multi-Layer Platform for Real-Time Distributed Robotics Across Edge, Fog, and Cloud Infrastructures"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [Kubernetes, DDS, Kafka, Redis, ROS2, adaptive data distribution, hierarchical rate limiting, multi-layer configuration service]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Cedric Melancon, Julien Gascon-Samson, Maarouf Saad, Kuljeet Kaur, Simon Savard"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," \xc9cole de technologie sup\xe9rieure"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06344",children:"https://arxiv.org/pdf/2601.06344"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces BlazeAIoT, a modular platform that uses Kubernetes clusters and broker interoperability (e.g., DDS, Kafka) to unify distributed robotics across edge, fog, and cloud layers. It demonstrates that the platform can dynamically allocate services, maintain system health, and minimize latency, making it a scalable solution for real-time robotics and IoT applications."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Resource-Aware Task Allocator Design: Insights and Recommendations for Distributed Satellite Constellations"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed satellite systems], [Single-Level Tree Network (SLTN), resource-aware task allocator (RATA), blocking probability, solar-aware scheduling, energy consumption]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Bharadwaj Veeravalli"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," National University of Singapore"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06706",children:"https://arxiv.org/pdf/2601.06706"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper designs a Resource-Aware Task Allocator (RATA) for Distributed Satellite Systems using a Single-Level Tree Network architecture to manage real-time tasks. The empirical analysis shows that while system capacity increases with constellation size, blocking and delay grow non-linearly, and CPU availability, not energy, is the primary bottleneck causing task blocking."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] HiDVFS: A Hierarchical Multi-Agent DVFS Scheduler for OpenMP DAG Workloads"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [hierarchical multi-agent reinforcement learning, dynamic voltage and frequency scaling, OpenMP DAG scheduling, temperature-aware task allocation, makespan optimization]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Mohammad Pivezhandi, Abusayeed Saifullah, Ali Jannesari"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Iowa State University, University of Texas at Dallas"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06425",children:"https://arxiv.org/pdf/2601.06425"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes HiDVFS, a hierarchical multi-agent DVFS scheduler that optimizes task allocation and frequency scaling for OpenMP DAG workloads using profiling data and temperature sensors to prioritize makespan while reducing energy. Experiments on an NVIDIA Jetson TX2 show HiDVFS achieves significant speedup and energy reduction compared to existing methods."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] AIConfigurator: Lightning-Fast Configuration Optimization for Multi-Framework LLM Serving"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [performance modeling, configuration search, kernel-level database, GEMM, attention, communication, memory operations, distributed parallelism, tensor parallelism, pipeline parallelism, expert parallelism, CUDA graphs, KV-cache]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Tianhao Xu, Yiming Liu, Xianglong Lu, Yijia Zhao, Xuting Zhou, Aichen Feng, Yiyi Chen, Yi Shen, Qin Zhou, Xumeng Chen, Ilya Sherstyuk, Haorui Li, Rishi Thakkar, Ben Hamm, Yuanzhe Li, Xue Huang, Wenpeng Wu, Anish Shanbhag, Harry Kim, Chuan Chen, Junjie Lai"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," NVIDIA"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06288",children:"https://arxiv.org/pdf/2601.06288"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," AIConfigurator is a unified performance-modeling system that rapidly optimizes LLM inference configurations by decomposing inference into analytical primitives and using a calibrated kernel-level database, without requiring GPU profiling. It identifies configurations that improve performance by up to 40-50% for various models and completes searches within 30 seconds on average."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Privacy-Preserving Data Processing in Cloud : From Homomorphic Encryption to Federated Analytics"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [homomorphic encryption, secure multi-party computation, differential privacy, federated analytics, federated learning, hybrid privacy frameworks]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Gaurav Sarraf, Vibhor Pal"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Independent Researcher"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06710",children:"https://arxiv.org/pdf/2601.06710"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper reviews privacy-preserving data processing methods for cloud computing, including cryptographic techniques like homomorphic encryption and statistical approaches like differential privacy, as well as distributed frameworks like federated learning. It concludes by analyzing the trade-offs between security, efficiency, and accuracy in these methods and highlights the potential of hybrid frameworks to offer better privacy protection. The review serves as a crucial resource for understanding secure and effective solutions in data processing."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Rethinking Inter-Process Communication with Memory Operation Offloading"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [memory operation offloading, asynchronous pipelining, selective cache injection, hybrid coordination, shared-memory communication]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Misun Park, Richi Dubey, Yifan Yuan, Nam Sung Kim, Ada Gavrilovska"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Georgia Institute of Technology, Meta, University of Illinois\u2013Urbana-Champaign"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06331",children:"https://arxiv.org/pdf/2601.06331"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents ROCKET, a unified IPC runtime that integrates hardware- and software-based memory offloading into shared-memory communication to reduce CPU overhead from data copies. It introduces techniques like asynchronous pipelining and selective cache injection to coordinate offloading strategies. Evaluations show the system significantly reduces instruction counts, improves throughput, and lowers latency for modern data-intensive, multi-modal workloads."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Learning-Augmented Performance Model for Tensor Product Factorization in High-Order FEM"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [GPU kernels], [performance modeling, sum-factorization, tensor n-mode product, XGBoost, dependency-chain analysis, loop-body splitting, Roofline model, ECM model]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Xuanzhengbo Ren, Yuta Kawai, Tetsuya Hoshino, Hirofumi Tomita, Takahiro Katagiri, Daichi Mukunoki, Seiya Nishizawa"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Nagoya University, RIKEN R-CCS"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06886",children:"https://arxiv.org/pdf/2601.06886"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper develops a learning-augmented performance model for tensor product factorization kernels in high-order FEM. It combines an analytical dependency-chain formulation with XGBoost to estimate key parameters, focusing on instruction-level efficiency for loop-splitting configurations. The model significantly outperforms standard Roofline and ECM models in prediction accuracy on both Fujitsu A64FX and Intel Xeon processors."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] SkyNomad: On Using Multi-Region Spot Instances to Minimize AI Batch Job Cost"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [spot instances, multi-region scheduling, cost model, checkpoint-based recovery, deadline guarantee, migration]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zhifei Li, Tian Xia, Ziming Mao, Zihan Zhou, Ethan J. Jackson, Jamison Kerney, Zhanghao Wu, Pratik Mishra, Yi Xu, Yifan Qiao, Scott Shenker, Ion Stoica"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," UC Berkeley, Shanghai Jiao Tong University, AMD, ICSI"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06520",children:"https://arxiv.org/pdf/2601.06520"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," SkyNomad is a multi-region scheduling system that minimizes the cost of AI batch jobs by exploiting spatial and temporal heterogeneity in spot instance availability and prices, while guaranteeing deadlines. It uses lightweight probing, spot lifetime prediction, and a unified cost model to guide migration decisions between spot and on-demand instances. The evaluation shows it achieves significant cost savings (1.25-3.96x) in real deployments and performs close to an optimal policy in simulation."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Employ SmartNICs' Data Path Accelerators for Ordered Key-Value Stores"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed systems], [SmartNIC, Data Path Accelerators (DPAs), learned index, lock-free, PCIe, DMA, stateless clients, range queries]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Frederic Schimmelpfennig, Jan Sass, Reza Salkhordeh, Martin Kr\xf6ning, Stefan Lankes, Andr\xe9 Brinkmann"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Johannes Gutenberg University Mainz, RWTH Aachen University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06231",children:"https://arxiv.org/pdf/2601.06231"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces a key-value store that uses the Data Path Accelerators (DPAs) on a BlueField-3 SmartNIC to process requests directly, bypassing the host OS and minimizing PCIe crossings. It employs a lock-free learned index on the SmartNIC for efficient point and range queries, achieving high throughput. The analysis shows this architecture matches or exceeds state-of-the-art performance while suggesting hardware refinements for further acceleration."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [split computing, intermediate output integration, LiDAR, 3D object detection, edge computing, point cloud]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Taisuke Noguchi, Takayuki Nishio, Takuya Azumi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Saitama University, Institute of Science Tokyo"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07119",children:"https://arxiv.org/pdf/2601.07119"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes SC-MII, a split computing method for 3D object detection using multiple infrastructure LiDARs. Edge devices process initial DNN layers on local point clouds and send intermediate features to a server, which integrates them to complete inference. The approach significantly reduces edge device processing time and latency with minimal accuracy loss."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [distributed orchestration, resource allocation, task scheduling, three-service architecture]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Lei Zhang, Mouxiang Chen, Ruisheng Cao, Jiawei Chen, Fan Zhou, Yiheng Xu, Jiaxi Yang, Liang Chen, Changwei Luo, Kai Zhang, Fan Yan, KaShun Shum, Jiajun Zhang, Zeyu Cui, Hu Feng, Junyang Lin, Binyuan Hui, Min Yang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Alibaba Group"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07526",children:"https://arxiv.org/pdf/2601.07526"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces MegaFlow, a large-scale distributed orchestration system that abstracts agent training into three independent services (Model, Agent, and Environment) for flexible scaling and management. It successfully coordinates tens of thousands of concurrent agent tasks, addressing a critical infrastructure gap for training AI agents on complex tasks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Divergence-Based Adaptive Aggregation for Byzantine Robust Federated Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [divergence of degree, linear calibration, vetted root dataset, Byzantine attacks, client drift, federated averaging, non-convex models]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Bingnan Xiao, Feng Zhu, Jingjing Zhang, Wei Ni, Xin Wang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Fudan University, North Carolina State University, Edith Cowan University, University of New South Wales"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06903",children:"https://arxiv.org/pdf/2601.06903"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces two federated learning frameworks, DRAG and BR-DRAG, which use a divergence metric and linear calibration to align local model updates and mitigate client drift. BR-DRAG enhances this by using a trusted server dataset to defend against Byzantine attacks. The methods are proven to converge quickly under non-convex settings and are validated as effective against data heterogeneity and malicious attacks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Peformance Isolation for Inference Processes in Edge GPU Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [MPS, MIG, Green Contexts, temporal isolation, GPU partitioning, edge computing]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Juan Jos\xe9 Mart\xedn, Jos\xe9 Flich, Carles Hern\xe1ndez"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Universitat Polit\xe8cnica de Val\xe8ncia"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07600",children:"https://arxiv.org/pdf/2601.07600"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper analyzes GPU isolation mechanisms (MPS, MIG, Green Contexts) to ensure predictable inference times for deep learning models in safety-critical edge systems. The experimental evaluation on NVIDIA A100 and Jetson Orin platforms shows that MIG provides high isolation, while Green Contexts offer a promising low-overhead alternative for fine-grained SM allocation on edge devices, though without memory isolation."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] OpenTinker: Separating Concerns in Agentic Reinforcement Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm training], [reinforcement learning, large language model agents, separation of concerns, composable components, managed execution runtime, centralized scheduler, LoRA, full-parameter RL, supervised fine-tuning]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Siqi Zhu, Jiaxuan You"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Illinois Urbana-Champaign"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07376",children:"https://arxiv.org/pdf/2601.07376"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces OpenTinker, an infrastructure for RL of LLM agents that separates concerns into algorithm design, execution, and agent-environment interaction using lightweight, composable components. It features a centralized scheduler to manage diverse workloads like LoRA-based RL and inference over shared resources. The framework aims to lower the barrier for agentic RL by abstracting infrastructure, making it more reusable and accessible than monolithic pipelines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Advanced computing for reproducibility of astronomy Big Data Science, with a showcase of AMIGA and the SKA Science prototype"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [astronomy big data infrastructure], [semantic data models, federated infrastructures, reproducibility, SKA Regional Centre Network (SRCNet)]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Juli\xe1n Garrido, Susana S\xe1nchez, Edgar Ribeiro Jo\xe3o, Roger Ianjamasimanana, Manuel Parra, Lourdes Verdes-Montenegro"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Instituto de Astrof\xedsica de Andaluc\xeda, CSIC"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07439",children:"https://arxiv.org/pdf/2601.07439"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents the AMIGA group's research on using semantic data models and federated analysis services to address computing and reproducibility challenges for the SKA Observatory's Big Data. It concludes that for the SKAO to succeed, reproducibility requirements must be explicitly embedded into the fundamental architectural design of the SKA Regional Centre Network (SRCNet) to enable verifiable and sustainable research."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Bringing Computation to the data: Interoperable serverless function execution for astrophysical data analysis in the SRCNet"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [scientific computing, data-intensive workflows], [serverless computing, Function-as-a-Service (FaaS), data-proximate computation, Gaussian convolution, SKA Regional Centre Network (SRCNet)]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Manuel Parra-Roy\xf3n, Juli\xe1n Garrido-S\xe1nchez, Susana S\xe1nchez-Exp\xf3sito, Mar\xeda \xc1ngeles Mendoza, Rob Barnsley, Anthony Moraghan, Jes\xfas S\xe1nchez, Laura Darriba, Carlos Ru\xedz-Monje, Edgar Joao, Javier Mold\xf3n, Jes\xfas Salgado, Lourdes Verdes-Montenegro"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Instituto de Astrof\xedsica de Andaluc\xeda, Square Kilometre Array Observatory (SKAO), University of Sevilla, University of Manchester"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07308",children:"https://arxiv.org/pdf/2601.07308"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper explores the use of serverless Function-as-a-Service (FaaS) computing to enable interoperable, data-proximate astrophysical analysis within the SKA Regional Centre Network. It demonstrates the deployment of representative functions, such as Gaussian convolution, directly at data storage sites to reduce latency and transfers. The results indicate that serverless models provide a scalable and efficient approach for handling the massive data volumes expected from the Square Kilometre Array."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Beyond Single-GPU: Scaling PDLP to Distributed Multi-GPU Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [GPU kernels], [PDHG, distributed multi-GPU, two-dimensional grid partitioning, NCCL, block-wise random shuffling, nonzero-aware data distribution, fused CUDA kernels]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Hongpei Li, Yicheng Huang, Huikang Liu, Dongdong Ge, Yinyu Ye"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Cardinal Operations, Shanghai University of Finance and Economics, Shanghai Jiao Tong University, Stanford University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07628",children:"https://arxiv.org/pdf/2601.07628"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents a distributed implementation of the Primal-Dual Hybrid Gradient (PDHG) algorithm for solving massive-scale linear programming problems. The method uses a two-dimensional grid partitioning of the constraint matrix and techniques like block-wise shuffling and fused CUDA kernels to scale across multiple GPUs with low communication overhead. The experiments show that this distributed framework overcomes single-GPU memory limits and achieves strong scalability and high performance while maintaining numerical accuracy."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 50'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Reinforcement Learning-Guided Dynamic Multi-Graph Fusion for Evacuation Traffic Prediction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06664",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Toward Safe and Responsible AI Agents: A Three-Pillar Model for Transparency, Accountability, and Trustworthiness ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06223",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] A Review of Online Diffusion Policy RL Algorithms for Scalable Robotic Control ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06133",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06052",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] KASER: Knowledge-Aligned Student Error Simulator for Open-Ended Coding Tasks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06633",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] TimeGNN-Augmented Hybrid-Action MARL for Fine-Grained Task Partitioning and Energy-Aware Offloading in MEC ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06191",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Thinking with Deltas: Incentivizing Reinforcement Learning via Differential Visual Reasoning Policy ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06801",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] HiMeS: Hippocampus-inspired Memory System for Personalized AI Assistants ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06152",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Plasticity vs. Rigidity: The Impact of Low-Rank Adapters on Reasoning on a Micro-Budget ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06677",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] GanitLLM: Difficulty-Aware Bengali Mathematical Reasoning through Curriculum-GRPO ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06767",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Object-Centric World Models Meet Monte Carlo Tree Search ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06604",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] COVR",":Collaborative"," Optimization of VLMs and RL Agent for Visual-Based Control ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06122",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06794",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] From RLHF to Direct Alignment: A Theoretical Unification of Preference Learning for Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06108",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06795",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Future-as-Label: Scalable Supervision from Real-World Outcomes ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06336",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Personality-Aware Reinforcement Learning for Persuasive Dialogue with LLM-Driven Simulation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06877",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Code Evolution for Control: Synthesizing Policies via LLM-Driven Evolutionary Search ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06845",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] The Impact of Post-training on Data Contamination ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06103",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] A Brain-like Synergistic Core in LLMs Drives Behaviour and Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06851",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Characterising Toxicity in Generative Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06700",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] How well can off-the-shelf LLMs elucidate molecular structures from mass spectra using chain-of-thought reasoning? ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06289",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Deep Q-Network Based Resilient Drone Communication",":Neutralizing"," First-Order Markov Jammers ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06095",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] ArenaRL: Scaling RL for Open-Ended Agents via Tournament-based Relative Ranking ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06487",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Distributional Clarity: The Hidden Driver of RL-Friendliness in Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06911",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06953",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] MEDVISTAGYM: A Scalable Training Environment for Thinking with Medical Images via Tool-Integrated Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07107",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07122",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] ENTRA: Entropy-Based Redundancy Avoidance in Large Language Model Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07123",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Generating readily synthesizable small molecule fluorophore scaffolds with reinforcement learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07145",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Rewarding Creativity: A Human-Aligned Generative Reward Model for Reinforcement Learning in Storytelling ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07149",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07160",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Offline Meta-Reinforcement Learning with Flow-Based Task Inference and Adaptive Correction of Feature Overgeneralization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07164",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07224",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07238",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] LRAS: Advanced Legal Reasoning with Agentic Search ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07296",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07304",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM Training ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07320",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07389",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Outcome-Grounded Advantage Reshaping for Fine-Grained Credit Assignment in Mathematical Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07408",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07463",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Graph Inference Towards ICD Coding ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07496",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07516",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Stagewise Reinforcement Learning and the Geometry of the Regret Landscape ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07524",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] GRPO with State Mutations: Improving LLM-Based Hardware Test Plan Generation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07593",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07718",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07782",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07821",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Large Language Models for Physics Instrument Design ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07580",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Reinforcement Learning for Micro-Level Claims Reserving ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07637",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 18'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] TeleMem: Building Long-Term and Multimodal Memory for Agentic AI ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06037",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Pareto-Optimal Model Selection for Low-Cost, Single-Lead EMG Control in Embedded Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06516",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Logic-Driven Semantic Communication for Resilient Multi-Agent Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06733",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Attention in Geometry: Scalable Spatial Modeling via Adaptive Density Fields and FAISS-Accelerated Kernels ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06135",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Bridging the AI divide in sub-Saharan Africa: Challenges and opportunities for inclusivity ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06145",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Lower Bounds for the Algorithmic Complexity of Learned Indexes ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06629",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06795",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Channel Knowledge Map Construction via Guided Flow Matching ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06156",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] MicLog: Towards Accurate and Efficient LLM-based Log Parsing via Progressive Meta In-Context Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07005",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Jasper: ANNS Quantized for Speed, Built for Change on GPU ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07048",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07160",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07263",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Software-Hardware Co-optimization for Modular E2E AV Paradigm: A Unified Framework of Optimization Approaches, Simulation Environment and Evaluation Metrics ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07393",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] PLANET v2.0: A comprehensive Protein-Ligand Affinity Prediction Model Based on Mixture Density Network ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07415",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Pheromone-Focused Ant Colony Optimization algorithm for path planning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07597",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Learning to accelerate Krasnosel'skii-Mann fixed-point iterations with guarantees ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07665",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Match Made with Matrix Completion: Efficient Learning under Matching Interference ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06982",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] A Model of Artificial Jagged Intelligence ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07573",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2026-01-14",children:"2026-01-14"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 9"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260114] Coordinated Cooling and Compute Management for AI Datacenters"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [GPU profiling, hierarchical control, DVFS, thermal modeling, joint cooling-compute optimization]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Nardos Belay Abera, Yize Chen"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Alberta"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08113",children:"https://arxiv.org/pdf/2601.08113"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes a hierarchical control framework that co-optimizes computing (via GPU parallelism and DVFS) and cooling management for AI datacenters, based on workload and thermal dynamics models. Using real Azure traces and GPU profiling, the method balances serving latency and thermal constraints, significantly improving datacenter energy efficiency."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260114] Improving Zero-shot ADL Recognition with Large Language Models through Event-based Context and Confidence"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [event-based segmentation, zero-shot learning, confidence estimation, prompting strategies, smart home sensor data]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Michele Fiori, Gabriele Civitarese, Marco Colussi, Claudio Bettini"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Milan"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08241",children:"https://arxiv.org/pdf/2601.08241"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a zero-shot method for recognizing Activities of Daily Living (ADLs) using Large Language Models with event-based segmentation instead of traditional time-based windows, and introduces a novel confidence estimation measure. The approach outperforms existing time-based LLM methods and even supervised data-driven methods on complex datasets, with the confidence measure effectively identifying correct predictions."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260114] Where to Split? A Pareto-Front Analysis of DNN Partitioning for Edge Inference"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [DNN partitioning, pipeline parallelism, Pareto front analysis, edge inference, latency-throughput trade-off]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Adiba Masud, Nicholas Foley, Pragathi Durga Rajarajan, Palden Lama"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The University of Texas at San Antonio"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08025",children:"https://arxiv.org/pdf/2601.08025"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces ParetoPipe, a framework that reframes DNN partitioning for edge inference as a multi-objective optimization problem, using Pareto front analysis to identify optimal strategies balancing latency and throughput. The main conclusion is that real-world deployments require navigating a complex trade-off space, and the framework's benchmarking on a heterogeneous testbed reveals these trade-offs under varying network conditions."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260114] Multivariate Polynomial Codes for Efficient Matrix Chain Multiplication in Distributed Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [multivariate polynomial coding, coded distributed computing, matrix chain multiplication, straggler mitigation, storage-computation trade-off]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jes\xfas G\xf3mez-Vilardeb\xf2"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Centre Tecnol\xf2gic de Telecomunicacions de Catalunya (CTTC/CERCA)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08708",children:"https://arxiv.org/pdf/2601.08708"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes two novel multivariate polynomial coding schemes to mitigate stragglers in distributed matrix chain multiplication. The method reduces storage overhead at workers compared to univariate polynomial codes, but at the cost of increased computational complexity. The main conclusion is that multivariate codes offer a practical trade-off between computation and storage efficiency for large-scale distributed linear algebra."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260114] MixServe: An Automatic Distributed Serving System for MoE Models with Hybrid Parallelism Based on Fused Communication Algorithm"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [mixture of experts, tensor parallelism, expert parallelism, hybrid parallelism, fused communication, all-reduce, all-to-all, automatic parallel strategy selection]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Bowen Zhou, Jinrui Jia, Wenhao He, Yong Zhang, Fang Dong"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Southeast University, The Chinese University of Hong Kong"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08800",children:"https://arxiv.org/pdf/2601.08800"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces MixServe, an automatic distributed serving system for MoE models. Its core method is a novel TP-EP hybrid parallelism based on a fused AR-A2A communication algorithm that overlaps intra-node and inter-node communication. Experiments show that MixServe significantly improves inference performance, including latency and throughput, compared to existing approaches."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260114] Hierarchical Precision and Recursion for Accelerating Symmetric Linear Solves on MXUs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [GPU kernels], [mixed-precision, recursive algorithms, Cholesky decomposition, triangular solve (TRSM), symmetric rank-k update (SYRK), hierarchical recursion, matrix processing units (MXUs)]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Vicki Carrica, Rabab Alomairy, Evelyne Ringoot, Alan Edelman"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Massachusetts Institute of Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08082",children:"https://arxiv.org/pdf/2601.08082"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces a portable, mixed-precision solver for symmetric linear systems, using a nested recursive algorithm that assigns low-precision arithmetic to off-diagonal blocks and high precision to diagonal blocks for numerical stability. Implemented in Julia, it achieves significant speedups on NVIDIA and AMD GPUs, with up to a 5x overall acceleration for Cholesky decomposition while maintaining high accuracy."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260114] Shifting the Sweet Spot: High-Performance Matrix-Free Method for High-Order Elasticity"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [high-performance computing, finite element methods], [matrix-free methods, sum-factorization, tensor factorization, Voigt symmetry, macro-kernel fusion, geometric multigrid, MFEM]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Dali Chang, Chong Zhang, Kaiqi Zhang, Mingguan Yang, Huiyuan Li, Weiqiang Kong"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Dalian University of Technology, Institute of Software Chinese Academy of Sciences"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08374",children:"https://arxiv.org/pdf/2601.08374"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"}),' This paper presents a highly optimized matrix-free operator for high-order finite element elasticity simulations, using techniques like tensor factorization and macro-kernel fusion to improve computational efficiency. The method successfully shifts the performance "sweet spot" to higher polynomial orders (p \u2265 6), achieving significant speedups over the baseline. It provides an efficient path for large-scale, high-order elasticity simulations on mainstream CPU hardware.']}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260114] Hierarchical Online-Scheduling for Energy-Efficient Split Inference with Progressive Transmission"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [split inference, Lyapunov optimization, hierarchical scheduling, progressive transmission, device-edge collaboration, energy efficiency]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zengzipeng Tang, Yuxuan Sun, Wei Chen, Jianwen Ding, Bo Ai, Yulin Shao"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Beijing Jiaotong University, The University of Hong Kong"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08135",children:"https://arxiv.org/pdf/2601.08135"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes ENACHI, a hierarchical online-scheduling framework that jointly optimizes task- and packet-level decisions using a two-tier Lyapunov-based approach and progressive transmission to maximize inference accuracy under energy and delay constraints. The method dynamically manages DNN partitioning, bandwidth allocation, and transmit power to adapt to channel conditions and per-task complexity. Experiments show it significantly improves accuracy and reduces energy consumption compared to benchmarks, demonstrating high scalability in multi-user scenarios."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260114] Matrix-PIC: Harnessing Matrix Outer-product for High-Performance Particle-in-Cell Simulations"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [high-performance computing], [matrix outer-product, block-matrix formulation, hybrid MPU-VPU pipeline, incremental particle sorting, gapped packed-memory array]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yizhuo Rao, Xingjian Cui, Jiabin Xie, Shangzhi Pang, Guangnan Feng, Jinhui Wei, Zhiguang Chen, Yutong Lu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Sun Yat-Sen University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08277",children:"https://arxiv.org/pdf/2601.08277"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents Matrix-PIC, a co-designed framework that accelerates Particle-in-Cell simulations by reformulating the current deposition step into block-matrix operations that leverage CPU-integrated Matrix Processing Units (MPUs). It combines MPU-based accumulation with VPU-based data preparation and an incremental sorter to maintain data locality. The method achieves significant speedups over baseline and GPU-optimized implementations, demonstrating the effectiveness of matrix-oriented co-design on modern CPU architectures."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 28'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Structure Detection for Contextual Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08120",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08763",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Provably Safe Reinforcement Learning using Entropy Regularizer ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08646",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08000",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08734",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Incorporating Cognitive Biases into Reinforcement Learning for Financial Decision-Making ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08247",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Scalable Multiagent Reinforcement Learning with Collective Influence Estimation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08210",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08310",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Model-Agnostic Solutions for Deep Reinforcement Learning in Non-Ergodic Contexts ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08726",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08237",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] AtomMem : Learnable Dynamic Agentic Memory with Atomic Memory Operation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08323",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08403",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] AUV Trajectory Learning for Underwater Acoustic Energy Transfer and Age Minimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08491",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08327",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08430",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08107",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Reinforcement Learning Methods for Neighborhood Selection in Local Search ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07948",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08679",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving? ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08434",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Your Group-Relative Advantage Is Biased ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08521",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] JudgeRLVR: Judge First, Generate Second for Efficient Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08468",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Reverse Flow Matching: A Unified Framework for Online Reinforcement Learning with Diffusion and Flow Policies ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08136",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] From Classical to Quantum Reinforcement Learning and Its Applications in Quantum Control: A Beginner's Tutorial ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08662",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Large Artificial Intelligence Model Guided Deep Reinforcement Learning for Resource Allocation in Non Terrestrial Networks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08254",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08166",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08052",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08808",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08026",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 7'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] HIPPO: Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08273",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08778",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Internal Deployment Gaps in AI Regulation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08005",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Reducing Compute Waste in LLMs through Kernel-Level DVFS ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08539",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] DataScribe: An AI-Native, Policy-Aligned Web Platform for Multi-Objective Materials Design and Discovery ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07966",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Autonomous Materials Exploration by Integrating Automated Phase Identification and AI-Assisted Human Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08185",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260114] Dynamic Graph Structure Learning via Resistance Curvature Flow ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08149",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2026-01-15",children:"2026-01-15"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 13"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] Transaction-Driven Dynamic Reconfiguration for Certificate-Based Payment Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed systems], [Byzantine Consistent Broadcast, dynamic reconfiguration, certificate-based payment, PDCC, leaderless PBFT]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Lingkang Shangguan"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The University of Sydney"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09146",children:"https://arxiv.org/pdf/2601.09146"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes PDCC, a transaction-driven dynamic reconfiguration protocol for certificate-based payment systems. It builds on Byzantine Consistent Broadcast to avoid global transaction ordering, enabling smooth membership changes without impacting system performance."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] Lean Clients, Full Accuracy: Hybrid Zeroth- and First-Order Split Federated Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [split federated learning, zeroth-order optimization, first-order optimization, hybrid optimization, auxiliary networks, low effective rank]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zhoubin Kou, Zihan Chen, Jing Yang, Cong Shen"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Virginia"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09076",children:"https://arxiv.org/pdf/2601.09076"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes HERON-SFL, a hybrid split federated learning framework that uses zeroth-order optimization on resource-constrained clients to reduce memory and computation costs, while keeping first-order optimization on the server. Theoretically, its convergence rate is independent of model dimensionality, and empirically it matches benchmark accuracy while significantly reducing client resource usage."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] A Machine Learning Approach Towards Runtime Optimisation of Matrix Multiplication"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [GPU kernels], [machine learning, autotuning, multi-threaded GEMM, BLAS, BLIS, MKL]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yufan Xia, Marco De La Pierre, Amanda S. Barnard, Giuseppe Maria Junior Barca"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Australian National University, Pawsey Supercomputing Research Centre"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09114",children:"https://arxiv.org/pdf/2601.09114"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a machine learning approach to optimize the runtime of matrix multiplication (GEMM) by automatically selecting the optimal number of threads for a given task. The method, part of an Architecture and Data-Structure Aware Linear Algebra (ADSALA) library, achieved a 25-40% speedup compared to traditional BLAS implementations on two HPC node architectures."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] Revisiting Disaggregated Large Language Model Serving for Performance and Energy Implications"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [disaggregated serving, KV cache transfer, dynamic voltage and frequency scaling (DVFS), performance-energy Pareto frontiers, colocated serving]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jiaxi Li, Yue Zhu, Eun Kyung Lee, Klara Nahrstedt"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," UIUC, IBM Research"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08833",children:"https://arxiv.org/pdf/2601.08833"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper systematically benchmarks disaggregated LLM serving, where prefill and decode stages run on separate GPUs, by evaluating different KV cache transfer paths and optimization strategies like frequency scaling. It finds that performance benefits are not guaranteed and depend on request load and transfer mediums, and that disaggregation does not lead to energy savings due to its inherently higher energy consumption."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] Optimizing View Change for Byzantine Fault Tolerance in Parallel Consensus"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed consensus], [mixed integer programming, benders decomposition, view change optimization, parallel BFT, leader selection]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yifei Xie, Btissam Er-Rahmadi, Xiao Chen, Tiejun Ma, Jane Hillston"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Edinburgh, Huawei Technologies R&D, University of Leicester"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09184",children:"https://arxiv.org/pdf/2601.09184"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a View Change Optimization (VCO) model using mixed integer programming and an improved Benders decomposition method to optimize leader selection and follower reassignment in parallel Byzantine Fault Tolerant consensus. The model aims to minimize latency during leader failures by considering communication delays and failure probabilities. Experiments on Microsoft Azure show that the VCO-driven approach outperforms existing methods, especially as network size increases."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [natural language processing, large language model, kubernetes scheduler extender, semantic parsing, soft affinity, intent-driven scheduling, AWS Bedrock]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Leszek Sliwko, Jolanta Mizeria-Pietraszko"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Standard Chartered Bank, Opole University of Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09282",children:"https://arxiv.org/pdf/2601.09282"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces a semantic scheduling system that uses a Large Language Model (LLM) to interpret natural language hints for workload placement in a Kubernetes cluster. The prototype demonstrated high parsing accuracy and achieved superior or equivalent scheduling quality compared to standard configurations, particularly in complex scenarios. The results validate the viability of using LLMs for accessible, intent-driven cluster orchestration, though latency remains a challenge for production use."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] Probabilistic Computers for MIMO Detection: From Sparsification to 2D Parallel Tempering"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [p-bit, graph sparsification, parallel tempering, FPGA, MIMO detection, Ising Hamiltonian, two-dimensional parallel tempering]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," M Mahmudul Hasan Sajeeb, Corentin Delacour, Kevin Callahan-Coray, Sanjay Seshan, Tathagata Srimani, Kerem Y. Camsari"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of California, Santa Barbara, Carnegie Mellon University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09037",children:"https://arxiv.org/pdf/2601.09037"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes a probabilistic computer using p-bits with graph sparsification and on-chip parallel tempering to solve dense combinatorial optimization problems like MIMO detection. It demonstrates improved bit error rates and faster convergence with two-dimensional parallel tempering on an FPGA. The results show potential for scalable hardware architectures to meet next-generation wireless throughput demands."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [GEPA framework, prompt optimization, genetic algorithm, OpenACC, parallel code generation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Samyak Jhaveri, Cristina V. Lopes"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of California, Irvine"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08884",children:"https://arxiv.org/pdf/2601.08884"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces a systematic prompt optimization approach using the GEPA (GEnetic-PAreto) framework to enhance the generation of OpenACC pragmas by smaller, cheaper LLMs. The method evolves prompts through a reflective feedback loop guided by expert-curated examples, significantly improving compilation success rates and functional GPU speedups. The results demonstrate that optimized prompting can effectively unlock the potential of small models for automated directive-based parallelization, offering a cost-effective alternative to larger models."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] DP-FEDSOFIM: Differentially Private Federated Stochastic Optimization using Regularized Fisher Information Matrix"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [differential privacy, federated learning, second-order optimization, Fisher Information Matrix, Sherman-Morrison formula, server-side preconditioning]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Sidhant R. Nair, Tanmay Sen, Mrinmay Sen"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Indian Institute of Technology Delhi, Indian Statistical Institute Kolkata, Indian Institute of Technology Hyderabad"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09166",children:"https://arxiv.org/pdf/2601.09166"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes DP-FedSOFIM, a differentially private federated learning method that uses a server-side second-order optimization framework with a regularized Fisher Information Matrix as a preconditioner. It achieves O(d) memory and computational complexity per client, making it scalable for high-dimensional models while preserving privacy. Empirical results on CIFAR-10 show it achieves superior test accuracy compared to first-order baselines across various privacy budgets."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] LatencyPrism: Online Non-intrusive Latency Sculpting for SLO-Guaranteed LLM Inference"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [latency sculpting, anomaly detection, root cause analysis, SLO guarantee, non-intrusive monitoring, distributed inference]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Du Yin, Jiayi Ren, Xiayu Sun, Tianyao Zhou, Haizhu Zhou, Ruiyan Ma, Danyang Zhang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Alibaba Cloud Computing, Xi'an Jiaotong University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09258",children:"https://arxiv.org/pdf/2601.09258"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents LatencyPrism, a zero-intrusion system for online latency monitoring and anomaly detection in LLM inference pipelines. It breaks down inference latency, distinguishes workload-driven variations from anomalies with high accuracy (F1-score 0.98), and guarantees SLO adherence without requiring code changes or service restarts. The system has been successfully deployed at scale across thousands of XPUs, enabling real-time, low-overhead monitoring and proactive alerting."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] Network-Based Quantum Computing: an efficient design framework for many-small-node distributed fault-tolerant quantum computing"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [quantum computing], [distributed fault-tolerant quantum computing, network-based quantum computation, logical qubit, algorithmic qubit, Bell-state distillation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Soshun Naito, Yasunari Suzuki, Yuuki Tokunaga"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The University of Tokyo, NTT Inc., RIKEN"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09374",children:"https://arxiv.org/pdf/2601.09374"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes Network-Based Quantum Computation (NBQC), a framework for distributed fault-tolerant quantum computing where computational data continuously moves through a network of many small nodes. It shows that NBQC achieves shorter execution times than circuit-based strategies and uses nodes more efficiently than measurement-based approaches, providing a foundation for scalable quantum architecture."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] AI-NativeBench: An Open-Source White-Box Agentic Benchmark Suite for AI-Native Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [Model Context Protocol (MCP), Agent-to-Agent (A2A), distributed tracing, white-box benchmarking, agentic spans]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zirui Wang, Guangba Yu, Michael R.Lyu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Sun Yat-sen University, The Chinese University of Hong Kong"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09393",children:"https://arxiv.org/pdf/2601.09393"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"}),' This paper introduces AI-NativeBench, an open-source, white-box benchmark suite for evaluating AI-Native systems by using distributed tracing to analyze agentic spans. The benchmark reveals key engineering insights, such as a "parameter paradox" where smaller models can outperform larger ones in protocol adherence and that inference costs dominate system performance.']}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260115] High-Performance Serverless Computing: A Systematic Literature Review on Serverless for HPC, AI, and Big Data"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [serverless computing, high-performance computing, cloud computing, systematic literature review, taxonomy]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Valerio Besozzi, Matteo Della Bartola, Patrizio Dazzi, Marco Danelutto"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Pisa, ISTI \u2013 National Research Council"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09334",children:"https://arxiv.org/pdf/2601.09334"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper conducts a systematic literature review of 122 research articles to explore the use of serverless computing for high-performance, AI, and big data workloads. It proposes a taxonomy of research directions and use cases, concluding that serverless is a promising model for improving scalability and resource utilization in compute-intensive applications."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 16'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] GIFT: Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09233",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] TranslateGemma Technical Report ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09012",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09136",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09260",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Reading or Reasoning? Format Decoupled Reinforcement Learning for Document OCR ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08834",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Reward Learning through Ranking Mean Squared Error ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09236",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Learning to Trust Experience: A Monitor-Trust-Regulator Framework for Learning under Unobservable Feedback Reliability ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09261",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09083",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09269",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Enhancing Spatial Reasoning in Large Language Models for Metal-Organic Frameworks Structure Prediction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09285",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop Scheduling under Uncertainty: Handling Random Arrivals and Machine Failures ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09293",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09353",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09361",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Draw it like Euclid: Teaching transformer models to generate CAD profiles using ruler and compass construction steps ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09428",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09609",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09667",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 11'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09085",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Navigating Ideation Space: Decomposed Conceptual Representations for Positioning Scientific Ideas ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.08901",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Hidden States as Early Signals: Step-level Trace Evaluation and Pruning for Efficient Test-Time Scaling ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09093",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Mi",":dm"," 2.0 Korea-centric Bilingual Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09066",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Discrete Solution Operator Learning for Geometry-Dependent PDEs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09143",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Human-AI Co-design for Clinical Prediction Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09072",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09083",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Layer-Parallel Training for Transformers ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09026",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09353",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Preliminary Tests of the Anticipatory Classifier System with Hindsight Experience Replay ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09400",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260115] Deep Operator Networks for Surrogate Modeling of Cyclic Adsorption Processes with Varying Initial Conditions ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09491",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2026-01-16",children:"2026-01-16"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 10"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260116] SCRamble: Adaptive Decentralized Overlay Construction for Blockchain Networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [blockchain networks], [decentralized protocol, overlay construction, peer-to-peer, scoring mechanism, network latency, block dissemination]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Evangelos Kolyvas, Alexandros Antonov, Spyros Voulgaris"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Athens University of Economics and Business"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10277",children:"https://arxiv.org/pdf/2601.10277"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces SCRamble, a decentralized protocol that reduces block dissemination time in blockchain networks. It uses a link selection strategy combining a scoring mechanism based on block arrival times and a heuristic considering network latency. The method improves transaction throughput and system security by accelerating block propagation."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260116] Fuzzychain-edge: A novel Fuzzy logic-based adaptive Access control model for Blockchain in Edge Computing"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [access control systems], [Zero-Knowledge Proofs, Fuzzy Logic, Blockchain, Smart Contracts, Edge Computing]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Khushbakht Farooq, Muhammad Ibrahim, Irsa Manzoor, Mukhtaj Khan, Wei Song"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," IEEE"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10105",children:"https://arxiv.org/pdf/2601.10105"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes Fuzzychain-edge, a novel access control framework that integrates Zero-Knowledge Proofs, fuzzy logic, and blockchain-based smart contracts for IoT in edge computing. It concludes that this approach enhances security, privacy, and traceability, providing a robust solution for sensitive data environments like healthcare."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260116] Clustering-Based User Selection in Federated Learning: Metadata Exploitation for 3GPP Networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [homogeneous Poisson point process, clustering, metadata-driven, non-IID, user selection]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Ce Zheng, Shiyao Ma, Ke Zhang, Chen Sun, Wenqi Zhang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Pengcheng Laboratory, Southwest University, Waseda University, SONY(China) Ltd"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10013",children:"https://arxiv.org/pdf/2601.10013"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a metadata-driven federated learning framework that uses a novel data partition model based on a homogeneous Poisson point process and a clustering-based user selection strategy to reduce data correlation. Experiments show the method improves model performance, stability, and convergence in non-IID scenarios, especially when few users are selected per round."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260116] Mitigating GIL Bottlenecks in Edge AI Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [Blocking Ratio (beta), adaptive thread pool, GIL contention, runtime profiling, saturation cliff]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Mridankan Mandal, Smit Sanjay Shende"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Indian Institute of Information Technology, Allahabad"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10582",children:"https://arxiv.org/pdf/2601.10582"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces a library-based adaptive runtime system that uses a novel Blocking Ratio metric to distinguish I/O wait from GIL contention, enabling automatic thread pool scaling to avoid performance degradation in Python-based edge AI systems. It demonstrates that this approach achieves high efficiency, outperforming alternatives like multiprocessing and asyncio, and remains relevant even in environments without the GIL."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260116] Breaking the Storage-Bandwidth Tradeoff in Distributed Storage with Quantum Entanglement"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed storage], [quantum entanglement, distributed storage systems, storage-bandwidth tradeoff, quantum communication, regenerating codes]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Lei Hu, Mohamed Nomeir, Alptug Aytekin, Sennur Ulukus"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Maryland"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10676",children:"https://arxiv.org/pdf/2601.10676"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper investigates the use of quantum communication and entanglement among helper nodes in distributed storage systems to improve the fundamental tradeoff between storage and repair bandwidth. It shows that, unlike classical systems, quantum resources can significantly enhance this tradeoff, and remarkably, when d \u2265 2k-2, both storage and repair bandwidth can be minimized simultaneously, breaking the classical tradeoff."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260116] Distributed Linearly Separable Computation with Arbitrary Heterogeneous Data Assignment"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed computation], [linearly separable computation, heterogeneous data assignment, communication cost, computable dimension, universal computing scheme, converse bound]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Ziting Zhang, Kai Wan, Minquan Cheng, Shuo Shao, Giuseppe Caire"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Huazhong University of Science and Technology, Guangxi Normal University, University of Shanghai for Science and Technology, Technische Universit\xe4t Berlin"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10177",children:"https://arxiv.org/pdf/2601.10177"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper studies distributed linearly separable computation with arbitrary heterogeneous data assignment, where workers may hold different numbers of datasets. It proposes a universal computing scheme and a universal converse bound to characterize the tradeoff between computable dimension and communication cost. The scheme and bound coincide in some parameter regimes and are extended to fractional communication costs."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260116] Fundamental Limits of Coded Polynomial Aggregation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed computing], [coded polynomial aggregation, polynomial coded computing, straggler-aware, exact recovery, interpolation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Xi Zhong, J\xf6rg Kliewer, Mingyue Ji"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Florida, New Jersey Institute of Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10028",children:"https://arxiv.org/pdf/2601.10028"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces a straggler-aware coded polynomial aggregation (CPA) framework for distributed computing, which directly recovers a weighted sum of polynomial evaluations without decoding each term individually. It establishes necessary and sufficient conditions for exact recovery, showing that CPA requires fewer worker responses than individual decoding, and provides explicit constructions that achieve the derived fundamental limit."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260116] Federated Unlearning in Edge Networks: A Survey of Fundamentals, Challenges, Practical Applications and Future Directions"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [federated learning, federated unlearning, machine unlearning, communication cost, resource allocation, security, privacy, edge networks]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jer Shyuan Ng, Wathsara Daluwatta, Shehan Edirimannage, Charitha Elvitigala, Asitha Kottahachchi Kankanamge Don, Ibrahim Khalil, Heng Zhang, Dusit Niyato"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Nanyang Technological University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09978",children:"https://arxiv.org/pdf/2601.09978"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This survey paper introduces Federated Unlearning (FUL), a method for removing a client's data influence from a trained federated learning model to comply with data deletion regulations. It reviews FUL frameworks addressing challenges like communication cost and security, and discusses applications in distributed networks. The paper concludes by highlighting open challenges and positioning FUL as key for building trustworthy, regulation-compliant federated systems."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260116] QFed: Parameter-Compact Quantum-Classical Federated Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [quantum federated learning, variational quantum circuits, quantum neural network, parameter reduction, hybrid quantum-classical training]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Samar Abdelghani, Soumaya Cherkaoui"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Polytechnique Montreal"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09809",children:"https://arxiv.org/pdf/2601.09809"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces QFed, a quantum-classical federated learning framework that uses a quantum neural network to generate parameters for a classical model, drastically reducing the number of trainable parameters. The method achieves a 77.6% parameter reduction in a VGG-like model on the FashionMNIST dataset while maintaining comparable accuracy, demonstrating the potential of quantum computing to enhance the efficiency of federated learning on edge devices."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260116] Chebyshev Accelerated Subspsace Eigensolver for Pseudo-hermitian Hamiltonians"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [numerical linear algebra], [Chebyshev filter, oblique Rayleigh-Ritz, pseudo-hermitian solver, Bethe-Salpeter equation, quadratic convergence, parallel matrix multiplication]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Edoardo Di Napoli, Cl\xe9ment Richefort, Xinzhe Wu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," J\xfclich Supercomputing Centre, Forschungszentrum J\xfclich"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10557",children:"https://arxiv.org/pdf/2601.10557"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper extends the Chebyshev Accelerated Subspace iteration Eigensolver (ChASE) to compute eigenpairs for pseudo-hermitian Hamiltonians arising from the Bethe-Salpeter equation in materials science. It introduces an oblique Rayleigh-Ritz projection for quadratic convergence and a parallel implementation of the Chebyshev filter with reduced communication. The new solver achieves performance and convergence comparable to the original Hermitian version."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 18'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] OUTLINEFORGE: Hierarchical Reinforcement Learning with Explicit States for Scientific Writing ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09858",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Urban Socio-Semantic Segmentation with Vision-Language Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10477",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10187",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Eluder dimension: localise it! ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09825",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10306",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10143",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Reinforcement Learning to Discover a NorthEast Monsoon Index for Monthly Rainfall Prediction in Thailand ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10181",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Combinatorial Optimization Augmented Machine Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10583",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] PRL: Process Reward Learning Improves LLMs' Reasoning Ability and Broadens the Reasoning Boundary ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10201",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] DecisionLLM: Large Language Models for Long Sequence Decision Exploration ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10148",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Reinforcement Learning with Multi-Step Lookahead Information Via Adaptive Batching ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10418",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10712",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09770",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] SuS: Strategy-aware Surprise for Intrinsic Exploration ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10349",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] StatLLaMA: A multi-stage training framework for building a domain-optimized statistical language model ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09718",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10029",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10079",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] CS-GBA: A Critical Sample-based Gradient-guided Backdoor Attack for Offline Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10407",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 12'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Development of Ontological Knowledge Bases by Leveraging Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10436",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] State of AI: An Empirical 100 Trillion Token Study with OpenRouter ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10088",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Single-Stage Huffman Encoder for ML Compression ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10673",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] FaTRQ: Tiered Residual Quantization for LLM Vector Search in Far-Memory-Aware ANNS Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09985",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] OctoBench: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10343",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09949",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10154",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Accelerated Regularized Wasserstein Proximal Sampling Algorithms ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09848",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] RAG-3DSG: Enhancing 3D Scene Graphs with Re-Shot Guided Retrieval-Augmented Generation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10168",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10373",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.09865",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260116] What Understanding Means in AI-Laden Astronomy ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.10038",children:"link"})]}),"\n"]})]})}function h(i={}){const{wrapper:e}={...(0,a.R)(),...i.components};return e?(0,s.jsx)(e,{...i,children:(0,s.jsx)(c,{...i})}):c(i)}}}]);