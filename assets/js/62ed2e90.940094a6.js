"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[368],{8263:(i,e,n)=>{n.r(e),n.d(e,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"daily/20260202-20260208","title":"20260202-20260208","description":"2026-02-02","source":"@site/docs/daily/20260202-20260208.md","sourceDirName":"daily","slug":"/daily/20260202-20260208","permalink":"/daily/20260202-20260208","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1770095379000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"20260126-20260201","permalink":"/daily/20260126-20260201"},"next":{"title":"Paper","permalink":"/category/paper"}}');var s=n(4848),a=n(8453);const t={},l="20260202-20260208",o={},c=[{value:"2026-02-02",id:"2026-02-02",level:2},{value:"2026-02-03",id:"2026-02-03",level:2}];function d(i){const e={a:"a",annotation:"annotation",h1:"h1",h2:"h2",header:"header",li:"li",math:"math",mn:"mn",mrow:"mrow",msup:"msup",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,a.R)(),...i.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"20260202-20260208",children:"20260202-20260208"})}),"\n",(0,s.jsx)(e.h2,{id:"2026-02-02",children:"2026-02-02"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 12"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260202] Towards Resiliency in Large Language Model Serving with KevlarFlow"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [decoupled model parallelism initialization, dynamic traffic rerouting, background KV cache replication, model parallelism, tensor parallelism, pipeline parallelism]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Shangshu Qian, Kipling Liu, P. C. Sruthi, Lin Tan, Yongle Zhang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Purdue University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22438",children:"https://arxiv.org/pdf/2601.22438"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces KevlarFlow, a fault-tolerant LLM serving architecture that uses decoupled model parallelism initialization, dynamic traffic rerouting, and background KV cache replication to handle hardware failures. It significantly reduces recovery time and improves latency and time-to-first-token metrics during failures compared to existing systems."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260202] Coordinating Power Grid Frequency Regulation Service with Data Center Load Flexibility"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [Exogenous Carbon, EcoCenter, frequency regulation, GPU data centers, load flexibility]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Ali Jahanshahi, Sara Rashidi Golrouye, Osten Anderson, Nanpeng Yu, Daniel Wong"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of California, Riverside"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22487",children:"https://arxiv.org/pdf/2601.22487"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces a framework called EcoCenter and a metric called Exogenous Carbon to enable GPU data centers to provide frequency regulation services to the power grid. It concludes that data center participation in this service can reduce the need for fossil-fueled reserves, and the resulting carbon savings often exceed the data centers' own operational emissions."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260202] AsyncMesh: Fully Asynchronous Optimization for Data and Pipeline Parallelism"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm training], [asynchronous optimization, sparse averaging, weight look-ahead, pipeline parallelism, data parallelism]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Thalaiyasingam Ajanthan, Sameera Ramasinghe, Gil Avraham, Hadi Mohaghegh Dolatabadi, Chamin P Hewa Koneputugodage, Violetta Shevchenko, Yan Zuo, Alexander Long"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Pluralis Research"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22442",children:"https://arxiv.org/pdf/2601.22442"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces AsyncMesh, a method that uses fully asynchronous updates for both data and pipeline parallelism to reduce communication overhead in distributed training. It employs weight look-ahead for pipeline stages and asynchronous sparse averaging with an EMA correction for data replicas to mitigate staleness. Experiments on large language models show it matches synchronous baseline performance while significantly cutting communication costs."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260202] SAIR: Cost-Efficient Multi-Stage ML Pipeline Autoscaling via In-Context Reinforcement Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [in-context reinforcement learning, Pareto-dominance reward shaping, surprisal-guided experience retrieval, GPU rate control, CUDA interception]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jianchang Su, Yifan Zhang, Shengkai Lin, Shizhen Zhao, Yusheng Zheng, Yiwei Yang, Wei Zhang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Connecticut, Shanghai Jiao Tong University, University of California, Santa Cruz"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22397",children:"https://arxiv.org/pdf/2601.22397"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," SAIR is an autoscaling framework for multi-stage ML inference pipelines that uses a Large Language Model as an in-context reinforcement learning controller to learn scaling policies online without gradient updates. It achieves improved latency and reduces resource cost significantly compared to existing baselines, demonstrating effective bottleneck detection without requiring offline training."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260202] Learning Provably Correct Distributed Protocols Without Human Knowledge"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [Monte Carlo Tree Search, transformer-based action encoder, global depth-first search, model checking, Satisfiability Modulo Theories (SMT)]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yujie Hui, Xiaoyi Lu, Andrew Perrault, Yang Wang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The Ohio State University, University of Florida"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22369",children:"https://arxiv.org/pdf/2601.22369"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes GGMS, a learning framework that combines a specialized Monte Carlo Tree Search with a transformer-based action encoder, global depth-first search, and model checker feedback to automatically design provably correct distributed protocols. It proves the search process is complete and demonstrates that GGMS can learn correct protocols for larger settings than existing methods."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260202] CONCUR: High-Throughput Agentic Batch Inference of LLM via Congestion-Based Concurrency Control"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [KV cache management, admission control, congestion control, batch inference, agentic workloads, middle-phase thrashing]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Qiaoling Chen, Zhisheng Ye, Tian Tang, Peng Sun, Boyu Tian, Guoteng Wang, Shenggui Li, Yonggang Wen, Zhenhua Han, Tianwei Zhang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Nanyang Technological University, Shanghai Qiji Zhifeng Co., Ltd."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22705",children:"https://arxiv.org/pdf/2601.22705"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces CONCUR, a proactive agent-level admission control system that prevents KV cache thrashing in LLM batch inference by dynamically regulating the number of active agents based on runtime cache pressure. It improves throughput significantly, up to 4.09x on Qwen3-32B, by maintaining cache efficiency for long-lived, asynchronous agentic workloads."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260202] FedAdaVR: Adaptive Variance Reduction for Robust Federated Learning under Limited Client Participation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [federated learning, variance reduction, adaptive optimizer, quantization, partial client participation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," S M Ruhul Kabir Howlader, Xiao Chen, Yifei Xie, Lu Liu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Leicester, University of Edinburgh, University of Exeter"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22204",children:"https://arxiv.org/pdf/2601.22204"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes FedAdaVR, a federated learning algorithm that combines an adaptive optimizer with variance reduction to mitigate errors from sporadic client participation by using stored client updates. It also introduces a quantized version, FedAdaVR-Quant, to reduce memory overhead. The method is proven to eliminate partial participation error and outperforms state-of-the-art baselines in experiments under IID and non-IID data settings."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260202] HetCCL: Accelerating LLM Training with Heterogeneous GPUs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm training], [collective communication, RDMA, NCCL, RCCL, All-Reduce, All-Gather, Reduce-Scatter, data parallelism, model parallelism]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Heehoon Kim, Jaehwan Lee, Taejeoung Kim, Jongwon Park, Jinpyo Kim, Pyongwon Suh, Ryan H. Choi, Sangwoo Lee, Jaejin Lee"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Seoul National University, Moreh Inc., Samsung Research"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22585",children:"https://arxiv.org/pdf/2601.22585"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces HetCCL, a collective communication library that enables high-performance communication across heterogeneous GPUs (e.g., NVIDIA and AMD) by unifying vendor-specific backends like NCCL and RCCL without requiring driver modifications. It matches the performance of vendor libraries in homogeneous setups and uniquely scales in heterogeneous environments, allowing efficient large language model training on mixed GPU clusters without changes to existing deep learning applications."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260202] ZK-HybridFL: Zero-Knowledge Proof-Enhanced Hybrid Ledger for Federated Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [federated learning, directed acyclic graph (DAG) ledger, sidechains, zero-knowledge proofs (ZKPs), event-driven smart contracts, oracle-assisted sidechain, challenge mechanism]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Amirhossein Taherpour, Xiaodong Wang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Columbia University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22302",children:"https://arxiv.org/pdf/2601.22302"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes ZK-HybridFL, a secure decentralized federated learning framework that integrates a DAG ledger with sidechains and zero-knowledge proofs for privacy-preserving model validation. The method uses event-driven smart contracts and an oracle-assisted sidechain to verify local updates without exposing data, and includes a challenge mechanism to detect adversarial behavior. Experiments show it achieves faster convergence, higher accuracy, and robust security compared to prior frameworks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260202] SQUAD: Scalable Quorum Adaptive Decisions via ensemble of early exit neural networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [early-exit neural networks, ensemble learning, neural architecture search, quorum-based stopping, dynamic inference]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Matteo Gambella, Fabrizio Pittorino, Giuliano Casale, Manuel Roveri"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Politecnico di Milano, Imperial College London"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22711",children:"https://arxiv.org/pdf/2601.22711"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces SQUAD, an inference scheme that combines early-exit neural networks with distributed ensemble learning, using a quorum-based voting mechanism to decide when to stop computation. It also proposes QUEST, a neural architecture search method to optimize the diversity of the ensemble learners. The method improves test accuracy by up to 5.95% over state-of-the-art dynamic solutions and reduces inference latency by up to 70.60% compared to static ensembles."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260202] AscendCraft: Automatic Ascend NPU Kernel Generation via DSL-Guided Transcompilation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [GPU kernels], [DSL-guided transcompilation, LLM lowering passes, AscendC, kernel generation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zhongzhen Wen, Shudi Shao, Zhong Li, Yu Ge, Tongtong Xu, Yuanyi Lin, Tian Zhang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Nanjing University, Huawei"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22760",children:"https://arxiv.org/pdf/2601.22760"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces AscendCraft, a method that uses a domain-specific language (DSL) and LLM-guided transcompilation to automatically generate correct and performant kernels for Ascend NPUs. The approach achieves high compilation success and functional correctness, with many generated kernels matching or exceeding PyTorch eager execution performance, demonstrating the effectiveness of DSL abstraction for NPU kernel generation."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260202] ERA: Epoch-Resolved Arbitration for Duelling Admins in Group Management CRDTs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed systems], [CRDTs, Byzantine fault tolerance, epoch events, finality, arbitration]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Kegan Dougal"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Element Creations Ltd"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22963",children:"https://arxiv.org/pdf/2601.22963"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"}),' The paper proposes ERA (Epoch-Resolved Arbitration), a method using asynchronous "epoch events" to introduce a bounded total order and arbitrate concurrent events in group management CRDTs. It concludes that this approach prevents Byzantine admins from exploiting concurrency in the "Duelling Admins" problem, improving consistency and providing finality while preserving availability.']}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 39'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Continual Policy Distillation from Distributed Reinforcement Learning Teachers ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22475",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] ShellForge: Adversarial Co-Evolution of Webshell Generation and Multi-View Detection for Robust Webshell Defense ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22182",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Real-Time Aligned Reward Model beyond Semantics ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22664",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Unrewarded Exploration in Large Language Models Reveals Latent Learning from Psychology ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22474",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Action-Sufficient Goal Representations ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22496",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Learn More with Less: Uncertainty Consistency Guided Query Selection for RLVR ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22595",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Aligning Microscopic Vehicle and Macroscopic Traffic Statistics: Reconstructing Driving Behavior from Partial Data ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22242",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Models Under SCOPE: Scalable and Controllable Routing via Pre-hoc Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22323",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Latent Spherical Flow Policy for Reinforcement Learning with Combinatorial Actions ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22211",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Quantum-Inspired Reinforcement Learning for Secure and Sustainable AIoT-Driven Supply Chain Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22339",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Exo-Plore: Exploring Exoskeleton Control Space through Human-aligned Simulation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22550",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Detect and Act: Automated Dynamic Optimizer through Meta-Black-Box Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22542",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] From Self-Evolving Synthetic Data to Verifiable-Reward RL: Post-Training Multi-turn Interactive Tool-Using Agents ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22607",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] RulePlanner: All-in-One Reinforcement Learner for Unifying Design Rules in 3D Floorplanning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22476",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22545",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Learning Reward Functions for Cooperative Resilience in Multi-Agent Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22292",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] A Step Back: Prefix Importance Ratio Stabilizes Policy Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22718",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] TSPO: Breaking the Double Homogenization Dilemma in Multi-turn Search Policy Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22776",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Clipping-Free Policy Optimization for Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22801",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] CVeDRL: An Efficient Code Verifier via Difficulty-aware Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22803",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Offline Reinforcement Learning of High-Quality Behaviors Under Robust Style Alignment ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22823",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Degradation-Aware Frequency Regulation of a Heterogeneous Battery Fleet via Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22865",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Reinforcement Learning-Based Co-Design and Operation of Chiller and Thermal Energy Storage for Cost-Optimal HVAC Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22880",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] PlatoLTL: Learning to Generalize Across Symbols in LTL Instructions for Multi-Task RL ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22891",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] MulFeRL: Enhancing Reinforcement Learning with Verbal Feedback in a Multi-turn Loop ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22900",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] MTDrive: Multi-turn Interactive Reinforcement Learning for Autonomous Driving ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22930",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Golden Goose: A Simple Trick to Synthesize Unlimited RLVR Tasks from Unverifiable Internet Text ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22975",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Automatic Constraint Policy Optimization based on Continuous Constraint Interpolation Framework for Offline Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23010",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Mem-T: Densifying Rewards for Long-Horizon Memory Agents ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23014",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Guided by Trajectories: Repairing and Rewarding Tool-Use Trajectories for Tool-Integrated Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23032",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] From Absolute to Relative: Rethinking Reward Shaping in Group-Based Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23058",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] RN-D: Discretized Categorical Actors with Regularized Networks for On-Policy Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23075",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Why GRPO Needs Normalization: A Local-Curvature Perspective on Adaptive Gradients ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23135",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] THINKSAFE: Self-Generated Safety Alignment for Reasoning Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23143",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] On Safer Reinforcement Learning Policies for Sedation and Analgesia in Intensive Care ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23154",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Unsupervised Hierarchical Skill Discovery ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23156",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Med-Scout: Curing MLLMs' Geometric Blindness in Medical Perception via Geometry-Aware RL Post-Training ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23220",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Agile Reinforcement Learning through Separable Neural Architecture ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23225",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23266",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 10'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Predicting Intermittent Job Failure Categories for Diagnosis Using Few-Shot Fine-Tuned Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22264",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Scalable Topology-Preserving Graph Coarsening with Graph Collapse ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22943",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Why GRPO Needs Normalization: A Local-Curvature Perspective on Adaptive Gradients ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23135",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Unsupervised Hierarchical Skill Discovery ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23156",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23180",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] YuriiFormer: A Suite of Nesterov-Accelerated Transformers ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23236",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Spectral Gradient Descent Mitigates Anisotropy-Driven Misalignment: A Case Study in Phase Retrieval ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22652",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] A Cross-Domain Graph Learning Protocol for Single-Step Molecular Geometry Refinement ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.22723",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Disentangling multispecific antibody function with graph neural networks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23212",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260202] Nested Slice Sampling: Vectorized Nested Sampling for GPU-Accelerated Inference ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.23252",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2026-02-03",children:"2026-02-03"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 31"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Stabilizing Decentralized Federated Fine-Tuning via Topology-Aware Alternating LoRA"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm training], [decentralized federated learning, low-rank adaptation, parameter-efficient fine-tuning, alternating optimization, topology-aware]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Xiaoyu Wang, Xiaotian Li, Zhixiang Zhou, Chen Li, Yong Liu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," New York University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00451",children:"https://arxiv.org/pdf/2602.00451"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes TAD-LoRA, a topology-aware decentralized framework that coordinates the alternating updates and mixing of LoRA factors to stabilize federated fine-tuning under dynamic communication graphs. It theoretically proves convergence and shows the method achieves robust performance, especially under moderately and weakly connected network topologies."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Self-Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [self-attention, Taylor approximation, symmetric tensor products, polynomial-kernel feature basis, constant cost per token]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Franz A. Heinsen, Leo Kozachkov"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," GlassRoom Software LLC, Brown University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00294",children:"https://arxiv.org/pdf/2602.00294"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces a method to compute self-attention with constant cost per token by using a symmetry-aware Taylor approximation, decomposing the expansion into symmetric tensor product chains. This enables unbounded token generation with fixed memory and compute, drastically reducing the infrastructure and energy demands of large Transformer models."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] VoxServe: Streaming-Centric Serving System for Speech Language Models"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [model-execution abstraction, streaming-aware scheduling, asynchronous inference pipeline]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Keisuke Kamahori, Wei-Tzu Lee, Atindra Jha, Rohan Kadekodi, Stephanie Wang, Arvind Krishnamurthy, Baris Kasikci"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Washington, Stanford University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00269",children:"https://arxiv.org/pdf/2602.00269"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," VoxServe is a serving system for Speech Language Models that introduces a model-execution abstraction to decouple architecture from system optimizations, enabling support for diverse models. It uses streaming-aware scheduling and an asynchronous inference pipeline to improve efficiency. The system achieves 10-20x higher throughput than existing implementations at comparable latency while maintaining high streaming viability."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] A Fault-Tolerant Version of Safra's Termination Detection Algorithm"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed algorithms], [Safra's algorithm, token ring, fault tolerance, model checking, termination detection]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Wan Fokkink, Georgios Karlos, Andy Tatman"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Vrije Universiteit Amsterdam, Paderborn University, University of Groningen"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00272",children:"https://arxiv.org/pdf/2602.00272"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper adapts Safra's classic termination detection algorithm to be fault-tolerant by splitting the global token counter into per-node counters and using a decentralized mechanism to restore the token ring after crashes. The proposed variant imposes no additional message overhead and can tolerate any number of simultaneous crashes. Correctness is proven and supported by model checking analysis."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Standardized Methods and Recommendations for Green Federated Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [federated learning, carbon accounting, NVFlare, CodeCarbon, energy model, communication emissions]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Austin Tapp, Holger R. Roth, Ziyue Xu, Abhijeet Parida, Hareem Nisar, Marius George Linguraru"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Children's National Hospital, NVIDIA, George Washington University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00343",children:"https://arxiv.org/pdf/2602.00343"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"}),' This paper proposes a standardized carbon-accounting methodology for Federated Learning (FL) using NVIDIA NVFlare and CodeCarbon to track CO2e emissions across different training phases and network communication. It demonstrates that system-level inefficiencies and hardware heterogeneity can drastically increase the carbon footprint, highlighting the need for per-site and per-round reporting. The main conclusion is that this standardized method is a prerequisite for reproducible and comparable "green" FL evaluation.']}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] What Artificial Intelligence can do for High-Performance Computing systems?"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [reinforcement learning, graph neural networks, time-series models, language models, surrogate modeling, performance estimation, scheduling, fault detection]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Pierrick Pochelu, Hyacinthe Cartiaux, Julien Schleich"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," LuxProvide S.A., University of Luxembourg"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00014",children:"https://arxiv.org/pdf/2602.00014"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This review paper surveys how AI and machine learning techniques can improve the operational efficiency of High-Performance Computing systems. It analyzes 74 publications, identifying key application areas like scheduling, performance optimization, and fault detection. The main conclusion is that AI integration, including specialized language models and hybrid ML-heuristic approaches, offers significant opportunities for HPC efficiency but requires advances in MLOps and standardization."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] FedMOA: Federated GRPO for Personalized Reasoning LLMs under Heterogeneous Rewards"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [post-training], [federated learning, group relative policy optimization, hypergradient descent, multi-objective alignment, personalized reasoning]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Ziyao Wang, Daeun Jung, Yexiao He, Guoheng Sun, Zheyu Shen, Myungjin Lee, Ang Li"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Maryland, College Park, Cisco Research"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00453",children:"https://arxiv.org/pdf/2602.00453"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes FedMOA, a federated learning framework that adapts Group Relative Policy Optimization (GRPO) for personalized reasoning in large language models under heterogeneous client rewards. It introduces an online adaptive weighting mechanism for local training and a task-aware aggregation strategy on the server. Experiments show FedMOA outperforms standard federated averaging, improving accuracy, personalization, and multi-objective balance."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Asynchronous MultiAgent Reinforcement Learning for 5G Routing under Side Constraints"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [multi-agent reinforcement learning, asynchronous learning, PPO, routing, O-RAN]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Sebastian Racedo, Brigitte Jaumard, Oscar Delgado, Meysam Masoudi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Concordia University, Ecole de Technologie Sup\xe9rieure (ETS), Ericsson"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00035",children:"https://arxiv.org/pdf/2602.00035"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes an asynchronous multi-agent reinforcement learning (AMARL) framework for 5G routing, where independent PPO agents per service plan routes in parallel and coordinate via a shared global resource environment. The method achieves similar performance to a centralized baseline in terms of Grade of Service and latency, while offering reduced training time and improved robustness to demand shifts, demonstrating a scalable approach for distributed network optimization."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] PROBE: Co-Balancing Computation and Communication in MoE Inference via Real-Time Predictive Prefetching"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [mixture-of-experts, expert parallelism, continuous lookahead pipelining, predictive prefetching, gate-initialized lookahead predictor, hardware-aware balance planning, phase-locked co-scheduling]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Qianchao Zhu, Xucheng Ye, Yuliang Liu, Haodong Ouyang, Chengru Song"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Kling Infra, Kuaishou Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00509",children:"https://arxiv.org/pdf/2602.00509"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces PROBE, an inference system for Mixture-of-Experts models that uses real-time predictive prefetching to balance computation and communication. Its core method involves predicting upcoming expert activations and proactively planning token assignments and expert transfers to hide network latency behind computation. The system reduces prefill latency and improves decoding throughput under dynamic workloads compared to state-of-the-art baselines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Training LLMs with Fault Tolerant HSDP on 100,000 GPUs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [Fault Tolerant Hybrid-Shared Data Parallelism (FT-HSDP), Fault Tolerant All Reduce (FTAR), non-blocking catch-up protocol, data parallel replicas]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Omkar Salpekar, Rohan Varma, Kenny Yu, Vladimir Ivanov, Yang Wang, Ahmed Sharif, Min Si, Shawn Xu, Feng Tian, Shengbao Zheng, Tristan Rice, Ankush Garg, Shangfu Peng, Shreyas Siravara, Wenyin Fu, Rodrigo de Castro, Adithya Gangidi, Andrey Obraztsov, Sharan Narang, Sergey Edunov, Maxim Naumov, Chunqiang Tang, Mathew Oldham"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Meta Platforms, Thinking Machines Labs, The Ohio State University, Genesis Molecular AI"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00277",children:"https://arxiv.org/pdf/2602.00277"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes Fault Tolerant Hybrid-Shared Data Parallelism (FT-HSDP), a novel training paradigm that uses data parallel replicas as fault tolerance units to minimize stall time during GPU failures. It introduces techniques like a Fault Tolerant All Reduce protocol and a non-blocking catch-up protocol. The method reduces recovery stall time from 10 to 3 minutes at O(100K) GPU scale, boosting effective training time from 44% to 80% without degrading model accuracy."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Forecasting Energy Availability in Local Energy Communities via LSTM Federated Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [Federated Learning, LSTM, forecasting, privacy-preserving]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Fabio Turazza, Marcello Pietri, Natalia Selini Hadjidimitriou, Marco Mamei"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Modena and Reggio Emilia"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00694",children:"https://arxiv.org/pdf/2602.00694"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes using Federated Learning combined with Long Short-Term Memory (LSTM) networks to forecast energy availability in Local Energy Communities while preserving user data privacy. It demonstrates that this approach can create an accurate forecasting model without sharing sensitive consumption data among users, highlighting a trade-off between data sharing and prediction accuracy."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] HyperOffload: Graph-Driven Hierarchical Memory Management for Large Language Models on SuperNode Architectures"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [graph-driven memory management, compiler-assisted offloading, static scheduling, remote memory access, hierarchical supernode architecture]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Fangxin Liu, Qinghua Zhang, Hanjing Shen, Qinghua Zhang, Zhibo Liang, Li Jiang, Haibing Guan, Chong Bao, Xuefeng Jin"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Shanghai Jiao Tong University, Huawei Technologies Co., Ltd."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00748",children:"https://arxiv.org/pdf/2602.00748"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes HyperOffload, a compiler-assisted framework that uses graph-driven memory management to explicitly treat remote memory access as operations in the computation graph. This enables static scheduling of data transfers to hide latency, reducing peak device memory usage by up to 26% for LLM inference while maintaining performance. The work demonstrates that integrating memory-augmented hardware into compiler optimization is key for scaling next-generation AI workloads."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] System-Level Performance Modeling of Photonic In-Memory Computing"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [photonic computing], [photonic SRAM, system-level modeling, algorithm-to-hardware mapping, opto-electronic conversion, silicon photonics]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jebacyril Arockiaraj, Sasindu Wijeratne, Sugeet Sunder, Md Abdullah-Al Kaiser, Akhilesh Jaiswal, Ajey P. Jacob, Viktor Prasanna"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Southern California, University of Wisconsin-Madison"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00892",children:"https://arxiv.org/pdf/2602.00892"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper develops a system-level performance model for photonic in-memory computing, accounting for latencies like external memory access. It maps high-performance computing workloads to a photonic SRAM hardware model. The model shows the fabricated photonic SRAM array can sustain up to 1.5 TOPS with an average energy efficiency of 2.5 TOPS/W on the evaluated workloads."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] FUPareto: Bridging the Forgetting-Utility Gap in Federated Unlearning via Pareto Augmented Optimization"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," TBD"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zeyan Wang, Zhengmao Liu, Yongxin Cai, Chi Li, Xiaoying Tang, Jingchao Chen, Zibin Pan, Jing Qiu"]}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.strong,{children:"institution:"})}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01852",children:"https://arxiv.org/pdf/2602.01852"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Low-latency Federated LLM Fine-tuning Over Wireless Networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm training], [federated learning, client-specific pruning, bandwidth allocation, block coordinate descent, LoRA, model compression]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zhiwen Pang, Kang Wei, Long Shi, Zhe Wang, Jun Li, Feng Shu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Nanjing University of Science and Technology, Southeast University, Hainan University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01024",children:"https://arxiv.org/pdf/2602.01024"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a joint client-specific pruning and bandwidth allocation (JCPBA) framework to reduce the latency of federated fine-tuning for large language models over wireless networks. The method formulates and solves a latency minimization problem by optimizing pruning rates and bandwidth allocations for heterogeneous clients. Experiments show the framework significantly reduces fine-tuning time and achieves comparable or lower test loss with lower overhead compared to baselines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] FedBGS: A Blockchain Approach to Segment Gossip Learning in Decentralized Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [blockchain, gossip learning, federated analytics, differential privacy, homomorphic encryption, secure multi-party computation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Fabio Turazza, Marcello Pietri, Marco Picone, Marco Mamei"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Modena and Reggio Emilia"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01185",children:"https://arxiv.org/pdf/2602.01185"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes FedBGS, a fully decentralized framework that combines blockchain and segmented gossip learning to enhance federated learning. It aims to eliminate the central server as a single point of failure, thereby improving security, scalability, and handling of non-IID data. The main conclusion is that this approach provides comprehensive protection against various attacks while optimizing blockchain usage in federated environments."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] MedBeads: An Agent-Native, Immutable Data Substrate for Trustworthy Medical AI"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [Merkle DAG, Immutable Data, Breadth-First Search (BFS), FHIR-to-DAG conversion, Cryptographic Chain, Tamper-evidence]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Takahito Nakajima"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Tsukuba"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01086",children:"https://arxiv.org/pdf/2602.01086"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"}),' The paper proposes MedBeads, an agent-native data infrastructure that structures clinical events as immutable nodes in a Merkle DAG to provide deterministic, tamper-evident context for LLMs. This addresses the "Context Mismatch" in medical AI by replacing probabilistic data retrieval with deterministic graph traversal, aiming to reduce hallucinations and improve auditability for trustworthy clinical agents.']}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Privocracy: Online Democracy through Private Voting"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [access control], [private voting, verifiable secret sharing, k-anonymity, asynchronous multiparty-computation, vote delegation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Pedro Campon\xeas, Hugo Pereira, Adrian Persaud, Kevin Gallagher, Santiago Torres-Arias"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," NOVA LINCS, NOVA School of Science and Technology, Purdue University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01341",children:"https://arxiv.org/pdf/2602.01341"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces Privocracy, an access control mechanism that replaces unilateral administrative privileges with a secure, private e-voting procedure to authorize sensitive commands. The system achieves everlasting vote privacy and incorporates features like delegation and rapid voting. The authors conclude that Privocracy efficiently distributes trust to minimize single points of failure and can be deployed on commodity hardware."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Mean field optimal Core Allocation across Malleable jobs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [scheduling theory], [mean field analysis, Whittle policy, concave speedup functions, core allocation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zhouzi Li, Mor Harchol-Balter, Benjamin Berg"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Carnegie Mellon University, UNC Chapel Hill"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01411",children:"https://arxiv.org/pdf/2602.01411"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper solves the Core Allocation to Malleable jobs (CAM) problem by analyzing it in the mean field asymptotic regime, deriving two optimal policies: FW-CAM and WHAM. The main conclusion is that WHAM is asymptotically optimal and serves as a good heuristic, and that in the mean field regime, job sizes are not relevant for finding an optimal policy."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Fast Sparse Matrix Permutation for Mesh-Based Direct Solvers"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [sparse linear algebra], [nested dissection, sparse matrix permutation, sparse Cholesky factorization, elimination-tree, quotient-graph ordering]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Behrooz Zarebavami, Ahmed H. Mahmoud, Ana Dodik, Changcheng Yuan, Serban D. Porumbescu, John D. Owens, Maryam Mehri Dehnavi, Justin Solomon"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Toronto, Massachusetts Institute of Technology, Texas A&M University, University of California, Davis, NVIDIA Research"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00898",children:"https://arxiv.org/pdf/2602.00898"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces a fast sparse matrix permutation algorithm designed for linear systems from triangle meshes. It relaxes strict balance and separator optimality to achieve faster partitioning and elimination-tree construction, decomposing the permutation into patch-level local orderings and a compact separator ordering. The method reduces permutation time and improves sparse Cholesky solve performance by up to 6.27x when integrated into vendor solvers on CPUs and GPUs."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] BOA Constrictor: Squeezing Performance out of GPUs in the Cloud via Budget-Optimal Allocation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [budget-optimal allocation, scheduling, job completion time, GPU allocation, cost-performance tradeoff]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zhouzi Li, Cindy Zhu, Arpan Mukhopadhyay, Mor Harchol-Balter, Benjamin Berg"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Carnegie Mellon University, University of Warwick, UNC Chapel Hill"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01404",children:"https://arxiv.org/pdf/2602.01404"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces BOA Constrictor, a scheduler that uses a Budget-Optimal Allocation (BOA) policy to optimize the allocation of rented cloud GPUs for ML training jobs under a fixed budget constraint. It formulates the problem as a budget-constrained scheduling problem to minimize average job completion time. The method demonstrates significant performance improvements, reducing average JCT by up to 2x and cutting the required budget for a target JCT by up to 2x compared to heuristic schedulers."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Developing a Portable Solution for Post-Event Analysis Pipelines"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [Science Gateway, Apache Airflow, Photogrammetry, Machine Learning, Data Visualization, Directed Acyclic Graphs (DAGs)]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Leonardo Pelonero, Fabio Vitello, Eva Sciacca, Mauro Imbrosciano, Salvatore Scavo, Ugo Becciani"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," INAF Astrophysical Observatory of Catania"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01798",children:"https://arxiv.org/pdf/2602.01798"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents a Science Gateway framework for creating portable, automated post-event analysis pipelines that integrate photogrammetry, data visualization, and AI technologies on aerial images. The core method involves migrating standalone workflows into a single orchestrated pipeline using Apache Airflow and DAGs within a Science Gateway platform. The main conclusion is that this framework enables efficient assessment of extreme natural events and their impact on at-risk assets, supporting timely hazard management and decision-making."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] TriCloudEdge: A multi-layer Cloud Continuum"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [cloud continuum, edge computing, federated learning, WebSocket, MQTT, Zenoh, model adaptation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," George Violettas, Lefteris Mamatas"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Macedonia"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02121",children:"https://arxiv.org/pdf/2602.02121"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes TriCloudEdge, a three-tier cloud continuum architecture that integrates far-edge devices, intermediate edge nodes, and central cloud services to distribute computational tasks. It compares a multi-protocol approach (WebSocket, MQTT, HTTP) with a versatile protocol (Zenoh) for data transfer, demonstrating trade-offs in resource utilization and communication efficiency. The results show that this architecture can effectively address latency and privacy concerns by distributing AI workloads across the continuum."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Grappa: Gradient-Only Communication for Scalable Graph Neural Network Training"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [gradient-only communication, coverage-corrected gradient aggregation, periodic repartitioning]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Chongyang Xu, Christoph Siebenbrunner, Laurent Bindschaedler"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Max Planck Institute for Software Systems (MPI-SWS), Vienna University of Economics and Business (WU)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01872",children:"https://arxiv.org/pdf/2602.01872"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," Grappa is a distributed GNN training framework that eliminates per-iteration cross-partition data fetching by having partitions train in isolation and only exchange gradients. It recovers accuracy through periodic graph repartitioning and a coverage-corrected gradient aggregation technique. The paper shows that Grappa trains GNNs significantly faster than state-of-the-art systems while achieving better accuracy, especially for deeper models, and scales to trillion-edge graphs on commodity hardware."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] vLLM-Omni: Fully Disaggregated Serving for Any-to-Any Multimodal Models"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [stage abstraction, disaggregated serving, request batching, GPU allocation, inter-stage connectors]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Peiqi Yin, Jiangyun Zhu, Han Gao, Chenguang Zheng, Yongxiang Huang, Taichang Zhou, Ruirui Yang, Weizhi Liu, Weiqing Chen, Canlin Guo, Didan Deng, Zifeng Mo, Cong Wang, James Cheng, Roger Wang, Hongsheng Liu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Huawei, The Chinese University of Hong Kong, Institute of Software Chinese Academy of Sciences, Sun Yat-sen University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02204",children:"https://arxiv.org/pdf/2602.02204"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces vLLM-Omni, a serving system that decomposes complex any-to-any multimodal models into interconnected stages for disaggregated execution. It optimizes resource use with per-stage batching and flexible GPU allocation. Experiments show it reduces job completion time by up to 91.4% compared to baseline methods."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] ECHO-2: A Large Scale Distributed Rollout Framework for Cost-efficient Reinforcement Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [post-training], [distributed reinforcement learning, policy staleness, peer-assisted pipelined broadcast, cost-aware activation, GRPO]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jie Xiao, Meng Chen, Qingnan Ren, Song Jingwei, Jiaqi Huang, Yangshen Deng, Chris Tong, Wanyi Chen, Suli Wang, Ziqian Bi, Shuo Lu, Yiqun Duan, Lynn Ai, Eric Yang, Bill Shi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Gradient, Fudan University, The University of Hong Kong, University of Edinburgh, Technical University of Darmstadt"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02192",children:"https://arxiv.org/pdf/2602.02192"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces ECHO-2, a distributed framework for cost-efficient reinforcement learning (RL) post-training of large language models. It enables overlapping rollout generation, policy dissemination, and centralized learning by treating policy staleness as a controllable parameter and uses techniques like peer-assisted broadcast and cost-aware worker activation. Experiments show that ECHO-2 significantly improves cost efficiency while maintaining reward performance comparable to strong baselines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Enabling AI Deep Potentials for Ab Initio-quality Molecular Dynamics Simulations in GROMACS"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [GPU kernels], [deep potentials, molecular dynamics, GROMACS, DeePMD-kit, attention mechanism, GNN, CUDA, kernel-launch overhead, domain-decomposed inference]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Andong Hu, Luca Pennati, Stefano Markidis, Ivy Peng"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," KTH Royal Institute of Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02234",children:"https://arxiv.org/pdf/2602.02234"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper integrates AI deep potentials into the GROMACS molecular dynamics simulation software by coupling it with the DeePMD-kit backend, enabling ab initio-quality simulations. It evaluates two neural network architectures (DPA2 and DPA3) on protein benchmarks, finding that the attention-based DPA2 significantly outperforms the GNN-based DPA3 in throughput on GPUs. The study identifies kernel-launch overhead and domain-decomposed inference as key optimization targets for production MD simulations."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Hierarchical Federated Learning with SignSGD: A Highly Communication-Efficient Approach"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [hierarchical federated learning, SignSGD, majority-vote aggregation, gradient compression, quantization, communication-efficient]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Amirreza Kazemi, Seyed Mohammad Azimi-Abarghouyi, Gabor Fodor, Carlo Fischione"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," KTH Royal Institute of Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02355",children:"https://arxiv.org/pdf/2602.02355"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes HierSignSGD, a hierarchical federated learning framework that uses one-bit gradient compression (SignSGD) and majority-vote aggregation at edge servers to drastically reduce communication costs. The method achieves accuracy comparable to full-precision SGD while being robust to aggressive downlink sparsification, making it highly efficient for large-scale IoT and wireless systems."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] sVIRGO: A Scalable Virtual Tree Hierarchical Framework for Distributed Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed systems], [virtual hierarchical tree, multi-region coordination, layer-scoped command execution, dynamic role mapping, fault tolerance]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Lican Huang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Hangzhou Domain Zones Technology Co., Ltd."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02438",children:"https://arxiv.org/pdf/2602.02438"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes sVIRGO, a framework that constructs a scalable virtual tree hierarchy directly on physical nodes without overlay networks, enabling dynamic role assignment and locality-preserving coordination. It achieves robust, large-scale coordination across thousands of regions with near-zero recovery latency and bounded communication overhead, ensuring safety and liveness under dynamic or adversarial conditions."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] Building a Correct-by-Design Lakehouse. Data Contracts, Versioning, and Transactional Pipelines for Humans and Agents"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [data contracts, Git-like versioning, transactional pipelines, verification, lakehouse]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Weiming Sheng, Jinlang Wang, Manuel Barros, Aldrin Montana, Jacopo Tagliabue, Luca Bigon"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Columbia University, University of Wisconsin-Madison, Carnegie Mellon University, Bauplan Labs"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02335",children:"https://arxiv.org/pdf/2602.02335"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents Bauplan, a code-first lakehouse designed to ensure correctness through three integrated axes: typed table contracts for static checking, Git-like data versioning for collaboration, and transactional pipeline runs for atomicity. It aims to make illegal data states unrepresentable, providing safety for concurrent operations by humans and AI agents. Early results from a formal transaction model are reported, with future work motivated by identified counterexamples."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260203] LCLs Beyond Bounded Degrees"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed computing], [Locally Checkable Labelings, Locally Finite Labelings, LOCAL model, gap results, polynomial regime, trees, unbounded degree]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Gustav Schmid"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Freiburg"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02340",children:"https://arxiv.org/pdf/2602.02340"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper investigates the complexity of distributed graph labeling problems (LCLs) on trees with unbounded node degrees. It introduces Locally Finite Labelings (LFLs), a restricted class of problems where nodes have only finitely many local configurations. The main conclusion is that for LFLs, the deterministic LOCAL complexity on trees is either polylogarithmic or exactly polynomial (\u0398(n^{1/k})), restoring the strong gap results that disappear for general LCLs in the unbounded-degree setting."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 101'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Search Inspired Exploration in Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00460",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] AdaFuse: Adaptive Multimodal Fusion for Lung Cancer Risk Prediction via Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00347",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Joint Continual Learning of Local Language Models and Cloud Offloading Decisions with Budget Constraints ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00166",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Distributional Reinforcement Learning for Condition-Based Maintenance of Multi-Pump Equipment ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00051",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] LLMs as High-Dimensional Nonlinear Autoregressive Models with Attention: Training, Alignment and Inference ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00426",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] ZEST: Zero-shot Embodied Skill Transfer for Athletic Robot Control ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00401",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Open Materials Generation with Inference-Time Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00424",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00190",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Variational Approach for Job Shop Scheduling ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00408",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Sample Complexity Analysis for Constrained Bilevel Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00282",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] KEPO: Knowledge-Enhanced Preference Optimization for Reinforcement Learning with Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00400",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] CamReasoner: Reinforcing Camera Movement Understanding via Structured Spatial Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00181",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Representation Learning Enhanced Deep Reinforcement Learning for Optimal Operation of Hydrogen-based Multi-Energy Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00027",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Learning Robust Reasoning through Guided Adversarial Self-Play ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00173",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] AREAL-DTA: Dynamic Tree Attention for Efficient Reinforcement Learning of Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00482",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] DROGO: Default Representation Objective via Graph Optimization in Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00403",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Minerva: Reinforcement Learning with Verifiable Rewards for Cyber Threat Intelligence LLMs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00513",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] How Far Are LLMs from Professional Poker Players? Revisiting Game-Theoretic Reasoning with Agentic Tool Use ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00528",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Reinforcement Learning-assisted Constraint Relaxation for Constrained Expensive Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00532",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Surrogate Ensemble in Expensive Multi-Objective Optimization via Deep Q-Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00540",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Learning to Decode Against Compositional Hallucination in Video Multimodal Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00559",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Learning Modal-Mixed Chain-of-Thought Reasoning with Latent Embeddings ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00574",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Safe Langevin Soft Actor Critic ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00587",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Equilibrium of Feasible Zone and Uncertain Model in Safe Exploration ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00636",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] SA-VLA: Spatially-Aware Flow-Matching for Vision-Language-Action Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00743",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00759",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Communications-Incentivized Collaborative Reasoning in NetGPT through Agentic Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00766",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Fast Non-Episodic Finite-Horizon RL with K-Step Lookahead Thresholding ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00781",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] World Models as an Intermediary between Agents and the Real World ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00785",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Resource-Efficient Reinforcement for Reasoning Large Language Models via Dynamic One-Shot Policy Refinement ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00815",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Learning Abstractions for Hierarchical Planning in Program-Synthesis Agents ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00929",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00983",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Reasoning and Tool-use Compete in Agentic RL",":From"," Quantifying Interference to Disentangled Tuning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00994",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] ESSAM: A Novel Competitive Evolution Strategies Approach to Reinforcement Learning for Memory Efficient LLMs Fine-Tuning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01003",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Discovering Process-Outcome Credit in Multi-Step LLM Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01034",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Good SFT Optimizes for SFT, Better SFT Prepares for Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01058",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] SetPO: Set-Level Policy Optimization for Diversity-Preserving LLM Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01062",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Probing RLVR training instability through the lens of objective-level hacking ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01103",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Lyapunov Stability-Aware Stackelberg Game for Low-Altitude Economy: A Control-Oriented Pruning-Based DRL Approach ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01131",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Self-Generative Adversarial Fine-Tuning for Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01137",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] PolicyFlow: Policy Optimization with Continuous Normalizing Flow in Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01156",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Sample Efficient Active Algorithms for Offline Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01260",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Mixture-of-World Models: Scaling Multi-Task Reinforcement Learning with Modular Latent Dynamics ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01270",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] From Intents to Actions: Agentic AI in Autonomous Networks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01271",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Adaptive Quantum-Safe Cryptography for 6G Vehicular Networks via Context-Aware Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01342",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] CRAFT: Calibrated Reasoning with Answer-Faithful Traces via Reinforcement Learning for Multi-Hop Question Answering ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01348",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] PromptRL: Prompt Matters in RL for Flow-Based Image Generation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01382",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] The Enhanced Physics-Informed Kolmogorov-Arnold Networks: Applications of Newton's Laws in Financial Deep Reinforcement Learning (RL) Algorithms ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01388",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] TQL: Scaling Q-Functions with Transformers by Preventing Attention Collapse ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01439",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Provable Cooperative Multi-Agent Exploration for Reward-Free MDPs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01453",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01511",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] A Relative-Budget Theory for Reinforcement Learning with Verifiable Rewards in Large Language Model Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01523",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Making Bias Non-Predictive: Training Robust LLM Judges via Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01528",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] MAGIC: A Co-Evolving Attacker-Defender Adversarial Game for Robust LLM Safety ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01539",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Toward Cognitive Supersensing in Multimodal Large Language Model ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01541",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] The Multiple Ticket Hypothesis: Random Sparse Subnetworks Suffice for RLVR ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01599",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Adaptive Rollout Allocation for Online Reinforcement Learning with Verifiable Rewards ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01601",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Boosting Maximum Entropy Reinforcement Learning via One-Step Flow Matching ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01606",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] SUSD: Structured Unsupervised Skill Discovery through State Factorization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01619",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01649",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01664",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] TABX: A High-Throughput Sandbox Battle Simulator for Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01665",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01675",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Semantic-aware Wasserstein Policy Regularization for Large Language Model Alignment ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01685",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Restoring Exploration after Post-Training: Latent Exploration Decoding for Large Reasoning Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01698",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Mitigating loss of control in advanced AI systems through instrumental goal trajectories ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01699",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01705",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Adversarial Reward Auditing for Active Detection and Mitigation of Reward Hacking ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01750",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01776",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Grad2Reward: From Sparse Judgment to Dense Rewards for Improving Open-Ended LLM Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01791",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Beyond Precision: Training-Inference Mismatch is an Optimization Problem and Simple LR Scheduling Fixes It ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01826",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Designing Time Series Experiments in A/B Testing with Transformer Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01853",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] VLM-Guided Experience Replay ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01915",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Zero-Shot Off-Policy Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01962",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01970",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02035",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] FORLER: Federated Offline Reinforcement Learning with Q-Ensemble and Actor Rectification ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02055",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Probabilistic Performance Guarantees for Multi-Task Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02098",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Think Dense, Not Long: Dynamic Decoupled Conditional Advantage for Efficient Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02099",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02137",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Learning Generative Selection for Best-of-N ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02143",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] ECHO: Entropy-Confidence Hybrid Optimization for Test-Time Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02150",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Online Fine-Tuning of Pretrained Controllers for Autonomous Driving via Real-Time Recurrent RL ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02236",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Learning While Staying Curious: Entropy-Preserving Supervised Fine-Tuning via Adaptive Self-Distillation for Large Reasoning Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02244",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Segment to Focus: Guiding Latent Action Models in the Presence of Distractors ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02259",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Learning Markov Decision Processes under Fully Bandit Feedback ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02260",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Choice-Model-Assisted Q-learning for Delayed-Feedback Revenue Management ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02283",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Advancing General-Purpose Reasoning Models with Modular Gradient Surgery ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02301",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Position: Explaining Behavioral Shifts in Large Language Models Requires a Comparative Approach ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02304",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] SWE-Universe: Scale Real-World Verifiable Environments to Millions ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02361",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] SLIME: Stabilized Likelihood Implicit Margin Enforcement for Preference Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02383",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02395",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] World-Gymnast: Training Robots with Reinforcement Learning in a World Model ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02454",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Conflict-Aware Client Selection for Multi-Server Federated Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02458",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02488",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Design and Empirical Study of a Large Language Model-Based Multi-Agent Investment System for Chinese Public REITs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00082",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Reinforcement Learning for Control Systems with Time Delays: A Comprehensive Survey ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00399",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Stabilizing Fixed-Point Iteration for Markov Chain Poisson Equations ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00474",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] FinEvo: From Isolated Backtests to Ecological Market Games for Multi-Agent Financial Strategy Evolution ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00948",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Non-Uniform Noise-to-Signal Ratio in the REINFORCE Policy-Gradient Estimator ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01460",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Well-Posed KL-Regularized Control via Wasserstein and Kalman-Wasserstein KL Divergences ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02250",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 39'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Harvest: Opportunistic Peer-to-Peer GPU Caching for LLM Inference ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00328",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Autonomous Data Processing using Meta-Agents ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00307",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Fast Forward: Accelerating LLM Prefill with Predictive FFN Sparsity ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00397",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Agentic Framework for Epidemiological Modeling ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00299",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Generation Order and Parallel Decoding in Masked Diffusion Models: An Information-Theoretic Perspective ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00286",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] 3DGS",(0,s.jsxs)(e.span,{className:"katex",children:[(0,s.jsx)(e.span,{className:"katex-mathml",children:(0,s.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,s.jsxs)(e.semantics,{children:[(0,s.jsx)(e.mrow,{children:(0,s.jsxs)(e.msup,{children:[(0,s.jsx)(e.mrow,{}),(0,s.jsx)(e.mn,{children:"2"})]})}),(0,s.jsx)(e.annotation,{encoding:"application/x-tex",children:"^2"})]})})}),(0,s.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,s.jsxs)(e.span,{className:"base",children:[(0,s.jsx)(e.span,{className:"strut",style:{height:"0.8141em"}}),(0,s.jsxs)(e.span,{className:"mord",children:[(0,s.jsx)(e.span,{}),(0,s.jsx)(e.span,{className:"msupsub",children:(0,s.jsx)(e.span,{className:"vlist-t",children:(0,s.jsx)(e.span,{className:"vlist-r",children:(0,s.jsx)(e.span,{className:"vlist",style:{height:"0.8141em"},children:(0,s.jsxs)(e.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,s.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,s.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,s.jsx)(e.span,{className:"mord mtight",children:"2"})})]})})})})})]})]})})]}),"-TR: Scalable Second-Order Trust-Region Method for 3D Gaussian Splatting ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00395",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Representation Learning Enhanced Deep Reinforcement Learning for Optimal Operation of Hydrogen-based Multi-Energy Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00027",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Scalable Generative Game Engine: Breaking the Resolution Wall via Hardware-Algorithm Co-Design ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00608",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Environment-Aware Adaptive Pruning with Interleaved Inference Orchestration for Vision-Language-Action Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00780",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Multi-Objective Multi-Fidelity Bayesian Optimization with Causal Priors ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00788",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Exploration of Unary Arithmetic-Based Matrix Multiply Units for Low Precision DL Accelerators ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00838",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] LASS-ODE: Scaling ODE Computations to Connect Foundation Models with Dynamical Physical Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01009",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Superposition unifies power-law training dynamics ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01045",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Not All Preferences Are Created Equal: Stability-Aware and Gradient-Efficient Alignment for Reasoning Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01207",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Sample Efficient Active Algorithms for Offline Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01260",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01274",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] LLM-Driven Ontology Construction for Enterprise Knowledge Graphs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01276",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Gradient-Aligned Calibration for Post-Training Quantization of Diffusion Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01289",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Improve the Trade-off Between Watermark Strength and Speculative Sampling Efficiency for Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01428",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01649",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] TABX: A High-Throughput Sandbox Battle Simulator for Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01665",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Real-Time Loop Closure Detection in Visual SLAM via NetVLAD and Faiss ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01673",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Physics Informed Generative AI Enabling Labour Free Segmentation For Microscopy Analysis ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01710",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] PRISM: Parametrically Refactoring Inference for Speculative Sampling Draft Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01762",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01801",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] IntraSlice: Towards High-Performance Structural Pruning with Block-Intra PCA for LLMs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01975",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Position: The Need for Ultrafast Training ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02005",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] BAPS: A Fine-Grained Low-Precision Scheme for Softmax in Attention via Block-Aware Precision reScaling ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02071",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Toxicity Assessment in Preclinical Histopathology via Class-Aware Mahalanobis Distance for Known and Novel Anomalies ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02124",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Scalable Spatio-Temporal SE(3) Diffusion for Long-Horizon Protein Dynamics ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02128",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Generalized Optimal Classification Trees: A Mixed-Integer Programming Approach ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02173",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02197",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Spark: Modular Spiking Neural Networks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02306",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Towards Agentic Intelligence for Materials Science ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00169",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Action-Free Offline-to-Online RL via Discretised State Policies ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00629",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] A New Workflow for Materials Discovery Bridging the Gap Between Experimental Databases and Graph Neural Networks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.00756",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] WAKESET: A Large-Scale, High-Reynolds Number Flow Dataset for Machine Learning of Turbulent Wake Dynamics ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01379",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] FluxNet: Learning Capacity-Constrained Local Transport Operators for Conservative and Bounded PDE Surrogates ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.01941",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260203] Training-free score-based diffusion for parameter-dependent stochastic dynamical systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.02113",children:"link"})]}),"\n"]})]})}function h(i={}){const{wrapper:e}={...(0,a.R)(),...i.components};return e?(0,s.jsx)(e,{...i,children:(0,s.jsx)(d,{...i})}):d(i)}},8453:(i,e,n)=>{n.d(e,{R:()=>t,x:()=>l});var r=n(6540);const s={},a=r.createContext(s);function t(i){const e=r.useContext(a);return r.useMemo(function(){return"function"==typeof i?i(e):{...e,...i}},[e,i])}function l(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(s):i.components||s:t(i.components),r.createElement(a.Provider,{value:e},i.children)}}}]);