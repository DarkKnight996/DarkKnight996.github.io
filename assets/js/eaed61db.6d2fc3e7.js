"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[891],{1847:(i,e,n)=>{n.r(e),n.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"daily/20260223-20260301","title":"20260223-20260301","description":"2026-02-23","source":"@site/docs/daily/20260223-20260301.md","sourceDirName":"daily","slug":"/daily/20260223-20260301","permalink":"/daily/20260223-20260301","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1772076407000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"20260216-20260222","permalink":"/daily/20260216-20260222"},"next":{"title":"Paper","permalink":"/category/paper"}}');var s=n(4848),t=n(8453);const a={},o="20260223-20260301",l={},c=[{value:"2026-02-23",id:"2026-02-23",level:2},{value:"2026-02-24",id:"2026-02-24",level:2},{value:"2026-02-26",id:"2026-02-26",level:2}];function h(i){const e={a:"a",annotation:"annotation",h1:"h1",h2:"h2",header:"header",li:"li",math:"math",mi:"mi",mn:"mn",mrow:"mrow",msup:"msup",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,t.R)(),...i.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"20260223-20260301",children:"20260223-20260301"})}),"\n",(0,s.jsx)(e.h2,{id:"2026-02-23",children:"2026-02-23"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 13"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] Message-Oriented Middleware Systems: Technology Overview"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed systems], [message-oriented middleware, publish/subscribe, brokers, multi-tenancy, flow control]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Wael Al-Manasrah, Zuhair AlSader, Tim Brecht, Ahmed Alquraan, Samer Al-Kiswany"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Waterloo"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17774",children:"https://arxiv.org/pdf/2602.17774"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents a comprehensive characterization study of ten open-source message-oriented middleware (MOM) systems, analyzing 42 features across them. The main conclusion is that MOM systems have evolved into flexible frameworks for cloud applications, and the authors identify an opportunity for the community to consolidate efforts on fewer open-source projects."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] Distributed Triangle Enumeration in Hypergraphs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed algorithms], [CONGEST model, hypergraph, triangle enumeration, computational models, sparse hypergraphs]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Duncan Adamson, Will Rosenbaum, Paul G. Spirakis"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of St Andrews, University of Liverpool"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17834",children:"https://arxiv.org/pdf/2602.17834"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces new computational models for distributed algorithms on hypergraphs, generalizing the CONGEST model. It presents algorithms for distributed triangle enumeration in these models, proves their optimality in some cases, and develops efficient methods for sparse hypergraph classes. The work establishes a foundational framework for distributed sub-hypergraph enumeration."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] Collaborative Processing for Multi-Tenant Inference on Memory-Constrained Edge TPUs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [collaborative processing, model partitioning, queueing model, memory swapping, adaptive scheduling, Edge TPU]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Nathan Ng, Walid A. Hanafy, Prashanthi Kadambi, Balachandra Sunil, Ayush Gupta, David Irwin, Yogesh Simmhan, Prashant Shenoy"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Massachusetts Amherst, Indian Institute of Science"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17808",children:"https://arxiv.org/pdf/2602.17808"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents SwapLess, a system that uses an analytic queueing model to adaptively partition AI model inference between CPU and Edge TPU resources and allocate CPU cores online, minimizing end-to-end latency. It demonstrates that this approach significantly reduces mean latency for both single-tenant and multi-tenant workloads compared to default compiler strategies."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] It's Not Just Timestamps: A Study on Docker Reproducibility"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [container security], [Docker, reproducible builds, software supply chain, Dockerfile, OCI images, bitwise reproducibility, timestamps, metadata, caching]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Oreofe Solarin"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Case Western Reserve University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17678",children:"https://arxiv.org/pdf/2602.17678"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper builds a measurement pipeline to analyze the bitwise reproducibility of Docker container images built from Dockerfiles in a sample of 2,000 GitHub repositories. It concludes that very few Docker builds are reproducible, and the primary causes are developer-controlled factors like uncleaned caches and floating software versions, not just timestamps."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] Distributed Security: From Isolated Properties to Synergistic Trust"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed systems security], [Byzantine fault tolerance, consensus protocols, secure multi-party computation, cryptographic primitives, agreement, consistency, privacy, verifiability, accountability]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Minghui Xu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Shandong University, Quan Cheng Laboratory"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18063",children:"https://arxiv.org/pdf/2602.18063"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This vision paper argues for a paradigm shift in distributed security research, moving from the isolated study of foundational properties like agreement and privacy to understanding their synergistic combinations. The core method involves analyzing the convergence of these properties to create a unified fabric of trust. The main conclusion is that the future of the field lies in harnessing these synergies rather than optimizing individual properties in isolation."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] Faster Parallel Batch-Dynamic Algorithms for Low Out-Degree Orientation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [graph algorithms], [parallel batch-dynamic algorithms, low out-degree orientation, arboricity, polylogarithmic span]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Guy Blelloch, Andrew Brady, Laxman Dhulipala, Jeremy Fineman, Kishen Gowda, Chase Hutton"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Carnegie Mellon University, University of Maryland, Georgetown University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17811",children:"https://arxiv.org/pdf/2602.17811"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents new parallel batch-dynamic algorithms for maintaining a low out-degree orientation of an undirected graph. The algorithms achieve polylogarithmic span and improve upon prior work by reducing the work per edge update, offering results with asymptotically optimal expected work, expected worst-case work of O(\u221alog n), and O(log\xb2 n) expected worst-case work for different orientation bounds."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] Joint Training on AMD and NVIDIA GPUs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm training], [heterogeneous training, CPU-Forwarding Communication, Device-Direct Communication, GPUDirect RDMA, CPU-offloading P2P, multi-NIC parallel data transfer]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jon Hu, Thomas Jia, Jing Zhu, Zhendong Yu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Zettabyte AI, Inc."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18007",children:"https://arxiv.org/pdf/2602.18007"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes two methods for joint training of large language models on heterogeneous clusters containing both AMD and NVIDIA GPUs. The core contribution is a high-performance Device-Direct Communication approach that enables direct data transfer between different vendor GPUs, eliminating host-memory staging. Experiments show this method achieves up to 98% of the throughput of a homogeneous NVIDIA system while maintaining training stability."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] GPU Memory and Utilization Estimation for Training-Aware Resource Management: Opportunities and Limitations"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [memory estimation, utilization estimation, analytical models, ML-based estimators, PyTorch FakeTensor, Horus, interference-aware scheduling]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Ehsan Yousefzadeh-Asl-Miandoab, Reza Karimzadeh, Danyal Yorulmaz, Bulat Ibragimov, P\u0131nar T\xf6z\xfcn"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," IT University of Copenhagen, University of Copenhagen"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17817",children:"https://arxiv.org/pdf/2602.17817"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper systematically analyzes three paradigms for estimating GPU memory and utilization\u2014analytical models, CPU-side libraries, and ML-based estimators\u2014to improve resource management for collocated deep learning training. The evaluation reveals key trade-offs: analytical models are hardware-dependent, libraries impose integration costs, and ML estimators struggle with generalization. The authors release datasets and tools to support further research in this area."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] Closing Africa's Early Warning Gap: AI Weather Forecasting for Disaster Prevention"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [NVIDIA Earth-2, PostgreSQL, ProcessPoolExecutor, aiobotocore, async Python, database-backed serving, coordinate management, WhatsApp distribution]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Qness Ndlovu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Dimension Research Lab"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17726",children:"https://arxiv.org/pdf/2602.17726"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents a low-cost, production-grade architecture using NVIDIA Earth-2 AI weather models and PostgreSQL caching to deliver national-scale weather forecasts in Africa. The system reduces deployment costs by over 2,000x compared to traditional radar, enabling effective early warning systems via widely accessible channels like WhatsApp. The main conclusion is that this AI-driven approach makes continent-scale disaster prevention economically viable, potentially reducing disaster death rates significantly."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] Mind the Boundary: Stabilizing Gemini Enterprise A2A via a Cloud Run Hub Across Projects and Accounts"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [agent-to-agent (A2A) protocol, JSON-RPC, Cloud Run, retrieval-augmented generation (RAG), Vertex AI, Google Cloud Storage, IAM authentication]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Takao Morita"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Independent Researcher"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17675",children:"https://arxiv.org/pdf/2602.17675"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper implements an A2A Hub orchestrator on Cloud Run to route queries from the Gemini Enterprise UI to various backend agents and tools across different Google Cloud projects and accounts. It identifies and addresses a key interoperability gap where the UI's text-only input constraints cause errors with structured JSON-RPC responses, solved by enforcing a text-only compatibility mode. The main conclusion is that practical, stable multi-agent orchestration requires managing not just protocol compliance but also UI constraints and cross-boundary authentication."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] A reliability- and latency-driven task allocation framework for workflow applications in the edge-hub-cloud continuum"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [edge computing], [binary integer linear programming, multi-objective optimization, task allocation, time redundancy]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Andreas Kouloumpris, Georgios L. Stavrinides, Maria K. Michael, Theocharis Theocharides"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Cyprus, KIOS Research and Innovation Center of Excellence"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18158",children:"https://arxiv.org/pdf/2602.18158"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes an exact multi-objective task allocation framework using binary integer linear programming to jointly optimize reliability and latency for workflow applications in an edge-hub-cloud architecture. The method incorporates time redundancy and key constraints, demonstrating significant improvements in reliability and latency over baselines in experiments with real-world and synthetic workflows."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] It does not matter how you define locally checkable labelings"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed graph algorithms], [locally checkable labeling, LOCAL model, round elimination, symmetry-breaking oracle, node-edge checkable]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Antonio Cruciani, Avinandan Das, Alesya Raevskaya, Jukka Suomela"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Aalto University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18188",children:"https://arxiv.org/pdf/2602.18188"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"}),' The paper shows that the family of Locally Checkable Labeling (LCL) problems is robust to definitional variations by proving local reductions between a standard LCL formalism and a more restricted "node-edge checkable" formalism. The main conclusion is that even with a stricter definition, LCL problems retain counterintuitive properties, indicating these properties are inherent to the problem family and not artifacts of the original definition.']}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260223] Green by Design: Constraint-Based Adaptive Deployment in the Cloud Continuum"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [cloud-edge deployment], [green constraints, adaptive orchestration, energy-aware scheduling, cloud continuum, deployment plans]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Andrea D'Iapico, Monica Vitali"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Politecnico di Milano"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18287",children:"https://arxiv.org/pdf/2602.18287"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"}),' This paper proposes a methodology for generating environmentally sustainable deployment plans for cloud-native applications across the cloud-edge continuum. The core method involves automatically learning and updating "green constraints" from monitoring data on energy consumption and infrastructure carbon intensity to guide an adaptive scheduler. The approach is validated to effectively reduce energy usage and associated emissions in realistic deployment scenarios.']}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 17'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Whole-Brain Connectomic Graph Model Enables Whole-Body Locomotion Control in Fruit Fly ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17997",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Gradient Regularization Prevents Reward Hacking in Reinforcement Learning from Human Feedback and Verifiable Rewards ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18037",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] MePoly: Max Entropy Polynomial Policy Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17832",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Epistemic Traps: Rational Misalignment Driven by Model Misspecification ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17676",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18025",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Optimal Multi-Debris Mission Planning in LEO: A Deep Reinforcement Learning Approach with Co-Elliptic Transfers and Refueling ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17685",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] CodeScaler: Scaling Code LLM Training and Test-Time Inference via Execution-Free Reward Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17684",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Flow Actor-Critic for Offline Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18015",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Mean-Field Reinforcement Learning without Synchrony ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18026",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] MIRA: Memory-Integrated Reinforcement Learning Agent with Limited LLM Guidance ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17930",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Learning Optimal and Sample-Efficient Decision Policies with Guarantees ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17978",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Memory-Based Advantage Shaping for LLM-Guided Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17931",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Interacting safely with cyclists using Hamilton-Jacobi reachability and reinforcement learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18097",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] TempoNet: Slack-Quantized Transformer-Guided Reinforcement Scheduler for Adaptive Deadline-Centric Real-Time Dispatchs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18109",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Flow Matching with Injected Noise for Offline-to-Online Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18117",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] PRISM: Parallel Reward Integration with Symmetry for MORL ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18277",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18291",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 9'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Solving and learning advective multiscale Darcian dynamics with the Neural Basis Method ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17776",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Hardware-Friendly Input Expansion for Accelerating Function Approximation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17952",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Multi-material Multi-physics Topology Optimization with Physics-informed Gaussian Process Priors ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17783",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] A Case Study of Selected PTQ Baselines for Reasoning LLMs on Ascend NPU ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17693",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Balancing Symmetry and Efficiency in Graph Flow Matching ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18084",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] A Probabilistic Framework for LLM-Based Model Discovery ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18266",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] PRISM: Parallel Reward Integration with Symmetry for MORL ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18277",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] Clever Materials: When Models Identify Good Materials for the Wrong Reasons ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17730",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260223] AgriVariant: Variant Effect Prediction using DeepChem-Variant for Precision Breeding in Rice ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17747",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2026-02-24",children:"2026-02-24"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 19"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] WANSpec: Leveraging Global Compute Capacity for LLM Inference"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [speculative decoding, wide area network, load balancing, redundancy, auto-regressive decoding]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Noah Martin, Fahad Dogar"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Tufts University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18931",children:"https://arxiv.org/pdf/2602.18931"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces WANSpec, a method that leverages speculative decoding to offload the draft model's forward passes to under-utilized data centers across a wide area network. This approach reduces the computational load on high-demand data centers by over 50% while using judicious redundancy to avoid increasing request latency."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] When Coordination Is Avoidable: A Monotonicity Analysis of Organizational Tasks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [ai], [multi-agent systems], [monotonicity, interdependence taxonomy, coordination tax, multi-agent simulation, O*NET]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Harang Ju"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Johns Hopkins University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18673",children:"https://arxiv.org/pdf/2602.18673"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper applies a monotonicity criterion from distributed systems theory to organizational tasks, showing coordination is only necessary for non-monotonic tasks. It classifies enterprise workflows and occupational tasks, finding a significant portion are monotonic, implying much coordination spending is unnecessary for correctness."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] A Formal Framework for Predicting Distributed System Performance under Faults"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed systems, fault tolerance], [Maude, formal methods, fault injection, performance prediction, statistical analysis]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Ziwei Zhou, Si Liu, Zhou Zhou, Peixin Wang, MIn Zhang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," East China Normal University, Texas A&M University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19088",children:"https://arxiv.org/pdf/2602.19088"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents a formal framework that integrates a fault injector library with system models to predict the performance (e.g., throughput, latency) of distributed systems under various fault scenarios. The framework is formalized in Maude and implemented as an automated tool called PerF. The authors demonstrate that PerF accurately predicts performance, with results consistent with evaluations on real deployments."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] Deep Reinforcement Learning for Optimizing Energy Consumption in Smart Grid Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [deep reinforcement learning, physics-informed neural networks, optimal power flow, surrogate models, smart grid]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Abeer Alsheikhi, Amirfarhad Farhadi, Azadeh Zamanifar"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Iran University of Science and Technology, Islamic Azad University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18531",children:"https://arxiv.org/pdf/2602.18531"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes using Physics-Informed Neural Networks (PINNs) as a surrogate model to accelerate Deep Reinforcement Learning training for smart grid energy management. The PINN-based approach, which incorporates knowledge of physical laws, significantly improves sample efficiency and reduces the need for costly simulator interactions. The results show that this method achieves 50% faster training while maintaining performance comparable to using the original simulator."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] What Distributed Computing Got Wrong: The Category Mistake That Turned Design Choices into Laws of Nature"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed computing], [FITO, bilateral transactions, category mistake, impossibility theorems, FLP, CAP, Two Generals]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Paul Borrill"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," D\xc6D\xc6LUS"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18723",children:"https://arxiv.org/pdf/2602.18723"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper argues that foundational impossibility results in distributed computing, such as FLP and CAP, are not physical laws but consequences of the design choice of Forward-In-Time-Only (FITO) information flow. It proposes replacing unidirectional message passing with atomic bilateral transactions as an alternative model. The conclusion is that distributed computing has been optimizing within an unnecessarily constrained design space."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] Asymptotic Subspace Consensus in Dynamic Networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed computing], [asymptotic subspace consensus, oblivious message adversaries, convex hull, dynamic networks, averaging algorithms]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Matthias F\xfcgger, Thomas Nowak"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Universit\xe9 Paris-Saclay, CNRS, ENS Paris-Saclay, LMF, Institut Universitaire de France"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19121",children:"https://arxiv.org/pdf/2602.19121"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces the asymptotic subspace consensus problem, a relaxation of classic asymptotic consensus where process outputs converge to a common subspace rather than a single point. The authors provide a complete characterization of its solvability under oblivious message adversaries and show that many existing consensus algorithms degrade gracefully to solve this problem in weaker network conditions. They also present bounds on the rate of dimension reduction during convergence."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] ucTrace: A Multi-Layer Profiling Tool for UCX-driven Communication"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [HPC communication profiling], [UCX, MPI, GPU-aware communication, transport-layer profiling, interactive visualization]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Emir Gencer, Mohammad Kefah Taha Issa, Ilyas Turimbetov, James D. Trotter, Didem Unat"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Koc University, Simula Research Laboratory"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19084",children:"https://arxiv.org/pdf/2602.19084"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces ucTrace, a multi-layer profiling tool that captures and visualizes fine-grained communication at the UCX transport layer in HPC systems, linking operations to their originating MPI functions. It demonstrates the tool's utility in analyzing and optimizing communication patterns for large-scale, GPU-accelerated workloads. The main conclusion is that ucTrace effectively addresses the gap in existing tools by providing detailed, actionable insights into UCX-driven communication for performance tuning and debugging."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] BiScale: Energy-Efficient Disaggregated LLM Serving via Phase-Aware Placement and DVFS"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [prefill/decode disaggregation, DVFS, model predictive control, slack-aware adaptation, phase-aware placement]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Omar Basit, Yunzhao Liu, Z. Jonny Kong, Y. Charlie Hu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Purdue University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18755",children:"https://arxiv.org/pdf/2602.18755"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces BiScale, a two-tier energy optimization framework for disaggregated LLM serving that jointly optimizes GPU placement and frequency scaling (DVFS). It uses coarse-grained phase-aware placement and fine-grained, stage-specific frequency control (MPC for prefill, slack-aware for decode) to minimize energy while meeting latency SLOs. Evaluation shows it reduces energy by up to 39% in prefill and 48% in decode compared to DistServe while maintaining SLOs."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] Carbon-aware decentralized dynamic task offloading in MIMO-MEC networks via multi-agent reinforcement learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [multi-agent proximal policy optimization (PPO), decentralized execution with parameter sharing (DEPS), Decentralized Partially Observable Markov Decision Process (DEC-POMDP), carbon-aware computing, power control, task offloading]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Mubshra Zulfiqar, Muhammad Ayzed Mirza, Basit Qureshi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Wuhan University of Technology, Qilu Institute of Technology, Prince Sultan University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18797",children:"https://arxiv.org/pdf/2602.18797"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes CADDTO-PPO, a carbon-aware decentralized dynamic task offloading framework using multi-agent proximal policy optimization for MIMO-MEC networks. It models the system as a DEC-POMDP and employs decentralized execution with parameter sharing to enable autonomous agents to make local decisions on power control and offloading. The method achieves lower carbon intensity and near-zero packet overflow compared to baselines, with constant inference complexity suitable for sustainable IoT deployments."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] The Category Mistake of Cislunar Time: Why NASA Cannot Synchronize What Doesn't Exist"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [time synchronization, distributed systems], [Coordinated Lunar Time (LTC), atomic clocks, relativistic corrections, LunaNet, category mistake, ontic vs epistemic, Forward-In-Time-Only (FITO), Leibnizian operationalism, Wood-Spekkens fine-tuning argument]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Paul Borrill"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," D\xc6D\xc6LUS"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18641",children:"https://arxiv.org/pdf/2602.18641"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper argues that NASA's Coordinated Lunar Time (LTC) program is based on a philosophical category mistake, treating synchronized time as an independent ontic entity rather than an epistemic, model-dependent construct. It analyzes the program using concepts from quantum foundations, such as the ontic-epistemic distinction and Spekkens' operationalism, to conclude that the project is conceptually incoherent. The author proposes a transactional alternative based on bilateral atomic interactions instead of unidirectional time distribution."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] Semantic Conflict Model for Collaborative Data Structures"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed systems], [CRDT, semantic conflicts, three-way merge, eventual consistency, optimistic concurrency control, replicated journal]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Georgii Semenov, Vitaly Aksenov"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," ITMO University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19231",children:"https://arxiv.org/pdf/2602.19231"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces a semantic conflict model for collaborative data structures that identifies conflicts using semantic dependencies between operations and resolves them by rebasing operations via a three-way merge over a replicated journal. The model enables explicit, local-first conflict resolution without central coordination, as demonstrated on collaborative registers like a Last-Writer-Wins Register."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] Health+: Empowering Individuals via Unifying Health Data"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [multimodal data management, data fusion, user-centric privacy, cloud storage, information retrieval]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Sujaya Maiyya, Shantanu Sharma, Avinash Kumar"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Waterloo, New Jersey Institute of Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19319",children:"https://arxiv.org/pdf/2602.19319"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This vision paper proposes Health+, a user-centric system designed to unify and manage an individual's fragmented multimodal health data (e.g., images, reports, EHRs) through ingestion, storage, fusion, and querying. It emphasizes intuitive interfaces and privacy-aware sharing to empower patients. The main conclusion is that such a system can lay the foundation for a more connected and user-controlled health information ecosystem without requiring an institutional overhaul."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] Complex Event Processing in the Edge: A Combined Optimization Approach for Data and Code Placement"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [edge computing], [complex event processing, constrained programming optimization, critical path performance, virtual shared memory, task graph, code and data placement]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Halit Uyan\u0131k, Tolga Ovatman"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Istanbul Technical University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19338",children:"https://arxiv.org/pdf/2602.19338"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes a constrained programming optimization approach to balance execution costs and improve the critical path performance in Complex Event Processing (CEP) task graphs for IoT edge devices. It is implemented as a Python library that optimizes code and I/O assignments, virtualizing shared memory between devices. The results show that this optimization increases throughput and reduces delay during CEP operations."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] A Context-Aware Knowledge Graph Platform for Stream Processing in Industrial IoT"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [industrial IoT systems], [knowledge graph, Apache Kafka, Apache Flink, SPARQL, SWRL, context-aware reasoning, stream processing]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Monica Marconi Sciarroni, Emanuele Storti"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Polytechnic University of Marche"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19990",children:"https://arxiv.org/pdf/2602.19990"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a semantic platform that uses a Knowledge Graph to unify heterogeneous Industrial IoT data streams, enabling context-aware reasoning and dynamic access control. It relies on Apache Kafka and Flink for real-time processing and SPARQL/SWRL for stream discovery. The experimental evaluation demonstrates the effectiveness of this approach for creating interoperable data workflows in Industry 5.0 environments."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] Mitigating Artifacts in Pre-quantization Based Scientific Data Compressors with Quantization-aware Interpolation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [high-performance computing, data compression], [pre-quantization, error-bounded lossy compression, quantization-aware interpolation, artifact mitigation, parallel computing]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Pu Jiao, Sheng Di, Jiannan Tian, Mingze Xia, Xuan Wu, Yang Zhang, Xin Liang, Franck Cappello"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Kentucky, Argonne National Laboratory, Oakland University, Oregon State University, Miami University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.20097",children:"https://arxiv.org/pdf/2602.20097"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a novel quantization-aware interpolation algorithm to mitigate artifacts in pre-quantization based scientific data compressors. The method improves decompressed data quality while maintaining high compression throughput. Experiments on real-world datasets validate its effectiveness with leading compressors."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] GPU-Resident Gaussian Process Regression Leveraging Asynchronous Tasks with HPX"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [GPU kernels], [Gaussian Process Regression, Cholesky Decomposition, Asynchronous Many-task Runtimes, Tiled Algorithms, HPX, CUDA]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Henrik M\xf6llmann, Dirk Pfl\xfcger, Alexander Strack"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Institute of Parallel and Distributed Systems, University of Stuttgart"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19683",children:"https://arxiv.org/pdf/2602.19683"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper extends the GPRat library by implementing a fully GPU-resident Gaussian Process prediction pipeline using tiled algorithms and optimized CUDA libraries, managed asynchronously by the HPX runtime. The results show that the GPU implementation provides significant speedups for datasets larger than 128 samples, with performance gains of up to 4.6x for prediction and even surpassing cuSOLVER by up to 11% for large datasets when combining HPX with multiple CUDA streams."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] Why iCloud Fails: The Category Mistake of Cloud Synchronization"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed systems, cloud storage], [cloud synchronization, POSIX semantics, network partitioning, causal graph, Open Atomic Ethernet (OAE), transactional semantics]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Paul Borrill"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," DAEDAELUS"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19433",children:"https://arxiv.org/pdf/2602.19433"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper analyzes iCloud Drive's failures, arguing they stem from a \"Category Mistake\" where its synchronization semantics (based on Forward-In-Time-Only assumptions) fundamentally conflict with POSIX filesystem expectations. It concludes that Open Atomic Ethernet's bilateral, reversible transactional semantics provide a structural foundation to resolve these issues by aligning protocol behavior with physical reality."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] Linear Reservoir: A Diagonalization-Based Optimization"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [diagonalization, eigenvalue decomposition, eigenbasis transformation, computational complexity reduction, linear echo state networks]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Romain de Coudenhove, Yannis Bendi-Ouis, Anthony Strock, Xavier Hinaut"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," ENS PSL, Inria, LaBRI, IMN, Stanford University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19802",children:"https://arxiv.org/pdf/2602.19802"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces a diagonalization-based optimization for Linear Echo State Networks that reformulates reservoir dynamics in the eigenbasis of the recurrent matrix, reducing the per-step computational complexity from O(N\xb2) to O(N). The proposed methods preserve predictive accuracy while offering significant computational speedups, suggesting a paradigm shift towards direct eigenvalue selection for linear ESNs."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260224] A Risk-Aware UAV-Edge Service Framework for Wildfire Monitoring and Emergency Response"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [fire-history-weighted clustering, QoS-aware edge assignment, 2-opt route optimization, dynamic emergency rerouting, adaptive fleet sizing]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yulun Huang, Zhiyu Wang, Rajkumar Buyya"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The University of Melbourne"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19742",children:"https://arxiv.org/pdf/2602.19742"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes an integrated UAV-edge service framework that co-optimizes route planning, fleet sizing, and edge service provisioning using risk-aware clustering and dynamic rerouting for wildfire monitoring. Experiments show the framework significantly reduces response time, energy consumption, and fleet size compared to baseline methods, while its emergency mechanism meets strict deadlines with minimal operational disruption."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 42'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Learning to Detect Language Model Training Data via Active Reconstruction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19020",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Toward AI Autonomous Navigation for Mechanical Thrombectomy using Hierarchical Modular Multi-agent Reinforcement Learning (HM-MARL) ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18663",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] 1D-Bench: A Benchmark for Iterative UI Code Generation with Visual Feedback in Real-World ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18548",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Issues with Measuring Task Complexity via Random Policies in Robotic Tasks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18856",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] TAG: Thinking with Action Unit Grounding for Facial Expression Recognition ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18763",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Learning to Remember: End-to-End Training of Memory Agents for Long-Context Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18493",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] DeepInterestGR: Mining Deep Multi-Interest Using Multi-Modal LLMs for Generative Recommendation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18907",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] VariBASed: Variational Bayes-Adaptive Sequential Monte-Carlo Planning for Deep Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18857",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] TPRU: Advancing Temporal and Procedural Understanding in Large Multimodal Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18884",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Hierarchical Reward Design from Language: Enhancing Alignment of Agent Behavior with Human Specifications ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18582",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] FineRef: Fine-Grained Error Reflection and Correction for Long-Form Generation with Citations ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18437",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] In-Context Planning with Latent Temporal Abstractions ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18694",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Task-Aware Exploration via a Predictive Bisimulation Metric ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18724",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Adaptive Time Series Reasoning via Segment Selection ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18645",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] MagicAgent: Towards Generalized Agent Planning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19000",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] HONEST-CAV: Hierarchical Optimization of Network Signals and Trajectories for Connected and Automated Vehicles with Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18740",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Adaptive Problem Generation via Symbolic Representations ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19187",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] How to Allocate, How to Learn? Dynamic Rollout Allocation and Advantage Modulation for Policy Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19208",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Characterizing MARL for Energy Control: A Multi-KPI Benchmark on the CityLearn Environment ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19223",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Robust Exploration in Directed Controller Synthesis via Reinforcement Learning with Soft Mixture-of-Experts ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19244",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] DGPO: RL-Steered Graph Diffusion for Neural Architecture Generation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19261",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] ALPACA: A Reinforcement Learning Environment for Medication Repurposing and Treatment Optimization in Alzheimer's Disease ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19298",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] TOPReward: Token Probabilities as Hidden Zero-Shot Rewards for Robotics ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19313",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Learning to Reason for Multi-Step Retrieval of Personal Context in Personalized Question Answering ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19317",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Soft Sequence Policy Optimization: Bridging GMPO and SAPO ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19327",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] LLMs Can Learn to Reason Via Off-Policy RL ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19362",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Stable Deep Reinforcement Learning via Isotropic Gaussian Representations ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19373",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] IR",(0,s.jsxs)(e.span,{className:"katex",children:[(0,s.jsx)(e.span,{className:"katex-mathml",children:(0,s.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,s.jsxs)(e.semantics,{children:[(0,s.jsx)(e.mrow,{children:(0,s.jsxs)(e.msup,{children:[(0,s.jsx)(e.mrow,{}),(0,s.jsx)(e.mn,{children:"3"})]})}),(0,s.jsx)(e.annotation,{encoding:"application/x-tex",children:"^3"})]})})}),(0,s.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,s.jsxs)(e.span,{className:"base",children:[(0,s.jsx)(e.span,{className:"strut",style:{height:"0.8141em"}}),(0,s.jsxs)(e.span,{className:"mord",children:[(0,s.jsx)(e.span,{}),(0,s.jsx)(e.span,{className:"msupsub",children:(0,s.jsx)(e.span,{className:"vlist-t",children:(0,s.jsx)(e.span,{className:"vlist-r",children:(0,s.jsx)(e.span,{className:"vlist",style:{height:"0.8141em"},children:(0,s.jsxs)(e.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,s.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,s.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,s.jsx)(e.span,{className:"mord mtight",children:"3"})})]})})})})})]})]})})]}),": Contrastive Inverse Reinforcement Learning for Interpretable Detection and Mitigation of Reward Hacking ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19416",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] RAmmStein: Regime Adaptation in Mean-reverting Markets with Stein Thresholds -- Optimal Impulse Control in Concentrated AMMs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19419",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] SenTSR-Bench: Thinking with Injected Knowledge for Time-Series Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19455",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Cost-Aware Diffusion Active Search ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19538",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Advantage-based Temporal Attack in Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19582",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Meta-Learning and Meta-Reinforcement Learning - Tracing the Path towards DeepMind's Adaptive Agent ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19837",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] DSDR: Dual-Scale Diversity Regularization for Exploration in LLM Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19895",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Uncertainty-Aware Rank-One MIMO Q Network Framework for Accelerated Offline Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19917",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Janus-Q: End-to-End Event-Driven Trading via Hierarchical-Gated Reward Modeling ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19919",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Sparse Masked Attention Policies for Reliable Generalization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19956",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] A Secure and Private Distributed Bayesian Federated Learning Design ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.20003",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Descent-Guided Policy Gradient for Scalable Cooperative Multi-Agent Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.20078",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] ReSyn: Autonomously Scaling Synthetic Environments for Reasoning Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.20117",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] LAD: Learning Advantage Distribution for Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.20132",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] AAVGen: Precision Engineering of Adeno-associated Viral Capsids for Renal Selective Targeting ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18915",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 27'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Can Multimodal LLMs See Science Instruction? Benchmarking Pedagogical Reasoning in K-12 Classroom Videos ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18466",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] DeepInnovator: Triggering the Innovative Capabilities of LLMs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18920",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] IDLM: Inverse-distilled Diffusion Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19066",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Vectorized Bayesian Inference for Latent Dirichlet-Tree Allocation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18795",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] VariBASed: Variational Bayes-Adaptive Sequential Monte-Carlo Planning for Deep Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18857",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Habilis-",(0,s.jsxs)(e.span,{className:"katex",children:[(0,s.jsx)(e.span,{className:"katex-mathml",children:(0,s.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,s.jsxs)(e.semantics,{children:[(0,s.jsx)(e.mrow,{children:(0,s.jsx)(e.mi,{children:"\u03b2"})}),(0,s.jsx)(e.annotation,{encoding:"application/x-tex",children:"\u03b2"})]})})}),(0,s.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,s.jsxs)(e.span,{className:"base",children:[(0,s.jsx)(e.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,s.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"})]})})]}),": A Fast-Motion and Long-Lasting On-Device Vision-Language-Action Model ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18813",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Learning from Complexity: Exploring Dynamic Sample Pruning of Spatio-Temporal Training ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19113",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] ConfSpec: Efficient Step-Level Speculative Reasoning via Confidence-Gated Verification ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18447",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Exponential Convergence of (Stochastic) Gradient Descent for Separable Logistic Regression ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18946",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] InfEngine: A Self-Verifying and Self-Optimizing Intelligent Engine for Infrared Radiation Computing ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18985",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Task-Aware Exploration via a Predictive Bisimulation Metric ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18724",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] LLM-Assisted Replication for Quantitative Social Science ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18453",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] CORVET: A CORDIC-Powered, Resource-Frugal Mixed-Precision Vector Processing Engine for High-Throughput AIoT applications ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19268",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Taming Preconditioner Drift: Unlocking the Potential of Second-Order Optimizers for Federated Learning on Non-IID Data ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19271",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] CTS-Bench: Benchmarking Graph Coarsening Trade-offs for GNNs in Clock Tree Synthesis ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19330",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Laplacian Multi-scale Flow Matching for Generative Modeling ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19461",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Relational Feature Caching for Accelerating Diffusion Transformers ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19506",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Leap+Verify: Regime-Adaptive Speculative Weight Prediction for Accelerating Neural Network Training ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19580",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Rules or Weights? Comparing User Understanding of Explainable AI Techniques with the Cognitive XAI-Adaptive Model ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19620",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Iconographic Classification and Content-Based Recommendation for Digitized Artworks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19698",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Hexagon-MLIR: An AI Compilation Stack For Qualcomm's Neural Processing Units (NPUs) ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19762",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Fully Convolutional Spatiotemporal Learning for Microstructure Evolution Prediction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19915",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] DP-FedAdamW: An Efficient Optimizer for Differentially Private Federated Large Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19945",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] A Secure and Private Distributed Bayesian Federated Learning Design ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.20003",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Adaptation to Intrinsic Dependence in Diffusion Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.20126",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] AAVGen: Precision Engineering of Adeno-associated Viral Capsids for Renal Selective Targeting ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.18915",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260224] Kaiwu-PyTorch-Plugin: Bridging Deep Learning and Photonic Quantum Computing for Energy-Based Models and Active Sample Selection ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.19114",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2026-02-26",children:"2026-02-26"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 16"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] Lamport's Arrow of Time: The Category Mistake in Logical Clocks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed systems theory], [logical clocks, happens-before relation, directed acyclic graph (DAG), mutual information conservation, indefinite causal order, CAP theorem, Fischer-Lynch-Paterson]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Paul Borrill"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," D\xc6D\xc6LUS"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21730",children:"https://arxiv.org/pdf/2602.21730"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"}),' The paper critiques Lamport\'s logical clocks, arguing they embed a "forward-in-time-only" assumption that conflates epistemic ordering with an ontic claim of global causal acyclicity. It traces this conflation through impossibility results and modern physics, which only permits local causal structure. The authors propose mutual information conservation as a more fundamental primitive for distributed consistency than temporal precedence.']}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] DualPath: Breaking the Storage Bandwidth Bottleneck in Agentic LLM Inference"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [KV-Cache, disaggregated architecture, RDMA, dual-path loading, global scheduler]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yongtong Wu, Shaoyuan Chen, Yinmin Zhong, Rilin Huang, Yixuan Tan, Wentao Zhang, Liyue Zhang, Shangyan Zhou, Yuxuan Liu, Shunfeng Zhou, Mingxing Zhang, Xin Jin, Panpan Huang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Peking University, Tsinghua University, DeepSeek-AI"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21548",children:"https://arxiv.org/pdf/2602.21548"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces DualPath, a system that breaks the KV-Cache storage bandwidth bottleneck in agentic LLM inference by enabling a novel storage-to-decode loading path alongside the traditional storage-to-prefill path, combined with a global scheduler. It demonstrates that this approach significantly improves both offline and online inference throughput without violating service-level objectives."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] Type-Based Enforcement of Non-Interference for Choreographic Programming"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [programming languages, security], [type system, non-interference, choreographic programming, constraint generation, program-counter discipline]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Marco Bertoni, Saverio Giallorenzo, Marco Peressotti"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Inria Paris, Universit\xe9 di Bologna, Inria Sophia Antipolis, University of Southern Denmark"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21630",children:"https://arxiv.org/pdf/2602.21630"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper develops a policy-parametric type system for choreographic programming to enforce information flow security. The method handles both explicit and implicit flows via a program-counter discipline and supports recursive procedures through constraint-based context reconstruction. The main conclusion is a proof of termination-insensitive non-interference, ensuring that secret data is not leaked to public observers in distributed protocols."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] Multi-Layer Scheduling for MoE-Based LLM Reasoning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [multi-layer scheduling, mixture-of-experts (MoE), Shortest-Job-First (SJF), priority-aware aging, load-aware dispatching, KV cache, expert hotspots]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yifan Sun, Gholamreza Haffar, Minxian Xu, Rajkumar Buyya, Adel N. Toosi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The University of Melbourne, Monash University, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21626",children:"https://arxiv.org/pdf/2602.21626"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a multi-layer scheduling framework for efficient Mixture-of-Experts (MoE) based LLM serving, operating at the request, engine, and expert levels. It demonstrates that this approach outperforms the vLLM framework, achieving significant reductions in both Time To First Token and Time-Per-Output-Token latency."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] JSAM: Privacy Straggler-Resilient Joint Client Selection and Incentive Mechanism Design in Differentially Private Federated Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [differential privacy, federated learning, incentive mechanism design, client selection, Bayesian-optimal framework]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Ruichen Xu, Ying-Jun Angela Zhang, Jianwei Huang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The Chinese University of Hong Kong, Shenzhen Institute of Artificial Intelligence and Robotics for Society"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21844",children:"https://arxiv.org/pdf/2602.21844"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes JSAM, a framework that jointly optimizes client selection and privacy compensation in differentially private federated learning to maximize training effectiveness under a budget. It shows that servers should preferentially select privacy-tolerant clients and reveals that clients with minimal privacy sensitivity may incur the highest cumulative costs due to frequent participation. Evaluations demonstrate that JSAM achieves up to 15% higher test accuracy compared to unbiased selection mechanisms."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] General Convex Agreement with Near-Optimal Communication"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed consensus], [convex agreement, Byzantine agreement, extractor graphs, deterministic committees, communication complexity, Helly number]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Marc Dufay, Diana Ghinea, Anton Paramonov"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," ETH Zurich, Lucerne University of Applied Sciences and Arts"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21411",children:"https://arxiv.org/pdf/2602.21411"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents deterministic synchronous Convex Agreement protocols for abstract convexity spaces, using extractor graphs to assign parties to committees resilient against adaptive adversaries. It achieves near-optimal communication complexity and round complexity, with resilience depending on the Helly number of the convexity space and whether input length bounds are known."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] Make Every Draft Count: Hidden State based Speculative Decoding"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [speculative decoding, hidden state reuse, auto-regressive hidden states, token tree, draft model]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yuetao Chen, Xuliang Wang, Xinzhou Zheng, Ming Li, Peng Wang, Hong Xu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The Chinese University of Hong Kong, University of Waterloo, University of Science and Technology of China"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21224",children:"https://arxiv.org/pdf/2602.21224"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a novel speculative decoding system that reuses the hidden states from discarded draft tokens to improve computational efficiency. The core method involves performing auto-regressive prediction at the hidden state level and injecting token information later, enabling the construction of high-quality draft token trees from verification failures. The system achieves up to 3.3x speedup compared to standard speculative decoding by transforming wasted computation into reusable tokens."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] PiPNN: Ultra-Scalable Graph-Based Nearest Neighbor Indexing"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [graph-based indexing, approximate nearest neighbor search, HashPrune, beam search, dense matrix multiplication, online pruning]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Tobias Rubel, Richard Wen, Laxman Dhulipala, Lars Gottesb\xfcren, Rajesh Jayaram, Jakub \u0141\u0105cki"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Maryland, Google Research"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21247",children:"https://arxiv.org/pdf/2602.21247"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces PiPNN, a new graph construction algorithm for approximate nearest neighbor search that uses a core component called HashPrune to dynamically prune edges and perform bulk distance comparisons. This method avoids the search bottleneck of traditional graph-based indexes like HNSW and Vamana, enabling much faster construction. The authors demonstrate that PiPNN builds high-quality indexes up to 12.9x faster than prior methods and can construct billion-scale indexes in under 20 minutes on a single machine."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] Epoch-based Optimistic Concurrency Control in Geo-replicated Databases"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed databases], [epoch-based replication, optimistic concurrency control, deterministic re-execution, conflict graph, maximum weight independent set, multi-leader replication]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yunhao Mao, Harunari Takata, Michail Bachras, Yuqiu Zhang, Shiquan Zhang, Gengrui Zhang, Hans-Arno Jacobsen"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Toronto, Keio University, Concordia University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21566",children:"https://arxiv.org/pdf/2602.21566"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces Minerva, a geo-replicated database system that uses an epoch-based optimistic concurrency control protocol with deterministic re-execution and a conflict graph algorithm to resolve transaction conflicts. It decouples data propagation from commitment to enable high concurrency in multi-leader settings. The evaluation shows it significantly outperforms existing systems in throughput under high latency and scalability."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] DHP: Efficient Scaling of MLLM Training with Dynamic Hybrid Parallelism"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [multi-modal training], [dynamic hybrid parallelism, non-power-of-two parallelism, polynomial-time algorithm, data parallelism, tensor parallelism, pipeline parallelism, sequence parallelism]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yifan Niu, Han Xiao, Dongyi Liu, Wei Zhou, Jia Li"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The Hong Kong University of Science and Technology (Guangzhou), Huawei Technologies Co., Ltd., The Hong Kong University of Science and Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21788",children:"https://arxiv.org/pdf/2602.21788"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes Dynamic Hybrid Parallelism (DHP), a method that adaptively reconfigures communication groups and parallelism degrees during Multimodal Large Language Model (MLLM) training to handle heterogeneous data efficiently. It introduces a polynomial-time algorithm to generate near-optimal parallelism strategies with minimal overhead. The results show that DHP significantly outperforms existing frameworks like Megatron-LM and DeepSpeed, achieving up to 1.36x speedup in training throughput while maintaining near-linear scaling efficiency."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] Energy Efficient Federated Learning with Hyperdimensional Computing over Wireless Communication Networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [hyperdimensional computing, differential privacy, resource allocation, alternating optimization, energy efficiency]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yahao Ding, Yinchao Yang, Jiaxiang Wang, Zhaohui Yang, Dusit Niyato, Zhu Han, Mohammad Shikh-Bahaei"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," King's College London, Zhejiang University, Nanyang Technological University, University of Houston, Kyung Hee University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21949",children:"https://arxiv.org/pdf/2602.21949"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a federated learning framework that uses hyperdimensional computing for lightweight local training and applies differential privacy for security, jointly optimizing resource allocation to minimize total energy consumption. The method significantly reduces energy usage and communication rounds compared to neural network baselines while maintaining model accuracy."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] PASTA: A Modular Program Analysis Tool Framework for Accelerators"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [GPU kernels], [performance analysis, profiling, modular framework, GPU-accelerated backend, deep learning workloads]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Mao Lin, Hyeran Jeon, Keren Zhou"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of California, Merced, George Mason University, OpenAI"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.22103",children:"https://arxiv.org/pdf/2602.22103"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents PASTA, a modular and low-overhead program analysis tool framework for hardware accelerators. It abstracts low-level profiling APIs and deep learning frameworks to provide a unified interface for performance analysis. The evaluation shows PASTA offers detailed insights with significantly lower overhead than conventional tools, making it suitable for modern accelerator environments."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] LLMTailor: A Layer-wise Tailoring Tool for Efficient Checkpointing of Large Language Models"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [checkpointing, layer-wise tailoring, selective checkpointing, checkpoint merging]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Minqiu Sun, Xin Huang, Luanzheng Guo, Nathan R. Tallent, Kento Sato, Dong Dai"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Delaware, RIKEN Center for Computational Science, Pacific Northwest National Laboratory"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.22158",children:"https://arxiv.org/pdf/2602.22158"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes LLMTailor, a checkpoint-merging framework that selectively saves only the layers of a large language model that have undergone significant updates, rather than the entire model state. This method significantly reduces checkpoint storage size and I/O time while maintaining model quality, as demonstrated in evaluations with models like Llama3.1-8B and Qwen2.5-7B."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] Hybrid Consensus with Quantum Sybil Resistance"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [quantum cryptography, consensus protocols], [quantum position verification, hybrid consensus, Sybil resistance, Proof-of-Work, Proof-of-Stake]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Dar Gilboa, Siddhartha Jain, Or Sattath"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Google Quantum AI, University of Texas at Austin, Ben-Gurion University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.22195",children:"https://arxiv.org/pdf/2602.22195"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a decentralized consensus protocol that uses quantum position verification as a Sybil resistance mechanism, combining it with classical hybrid consensus. The method improves energy efficiency compared to Proof-of-Work-based hybrid protocols and offers faster confirmation times while avoiding the compounding wealth issue of Proof-of-Stake. The protocol is secure in the standard model and includes a spam prevention mechanism in the Random Oracle model."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [RAG, tree-based merger, module-based pre-processor, Darshan, TraceBench]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Chris Egersdoerfer, Arnav Sareen, Jean Luca Bez, Suren Byna, Dongkuan, Dong Dai"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Delaware, University of North Carolina at Charlotte, Lawrence Berkeley National Laboratory, The Ohio State University, North Carolina State University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.22017",children:"https://arxiv.org/pdf/2602.22017"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes IOAgent, a tool that uses LLMs to automate the diagnosis of I/O performance issues in HPC systems by analyzing Darshan trace files. It integrates a pre-processor, a RAG-based knowledge module, and a tree-based merger to provide accurate, referenced diagnoses. The evaluation shows it matches or outperforms existing tools and works with various LLMs."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260226] A task-based data-flow methodology for programming heterogeneous systems with multiple accelerator APIs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [task-based data-flow, directed acyclic graph (DAG), OpenMP/OmpSs-2, task-aware APIs (TA-libs), TACUDA, TASYCL, nOS-V, runtime interoperability]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Aleix Bon\xe9, Alejandro Aguirre, David \xc1lvarez, Pedro J. Martinez-Ferrer, Vicen\xe7 Beltran"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Barcelona Supercomputing Center (BSC), Universitat Polit\xe8cnica de Catalunya - BarcelonaTech (UPC)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21897",children:"https://arxiv.org/pdf/2602.21897"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes a task-based data-flow methodology using task-aware libraries (e.g., TACUDA, TASYCL) and the nOS-V threading library to seamlessly integrate multiple accelerator programming models (like CUDA and SYCL) within a single application. This approach manages computations as a DAG via a runtime system to avoid manual orchestration and thread contention. The results show that this method enables efficient and transparent use of diverse accelerators, mitigating performance interference and is applicable to current and future heterogeneous systems."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 17'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] On the Structural Non-Preservation of Epistemic Behaviour under Policy Transformation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21424",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] CCCaption: Dual-Reward Reinforcement Learning for Complete and Correct Image Captioning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21655",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Overconfident Errors Need Stronger Correction: Asymmetric Confidence Penalties for Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21420",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Self-Correcting VLA: Online Action Refinement via Sparse World Imagination ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21633",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Generalisation of RLHF under Reward Shift and Clipped KL Regularisation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21765",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Hierarchical Lead Critic based Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21680",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Two-Stage Active Distribution Network Voltage Control via LLM-RL Collaboration: A Hybrid Knowledge-Data-Driven Approach ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21715",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Alignment-Weighted DPO: A principled reasoning approach to improve safety alignment ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21346",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Tool-R0: Self-Evolving LLM Agents for Tool-Learning from Zero Data ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21320",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Evaluating the relationship between regularity and learnability in recursive numeral systems using Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21720",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21534",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] GradAlign: Gradient-Aligned Data Selection for LLM Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21492",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] ImpRIF: Stronger Implicit Reasoning Leads to Better Complex Instruction Following ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21228",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Training Generalizable Collaborative Agents via Strategic Risk Aversion ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21515",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Distill and Align Decomposition for Enhanced Claim Verification ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21857",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] SWE-Prot\xe9g\xe9: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.22124",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.22146",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 8'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] SymTorch: A Framework for Symbolic Distillation of Deep Neural Networks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21307",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Error-awareness Accelerates Active Automata Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21674",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Excitation: Momentum For Experts ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21798",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] AngelSlim: A more accessible, comprehensive, and efficient toolkit for large model compression ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21233",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Asymptotically Fast Clebsch-Gordan Tensor Products with Vector Spherical Harmonics ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21466",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] The Error of Deep Operator Networks Is the Sum of Its Parts: Branch-Trunk and Mode Error Decompositions ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21910",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Counterdiabatic Hamiltonian Monte Carlo ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21272",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260226] Towards single-shot coherent imaging via overlap-free ptychography ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.21361",children:"link"})]}),"\n"]})]})}function d(i={}){const{wrapper:e}={...(0,t.R)(),...i.components};return e?(0,s.jsx)(e,{...i,children:(0,s.jsx)(h,{...i})}):h(i)}},8453:(i,e,n)=>{n.d(e,{R:()=>a,x:()=>o});var r=n(6540);const s={},t=r.createContext(s);function a(i){const e=r.useContext(t);return r.useMemo(function(){return"function"==typeof i?i(e):{...e,...i}},[e,i])}function o(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(s):i.components||s:a(i.components),r.createElement(t.Provider,{value:e},i.children)}}}]);