"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[786],{8453:(i,e,n)=>{n.d(e,{R:()=>t,x:()=>l});var r=n(6540);const s={},a=r.createContext(s);function t(i){const e=r.useContext(a);return r.useMemo(function(){return"function"==typeof i?i(e):{...e,...i}},[e,i])}function l(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(s):i.components||s:t(i.components),r.createElement(a.Provider,{value:e},i.children)}},9880:(i,e,n)=>{n.r(e),n.d(e,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"daily/20260112-20260118","title":"20260112-20260118","description":"2026-01-12","source":"@site/docs/daily/20260112-20260118.md","sourceDirName":"daily","slug":"/daily/20260112-20260118","permalink":"/daily/20260112-20260118","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1768276593000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"20260105-20260111","permalink":"/daily/20260105-20260111"},"next":{"title":"Paper","permalink":"/category/paper"}}');var s=n(4848),a=n(8453);const t={},l="20260112-20260118",o={},d=[{value:"2026-01-12",id:"2026-01-12",level:2},{value:"2026-01-13",id:"2026-01-13",level:2}];function c(i){const e={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...i.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"20260112-20260118",children:"20260112-20260118"})}),"\n",(0,s.jsx)(e.h2,{id:"2026-01-12",children:"2026-01-12"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 5"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260112] LACIN: Linearly Arranged Complete Interconnection Networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [interconnection networks], [complete graph, isoport, wiring, routing, Dragonfly, HyperX]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Ram\xf3n Beivide, Crist\xf3bal Camarero, Carmen Mart\xednez, Enrique Vallejo, Mateo Valero"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Universidad de Cantabria, Barcelona Supercomputing Center"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05668",children:"https://arxiv.org/pdf/2601.05668"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces LACIN, a method for implementing Complete Interconnection Networks (CINs) by connecting switches using identically indexed ports (isoport). This approach simplifies network cabling and routing complexity. It facilitates the deployment of scalable networks from VLSI systems to large supercomputers."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260112] MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm training], [mixture-of-experts, memory wall, activation checkpointing, kernel co-design, token dispatch, memory-efficient training]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jiyuan Zhang, Yining Liu, Siqi Yan, Lisen Deng, Jennifer Cao, Shuqi Yang, Min Ni, Bi Xue, Shen Li"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Meta Platforms Inc, Thinking Machines Lab"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05296",children:"https://arxiv.org/pdf/2601.05296"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces MoEBlaze, a memory-efficient training framework for Mixture-of-Experts models that co-designs an end-to-end token dispatch method and optimized kernels to eliminate intermediate activation buffers and reduce memory footprint. The system achieves significant performance gains and memory savings, demonstrating over 4x speedups and over 50% memory reduction compared to existing frameworks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260112] Self-Evolving Distributed Memory Architecture for Scalable AI Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [distributed memory architecture, dual memory system, memory-guided matrix processing, memory-aware peer selection, runtime-adaptive deployment]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zixuan Li, Chuanzhen Wang, Haotian Sun"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Tongji University, Pacific Coast University, Northern Research Laboratory"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05569",children:"https://arxiv.org/pdf/2601.05569"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a Self-Evolving Distributed Memory Architecture, a three-layer framework that unifies memory management across computation, communication, and deployment layers using techniques like dynamic partitioning and a dual memory system. The experiments show it outperforms baselines like Ray Distributed in memory utilization, operational speed, and communication latency. The main conclusion is that coordinated, adaptive memory management across architectural layers is crucial for scalable and efficient distributed AI systems."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260112] Multi-Modal Style Transfer-based Prompt Tuning for Efficient Federated Domain Generalization"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [multi-modal training], [federated domain generalization, multi-modal style transfer, prompt tuning, dual-prompt module, domain-aware prompt generation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yuliang Chen, Xi Lin, Jun Wu, Xiangrui Cai, Qiaolun Zhang, Xichun Fan, Jiapeng Xu, Xiu Su"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Shanghai Jiao Tong University, Nankai University, Polytechnic Institute of Milan, New York University Shanghai, Central South University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05955",children:"https://arxiv.org/pdf/2601.05955"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes FaST-PT, a federated domain generalization framework that uses a lightweight Multi-Modal Style Transfer method for local feature augmentation and a dual-prompt module with Domain-aware Prompt Generation for efficient unseen domain adaptation. The method demonstrates superior performance over state-of-the-art FDG methods on benchmark datasets like PACS and DomainNet, validating its effectiveness and efficiency."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260112] Performance-Portable Optimization and Analysis of Multiple Right-Hand Sides in a Lattice QCD Solver"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [high-performance computing], [multiple right-hand sides, SIMD, data layout, auto-vectorization, GMRES, performance portability, SME]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Shiting Long, Gustavo Ramirez-Hidalgo, Stepan Nassyr, Jose Jimenez-Merchan, Andreas Frommer, Dirk Pleiter"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," KTH Royal Institute of Technology, Forschungszentrum J\xfclich GmbH, University of Wuppertal, University of Groningen"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05816",children:"https://arxiv.org/pdf/2601.05816"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper extends a lattice QCD solver to support multiple right-hand sides and optimizes it with a flexible data layout interface for better SIMD utilization. The optimizations are evaluated on x86 and Arm clusters, demonstrating performance portability and revealing insights into architectural constraints and compiler behavior. An early assessment of the Arm SME instruction set is also provided."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 19'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] WildSci: Advancing Scientific Reasoning from In-the-Wild Literature ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05567",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] On the Limits of Self-Improving in LLMs and Why AGI, ASI and the Singularity Are Not Near Without Symbolic Model Synthesis ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05280",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05836",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05475",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05257",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05870",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Do LLMs Need Inherent Reasoning Before Reinforcement Learning? A Study in Korean Self-Correction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05459",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05890",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05432",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05899",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05607",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05593",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Sequential Bayesian Optimal Experimental Design in Infinite Dimensions via Policy Gradient Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05868",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Autonomous Discovery of the Ising Model's Critical Parameters with Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05577",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05578",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05465",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05787",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Dual-Phase LLM Reasoning: Self-Evolved Mathematical Frameworks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05616",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05808",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 9'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05684",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05593",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05407",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05732",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] DNATokenizer: A GPU-First Byte-to-Identifier Tokenizer for High-Throughput DNA Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05531",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Influence of Parallelism in Vector-Multiplication Units on Correlation Power Analysis ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05828",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Tracing Stereotypes in Pre-trained Transformers: From Biased Neurons to Fairer Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05663",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] A Survey of Agentic AI and Cybersecurity: Challenges, Opportunities and Use-case Prototypes ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05293",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260112] Can We Predict Before Executing Machine Learning Agents? ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05930",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2026-01-13",children:"2026-01-13"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 18"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Behavioral Analytics for Continuous Insider Threat Detection in Zero-Trust Architectures"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [AdaBoost, SMOTE, PCA, SVM, ANN, Bayesian Network, behavioral analytics, insider threat detection]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Gaurav Sarraf"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Independent researcher"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06708",children:"https://arxiv.org/pdf/2601.06708"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a framework using behavioral analytics and machine learning for continuous insider threat detection in zero-trust architectures. It employs data preprocessing (SMOTE, PCA) and benchmarks classifiers, finding that an AdaBoost model achieves the highest performance (98% accuracy). The results demonstrate the effectiveness of AdaBoost-based analytics for reinforcing security in zero-trust settings."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] BlazeAIoT: A Modular Multi-Layer Platform for Real-Time Distributed Robotics Across Edge, Fog, and Cloud Infrastructures"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [Kubernetes, DDS, Kafka, Redis, ROS2, adaptive data distribution, hierarchical rate limiting, multi-layer configuration service]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Cedric Melancon, Julien Gascon-Samson, Maarouf Saad, Kuljeet Kaur, Simon Savard"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," \xc9cole de technologie sup\xe9rieure"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06344",children:"https://arxiv.org/pdf/2601.06344"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces BlazeAIoT, a modular platform that uses Kubernetes clusters and broker interoperability (e.g., DDS, Kafka) to unify distributed robotics across edge, fog, and cloud layers. It demonstrates that the platform can dynamically allocate services, maintain system health, and minimize latency, making it a scalable solution for real-time robotics and IoT applications."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Resource-Aware Task Allocator Design: Insights and Recommendations for Distributed Satellite Constellations"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed satellite systems], [Single-Level Tree Network (SLTN), resource-aware task allocator (RATA), blocking probability, solar-aware scheduling, energy consumption]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Bharadwaj Veeravalli"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," National University of Singapore"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06706",children:"https://arxiv.org/pdf/2601.06706"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper designs a Resource-Aware Task Allocator (RATA) for Distributed Satellite Systems using a Single-Level Tree Network architecture to manage real-time tasks. The empirical analysis shows that while system capacity increases with constellation size, blocking and delay grow non-linearly, and CPU availability, not energy, is the primary bottleneck causing task blocking."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] HiDVFS: A Hierarchical Multi-Agent DVFS Scheduler for OpenMP DAG Workloads"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [hierarchical multi-agent reinforcement learning, dynamic voltage and frequency scaling, OpenMP DAG scheduling, temperature-aware task allocation, makespan optimization]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Mohammad Pivezhandi, Abusayeed Saifullah, Ali Jannesari"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Iowa State University, University of Texas at Dallas"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06425",children:"https://arxiv.org/pdf/2601.06425"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes HiDVFS, a hierarchical multi-agent DVFS scheduler that optimizes task allocation and frequency scaling for OpenMP DAG workloads using profiling data and temperature sensors to prioritize makespan while reducing energy. Experiments on an NVIDIA Jetson TX2 show HiDVFS achieves significant speedup and energy reduction compared to existing methods."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] AIConfigurator: Lightning-Fast Configuration Optimization for Multi-Framework LLM Serving"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [performance modeling, configuration search, kernel-level database, GEMM, attention, communication, memory operations, distributed parallelism, tensor parallelism, pipeline parallelism, expert parallelism, CUDA graphs, KV-cache]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Tianhao Xu, Yiming Liu, Xianglong Lu, Yijia Zhao, Xuting Zhou, Aichen Feng, Yiyi Chen, Yi Shen, Qin Zhou, Xumeng Chen, Ilya Sherstyuk, Haorui Li, Rishi Thakkar, Ben Hamm, Yuanzhe Li, Xue Huang, Wenpeng Wu, Anish Shanbhag, Harry Kim, Chuan Chen, Junjie Lai"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," NVIDIA"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06288",children:"https://arxiv.org/pdf/2601.06288"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," AIConfigurator is a unified performance-modeling system that rapidly optimizes LLM inference configurations by decomposing inference into analytical primitives and using a calibrated kernel-level database, without requiring GPU profiling. It identifies configurations that improve performance by up to 40-50% for various models and completes searches within 30 seconds on average."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Privacy-Preserving Data Processing in Cloud : From Homomorphic Encryption to Federated Analytics"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [homomorphic encryption, secure multi-party computation, differential privacy, federated analytics, federated learning, hybrid privacy frameworks]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Gaurav Sarraf, Vibhor Pal"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Independent Researcher"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06710",children:"https://arxiv.org/pdf/2601.06710"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper reviews privacy-preserving data processing methods for cloud computing, including cryptographic techniques like homomorphic encryption and statistical approaches like differential privacy, as well as distributed frameworks like federated learning. It concludes by analyzing the trade-offs between security, efficiency, and accuracy in these methods and highlights the potential of hybrid frameworks to offer better privacy protection. The review serves as a crucial resource for understanding secure and effective solutions in data processing."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Rethinking Inter-Process Communication with Memory Operation Offloading"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [memory operation offloading, asynchronous pipelining, selective cache injection, hybrid coordination, shared-memory communication]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Misun Park, Richi Dubey, Yifan Yuan, Nam Sung Kim, Ada Gavrilovska"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Georgia Institute of Technology, Meta, University of Illinois\u2013Urbana-Champaign"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06331",children:"https://arxiv.org/pdf/2601.06331"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents ROCKET, a unified IPC runtime that integrates hardware- and software-based memory offloading into shared-memory communication to reduce CPU overhead from data copies. It introduces techniques like asynchronous pipelining and selective cache injection to coordinate offloading strategies. Evaluations show the system significantly reduces instruction counts, improves throughput, and lowers latency for modern data-intensive, multi-modal workloads."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Learning-Augmented Performance Model for Tensor Product Factorization in High-Order FEM"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [GPU kernels], [performance modeling, sum-factorization, tensor n-mode product, XGBoost, dependency-chain analysis, loop-body splitting, Roofline model, ECM model]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Xuanzhengbo Ren, Yuta Kawai, Tetsuya Hoshino, Hirofumi Tomita, Takahiro Katagiri, Daichi Mukunoki, Seiya Nishizawa"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Nagoya University, RIKEN R-CCS"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06886",children:"https://arxiv.org/pdf/2601.06886"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper develops a learning-augmented performance model for tensor product factorization kernels in high-order FEM. It combines an analytical dependency-chain formulation with XGBoost to estimate key parameters, focusing on instruction-level efficiency for loop-splitting configurations. The model significantly outperforms standard Roofline and ECM models in prediction accuracy on both Fujitsu A64FX and Intel Xeon processors."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] SkyNomad: On Using Multi-Region Spot Instances to Minimize AI Batch Job Cost"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [spot instances, multi-region scheduling, cost model, checkpoint-based recovery, deadline guarantee, migration]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zhifei Li, Tian Xia, Ziming Mao, Zihan Zhou, Ethan J. Jackson, Jamison Kerney, Zhanghao Wu, Pratik Mishra, Yi Xu, Yifan Qiao, Scott Shenker, Ion Stoica"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," UC Berkeley, Shanghai Jiao Tong University, AMD, ICSI"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06520",children:"https://arxiv.org/pdf/2601.06520"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," SkyNomad is a multi-region scheduling system that minimizes the cost of AI batch jobs by exploiting spatial and temporal heterogeneity in spot instance availability and prices, while guaranteeing deadlines. It uses lightweight probing, spot lifetime prediction, and a unified cost model to guide migration decisions between spot and on-demand instances. The evaluation shows it achieves significant cost savings (1.25-3.96x) in real deployments and performs close to an optimal policy in simulation."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Employ SmartNICs' Data Path Accelerators for Ordered Key-Value Stores"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed systems], [SmartNIC, Data Path Accelerators (DPAs), learned index, lock-free, PCIe, DMA, stateless clients, range queries]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Frederic Schimmelpfennig, Jan Sass, Reza Salkhordeh, Martin Kr\xf6ning, Stefan Lankes, Andr\xe9 Brinkmann"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Johannes Gutenberg University Mainz, RWTH Aachen University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06231",children:"https://arxiv.org/pdf/2601.06231"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces a key-value store that uses the Data Path Accelerators (DPAs) on a BlueField-3 SmartNIC to process requests directly, bypassing the host OS and minimizing PCIe crossings. It employs a lock-free learned index on the SmartNIC for efficient point and range queries, achieving high throughput. The analysis shows this architecture matches or exceeds state-of-the-art performance while suggesting hardware refinements for further acceleration."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [split computing, intermediate output integration, LiDAR, 3D object detection, edge computing, point cloud]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Taisuke Noguchi, Takayuki Nishio, Takuya Azumi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Saitama University, Institute of Science Tokyo"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07119",children:"https://arxiv.org/pdf/2601.07119"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes SC-MII, a split computing method for 3D object detection using multiple infrastructure LiDARs. Edge devices process initial DNN layers on local point clouds and send intermediate features to a server, which integrates them to complete inference. The approach significantly reduces edge device processing time and latency with minimal accuracy loss."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [distributed orchestration, resource allocation, task scheduling, three-service architecture]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Lei Zhang, Mouxiang Chen, Ruisheng Cao, Jiawei Chen, Fan Zhou, Yiheng Xu, Jiaxi Yang, Liang Chen, Changwei Luo, Kai Zhang, Fan Yan, KaShun Shum, Jiajun Zhang, Zeyu Cui, Hu Feng, Junyang Lin, Binyuan Hui, Min Yang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Alibaba Group"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07526",children:"https://arxiv.org/pdf/2601.07526"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces MegaFlow, a large-scale distributed orchestration system that abstracts agent training into three independent services (Model, Agent, and Environment) for flexible scaling and management. It successfully coordinates tens of thousands of concurrent agent tasks, addressing a critical infrastructure gap for training AI agents on complex tasks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Divergence-Based Adaptive Aggregation for Byzantine Robust Federated Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [divergence of degree, linear calibration, vetted root dataset, Byzantine attacks, client drift, federated averaging, non-convex models]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Bingnan Xiao, Feng Zhu, Jingjing Zhang, Wei Ni, Xin Wang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Fudan University, North Carolina State University, Edith Cowan University, University of New South Wales"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06903",children:"https://arxiv.org/pdf/2601.06903"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces two federated learning frameworks, DRAG and BR-DRAG, which use a divergence metric and linear calibration to align local model updates and mitigate client drift. BR-DRAG enhances this by using a trusted server dataset to defend against Byzantine attacks. The methods are proven to converge quickly under non-convex settings and are validated as effective against data heterogeneity and malicious attacks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Peformance Isolation for Inference Processes in Edge GPU Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [MPS, MIG, Green Contexts, temporal isolation, GPU partitioning, edge computing]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Juan Jos\xe9 Mart\xedn, Jos\xe9 Flich, Carles Hern\xe1ndez"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Universitat Polit\xe8cnica de Val\xe8ncia"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07600",children:"https://arxiv.org/pdf/2601.07600"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper analyzes GPU isolation mechanisms (MPS, MIG, Green Contexts) to ensure predictable inference times for deep learning models in safety-critical edge systems. The experimental evaluation on NVIDIA A100 and Jetson Orin platforms shows that MIG provides high isolation, while Green Contexts offer a promising low-overhead alternative for fine-grained SM allocation on edge devices, though without memory isolation."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] OpenTinker: Separating Concerns in Agentic Reinforcement Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm training], [reinforcement learning, large language model agents, separation of concerns, composable components, managed execution runtime, centralized scheduler, LoRA, full-parameter RL, supervised fine-tuning]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Siqi Zhu, Jiaxuan You"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Illinois Urbana-Champaign"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07376",children:"https://arxiv.org/pdf/2601.07376"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces OpenTinker, an infrastructure for RL of LLM agents that separates concerns into algorithm design, execution, and agent-environment interaction using lightweight, composable components. It features a centralized scheduler to manage diverse workloads like LoRA-based RL and inference over shared resources. The framework aims to lower the barrier for agentic RL by abstracting infrastructure, making it more reusable and accessible than monolithic pipelines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Advanced computing for reproducibility of astronomy Big Data Science, with a showcase of AMIGA and the SKA Science prototype"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [astronomy big data infrastructure], [semantic data models, federated infrastructures, reproducibility, SKA Regional Centre Network (SRCNet)]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Juli\xe1n Garrido, Susana S\xe1nchez, Edgar Ribeiro Jo\xe3o, Roger Ianjamasimanana, Manuel Parra, Lourdes Verdes-Montenegro"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Instituto de Astrof\xedsica de Andaluc\xeda, CSIC"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07439",children:"https://arxiv.org/pdf/2601.07439"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents the AMIGA group's research on using semantic data models and federated analysis services to address computing and reproducibility challenges for the SKA Observatory's Big Data. It concludes that for the SKAO to succeed, reproducibility requirements must be explicitly embedded into the fundamental architectural design of the SKA Regional Centre Network (SRCNet) to enable verifiable and sustainable research."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Bringing Computation to the data: Interoperable serverless function execution for astrophysical data analysis in the SRCNet"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [scientific computing, data-intensive workflows], [serverless computing, Function-as-a-Service (FaaS), data-proximate computation, Gaussian convolution, SKA Regional Centre Network (SRCNet)]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Manuel Parra-Roy\xf3n, Juli\xe1n Garrido-S\xe1nchez, Susana S\xe1nchez-Exp\xf3sito, Mar\xeda \xc1ngeles Mendoza, Rob Barnsley, Anthony Moraghan, Jes\xfas S\xe1nchez, Laura Darriba, Carlos Ru\xedz-Monje, Edgar Joao, Javier Mold\xf3n, Jes\xfas Salgado, Lourdes Verdes-Montenegro"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Instituto de Astrof\xedsica de Andaluc\xeda, Square Kilometre Array Observatory (SKAO), University of Sevilla, University of Manchester"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07308",children:"https://arxiv.org/pdf/2601.07308"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper explores the use of serverless Function-as-a-Service (FaaS) computing to enable interoperable, data-proximate astrophysical analysis within the SKA Regional Centre Network. It demonstrates the deployment of representative functions, such as Gaussian convolution, directly at data storage sites to reduce latency and transfers. The results indicate that serverless models provide a scalable and efficient approach for handling the massive data volumes expected from the Square Kilometre Array."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260113] Beyond Single-GPU: Scaling PDLP to Distributed Multi-GPU Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [GPU kernels], [PDHG, distributed multi-GPU, two-dimensional grid partitioning, NCCL, block-wise random shuffling, nonzero-aware data distribution, fused CUDA kernels]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Hongpei Li, Yicheng Huang, Huikang Liu, Dongdong Ge, Yinyu Ye"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Cardinal Operations, Shanghai University of Finance and Economics, Shanghai Jiao Tong University, Stanford University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07628",children:"https://arxiv.org/pdf/2601.07628"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents a distributed implementation of the Primal-Dual Hybrid Gradient (PDHG) algorithm for solving massive-scale linear programming problems. The method uses a two-dimensional grid partitioning of the constraint matrix and techniques like block-wise shuffling and fused CUDA kernels to scale across multiple GPUs with low communication overhead. The experiments show that this distributed framework overcomes single-GPU memory limits and achieves strong scalability and high performance while maintaining numerical accuracy."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 50'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Reinforcement Learning-Guided Dynamic Multi-Graph Fusion for Evacuation Traffic Prediction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06664",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Toward Safe and Responsible AI Agents: A Three-Pillar Model for Transparency, Accountability, and Trustworthiness ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06223",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] A Review of Online Diffusion Policy RL Algorithms for Scalable Robotic Control ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06133",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06052",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] KASER: Knowledge-Aligned Student Error Simulator for Open-Ended Coding Tasks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06633",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] TimeGNN-Augmented Hybrid-Action MARL for Fine-Grained Task Partitioning and Energy-Aware Offloading in MEC ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06191",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Thinking with Deltas: Incentivizing Reinforcement Learning via Differential Visual Reasoning Policy ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06801",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] HiMeS: Hippocampus-inspired Memory System for Personalized AI Assistants ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06152",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Plasticity vs. Rigidity: The Impact of Low-Rank Adapters on Reasoning on a Micro-Budget ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06677",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] GanitLLM: Difficulty-Aware Bengali Mathematical Reasoning through Curriculum-GRPO ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06767",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Object-Centric World Models Meet Monte Carlo Tree Search ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06604",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] COVR",":Collaborative"," Optimization of VLMs and RL Agent for Visual-Based Control ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06122",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06794",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] From RLHF to Direct Alignment: A Theoretical Unification of Preference Learning for Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06108",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06795",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Future-as-Label: Scalable Supervision from Real-World Outcomes ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06336",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Personality-Aware Reinforcement Learning for Persuasive Dialogue with LLM-Driven Simulation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06877",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Code Evolution for Control: Synthesizing Policies via LLM-Driven Evolutionary Search ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06845",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] The Impact of Post-training on Data Contamination ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06103",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] A Brain-like Synergistic Core in LLMs Drives Behaviour and Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06851",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Characterising Toxicity in Generative Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06700",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] How well can off-the-shelf LLMs elucidate molecular structures from mass spectra using chain-of-thought reasoning? ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06289",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Deep Q-Network Based Resilient Drone Communication",":Neutralizing"," First-Order Markov Jammers ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06095",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] ArenaRL: Scaling RL for Open-Ended Agents via Tournament-based Relative Ranking ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06487",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Distributional Clarity: The Hidden Driver of RL-Friendliness in Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06911",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06953",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] MEDVISTAGYM: A Scalable Training Environment for Thinking with Medical Images via Tool-Integrated Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07107",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07122",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] ENTRA: Entropy-Based Redundancy Avoidance in Large Language Model Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07123",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Generating readily synthesizable small molecule fluorophore scaffolds with reinforcement learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07145",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Rewarding Creativity: A Human-Aligned Generative Reward Model for Reinforcement Learning in Storytelling ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07149",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07160",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Offline Meta-Reinforcement Learning with Flow-Based Task Inference and Adaptive Correction of Feature Overgeneralization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07164",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07224",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07238",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] LRAS: Advanced Legal Reasoning with Agentic Search ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07296",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07304",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM Training ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07320",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07389",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Outcome-Grounded Advantage Reshaping for Fine-Grained Credit Assignment in Mathematical Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07408",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07463",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Graph Inference Towards ICD Coding ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07496",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07516",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Stagewise Reinforcement Learning and the Geometry of the Regret Landscape ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07524",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] GRPO with State Mutations: Improving LLM-Based Hardware Test Plan Generation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07593",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07718",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07782",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07821",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Large Language Models for Physics Instrument Design ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07580",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Reinforcement Learning for Micro-Level Claims Reserving ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07637",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 18'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] TeleMem: Building Long-Term and Multimodal Memory for Agentic AI ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06037",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Pareto-Optimal Model Selection for Low-Cost, Single-Lead EMG Control in Embedded Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06516",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Logic-Driven Semantic Communication for Resilient Multi-Agent Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06733",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Attention in Geometry: Scalable Spatial Modeling via Adaptive Density Fields and FAISS-Accelerated Kernels ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06135",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Bridging the AI divide in sub-Saharan Africa: Challenges and opportunities for inclusivity ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06145",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Lower Bounds for the Algorithmic Complexity of Learned Indexes ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06629",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06795",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Channel Knowledge Map Construction via Guided Flow Matching ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06156",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] MicLog: Towards Accurate and Efficient LLM-based Log Parsing via Progressive Meta In-Context Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07005",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Jasper: ANNS Quantized for Speed, Built for Change on GPU ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07048",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07160",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07263",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Software-Hardware Co-optimization for Modular E2E AV Paradigm: A Unified Framework of Optimization Approaches, Simulation Environment and Evaluation Metrics ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07393",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] PLANET v2.0: A comprehensive Protein-Ligand Affinity Prediction Model Based on Mixture Density Network ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07415",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Pheromone-Focused Ant Colony Optimization algorithm for path planning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07597",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Learning to accelerate Krasnosel'skii-Mann fixed-point iterations with guarantees ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07665",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] Match Made with Matrix Completion: Efficient Learning under Matching Interference ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.06982",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260113] A Model of Artificial Jagged Intelligence ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.07573",children:"link"})]}),"\n"]})]})}function h(i={}){const{wrapper:e}={...(0,a.R)(),...i.components};return e?(0,s.jsx)(e,{...i,children:(0,s.jsx)(c,{...i})}):c(i)}}}]);