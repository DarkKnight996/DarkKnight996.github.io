"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[513],{4793:(i,e,n)=>{n.r(e),n.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"daily/20251027-20251102","title":"20251027-20251102","description":"2025-10-27","source":"@site/docs/daily/20251027-20251102.md","sourceDirName":"daily","slug":"/daily/20251027-20251102","permalink":"/daily/20251027-20251102","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1761718130000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"20251020-20251026","permalink":"/daily/20251020-20251026"},"next":{"title":"Paper","permalink":"/category/paper"}}');var s=n(4848),a=n(8453);const t={},o="20251027-20251102",l={},c=[{value:"2025-10-27",id:"2025-10-27",level:2},{value:"2025-10-28",id:"2025-10-28",level:2},{value:"2025-10-29",id:"2025-10-29",level:2}];function h(i){const e={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...i.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"20251027-20251102",children:"20251027-20251102"})}),"\n",(0,s.jsx)(e.h2,{id:"2025-10-27",children:"2025-10-27"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv2510] Learning to Schedule: A Supervised Learning Framework for Network-Aware\nScheduling of Data-Intensive Workloads"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [scheduling], [network-aware scheduling, supervised learning, data-intensive workloads, Kubernetes, job completion time prediction]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Sankalpa Timilsina, Susmit Shannigrahi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Tennessee Technological University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"http://arxiv.org/pdf/2510.21419v1",children:"http://arxiv.org/pdf/2510.21419v1"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a network-aware job scheduler using supervised learning to predict job completion times based on real-time cluster telemetry. The system employs a prediction-and-ranking mechanism that evaluates nodes and selects optimal placements for data-intensive workloads. Evaluation on a geo-distributed Kubernetes cluster showed 34-54% higher accuracy in node selection compared to the default Kubernetes scheduler."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv2510] From SLA to vendor-neutral metrics: An intelligent knowledge-based\napproach for multi-cloud SLA-based broker"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [cloud computing, multi-cloud, SLA management, vendor-neutral metrics, intelligent knowledge-based system, auto-scaling]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," V\xedctor Ramp\xe9rez, Javier Soriano, David Lizcano, Shadi Aljawarneh, Juan A. Lara"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Universidad Polit\xe9cnica de Madrid (UPM), Madrid Open University (UDIMA)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"http://arxiv.org/pdf/2510.21173v1",children:"http://arxiv.org/pdf/2510.21173v1"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes an intelligent knowledge-based system that automatically translates high-level SLAs into vendor-neutral metrics for multi-cloud environments. The approach enables cross-provider metric measurement and provides consumer feedback through an intelligent tutoring system. Validation with IaaS and PaaS use cases demonstrates the system allows transparent multi-cloud exploitation across various application domains."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv2510] xMem: A CPU-Based Approach for Accurate Estimation of GPU Memory in Deep\nLearning Training Workloads"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [GPU memory estimation, dynamic analysis, resource management, scheduling]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jiabo Shi, Dimitrios Pezaros, Yehia Elkhatib"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Glasgow"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"http://arxiv.org/pdf/2510.21048v1",children:"http://arxiv.org/pdf/2510.21048v1"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," xMem proposes a CPU-based dynamic analysis framework to accurately estimate peak GPU memory requirements for deep learning training workloads without consuming GPU resources. The method achieves 91% reduction in median relative error and 75% reduction in OOM probability compared to existing solutions. This enables better GPU sharing and scheduling in cluster environments while significantly improving memory conservation potential."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv2510] Lincoln AI Computing Survey (LAICS) and Trends"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [Other models training, Other models inference], [AI accelerators, performance analysis, power consumption, market segmentation, computing architectures]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Albert Reuther, Peter Michaleas, Michael Jones, Vijay Gadepally, Jeremy Kepner"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," MIT Lincoln Laboratory"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"http://arxiv.org/pdf/2510.20931v1",children:"http://arxiv.org/pdf/2510.20931v1"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper updates the Lincoln AI Computing Survey by collecting performance and power consumption data of commercial AI accelerators, plotting them on scatter graphs, and analyzing market trends. It introduces a new categorization of computing architectures and examines how GenAI models have shifted computational demands toward matrix-vector operations and high memory bandwidth. The survey highlights ongoing innovations in AI hardware across various deployment scales from embedded systems to data centers."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv2510] ParaRNN: Unlocking Parallel Training of Nonlinear RNNs for Large\nLanguage Models"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [LLM training], [parallel training, nonlinear RNNs, sequence modeling, Newton's iterations, parallel reductions]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Federico Danieli, Pau Rodriguez, Miguel Sarabia, Xavier Suau, Luca Zappella"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Apple"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"http://arxiv.org/pdf/2510.21450v1",children:"http://arxiv.org/pdf/2510.21450v1"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," ParaRNN enables parallel training of nonlinear RNNs by formulating recurrence relationships as a system of equations and solving them using Newton's iterations with parallel reductions. This approach achieves up to 665x speedup over sequential methods and allows training 7B parameter RNNs with performance comparable to Transformers and Mamba2. The framework is released as open-source to facilitate scalable nonlinear RNN research."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv2510] REVE: A Foundation Model for EEG -- Adapting to Any Setup with\nLarge-Scale Pretraining on 25,000 Subjects"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [Other models training], [EEG foundation model, 4D positional encoding, masked autoencoding, brain-computer interfaces, clinical neuroscience]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yassine El Ouahidi, Jonathan Lys, Philipp Th\xf6lke, Nicolas Farrugia, Bastien Pasdeloup, Vincent Gripon, Karim Jerbi, Giulia Lioi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," IMT Atlantique, Universit\xe9 de Montr\xe9al, Mila, UNIQUE"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"http://arxiv.org/pdf/2510.21585v1",children:"http://arxiv.org/pdf/2510.21585v1"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," REVE introduces a novel 4D positional encoding scheme and uses masked autoencoding pretraining on 60,000 hours of EEG data from 25,000 subjects. The model achieves state-of-the-art performance across 10 EEG tasks including motor imagery and seizure detection. It demonstrates strong generalization with minimal fine-tuning and enables standardized EEG research through released code and weights."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2025-10-28",children:"2025-10-28"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 13"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Simopt-Power: Leveraging Simulation Metadata for Low-Power Design Synthesis"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [FPGA power optimization], [simulation metadata, Shannon Decomposition, activity profiling, truth table duplication, netlist transformation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Eashan Wadhwa, Shanker Shreejith"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Trinity College Dublin"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.21745",children:"https://arxiv.org/pdf/2510.21745"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents Simopt-Power, a framework that uses simulation metadata to identify high-toggle paths in FPGA designs and applies Shannon Decomposition to insert duplicate logic and relocate critical nets. The method achieves approximately 9% reduction in switching-induced power while adding only modest resource overhead. Results demonstrate that coupling simulation insights with targeted optimizations provides an effective approach for dynamic power reduction in FPGA design flows."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Separation of Unconscious Robots with Obstructed Visibility"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed robotics], [opaque robots, semicircle separation, look-compute-move cycle, semi-synchronous scheduler]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Prajyot Pyati, Navjot Kaur, Saswata Jana, Adri Bhattacharya, Partha Sarathi Mandal"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Indian Institute of Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.22434",children:"https://arxiv.org/pdf/2510.22434"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents a collision-free algorithm for unconscious robots with obstructed visibility that separates robots into concentric semicircles. The algorithm operates under a semi-synchronous scheduler and achieves separation in O(n) epochs. The robots coordinate without knowing the total number of robots but agree on one coordinate axis."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] When Agents are Powerful: Black Hole Search in Time-Varying Graphs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed algorithms], [global communication, 1-hop visibility, deterministic algorithms, mobile agents]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Tanvir Kaur, Ashish Saxena"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Indian Institute of Technology Ropar"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.22309",children:"https://arxiv.org/pdf/2510.22309"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper enhances Black Hole Search in dynamic graphs by equipping agents with global communication and 1-hop visibility capabilities. These improvements allow for more efficient solutions compared to previous face-to-face communication approaches. The enhanced agent capabilities reduce the number of agents required to successfully identify the black hole while ensuring at least one agent survives."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] A Feature Engineering Approach for Business Impact-Oriented Failure Detection in Distributed Instant Payment Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [feature engineering, anomaly detection, ISO 20022 message processing, processing time analysis, explainable AI]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Lorenzo Porcelli"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Bank of Italy, University of Salerno"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.21710",children:"https://arxiv.org/pdf/2510.21710"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces a feature engineering approach that computes processing times between consecutive ISO 20022 message exchanges to create system state representations for anomaly detection. The method enables early failure detection and incident classification in distributed instant payment systems. Experimental evaluation on TARGET Instant Payment Settlement demonstrates effectiveness in detecting diverse anomaly patterns while providing interpretable explanations for business impact assessment."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Heaven & Hell II: Scale Laws and Robustness in One-Step Heaven-Hell Consensus"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [ai], [network consensus], [Heaven-Hell dynamics, conservation-law perspective, tie-breaking policies, pointwise bounds, asynchronous updates, Coq proofs]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Nnamdi Daniel Aghanya, Romain Leemans"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Cranfield University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.21950",children:"https://arxiv.org/pdf/2510.21950"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper develops scale laws and operational refinements for Heaven-Hell consensus dynamics, using a conservation-law perspective to derive tighter bounds and robustness guarantees. The research establishes conditions for robust convergence under various scenarios including tie-breaking policies, asynchronous updates, and multiple hubs. All proofs are mechanized in Coq and experiments validate the tightness of the bounds across diverse network types."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Rethinking Inference Placement for Deep Learning across Edge and Cloud Platforms: A Multi-Objective Optimization Perspective and Future Directions"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [model offloading, model compression, model distillation, transmission compression, internal classifiers]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zongshun Zhang, Ibrahim Matta"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Boston University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.22909",children:"https://arxiv.org/pdf/2510.22909"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper surveys methods for optimizing deep learning inference placement across edge and cloud platforms using techniques like model partitioning, compression, and architecture adaptations. It analyzes how these approaches balance multiple objectives including latency, privacy, and monetary cost. The research concludes that effective inference placement requires multi-objective optimization across the computational continuum from devices to cloud."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] CodeAD: Synthesize Code of Rules for Log-based Anomaly Detection with LLMs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [hierarchical clustering, anchor-grounded sampling, agentic workflow, rule synthesis, contrastive log windows]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Junjie Huang, Minghua He, Jinyang Liu, Yintong Huo, Domenico Bianculli, Michael R. Lyu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The Chinese University of Hong Kong, Peking University, Singapore Management University, University of Luxembourg"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.22986",children:"https://arxiv.org/pdf/2510.22986"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," CodeAD automatically synthesizes lightweight Python rule functions for log-based anomaly detection using LLMs through hierarchical clustering and iterative agentic workflows. The framework achieves 3.6% higher F1 score than state-of-the-art methods while processing data 4x faster at minimal cost, providing an interpretable and efficient solution for real-time log analysis."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Power to the Clients: Federated Learning in a Dictatorship Setting"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [federated learning, byzantine clients, dictator clients, model convergence, attack strategies]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Mohammadsajad Alipour, Mohammad Mohammadi Amiri"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Rensselaer Polytechnic Institute"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.22149",children:"https://arxiv.org/pdf/2510.22149"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces dictator clients, a class of malicious participants in federated learning that can erase other clients' contributions while preserving their own. The authors propose attack strategies and analyze their effects on model convergence in various scenarios including collaboration and betrayal between multiple dictator clients. Their theoretical analysis and empirical evaluations demonstrate how these clients can significantly compromise the global model's integrity."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Sentinel: Dynamic Knowledge Distillation for Personalized Federated Intrusion Detection in Heterogeneous IoT Networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [personalized federated learning, knowledge distillation, dual-model architecture, class-balanced loss, gradient aggregation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Gurpreet Singh, Keshav Sood, P. Rajalakshmi, Yong Xiang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Deakin University, Indian Institute of Technology Hyderabad"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23019",children:"https://arxiv.org/pdf/2510.23019"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes Sentinel, a personalized federated intrusion detection system that uses a dual-model architecture with teacher-student knowledge distillation to handle data heterogeneity in IoT networks. It incorporates bidirectional distillation, feature alignment, and balanced loss functions to improve performance. Experiments show Sentinel outperforms existing methods while maintaining communication efficiency."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] AirFed: Federated Graph-Enhanced Multi-Agent Reinforcement Learning for Multi-UAV Cooperative Mobile Edge Computing"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [federated learning, graph attention networks, multi-agent reinforcement learning, trajectory planning, task offloading, resource allocation, gradient quantization]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zhiyu Wang, Suman Raj, Rajkumar Buyya"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The University of Melbourne, Indian Institute of Science"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23053",children:"https://arxiv.org/pdf/2510.23053"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes AirFed, a federated graph-enhanced multi-agent reinforcement learning framework that uses dual-layer Graph Attention Networks and a dual-Actor single-Critic architecture for UAV coordination in mobile edge computing. The system achieves significant improvements including 42.9% cost reduction, over 99% deadline satisfaction, and 54.5% lower communication overhead compared to state-of-the-art methods, demonstrating strong scalability for large-scale UAV deployments."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream Processing Pipelines"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [Hypergraph of Thoughts, multi-agent reasoning, resilient execution strategies, advanced query analysis]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Abolfazl Younesi, Zahra Najafabadi Samani, Thomas Fahringer"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Innsbruck"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23408",children:"https://arxiv.org/pdf/2510.23408"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," AutoStreamPipe uses Large Language Models with Hypergraph of Thoughts to automatically generate data stream processing pipelines from high-level user intents. The framework bridges the semantic gap between user requirements and platform-specific implementations through structured multi-agent reasoning. Experimental results show it significantly reduces development time by 6.3\xd7 and error rates by 5.19\xd7 compared to traditional LLM code-generation methods."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Bayes-Split-Edge: Bayesian Optimization for Constrained Collaborative Inference in Wireless Edge Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [Bayesian optimization, split learning, collaborative inference, wireless edge computing, constrained optimization, neural network splitting]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Fatemeh Zahra Safaeipour, Jacob Chakareski, Morteza Hashemi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Kansas, New Jersey Institute of Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23503",children:"https://arxiv.org/pdf/2510.23503"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes Bayes-Split-Edge, a Bayesian optimization framework that jointly optimizes transmission power and neural network split points for collaborative inference in wireless edge systems. The method uses a novel hybrid acquisition function to balance inference utility with energy and delay constraints. Results show it achieves 2.4\xd7 evaluation cost reduction compared to standard Bayesian optimization while matching exhaustive search performance under tight constraints."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] The First Star-by-star $N$-body/Hydrodynamics Simulation of Our Galaxy Coupling with a Surrogate Model"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [N-body simulation, smoothed-particle hydrodynamics, surrogate model, deep learning, Fugaku supercomputer]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Keiya Hirashima, Michiko S. Fujii, Takayuki R. Saitoh, Naoto Harada, Kentaro Nomura, Kohji Yoshikawa, Yutaka Hirai, Tetsuro Asano, Kana Moriwaki, Masaki Iwasawa, Takashi Okamoto, Junichiro Makino"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," RIKEN, University of Tokyo, Kobe University, Preferred Networks, University of Tsukuba, Tohoku University of Community Service and Science, Universitat de Barcelona, National Institute of Technology, Hokkaido University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23330",children:"https://arxiv.org/pdf/2510.23330"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents a novel integration scheme combining N-body/hydrodynamics simulations with machine learning surrogate models to bypass computational bottlenecks caused by supernova explosions. The method achieved 300 billion particles using 148,900 nodes, breaking the billion-particle barrier and enabling the first star-by-star galaxy simulation. This represents a major advancement in computational astrophysics by resolving individual stars in Milky Way simulations."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 52'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Transitive RL: Value Learning via Divide and Conquer ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22512",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Predictive Coding Enhances Meta-RL To Achieve Interpretable Bayes-Optimal Belief Representation Under Partial Observability ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22039",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Hazard-Responsive Digital Twin for Climate-Driven Urban Resilience and Equity ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22941",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22740",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22282",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Beyond Reasoning Gains: Mitigating General Capabilities Forgetting in Large Reasoning Models ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21978",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21758",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Advantage Shaping as Surrogate Reward Maximization: Unifying Pass@K Policy Gradients ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23049",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] PACR: Progressively Ascending Confidence Reward for LLM Reasoning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22255",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Is Temporal Difference Learning the Gold Standard for Stitching in RL? ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21995",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23038",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] FlowCritic: Bridging Value Estimation with Flow Matching in Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22686",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Offline Preference Optimization via Maximum Marginal Likelihood Estimation ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22881",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group Sequence Policy Optimization ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22477",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Dopamine-driven synaptic credit assignment in neural networks ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22178",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Activating Visual Context and Commonsense Reasoning through Masked Prediction in VLMs ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21807",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Towards Stable and Effective Reinforcement Learning for Mixture-of-Experts ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23027",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] UCB-type Algorithm for Budget-Constrained Expert Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22654",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Online Optimization for Offline Safe Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22027",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] GAPO: Group Adaptive Policy Optimization for Real-World Code Edit ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21830",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Guardian: Decoupling Exploration from Safety in Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22859",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] STAR-RIS-assisted Collaborative Beamforming for Low-altitude Wireless Networks ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22108",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22570",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Solving Continuous Mean Field Games: Deep Reinforcement Learning for Non-Stationary Dynamics ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22158",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22370",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22798",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Softmax is $1/2$-Lipschitz: A tight bound across all $\\ell_p$ norms ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23012",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22568",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Agentic Reinforcement Learning for Real-World Code Repair ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22075",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Computational Hardness of Reinforcement Learning with Partial $q^\u03c0$-Realizability ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21888",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Toward Agents That Reason About Their Computation ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22833",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable Reasoning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22543",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Do You Trust the Process?: Modeling Institutional Trust for Community Adoption of Reinforcement Learning Policies ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22017",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22832",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22319",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] SynCast: Synergizing Contradictions in Precipitation Nowcasting via Diffusion Sequential Preference Optimization ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21847",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Multi-Agent Conditional Diffusion Model with Mean Field Communication as Wireless Resource Allocation Planner ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22969",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Think before Recommendation: Autonomous Reasoning-enhanced Recommender ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23077",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Adapting Interleaved Encoders with PPO for Language-Guided Reinforcement Learning in BabyAI ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23148",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Guiding Skill Discovery with Foundation Models ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23167",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] TARC: Time-Adaptive Robotic Control ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23176",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23216",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23304",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N Sampling via max@k Optimisation ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23393",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Causal Deep Q Network ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23424",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] An Information-Theoretic Analysis of Out-of-Distribution Generalization in Meta-Learning with Applications to Meta-RL ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23448",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Learning to Reason Efficiently with Discounted Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23486",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Sequential Multi-Agent Dynamic Algorithm Configuration ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23535",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Multi-Agent Evolve: LLM Self-Improve through Co-evolution ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23595",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Right Place, Right Time: Market Simulation-based RL for Execution Optimisation ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22206",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Reinforcement learning-guided optimization of critical current in high-temperature superconductors ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22424",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] PASS-Enhanced MEC: Joint Optimization of Task Offloading and Uplink PASS Beamforming ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22948",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerat" total: 23'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21735",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Impact and Implications of Generative AI for Enterprise Architects in Agile Environments: A Systematic Literature Review ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22003",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Step2Motion: Locomotion Reconstruction from Pressure Sensing Insoles ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22712",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Accelerating Materials Design via LLM-Guided Evolutionary Search ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22503",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] PACR: Progressively Ascending Confidence Reward for LLM Reasoning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22255",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] AI-Enhanced Operator Assistance for UNICOS Applications ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21717",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Dopamine-driven synaptic credit assignment in neural networks ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22178",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] OpenEM: Large-scale multi-structural 3D datasets for electromagnetic methods ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21859",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Encoder-Decoder Diffusion Language Models for Efficient Training and Inference ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22852",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] QuArch: A Benchmark for Evaluating LLM Reasoning in Computer Architecture ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22087",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Residual-guided AI-CFD hybrid method enables stable and scalable simulations: from 2D benchmarks to 3D applications ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21804",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Graph-Coarsening Approach for the Capacitated Vehicle Routing Problem with Time Windows ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22329",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Approximate Gradient Coding for Distributed Learning with Heterogeneous Stragglers ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22539",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21879",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23127",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Guiding Skill Discovery with Foundation Models ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23167",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Accelerating Eigenvalue Dataset Generation via Chebyshev Subspace Filter ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23215",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Accelerating IC Thermal Simulation Data Generation via Block Krylov and Operator Action ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23221",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Progressive Growing of Patch Size: Curriculum Learning for Accelerated and Improved Medical Image Segmentation ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23241",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] PAHQ: Accelerating Automated Circuit Discovery through Mixed-Precision Inference Optimization ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23264",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Towards a Generalizable AI for Materials Discovery: Validation through Immersion Coolant Screening ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23371",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] HPC-Driven Modeling with ML-Based Surrogates for Magnon-Photon Dynamics in Hybrid Quantum Systems ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22221",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Reinforcement learning-guided optimization of critical current in high-temperature superconductors ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22424",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2025-10-29",children:"2025-10-29"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 14"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] Fault-Tolerant Multiparty Session Types with Global Escape Loops"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed systems], [multiparty session types, fault-tolerance, global escape loops, non-blocking messages, rotating coordinator algorithm]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Lukas Bartl, Julian Linne, Kirstin Peters"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Universit\xe4t Augsburg"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.24203",children:"https://arxiv.org/pdf/2510.24203"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper extends fault-tolerant multiparty session types with a novel global escape loop construct that allows processes to terminate distributed algorithms without global coordination. The approach uses non-blocking exit-messages to enable efficient fault-tolerant behavior in distributed systems. The method is demonstrated by analyzing a variant of the Chandra-Toueg rotating coordinator algorithm."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] CoMPSeT: A Framework for Comparing Multiparty Session Types"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [formal methods], [multiparty session types, choreographic languages, operational semantics]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Telmo Ribeiro, Jos\xe9 Proen\xe7a, M\xe1rio Florido"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Porto"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.24205",children:"https://arxiv.org/pdf/2510.24205"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces CoMPSeT, a framework for comparing different variations of Multiparty Session Types through feature combination and semantic animation. The tool provides mechanisms to analyze and contrast MPST implementations using concrete examples. CoMPSeT is implemented as an open-source web tool to help researchers understand MPST features and assist teachers in explaining global choreographies."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] Odyssey: An End-to-End System for Pareto-Optimal Serverless Query Processing"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [serverless data analytics], [query planning, cost model, execution engine, state space pruning, Pareto-optimal plans]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Shyam Jesalpura, Shengda Zhu, Amir Shaikhha, Antonio Barbalace, Boris Grot"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The University of Edinburgh"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.24307",children:"https://arxiv.org/pdf/2510.24307"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," Odyssey introduces an end-to-end serverless data analytics system that automatically generates and evaluates query plans using state space pruning and a novel search algorithm to find Pareto-optimal plans balancing cost and performance. The system consistently outperforms AWS Athena on both cost and latency metrics while accurately predicting monetary cost and query execution time."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [personalized federated learning, FedAvg, FLIU, client drift, out-of-distribution generalization, heterogeneous data]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Mortesa Hussaini, Jan Thei\xdf, Anthony Stein"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Hohenheim"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.24503",children:"https://arxiv.org/pdf/2510.24503"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes FLIU, a modified FedAvg approach with adaptive personalization factors, and evaluates both local performance and out-of-distribution generalization in personalized federated learning. The study finds that while personalized methods improve local performance, they inadequately address generalization capabilities compared to traditional federated learning. The research demonstrates the importance of balancing both local optimization and generalization in heterogeneous data environments."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] Differential Privacy: Gradient Leakage Attacks in Federated Learning Environments"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [Differential Privacy, DP-SGD, PDP-SGD, Gradient Leakage Attacks, Federated Learning]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Miguel Fernandez-de-Retana, Unai Zulaika, Rub\xe9n S\xe1nchez-Corcuera, Aitor Almeida"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Basque Center for Applied Mathematics, University of Deusto"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23931",children:"https://arxiv.org/pdf/2510.23931"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper evaluates differential privacy mechanisms (DP-SGD and PDP-SGD) as defenses against gradient leakage attacks in federated learning. The results show DP-SGD effectively mitigates reconstruction attacks with moderate utility trade-offs, while PDP-SGD maintains strong model performance but fails as a practical defense. These findings emphasize the need for empirical evaluation of privacy mechanisms beyond theoretical guarantees in distributed learning scenarios."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] SPEAR++: Scaling Gradient Inversion via Sparsely-Used Dictionary Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [gradient inversion attacks, sparsely-used dictionary learning, federated learning, ReLU activations, linear layers, FedAvg aggregation, DP noise robustness]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Alexander Bakarsky, Dimitar I. Dimitrov, Maximilian Baader, Martin Vechev"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"}),' ETH Zurich, INSAIT, Sofia University "St. Kliment Ohridski"']}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.24200",children:"https://arxiv.org/pdf/2510.24200"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," SPEAR++ improves upon the SPEAR gradient inversion attack by applying sparsely-used dictionary learning techniques to make the attack tractable for larger batch sizes. The new method maintains robustness to differential privacy noise and FedAvg aggregation while scaling to 10x larger batch sizes compared to the original SPEAR attack. This demonstrates practical vulnerability in federated learning systems even with privacy protections in place."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] Towards Exascale Computing for Astrophysical Simulation Leveraging the Leonardo EuroHPC System"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [astrophysical simulation], [GPU scaling, performance analysis, profiling tools, HPC optimization]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Nitin Shukla, Alessandro Romeo, Caterina Caravita, Michael Redenti, Radim Vavrik, Lubomir Riha, Andrea Mignone, Marco Rossazza, Stefano Truzzi, Luca Tornatore, Antonio Ragagnin, Tiago Castro, Geray S. Karademir, Klaus Dolag, Pranab J. Deka, Fabio Bacchini, Rostislav-Paul Wilhelm, Daniele Gregori, Elisabetta Boella"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," CINECA, IT4Innovations, University of Turin, INAF, Ludwig-Maximilians-Universit\xe4t M\xfcnchen, KU Leuven, E4 Computer Engineering"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.24175",children:"https://arxiv.org/pdf/2510.24175"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents performance optimization strategies for three astrophysical simulation codes (gPLUTO, OpenGadget3, iPIC3D) on the Leonardo EuroHPC system using profiling tools. The research demonstrates that all three codes achieve efficient scaling, reaching 80% scalability up to 1,024 GPUs, showing promising results for exascale computing in astrophysical simulations."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] ARIMA_PLUS: Large-scale, Accurate, Automatic and Interpretable In-Database Time Series Forecasting and Anomaly Detection in Google BigQuery"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [ARIMA_PLUS, time series forecasting, anomaly detection, BigQuery, SQL interface, modular structure, holiday effects, seasonality, trend]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Xi Cheng, Weijie Shen, Haoming Chen, Chaoyi Shen, Jean Ortega, Jiashang Liu, Steve Thomas, Honglin Zheng, Haoyun Wu, Yuxiang Li, Casey Lichtendahl, Jenny Ortiz, Gang Liu, Haiyang Qi, Omid Fatemieh, Chris Fry, Jing Jing Long"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Google"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.24452",children:"https://arxiv.org/pdf/2510.24452"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," ARIMA_PLUS is a novel framework that combines accurate time series models with scalable cloud infrastructure for forecasting and anomaly detection. It demonstrates superior accuracy over both statistical and neural network methods on benchmark datasets and achieves high throughput of over 18,000 time series per second when integrated into Google BigQuery. The system provides interpretable results through its modular structure handling holiday effects, seasonality, trend, and anomalies."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] The SAP Cloud Infrastructure Dataset: A Reality Check of Scheduling and Placement of VMs in Cloud Computing"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [cloud computing], [virtual machine scheduling, resource allocation, performance monitoring, workload management]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Arno Uhlig, Iris Braun, Matthias W\xe4hlisch"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," TU Dresden, SAP SE"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23911",children:"https://arxiv.org/pdf/2510.23911"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper analyzes VM scheduling and placement in SAP's cloud infrastructure using fine-grained telemetry data from 1,800 hypervisors and 48,000 VMs. The study identifies significant resource inefficiencies including CPU contention exceeding 40% and over 80% of VMs using less than 70% of allocated resources. Based on these findings, the authors derive requirements for improved scheduling algorithms and make their dataset publicly available for future research."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] A GPU-based Compressible Combustion Solver for Applications Exhibiting Disparate Space and Time Scales"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [computational fluid dynamics], [GPU optimization, AMReX framework, adaptive mesh refinement, bulk-sparse integration, column-major storage, roofline analysis]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Anthony Carreon, Jagmohan Singh, Shivank Sharma, Shuzhi Zhang, Venkat Raman"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Michigan"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23993",children:"https://arxiv.org/pdf/2510.23993"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents a GPU-optimized compressible combustion solver built on the AMReX framework that addresses performance bottlenecks through column-major storage, bulk-sparse chemical kinetics integration, and multi-GPU load balancing. The solver demonstrates 2-5\xd7 performance improvements over initial GPU implementations with near-ideal weak scaling across 1-96 NVIDIA H100 GPUs. Roofline analysis confirms substantial improvements in arithmetic intensity for both convection and chemistry routines, enabling efficient utilization of GPU resources for high-speed reacting flow simulations."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] PanDelos-plus: A parallel algorithm for computing sequence homology in pangenomic analysis"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [bioinformatics], [k-mer profiles, parallel computing, data decomposition, thread pool, lightweight data structures]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Simone Colli, Emiliano Maresi, Vincenzo Bonnici"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Parma"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23679",children:"https://arxiv.org/pdf/2510.23679"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," PanDelos-plus is a parallel algorithm that improves upon PanDelos by parallelizing computationally intensive phases using data decomposition and thread pools while employing lightweight data structures. Benchmarks show it achieves up to 14x faster execution and 96% reduced memory usage while maintaining accuracy. These improvements make large-scale bacterial pangenome analysis accessible for routine research on standard multicore workstations."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] Distributed Stochastic Momentum Tracking with Local Updates: Achieving Optimal Communication and Iteration Complexities"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [Local Momentum Tracking, momentum tracking, Loopless Chebyshev Acceleration, distributed optimization, communication complexity, iteration complexity]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Kun Huang, Shi Pu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The Chinese University of Hong Kong, Shenzhen"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.24155",children:"https://arxiv.org/pdf/2510.24155"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes Local Momentum Tracking (LMT), a distributed stochastic gradient method that combines local updates with momentum tracking and Loopless Chebyshev Acceleration to reduce communication overhead. LMT achieves linear speedup with respect to both local updates and number of agents, and attains optimal communication and iteration complexities depending on the number of local updates performed. This makes it the first method to simultaneously achieve these optimal complexity properties for distributed optimization over networks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] Exascale In-situ visualization for Astronomy & Cosmology"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [high-performance computing], [in-situ visualization, distributed database, streaming data, Hecuba framework, ChaNGa simulator]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Nicola Tuccari, Eva Sciacca, Yolanda Becerra, Enric Sosa Cintero, Emiliano Tramontana"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," INAF Astrophysical Observatory of Catania, Universit\xe0 di Catania, Barcelona Supercomputing Center"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.24545",children:"https://arxiv.org/pdf/2510.24545"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents an in-situ visualization approach using the Hecuba distributed database framework to stream astronomy and cosmology simulation data directly into visualization pipelines. By integrating Hecuba with the ChaNGa cosmological simulator, the method enables real-time visualization of N-body simulations using tools like ParaView and VisIVO. The approach successfully addresses the bottleneck of writing massive datasets to disk in exascale computing environments."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251029] In-Situ High Performance Visualization for Astronomy & Cosmology"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [high-performance computing visualization], [in-situ visualization, Hecuba framework, distributed database, ParaView, VisIVO, Changa simulator]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Nicola Tuccari, Eva Sciacca, Yolanda Becerra, Enric Sosa Cintero, Robert Wissing, Sijing Shen, Emiliano Tramontana"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," INAF Astrophysical Observatory of Catania, Universit\xe0 di Catania, Barcelona Supercomputing Center, University of Oslo"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.24547",children:"https://arxiv.org/pdf/2510.24547"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents an in-situ visualization approach using the Hecuba framework to process astronomy and cosmology simulation data concurrently with simulations, bypassing storage bottlenecks. The method integrates with the Changa cosmological simulator and visualization tools ParaView and VisIVO. The main conclusion is that this approach effectively handles petascale datasets by eliminating the need to store full simulation results while enabling real-time visualization."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 18'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24285",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Causal-Aware Generative Adversarial Networks with Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24046",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Latent Chain-of-Thought for Visual Reasoning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23925",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Survey and Tutorial of Reinforcement Learning Methods in Process Systems Engineering ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24272",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Sample-efficient and Scalable Exploration in Continuous-Time RL ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24482",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23882",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24461",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24235",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24020",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24151",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24432",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23868",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24431",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Debiasing Reward Models by Representation Learning with Guarantees ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23751",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Dual-Mind World Models: A General Framework for Learning in Dynamic Wireless Networks ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24546",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24650",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Learning to Drive Safely with Hybrid Options ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24674",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Greedy Sampling Is Provably Efficient for RLHF ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24700",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 12'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Fixed Point Neural Acceleration and Inverse Surrogate Model for Battery Parameter Identification ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24135",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Design and Optimization of Cloud Native Homomorphic Encryption Workflows for Privacy-Preserving ML Inference ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24498",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24085",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Causal-Aware Generative Adversarial Networks with Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24046",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point Arithmetic ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24061",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal Regression Trees ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23901",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24432",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Scalable GPU-Based Integrity Verification for Large Machine Learning Models ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23938",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Taming the Tail: NoI Topology Synthesis for Mixed DL Workloads on Chiplet-Based Accelerators ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24113",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23621",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] SymMaP: Improving Computational Efficiency in Linear Solvers through Symbolic Preconditioning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24170",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251029] Trajectory Design for UAV-Based Low-Altitude Wireless Networks in Unknown Environments: A Digital Twin-Assisted TD3 Approach ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.24255",children:"link"})]}),"\n"]})]})}function d(i={}){const{wrapper:e}={...(0,a.R)(),...i.components};return e?(0,s.jsx)(e,{...i,children:(0,s.jsx)(h,{...i})}):h(i)}},8453:(i,e,n)=>{n.d(e,{R:()=>t,x:()=>o});var r=n(6540);const s={},a=r.createContext(s);function t(i){const e=r.useContext(a);return r.useMemo(function(){return"function"==typeof i?i(e):{...e,...i}},[e,i])}function o(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(s):i.components||s:t(i.components),r.createElement(a.Provider,{value:e},i.children)}}}]);