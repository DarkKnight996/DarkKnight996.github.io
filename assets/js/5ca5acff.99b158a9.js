"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[513],{4793:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"daily/20251027-20251102","title":"20251027-20251102","description":"2025-10-27","source":"@site/docs/daily/20251027-20251102.md","sourceDirName":"daily","slug":"/daily/20251027-20251102","permalink":"/daily/20251027-20251102","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1761704882000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"20251020-20251026","permalink":"/daily/20251020-20251026"},"next":{"title":"Paper","permalink":"/category/paper"}}');var s=i(4848),a=i(8453);const t={},o="20251027-20251102",l={},d=[{value:"2025-10-27",id:"2025-10-27",level:2},{value:"2025-10-28",id:"2025-10-28",level:2},{value:"2025-10-29",id:"2025-10-29",level:2}];function c(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"20251027-20251102",children:"20251027-20251102"})}),"\n",(0,s.jsx)(n.h2,{id:"2025-10-27",children:"2025-10-27"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] Learning to Schedule: A Supervised Learning Framework for Network-Aware\nScheduling of Data-Intensive Workloads"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [scheduling], [network-aware scheduling, supervised learning, data-intensive workloads, Kubernetes, job completion time prediction]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Sankalpa Timilsina, Susmit Shannigrahi"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Tennessee Technological University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.21419v1",children:"http://arxiv.org/pdf/2510.21419v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a network-aware job scheduler using supervised learning to predict job completion times based on real-time cluster telemetry. The system employs a prediction-and-ranking mechanism that evaluates nodes and selects optimal placements for data-intensive workloads. Evaluation on a geo-distributed Kubernetes cluster showed 34-54% higher accuracy in node selection compared to the default Kubernetes scheduler."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] From SLA to vendor-neutral metrics: An intelligent knowledge-based\napproach for multi-cloud SLA-based broker"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [cloud computing, multi-cloud, SLA management, vendor-neutral metrics, intelligent knowledge-based system, auto-scaling]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," V\xedctor Ramp\xe9rez, Javier Soriano, David Lizcano, Shadi Aljawarneh, Juan A. Lara"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Universidad Polit\xe9cnica de Madrid (UPM), Madrid Open University (UDIMA)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.21173v1",children:"http://arxiv.org/pdf/2510.21173v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an intelligent knowledge-based system that automatically translates high-level SLAs into vendor-neutral metrics for multi-cloud environments. The approach enables cross-provider metric measurement and provides consumer feedback through an intelligent tutoring system. Validation with IaaS and PaaS use cases demonstrates the system allows transparent multi-cloud exploitation across various application domains."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] xMem: A CPU-Based Approach for Accurate Estimation of GPU Memory in Deep\nLearning Training Workloads"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [GPU memory estimation, dynamic analysis, resource management, scheduling]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Jiabo Shi, Dimitrios Pezaros, Yehia Elkhatib"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Glasgow"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.21048v1",children:"http://arxiv.org/pdf/2510.21048v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," xMem proposes a CPU-based dynamic analysis framework to accurately estimate peak GPU memory requirements for deep learning training workloads without consuming GPU resources. The method achieves 91% reduction in median relative error and 75% reduction in OOM probability compared to existing solutions. This enables better GPU sharing and scheduling in cluster environments while significantly improving memory conservation potential."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] Lincoln AI Computing Survey (LAICS) and Trends"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [Other models training, Other models inference], [AI accelerators, performance analysis, power consumption, market segmentation, computing architectures]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Albert Reuther, Peter Michaleas, Michael Jones, Vijay Gadepally, Jeremy Kepner"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," MIT Lincoln Laboratory"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.20931v1",children:"http://arxiv.org/pdf/2510.20931v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper updates the Lincoln AI Computing Survey by collecting performance and power consumption data of commercial AI accelerators, plotting them on scatter graphs, and analyzing market trends. It introduces a new categorization of computing architectures and examines how GenAI models have shifted computational demands toward matrix-vector operations and high memory bandwidth. The survey highlights ongoing innovations in AI hardware across various deployment scales from embedded systems to data centers."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] ParaRNN: Unlocking Parallel Training of Nonlinear RNNs for Large\nLanguage Models"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [LLM training], [parallel training, nonlinear RNNs, sequence modeling, Newton's iterations, parallel reductions]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Federico Danieli, Pau Rodriguez, Miguel Sarabia, Xavier Suau, Luca Zappella"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Apple"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.21450v1",children:"http://arxiv.org/pdf/2510.21450v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," ParaRNN enables parallel training of nonlinear RNNs by formulating recurrence relationships as a system of equations and solving them using Newton's iterations with parallel reductions. This approach achieves up to 665x speedup over sequential methods and allows training 7B parameter RNNs with performance comparable to Transformers and Mamba2. The framework is released as open-source to facilitate scalable nonlinear RNN research."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] REVE: A Foundation Model for EEG -- Adapting to Any Setup with\nLarge-Scale Pretraining on 25,000 Subjects"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [Other models training], [EEG foundation model, 4D positional encoding, masked autoencoding, brain-computer interfaces, clinical neuroscience]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Yassine El Ouahidi, Jonathan Lys, Philipp Th\xf6lke, Nicolas Farrugia, Bastien Pasdeloup, Vincent Gripon, Karim Jerbi, Giulia Lioi"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," IMT Atlantique, Universit\xe9 de Montr\xe9al, Mila, UNIQUE"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.21585v1",children:"http://arxiv.org/pdf/2510.21585v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," REVE introduces a novel 4D positional encoding scheme and uses masked autoencoding pretraining on 60,000 hours of EEG data from 25,000 subjects. The model achieves state-of-the-art performance across 10 EEG tasks including motor imagery and seizure detection. It demonstrates strong generalization with minimal fine-tuning and enables standardized EEG research through released code and weights."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"2025-10-28",children:"2025-10-28"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary\nWeights and Distilled Knowledge"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [Other models inference], [model compression, ternary quantization, knowledge distillation, vision-language models, CLIP]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Shu-Hao Zhang, Wei-Cheng Tang, Chen Wu, Peng Hu, Nan Li, Liang-Jie Zhang, Qi Zhang, Shao-Qun Zhang"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Nanjing University, Microsoft"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.21879v1",children:"http://arxiv.org/pdf/2510.21879v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," TernaryCLIP converts CLIP model weights to ternary format using quantization-aware training and knowledge distillation. The method achieves 99% ternarization with 1.58-bit representation while maintaining performance on zero-shot tasks. This enables efficient deployment on resource-constrained devices with significant compression and acceleration benefits."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] Encoder-Decoder Diffusion Language Models for Efficient Training and\nInference"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [LLM inference], [diffusion models, encoder-decoder architecture, efficient inference, parallel token sampling, block diffusion]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Marianne Arriola, Yair Schiff, Hao Phung, Aaron Gokaslan, Volodymyr Kuleshov"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Cornell University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.22852v1",children:"http://arxiv.org/pdf/2510.22852v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an encoder-decoder architecture for discrete diffusion language models that separates clean token representation from denoising computation. The method enables faster training and inference by using a lightweight decoder for iterative refinement while periodically updating encoder representations. Experimental results show superior trade-offs between generation quality and inference throughput on summarization, translation, and mathematical reasoning tasks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] Dopamine-driven synaptic credit assignment in neural networks"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [Other models training], [neural networks, credit assignment problem, dopamine optimizer, weight perturbation, reinforcement learning, adaptive learning rate, neuroAI]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Saranraj Nambusubramaniyan, Shervin Safavi, Raja Guru, Andreas Knoblauch"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Ulm, University of T\xfcbingen"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.22178v1",children:"http://arxiv.org/pdf/2510.22178v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces a dopamine-inspired derivative-free optimizer for neural networks that uses weight perturbation and reward prediction error to adapt learning rates. This method achieves comparable performance to gradient-based algorithms while being more computationally efficient and biologically plausible. The optimizer demonstrates accelerated convergence in XOR tasks and chaotic time series forecasting with reduced memory and computation requirements."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] Impact and Implications of Generative AI for Enterprise Architects in\nAgile Environments: A Systematic Literature Review"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [generative AI, enterprise architecture, agile environments, systematic literature review, architectural decision support, prompt engineering]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Stefan Julian Kooy, Jean Paul Sebastian Piest, Rob Henk Bemthuis"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Twente"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.22003v1",children:"http://arxiv.org/pdf/2510.22003v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper conducts a systematic literature review of 1,697 records to analyze the impact of Generative AI on enterprise architects in agile environments. The study identifies key use cases including design ideation, artifact creation, and architectural decision support, while highlighting risks like opacity, bias, and compliance concerns. The findings provide implications for capability building, governance, and establish a research agenda for human-AI collaboration in enterprise architecture."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] To Use or to Refuse? Re-Centering Student Agency with Generative AI in\nEngineering Design Education"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [generative AI, engineering education, design thinking, reflective practice, student agency]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Thijs Willems, Sumbul Khan, Qian Huang, Bradley Camburn, Nachamma Sockalingam, King Wang Poon"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Singapore University of Technology and Design"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.19342v1",children:"http://arxiv.org/pdf/2510.19342v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This study implemented a three-way framework (tool/teammate/non-use) in an AI-enhanced engineering design course to analyze student interactions with generative AI. Students developed practices like accelerated prototyping, prompt refinement, and hallucination recognition while learning to strategically reject AI outputs. The approach transformed AI efficiency into innovation by cultivating selective usage and deeper user research, making AI uptake an assessable design habit."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] PACR: Progressively Ascending Confidence Reward for LLM Reasoning"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [LLM training], [reinforcement learning, reasoning, confidence reward, exploration efficiency, model-intrinsic supervision]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Eunseop Yoon, Hee Suk Yoon, Jaehyun Jang, SooHwan Eom, Qi Dai, Chong Luo, Mark A. Hasegawa-Johnson, Chang D. Yoo"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Korea Advanced Institute of Science and Technology (KAIST), Microsoft Research Asia (MSRA), University of Illinois at Urbana-Champaign (UIUC)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.22255v1",children:"http://arxiv.org/pdf/2510.22255v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes PACR, a dense reward signal based on the model's progressively ascending confidence in the correct answer during reasoning. This method accelerates exploration and improves training efficiency in reinforcement learning with verifiable rewards. Results show PACR achieves better performance with fewer trajectories across multiple benchmarks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] Step2Motion: Locomotion Reconstruction from Pressure Sensing Insoles"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [Other models inference], [motion reconstruction, pressure sensing insoles, wearable sensors, locomotion analysis, IMU data]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Jose Luis Ponton, Eduardo Alvarado, Lin Geng Foo, Nuria Pelechano, Carlos Andujar, Marc Habermann"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Universitat Polit\xe8cnica de Catalunya, Max Planck Institute for Informatics"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.22712v1",children:"http://arxiv.org/pdf/2510.22712v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," Step2Motion reconstructs human locomotion using multi-modal data from sensor insoles combining pressure measurements and inertial data (accelerations and angular rates). The method demonstrates robust performance across diverse locomotion styles including walking, jogging, dancing and crouching movements. This approach enables unconstrained motion capture in real-world environments without line-of-sight limitations or movement restrictions."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] QuArch: A Benchmark for Evaluating LLM Reasoning in Computer\nArchitecture"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [LLM inference], [computer architecture, benchmark, reasoning evaluation, question-answering]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Shvetank Prakash, Andrew Cheng, Arya Tschand, Mark Mazumder, Varun Gohil, Jeffrey Ma, Jason Yik, Zishen Wan, Jessica Quaye, Elisavet Lydia Alvanaki, Avinash Kumar, Chandrashis Mazumdar, Tuhin Khare, Alexander Ingare, Ikechukwu Uchendu, Radhika Ghosal, Abhishek Tyagi, Chenyu Wang, Andrea Mattia Garavagno, Sarah Gu, Alice Guo, Grace Hur, Luca Carloni, Tushar Krishna, Ankita Nayak, Amir Yazdanbakhsh, Vijay Janapa Reddi"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Harvard University, Massachusetts Institute of Technology, Georgia Institute of Technology, Columbia University, University of Texas at Austin, UC Santa Cruz, University of Rochester, University of Genoa, Scuola Superiore Sant'Anna, Qualcomm AI Research, Google DeepMind"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.22087v1",children:"http://arxiv.org/pdf/2510.22087v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces QuArch, the first benchmark with 2,671 expert-validated QA pairs for evaluating LLM reasoning in computer architecture. The evaluation shows frontier models possess domain knowledge but struggle with higher-order architectural reasoning, achieving accuracies between 34%-72%. This community-developed benchmark establishes foundational standards for measuring LLM capabilities in computer architecture."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] AndroidControl-Curated: Revealing the True Potential of GUI Agents\nthrough Benchmark Purification"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training], [GUI agents, benchmark purification, on-device models, AndroidControl-Curated, Magma-R1 model]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Ho Fai Leung, Xiaoyan Xi, Fei Zuo"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," BMW ArcherMind Information Technology Co. Ltd. (BA TechWorks)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.18488v1",children:"http://arxiv.org/pdf/2510.18488v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies flaws in existing GUI agent benchmarks and creates AndroidControl-Curated through a purification pipeline. It develops Magma-R1-3B model via post-training on curated samples, achieving 75.3% success rate comparable to much larger models. The work demonstrates that GUI agents are more capable than previously measured and closer to practical deployment."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] CosmoCore Affective Dream-Replay Reinforcement Learning for Code\nGeneration"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training], [reinforcement learning, code generation, affective computing, hallucination mitigation, experience replay]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Santhosh Kumar Ravindran"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Microsoft Corporation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.18895v1",children:"http://arxiv.org/pdf/2510.18895v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," CosmoCore introduces an affective reinforcement learning framework that tags code generation trajectories with valence and surprise signals to prioritize replay of error episodes. This neuroscience-inspired approach reduces hallucinated code by 48% and accelerates self-correction by 45% in benchmarks. The system enhances traditional RLHF by incorporating emotional cues for more robust code generation in LLMs."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] DynaQuery: A Self-Adapting Framework for Querying Structured and\nMultimodal Data"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [LLM inference], [natural language querying, structured databases, multimodal data, schema linking, query planning, retrieval-augmented generation]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Aymane Hassini"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Al Akhawayn University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.18029v1",children:"http://arxiv.org/pdf/2510.18029v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," DynaQuery introduces a self-adapting framework with a Schema Introspection and Linking Engine (SILE) that enhances schema linking in query planning for structured and multimodal databases. It demonstrates superior robustness compared to unstructured RAG approaches by nearly eliminating catastrophic failures like schema hallucination. The framework provides a validated basis for developing reliable natural language database interfaces."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] Approximate Gradient Coding for Distributed Learning with Heterogeneous\nStragglers"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [Other models training], [gradient coding, distributed learning, straggler mitigation, optimization, convergence analysis]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Heekang Song, Wan Choi"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Korea Advanced Institute of Science and Technology, Seoul National University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.22539v1",children:"http://arxiv.org/pdf/2510.22539v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an optimized gradient coding scheme that minimizes residual error while ensuring unbiased gradient estimation by explicitly considering heterogeneous straggler probabilities. The authors derive closed-form solutions for encoding/decoding coefficients and develop data allocation strategies to reduce redundancy and computation load. Numerical results demonstrate that their approach significantly reduces straggler impact and accelerates convergence compared to existing methods."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv2510] FineVision: Open Data Is All You Need"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [Other models training], [vision-language models, dataset curation, data decontamination, human-in-the-loop pipeline, multi-modal datasets]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Luis Wiedmann, Orr Zohar, Amir Mahla, Xiaohan Wang, Rui Li, Thibaud Frere, Leandro von Werra, Aritra Roy Gosthipaty, Andr\xe9s Marafioti"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Hugging Face, Technical University Munich, Stanford University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"http://arxiv.org/pdf/2510.17269v1",children:"http://arxiv.org/pdf/2510.17269v1"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," FineVision introduces a semi-automated human-in-the-loop pipeline to create a unified vision-language dataset of 24 million samples from over 200 sources, featuring rigorous de-duplication and decontamination. The method combines automated processing with human oversight for quality control and schema validation. Models trained on this curated dataset consistently outperform those using existing open mixtures, demonstrating the value of scale and data hygiene in vision-language model development."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"2025-10-29",children:"2025-10-29"}),"\n",(0,s.jsx)(n.p,{children:"No interesting papers for me today"})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var r=i(6540);const s={},a=r.createContext(s);function t(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);