"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[372],{54:(i,n,e)=>{e.r(n),e.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>d,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"daily/20260105-20260111","title":"20260105-20260111","description":"2026-01-05","source":"@site/docs/daily/20260105-20260111.md","sourceDirName":"daily","slug":"/daily/20260105-20260111","permalink":"/daily/20260105-20260111","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1769568961000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"20251229-20260104","permalink":"/daily/20251229-20260104"},"next":{"title":"20260112-20260118","permalink":"/daily/20260112-20260118"}}');var s=e(4848),a=e(8453);const t={},l="20260105-20260111",o={},c=[{value:"2026-01-05",id:"2026-01-05",level:2},{value:"2026-01-06",id:"2026-01-06",level:2},{value:"2026-01-07",id:"2026-01-07",level:2},{value:"2026-01-08",id:"2026-01-08",level:2},{value:"2026-01-09",id:"2026-01-09",level:2}];function h(i){const n={a:"a",annotation:"annotation",h1:"h1",h2:"h2",header:"header",li:"li",math:"math",mi:"mi",mn:"mn",mrow:"mrow",msup:"msup",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,a.R)(),...i.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"20260105-20260111",children:"20260105-20260111"})}),"\n",(0,s.jsx)(n.h2,{id:"2026-01-05",children:"2026-01-05"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"cs.DC total: 9"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260105] From Consensus to Chaos: A Vulnerability Assessment of the RAFT Algorithm"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [distributed consensus], [RAFT, message replay attacks, message forgery, cryptography, authenticated message verification, freshness check]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Tamer Afifi, Abdelfatah Hegazy, Ehab Abousaif"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Arab Academy for Science, Technology & Maritime"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00273",children:"https://arxiv.org/pdf/2601.00273"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper conducts a security analysis of the RAFT distributed consensus algorithm, identifying vulnerabilities to replay and forgery attacks. It proposes a novel security enhancement framework using cryptography, authenticated message verification, and freshness checks to protect against these threats and build more resilient systems."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260105] Federated Customization of Large Models: Approaches, Experiments, and Insights"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [federated learning, prefix-tuning, fine-tuning, prompt engineering, knowledge distillation, retrieval-augmented generation]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Yuchuan Ye, Ming Ding, Youjia Chen, Peng Cheng, Dusit Niyato"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Fuzhou University, CSIRO Data61, La Trobe University, Nanyang Technological University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00526",children:"https://arxiv.org/pdf/2601.00526"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper explores federated customization of large models, reviewing techniques like fine-tuning and prefix-tuning within a federated learning framework. It experimentally validates federated prefix-tuning, showing it achieves performance close to centralized approaches with competitive efficiency and robustness."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260105] Cost-Performance Analysis of Cloud-Based Retail Point-of-Sale Systems: A Comparative Study of Google Cloud Platform and Microsoft Azure"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [cloud computing], [benchmarking, cost-performance analysis, scalability, response latency, throughput, API endpoints]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Ravi Teja Pagidoju"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Campbellsville University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00530",children:"https://arxiv.org/pdf/2601.00530"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents a systematic, code-driven benchmarking methodology to compare the performance and cost of deploying retail Point-of-Sale workloads on Google Cloud Platform and Microsoft Azure using free-tier resources. The main conclusion is that GCP offers 23.0% faster response times, while Azure demonstrates 71.9% higher cost efficiency for steady-state operations."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260105] Secure, Verifiable, and Scalable Multi-Client Data Sharing via Consensus-Based Privacy-Preserving Data Distribution"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [secure multi-party computation], [affine masking, consensus locking, step checksums, data checksums, IND-CPA security]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Prajwal Panth, Sahaj Raj Malla"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," KIIT University, Kathmandu University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00418",children:"https://arxiv.org/pdf/2601.00418"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes the Consensus-Based Privacy-Preserving Data Distribution (CPPDD) framework, which uses per-client affine masking and sequential consensus locking for secure multi-client data aggregation with verifiable integrity. It demonstrates linear scalability up to 500 clients, achieves 100% malicious deviation detection, and significantly reduces computational overhead compared to MPC and HE baselines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260105] Impact of Clustering on the Observability and Controllability of Complex Networks"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [network theory], [structured systems theory, Monte-Carlo simulations, clustering, scale-free networks, graph theory]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Mohammadreza Doostmohammadian, Hamid R. Rabiee"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Semnan University, Sharif University of Technology"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00221",children:"https://arxiv.org/pdf/2601.00221"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper uses structured systems theory and Monte-Carlo simulations to study how clustering affects the observability and controllability of scale-free networks. It concludes that densely clustered networks require fewer driver and observer nodes for control and observation, offering practical insights for optimizing network design in resource-constrained applications."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260105] Word Frequency Counting Based on Serverless MapReduce"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [serverless computing, mapreduce, function as a service (faas), word frequency counting, optimization]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Hanzhe Li, Bingchen Lin, Mengyuan Xu"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Xi\u2019an Jiaotong University, Chongqing University of Education, Qilu Institute of Technology"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00380",children:"https://arxiv.org/pdf/2601.00380"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes using a serverless MapReduce model on a Function-as-a-Service platform to optimize word frequency counting tasks. It focuses on determining the optimal number of map and reduce functions to minimize execution time and improve efficiency. The experiments show that increasing the number of functions improves performance, providing a method to find optimized configurations for such tasks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260105] Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [time-warp emulation, CUDA API interception, discrete-event simulation, virtual time coordination]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Amey Agrawal, Mayank Yadav, Sukrit Kumar, Anirudha Agrawal, Garv Ghai, Souradeep Bera, Elton Pinto, Sirish Gambhira, Mohammad Adain, Kasra Sohrab, Chus Antonanzas, Alexey Tumanov"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Georgia Institute of Technology"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00397",children:"https://arxiv.org/pdf/2601.00397"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents Revati, a GPU-free time-warp emulator for LLM serving that directly executes real serving system code by intercepting CUDA calls and performing virtual time jumps instead of running actual GPU kernels. It introduces a coordination protocol to synchronize these time jumps across distributed processes. The system achieves less than 5% prediction error and runs 5-17x faster than real GPU execution on frameworks like vLLM and SGLang."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260105] FlexSpec: Frozen Drafts Meet Evolving Targets in Edge-Cloud Collaborative LLM Speculative Decoding"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [speculative decoding, edge-cloud collaboration, shared-backbone architecture, channel-aware adaptive speculation]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Yuchen Li, Rui Kong, Zhonghao Lyu, Qiyang Li, Xinran Chen, Hengyi Cai, Lingyong Yan, Shuaiqiang Wang, Jiashu Zhao, Guangxu Zhu, Linghe Kong, Guihai Chen, Haoyi Xiong, Dawei Yin"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Baidu Inc., Shanghai Jiao Tong University, KTH Royal Institute of Technology, Wilfrid Laurier University, Shenzhen Research Institute of Big Data"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00644",children:"https://arxiv.org/pdf/2601.00644"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes FlexSpec, a framework for edge-cloud collaborative inference that uses a static, shared-backbone draft model at the edge to work with evolving target models in the cloud, eliminating the need for frequent model synchronization. It also introduces a channel-aware mechanism to dynamically adjust the draft length based on network conditions. Experiments show that FlexSpec improves inference efficiency over conventional speculative decoding approaches."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260105] Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [multi-agent systems, language model agents, bio-inspired self-healing, distributed computing continuum, fault diagnosis, resource reconfiguration]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Alaa Saleh, Praveen Kumar Donta, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Qiyang Zhang, Schahram Dustdar Susanna Pirttikangas, Lauri Lov\xe9n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Oulu, Stockholm University, EURECOM, University of Helsinki, RISE Research Institutes of Sweden, Lule\xe5 University of Technology, Peking University, TU Wien"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00339",children:"https://arxiv.org/pdf/2601.00339"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces ReCiSt, a bio-inspired self-healing framework for resilient distributed computing systems. It uses language model-powered agents across four computational layers to autonomously isolate faults, diagnose causes, and reconfigure resources. The evaluation demonstrates the framework's ability to perform self-healing within tens of seconds with low CPU overhead."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 15'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00186",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] Online Finetuning Decision Transformers with Pure RL Gradients ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00167",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] Can Optimal Transport Improve Federated Inverse Reinforcement Learning? ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00309",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00737",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] Reinforcement Learning with Function Approximation for Non-Markov Processes ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00151",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00607",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00245",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00538",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00116",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00423",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00677",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00257",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] Reinforcement learning with timed constraints for robotics motion planning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00087",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00728",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] ARISE: Adaptive Reinforcement Integrated with Swarm Exploration ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00693",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 1'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[arXiv260105] Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00282",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"2026-01-06",children:"2026-01-06"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"cs.DC total: 19"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] pMSz: A Distributed Parallel Algorithm for Correcting Extrema and Morse Smale Segmentations in Lossy Compression"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [high-performance computing], [distributed parallel algorithm, Morse-Smale segmentation, lossy compression, integral paths, steepest ascending directions, GPU]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Yuxiao Li, Mingze Xia, Xin Liang, Bei Wang, Robert Underwood, Sheng Di, Hemant Sharma, Dishant Beniwal, Franck Cappello, Hanqi Guo"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," The Ohio State University, Argonne National Laboratory, Oregon State University, University of Utah"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01787",children:"https://arxiv.org/pdf/2601.01787"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces pMSz, a distributed parallel algorithm that corrects topological distortions in lossy-compressed scientific data by preserving steepest ascending and descending directions instead of explicitly computing integral paths. This approach minimizes communication and achieves high parallel efficiency, scaling effectively to 128 GPUs on the Perlmutter supercomputer."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [Singleton Weight Sharing, Topological Synapse, KV-cache sparsification, witness complex, hybrid landmarking, Referential Injection]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Jorge L. Ruiz Williams"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Warp Research"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01298",children:"https://arxiv.org/pdf/2601.01298"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces Warp Cortex, an asynchronous architecture for multi-agent LLMs that decouples agent logic from memory to enable massive scaling. Its core methods include Singleton Weight Sharing and a Topological Synapse for KV-cache sparsification, reducing memory complexity. The authors demonstrate the system can support 100 concurrent agents on a single consumer GPU, with a theoretical capacity for over 1,000 agents."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] RelayGR: Scaling Long-Sequence Generative Recommendation via Cross-Stage Relay-Race Inference"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [KV cache, cross-stage relay-race inference, sequence-aware trigger, affinity-aware router, memory-aware expander]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Jiarui Wang, Huichao Chai, Yuanhang Zhang, Zongjin Zhou, Wei Guo, Xingkun Yang, Qiang Tang, Bo Pan, Jiawei Zhu, Ke Cheng, Yuting Yan, Shulan Wang, Yingjie Zhu, Zhengfan Yuan, Jiaqi Huang, Yuhan Zhang, Xiaosong Sun, Zhinan Zhang, Hong Zhu, Yongsheng Zhang, Tiantian Dong, Zhong Xiao, Deliang Liu, Chengzhou Lu, Yuan Sun, Zhiyuan Chen, Xinming Han, Zaizhu Liu, Yaoyuan Wang, Ziyang Zhang, Yong Liu, Jinxin Xu, Yajing Sun, Zhoujun Yu, Wenting Zhou, Qidong Zhang, Zhengyong Zhang, Zhonghai Gu, Yibo Jin, Yongxiang Feng, Pengfei Zuo"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Huawei Technologies Co., Ltd."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01712",children:"https://arxiv.org/pdf/2601.01712"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," RelayGR is a production system that scales long-sequence generative recommendation by pre-inferring and caching user-behavior prefixes in HBM across pipeline stages, enabling reuse during ranking. It uses a sequence-aware trigger, affinity-aware router, and memory-aware expander to manage cache footprint and locality. The system allows for longer sequences and significantly improves throughput while meeting strict latency SLOs."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] A Multi-Port Concurrent Communication Model for handling Compute Intensive Tasks on Distributed Satellite System Constellations"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [distributed satellite systems], [divisible load theory, multi-port concurrent communication, admission control, inter-satellite links, load allocation]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Bharadwaj Veeravalli"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," National University of Singapore"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01031",children:"https://arxiv.org/pdf/2601.01031"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper develops a Multi-Port Concurrent Communication Divisible Load Theory (MPCC-DLT) framework for scheduling compute-intensive tasks across distributed satellite constellations. It provides closed-form solutions for optimal load distribution and analyzes the trade-offs between computation and communication overhead. The main conclusion is that while highly distributable tasks benefit significantly, communication-heavy tasks show diminishing returns, and the extended framework with admission control enables practical, deadline-aware operation."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] DiT-HC: Enabling Efficient Training of Visual Generation Model DiT on HPC-oriented CPU Cluster"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion training], [communication-free tensor parallelism, AutoMem, HCOps, custom MPI backend, vector and matrix acceleration units]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Jinxiao Zhang, Yunpu Xu, Xiyong Wu, Runmin Dong, Shenggan Cheng, Yi Zhao, Mengxuan Chen, Qinrui Zheng, Jianting Liu, Haohuan Fu"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Sun Yat-sen University, National University of Singapore, National Supercomputing Center in Shenzhen"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01500",children:"https://arxiv.org/pdf/2601.01500"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," DiT-HC introduces a system for training the DiT generative model on HPC CPU clusters using techniques like communication-free tensor parallelism, optimized kernels, and a custom MPI backend. It achieves significant speedups and high weak scaling efficiency, demonstrating the feasibility of large-scale generative model training on CPU-based supercomputers."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] Performance and Security Aware Distributed Service Placement in Fog Computing"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [deep reinforcement learning, long short-term memory networks, prioritized experience replay, off-policy correction, multi-objective optimization, security score hierarchy]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Mohammad Goudarzi, Arash Shaghaghi, Zhiyu Wang, Rajkumar Buyya"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Monash University, The University of New South Wales"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01125",children:"https://arxiv.org/pdf/2601.01125"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a Security and Performance-Aware Distributed Deep Reinforcement Learning (SPA-DDRL) framework for service placement in Fog computing, which jointly optimizes latency and security using a distributed broker-learner architecture. The method integrates LSTM networks, Prioritized Experience Replay, and off-policy correction. Experiments show it improves service response time by 16.3% and converges 33% faster than baseline approaches while maintaining security compliance."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] Communication-Efficient Federated AUC Maximization with Cyclic Client Participation"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [federated learning, AUC maximization, cyclic client participation, minimax optimization, Polyak-\u0141ojasiewicz condition, communication complexity]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Umesh Vangapally, Wenhan Wu, Chen Chen, Zhishuai Guo"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Northern Illinois University, University of North Carolina at Charlotte, University of Central Florida"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01649",children:"https://arxiv.org/pdf/2601.01649"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes communication-efficient algorithms for federated AUC maximization under cyclic client participation, addressing the challenge of partial client availability in real-world federated learning. It analyzes two settings: one with a squared surrogate loss and one with general pairwise losses, establishing improved communication and iteration complexities, especially under the Polyak-\u0141ojasiewicz condition. Experiments on tasks like image classification and fraud detection demonstrate the methods' superior efficiency and effectiveness."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] FFCz: Fast Fourier Correction for Spectrum-Preserving Lossy Compression of Scientific Data"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [scientific data compression], [fast Fourier correction, error-bounded lossy compression, GPU parallelism, SZ3, ZFP, SPERR]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Congrong Ren, Robert Underwood, Sheng Di, Emrecan Kutay, Zarija Lukic, Aylin Yener, Franck Cappello, Hanqi Guo"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," The Ohio State University, Argonne National Laboratory, Lawrence Berkeley National Laboratory"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01596",children:"https://arxiv.org/pdf/2601.01596"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces FFCz, a fast Fourier correction algorithm that modifies the error from existing lossy compressors to preserve both spatial and frequency-domain accuracy in scientific data. It achieves this by iteratively projecting the spatial error vector to satisfy user-defined bounds in both domains, accelerated by GPU parallelism. The method is validated on datasets from cosmology, combustion, and X-ray diffraction, effectively maintaining critical spectral features."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] Making MoE based LLM inference resilient with Tarragon"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [mixture-of-experts, KV cache checkpointing, shadow experts, reconfigurable datapath, asynchronous recovery]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Songyu Zhang, Aaron Tam, Myungjin Lee, Shixiong Qi, K. K. Ramakrishnan"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of California, Riverside, Cisco Research, University of Kentucky"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01310",children:"https://arxiv.org/pdf/2601.01310"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents Tarragon, a resilient inference framework for Mixture-of-Experts LLMs. It confines failures to individual workers by using a reconfigurable datapath and self-healing mechanisms like incremental KV cache checkpointing and shadow experts. The evaluation shows it reduces failure-induced stalls by over 160x compared to prior systems while maintaining performance."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] OrchestrRL: Dynamic Compute and Network Orchestration for Disaggregated RL"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training], [disaggregated RL, adaptive compute scheduler, reconfigurable hybrid optical-electrical fabric, RFabric, parallelism switching, RLSim]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Xin Tan, Yicheng Feng, Yu Zhou, Yimin Jiang, Yibo Zhu, Hong Xu"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," The Chinese University of Hong Kong, StepFun"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01209",children:"https://arxiv.org/pdf/2601.01209"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces OrchestrRL, a framework that dynamically orchestrates compute and network resources for disaggregated reinforcement learning. It co-designs an adaptive compute scheduler and a reconfigurable network fabric (RFabric) to address bottlenecks in generation and dynamic traffic patterns. The evaluation shows OrchestrRL improves throughput by up to 1.40x and RFabric offers better performance-cost efficiency than static networks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] Cutting Quantum Circuits Beyond Qubits"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [quantum computing], [circuit cutting, qudit decomposition, Gell-Mann matrices, distributed quantum computing, memory reduction]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Manav Seksaria, Anil Prabhakar"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Indian Institute of Technology Madras"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02064",children:"https://arxiv.org/pdf/2601.02064"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper extends quantum circuit cutting to mixed-dimensional qudit registers by decomposing non-local interactions using tensor products of generalized Gell-Mann matrices. This enables simulation of high-dimensional circuits on disconnected hardware fragments, achieving exact state reconstruction and reducing memory usage significantly, as demonstrated in an 8-particle system."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [federated learning, personalized federated learning, cosine sparsification, parameter packing, dual-weighted aggregation, sparse updates, Non-IID data]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Qiantao Yang, Liquan Chen, Mingfu Xue, Songze Li"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Southeast University, Purple Mountain Laboratories, East China Normal University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01840",children:"https://arxiv.org/pdf/2601.01840"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes FedCSPACK, a personalized federated learning method that uses cosine sparsification for parameter packing and a dual-weighted aggregation mechanism to reduce communication costs and mitigate data heterogeneity. It concludes that this approach effectively improves communication and computational efficiency while maintaining high model accuracy across heterogeneous datasets."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] Vouchsafe: A Zero-Infrastructure Capability Graph Model for Offline Identity and Trust"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [identity and trust systems], [Ed25519, SHA-256, JSON Web Tokens, Zero-Infrastructure Capability Graph, offline verification]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Jay Kuri"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Ionzero Inc."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02254",children:"https://arxiv.org/pdf/2601.02254"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces Vouchsafe, a system that implements a Zero-Infrastructure Capability Graph model for offline identity and trust. It uses self-contained, signed statements with standard cryptographic primitives like Ed25519 and JWTs, enabling trust verification without any online infrastructure. The main conclusion is that a practical, offline-verifiable trust substrate can be built today using only locally available cryptographic data."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] Deciding Serializability in Network Systems"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [formal verification], [Petri net reachability, semilinear-set compression, Presburger-formula manipulation, network-system abstraction]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Guy Amir, Mark Barbone, Nicolas Amat, Jules Jacobs"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Cornell University, ONERA, Jane Street Capital"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02251",children:"https://arxiv.org/pdf/2601.02251"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents the SER modeling language and an automated decision procedure for verifying serializability in concurrent programs. The method compiles programs to a network-system abstraction and reduces the verification problem to a Petri net reachability query, using optimizations like slicing and semilinear-set compression. The authors conclude that their framework can successfully handle models of real-world systems like stateful firewalls and BGP routers."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] Benchmarking Quantum Data Center Architectures: A Performance and Scalability Perspective"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [quantum computing systems], [quantum data center, distributed quantum computing, entanglement generation, Bell State Measurement, teleportation, QFly, BCube, Clos, Fat-Tree]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Shahrooz Pouryousef, Eneet Kaur, Hassan Shapourian, Don Towsley, Ramana Kompella, Reza Nejabati"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Cisco Research, University of Massachusetts Amherst"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01353",children:"https://arxiv.org/pdf/2601.01353"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper benchmarks four quantum data center architectures (QFly, BCube, Clos, Fat-Tree) by analyzing their performance under quantum-specific constraints like entanglement generation delays and resource contention. The study concludes that distributed quantum performance is shaped by a complex interaction of topology, scheduling policies, and physical-layer parameters."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] SuperSFL: Resource-Heterogeneous Federated Split Learning with Weight-Sharing Super-Networks"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [federated split learning, weight-sharing super-network, three-phase gradient fusion, resource-aware subnetwork, gradient fusion]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Abdullah Al Asif, Sixing Yu, Juan Pablo Munoz, Arya Mazaheri, Ali Jannesari"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Iowa State University, Intel Corporation, Technical University of Darmstadt"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02092",children:"https://arxiv.org/pdf/2601.02092"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes SuperSFL, a federated split learning framework that uses a weight-sharing super-network to generate client-specific subnetworks for heterogeneous edge devices and employs a Three-Phase Gradient Fusion mechanism for optimization. It demonstrates faster convergence, lower communication cost, and improved energy efficiency compared to baseline methods, making it a practical solution for heterogeneous edge environments."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] Placement Semantics for Distributed Deep Learning: A Systematic Framework for Analyzing Parallelism Strategies"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [placement semantics, data parallelism, tensor parallelism, pipeline parallelism, ZeRO, FSDP, memory consumption, communication volume]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Deep Pankajbhai Mehta"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Adobe Inc."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02311",children:"https://arxiv.org/pdf/2601.02311"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper introduces a systematic framework called "placement semantics" to analyze distributed deep learning parallelism strategies by specifying how training states are placed across devices. From this specification alone, it can derive key performance metrics like memory use and communication cost, unifying strategies like ZeRO and pipeline parallelism. The main conclusion is that this framework provides a theoretical foundation to predict and compare strategy behavior without implementation details, matching published empirical results.']}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] Bringing computation to the data: A MOEA-driven approach for optimising data processing in the context of the SKA and SRCNet"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [Multi-Objective Evolutionary Algorithms (MOEAs), Function-as-a-Service (FaaS), in-situ processing, distributed computing, data-intensive workflows]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Manuel Parra-Roy\xf3n, \xc1lvaro Rodr\xedguez-Gallardo, Susana S\xe1nchez-Exp\xf3sito, Laura Darriba-Pol, Jes\xfas S\xe1nchez-Casta\xf1eda, M. \xc1ngeles Mendoza, Juli\xe1n Garrido, Javier Mold\xf3n, Lourdes Verdes-Montenegro"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Instituto de Astrof\xedsica de Andaluc\xeda, IAA-CSIC"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01980",children:"https://arxiv.org/pdf/2601.01980"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a framework that integrates Function-as-a-Service (FaaS) with a decision-making entity based on Multi-Objective Evolutionary Algorithms (MOEAs) to optimize data processing workflows for the SKA telescope. The approach moves computation closer to the data to overcome network bottlenecks, using MOEAs to find execution plans that balance time and energy costs. The conclusion is that this provides a baseline for efficient, cost-aware computation-to-data strategies within the SKA Regional Centres Network."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260106] BigSUMO: A Scalable Framework for Big Data Traffic Analytics and Parallel Simulation"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [parallel simulation, SUMO, loop detector data, probe trajectory data, descriptive analytics, prescriptive analytics, interruption detection]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Rahul Sengupta, Nooshin Yousefzadeh, Manav Sanghvi, Yash Ranjan, Anand Rangarajan, Sanjay Ranka, Yashaswi Karnati, Jeremy Dilmore, Tushar Patel, Ryan Casburn"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Florida, NVIDIA Corp., FDOT"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02286",children:"https://arxiv.org/pdf/2601.02286"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper presents BigSUMO, a scalable open-source framework that ingests traffic data like loop detector and probe trajectories to perform descriptive analytics and interruption detection, then uses the SUMO microsimulator for parallel prescriptive simulations of "what-if" scenarios. The main conclusion is that this end-to-end, modular system provides a cost-effective and deployable tool for traffic management and optimization in smart cities.']}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 22'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] SmartFlow Reinforcement Learning and Agentic AI for Bike-Sharing Optimisation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00868",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Horizon Reduction as Information Loss in Offline Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00831",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01288",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01785",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01665",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01562",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Dichotomous Diffusion Policy Optimization ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00898",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01577",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01800",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01802",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Moments Matter",":Stabilizing"," Policy Optimization using Return Distributions ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01803",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01904",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Distorted Distributional Policy Evaluation for Offline Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01917",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] GDRO: Group-level Reward Post-training Suitable for Diffusion Models ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02036",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02061",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02075",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02151",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] ACDZero: Graph-Embedding-Based Tree Search for Mastering Automated Cyber Defense ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02196",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02201",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02204",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02256",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Reinforcement Learning for Option Hedging: Static Implied-Volatility Fit versus Shortfall-Aware Performance ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01709",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 17'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] RovoDev Code Reviewer: A Large-Scale Online Evaluation of LLM-based Code Review Automation at Atlassian ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01129",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] UltraEval-Audio: A Unified Framework for Comprehensive Evaluation of Audio Foundation Models ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01373",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Digital Twin-Driven Communication-Efficient Federated Anomaly Detection for Industrial IoT ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01701",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Accelerating Decentralized Optimization via Overlapping Local Steps ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01493",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Accelerated Full Waveform Inversion by Deep Compressed Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01268",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01513",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Efficient Cover Construction for Ball Mapper via Accelerated Range Queries ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01405",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Generating Diverse TSP Tours via a Combination of Graph Pointer Network and Dispersion ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01132",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Promptable Foundation Models for SAR Remote Sensing: Adapting the Segment Anything Model for Snow Avalanche Segmentation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01213",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01807",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Yukthi Opus: A Multi-Chain Hybrid Metaheuristic for Large-Scale NP-Hard Optimization ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01832",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02071",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02213",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02253",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Physically-Constrained Autoencoder-Assisted Bayesian Optimization for Refinement of High-Dimensional Defect-Sensitive Single Crystalline Structure ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00855",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Learning Relationship between Quantum Walks and Underdamped Langevin Dynamics ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.01589",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260106] Predicting Early and Complete Drug Release from Long-Acting Injectables Using Explainable Machine Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02265",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"2026-01-07",children:"2026-01-07"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"cs.DC total: 7"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260107] Proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024)"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Wim Vanderbauwhede, Lauritz Thamsen, Jos\xe9 Cano"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02898",children:"https://arxiv.org/pdf/2601.02898"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260107] Exploring Blockchain Interoperability: Frameworks, Use Cases, and Future Challenges"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [blockchain interoperability], [blockchain, interoperability, cross-chain communication, layer-0, layer-1, layer-2, smart contracts, consensus algorithms]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Stanly Wilson, Kwabena Adu-Duodu, Yinhao Li, Ellis Solaiman, Omer Rana, Rajiv Ranjan"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Newcastle University, Cardiff University, St Vincent Pallotti College of Engineering & Technology"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02949",children:"https://arxiv.org/pdf/2601.02949"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper explores frameworks and solutions for blockchain interoperability, discussing platforms that enable heterogeneous blockchains to connect and share information. It concludes that as applications become more complex, interoperable solutions are a necessity, but several challenges remain to be solved in this domain."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260107] Optimal Oblivious Load-Balancing for Sparse Traffic in Large-Scale Satellite Networks"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [network routing], [oblivious load-balancing, torus network, linear programming, Valiant Load Balancing, worst-case load]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Rudrapatna Vallabh Ramakanth, Eytan Modiano"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Massachusetts Institute of Technology"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02537",children:"https://arxiv.org/pdf/2601.02537"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper formulates the problem of oblivious load-balancing for sparse traffic in a torus network as a linear program and constructs an optimal routing scheme. It shows that the Valiant Load Balancing scheme is suboptimal for sparse traffic and establishes a lower bound for any oblivious scheme, along with a performance gap compared to non-oblivious routing."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260107] Software-Defined Agentic Serving"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [software-defined networking, dynamic communication, multi-agent pipelines, runtime state, batching, streaming, pipelining]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Saurabh Agarwal, Marco Laju, Jayanth Srinivasa, Myungjin Lee, Aditya Akella"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Texas-Austin, Cisco-Research"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03197",children:"https://arxiv.org/pdf/2601.03197"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes a new software-defined networking (SDN)-inspired framework for serving multi-agent LLM pipelines. It aims to make agent communication programmable and adaptive to runtime system state, enabling more efficient and responsive serving. The authors conclude that this architecture addresses the limitations of static serving strategies and paves the way for intent-driven agentic systems."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260107] First Provably Optimal Asynchronous SGD for Homogeneous and Heterogeneous Data"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [asynchronous SGD, staleness, heterogeneous workers, federated learning, gradient table, task allocation]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Artavazd Maranjyan"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," King Abdullah University of Science and Technology"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02523",children:"https://arxiv.org/pdf/2601.02523"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This dissertation introduces new asynchronous SGD algorithms, Ringmaster ASGD and Ringleader ASGD, which use techniques like selective update discarding and structured gradient tables to handle staleness and heterogeneous data. It demonstrates that these methods can achieve optimal time complexity, matching synchronous guarantees, and proposes ATA for adaptive task allocation to improve resource efficiency. The work establishes asynchronous optimization as a theoretically sound and efficient foundation for distributed learning."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260107] APoW: Auditable Proof-of-Work Against Block Withholding Attacks"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [blockchain security], [proof-of-work, nonce space auditing, block withholding attack detection, hashcash, decentralized mining pools]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Sergio Demian Lerner"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Fairgate Labs, Rootstock Labs"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02496",children:"https://arxiv.org/pdf/2601.02496"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces APoW, an auditable proof-of-work scheme that enables miners to probabilistically attest to having searched specific nonce space regions, allowing retroactive auditing of claimed work. This method facilitates the detection of block withholding attacks in mining pools without trusted hardware, thereby supporting the design of verifiable, decentralized pools. The construction maintains core PoW properties while adding an auditability layer, which can be deployed either via consensus changes or as a pool-level mechanism."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260107] Chronicals: A High-Performance Framework for LLM Fine-Tuning with 3.51x Speedup over Unsloth"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [fused triton kernels, cut cross-entropy, lora+, sequence packing, flashattention, online softmax]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Arjun S. Nair"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Independent Researcher"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02609",children:"https://arxiv.org/pdf/2601.02609"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," Chronicals is a high-performance framework for LLM fine-tuning that integrates four key optimizations: fused Triton kernels, a memory-efficient Cut Cross-Entropy loss, LoRA+ with differential learning rates, and sequence packing. It achieves a 3.51x speedup over the Unsloth framework for full fine-tuning by dramatically reducing memory footprint and computational waste. The paper also critically notes that a competing benchmark showed zero gradient norms, indicating the model was not actually training."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 22'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] IBISAgent: Reinforcing Pixel-Level Visual Reasoning in MLLMs for Universal Biomedical Object Referring and Segmentation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03054",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] WebGym: Scaling Training Environments for Visual Web Agents with Realistic Tasks ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02439",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Dementia-R1: Reinforced Pretraining and Reasoning from Unstructured Clinical Notes for Real-World Dementia Prognosis ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03018",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] One Sample to Rule Them All: Extreme Data Efficiency in RL Scaling ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03111",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] In-Context Reinforcement Learning through Bayesian Fusion of Context and Value Prior ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03015",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] SWaRL: Safeguard Code Watermarking via Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02602",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Unified Thinker: A General Reasoning Modular Core for Image Generation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03127",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Correct, Concise and Complete: Multi-stage Training For Adaptive Reasoning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02972",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] UltraLogic: Enhancing LLM Reasoning through Large-Scale Data Synthesis and Bipolar Float Reward ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03205",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] MiMo-V2-Flash Technical Report ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02780",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] The World is Not Mono: Enabling Spatial Understanding in Large Audio-Language Models ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02954",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] LLM-Enhanced Reinforcement Learning for Time Series Anomaly Detection ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02511",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] SimRPD: Optimizing Recruitment Proactive Dialogue Agents through Simulator-Based Data Evaluation and Selection ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02871",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Textual Explanations and Their Evaluations for Reinforcement Learning Policy ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02514",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Sample-Efficient Neurosymbolic Deep Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02850",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] AI-Native Integrated Sensing and Communications for Self-Organizing Wireless Networks: Architectures, Learning Paradigms, and System-Level Design ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02398",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Effective Online 3D Bin Packing with Lookahead Parcels Using Monte Carlo Tree Search ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02649",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Closing the Reality Gap: Zero-Shot Sim-to-Real Deployment for Dexterous Force-Based Grasping and Manipulation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02778",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Inferring Causal Graph Temporal Logic Formulas to Expedite Reinforcement Learning in Temporally Extended Tasks ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02666",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Time-Scaling Is What Agents Need Now ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02714",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] ChemBART: A Pre-trained BART Model Assisting Organic Chemistry Analysis ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02915",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Q-Regularized Generative Auto-Bidding: From Suboptimal Trajectories to Optimal Policies ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02754",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 7'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Threat Detection in Social Media Networks Using Machine Learning Based Network Analysis ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02581",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] A large-scale nanocrystal database with aligned synthesis and properties enabling generative inverse design ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02424",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] PersonaLedger: Generating Realistic Financial Transactions with Persona Conditioned LLMs and Rule Grounded Feedback ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03149",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] RadioDiff-Flux: Efficient Radio Map Construction via Generative Denoise Diffusion Model Trajectory Midpoint Reuse ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02790",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Dynamic Hyperparameter Importance for Efficient Multi-Objective Optimization ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03166",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] Sample-Efficient Neurosymbolic Deep Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02850",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260107] The Vibe-Check Protocol: Quantifying Cognitive Offloading in AI Programming ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.02410",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"2026-01-08",children:"2026-01-08"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"cs.DC total: 6"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260108] Majorum: Ebb-and-Flow Consensus with Dynamic Quorums"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [distributed consensus], [ebb-and-flow, dynamic availability, quorum-based protocol, TOB-SVD, finality, Byzantine fault tolerance]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Francesco D'Amato, Roberto Saltini, Thanh-Hai Tran, Yann Vonlanthen, Luca Zanolini"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Ethereum Foundation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03862",children:"https://arxiv.org/pdf/2601.03862"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents Majorum, a consensus protocol that combines a dynamically available quorum-based protocol (TOB-SVD) with a finality layer to achieve both liveness and strong safety. Under optimistic conditions, it achieves finality in as few as three slots with only one voting phase per slot, significantly improving optimistic finality time compared to existing systems like Ethereum."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260108] Failure-Resilient and Carbon-Efficient Deployment of Microservices over the Cloud-Edge Continuum"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [cloud-edge computing], [microservices, deployment automation, failure resilience, carbon efficiency, workload rebalancing, service migration]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Francisco Ponce, Simone Gazza, Andrea D'Iapico, Roberto Amadini, Antonio Brogi, Stefano Forti, Saverio Giallorenzo, Pierluigi Plebani, Davide Usai, Monica Vitali, Gianluigi Zavattaro, Jacopo Soldani"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Pisa, University of Bologna, Politecnico di Milano"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04123",children:"https://arxiv.org/pdf/2601.04123"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces the FREEDA toolchain, which automates the deployment of microservices across the Cloud-Edge Continuum by continuously adapting to changing conditions like resource availability and carbon intensity. It demonstrates that FREEDA can autonomously reconfigure deployments through service migration and workload rebalancing to achieve an optimal balance among failure resilience, performance, and reduced carbon emissions."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260108] Hummingbird: SLO-Oriented GPU Preemption at Microsecond-scale"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [GPU preemption, temporal sharing, spatial sharing, SLO attainment, microsecond-scale scheduling]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Tiancheng Hu, Chenxi Wang, Ting Cao, Jin Qin, Lei Chen, Xinyu Xiao, Junhao Hu, Hongliang Tian, Shoumeng Yan, Huimin Cui, Quan Chen, Tao Xie"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Peking University, University of Chinese Academy of Sciences, Tsinghua University, Huazhong University of Science and Technology, Ant Group, Shanghai Jiao Tong University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04071",children:"https://arxiv.org/pdf/2601.04071"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents Hummingbird, a GPU scheduling system that enables microsecond-scale preemption on closed-source GPUs to harvest idle time slices. It significantly improves the SLO attainment of high-priority tasks while boosting the throughput of low-priority tasks, thereby enhancing GPU utilization."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260108] A Scheduling Framework for Efficient MoE Inference on Edge GPU-NDP Systems"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [tensor parallelism, load-balancing-aware scheduling, dataset-free pre-fetching, near-data processing (NDP), Mixture-of-Experts (MoE)]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Qi Wu, Chao Fang, Jiayuan Chen, Ye Lin, Yueqi Zhang, Yichuan Bai, Yuan Du, Li Du"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Nanjing University, China Mobile Research Institute"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03992",children:"https://arxiv.org/pdf/2601.03992"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a scheduling framework to accelerate Mixture-of-Experts (MoE) model inference on edge GPU systems with near-data processing (NDP) units. The core method employs tensor parallelism for experts, a load-balancing scheduler, and a dataset-free pre-fetching strategy to overcome memory and utilization challenges. The framework achieves up to 2.56x speedup in end-to-end latency compared to state-of-the-art approaches."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260108] Revisiting Speculative Leaderless Protocols for Low-Latency BFT Replication"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [distributed systems, fault tolerance], [leaderless BFT, speculative protocols, optimistic fast path, PBFT fallback, network delay estimation, clock synchronization]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Daniel Qian, Xiyu Hao, Jinkun Geng, Yuncheng Yao, Aurojit Panda, Jinyang Li, Anirudh Sivaraman"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," New York University, Stony Brook University, New York University Shanghai"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03390",children:"https://arxiv.org/pdf/2601.03390"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents Aspen, a leaderless Byzantine Fault Tolerant (BFT) protocol that uses a best-effort sequencing layer with synchronized clocks and network delay estimates to achieve low-latency consensus (2\u0394+\u03b5) even under contention. It requires extra replicas (n=3f+2p+1) to tolerate network delays and falls back to a PBFT-style protocol when optimistic conditions fail. Experiments show Aspen commits requests in under 75 ms, offering a 1.2\u20133.3\xd7 speedup over prior protocols while handling 19,000 requests per second."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260108] Local Gradient Regulation Stabilizes Federated Learning under Client Heterogeneity"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [federated learning, client heterogeneity, gradient regulation, Exploratory\u2013Convergent Gradient Re-aggregation (ECGR), swarm intelligence]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Ping Luo, Jiahuan Wang, Ziqing Wen, Tao Sun, Dongsheng Li"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," National University of Defense Technology"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03584",children:"https://arxiv.org/pdf/2601.03584"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes a client-side method called Exploratory\u2013Convergent Gradient Re-aggregation (ECGR) to stabilize federated learning by regulating local gradient dynamics under heterogeneous data distributions. It concludes that this regulation of local gradients effectively suppresses destabilizing drift and consistently improves the stability and convergence of federated learning across various state-of-the-art methods."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 27'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Aligning Findings with Diagnosis: A Self-Consistent Reinforcement Learning Framework for Trustworthy Radiology Reporting ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03321",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03555",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] O-Researcher: An Open Ended Deep Research Model via Multi-Agent Distillation and Agentic RL ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03743",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] NeoAMT: Neologism-Aware Agentic Machine Translation with Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03790",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03969",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04126",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Agentic Rubrics as Contextual Verifiers for SWE Agents ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04171",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Shielded RecRL: Explanation Generation for Recommender Systems without Ranking Degradation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03608",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] R",(0,s.jsxs)(n.span,{className:"katex",children:[(0,s.jsx)(n.span,{className:"katex-mathml",children:(0,s.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,s.jsxs)(n.semantics,{children:[(0,s.jsx)(n.mrow,{children:(0,s.jsxs)(n.msup,{children:[(0,s.jsx)(n.mrow,{}),(0,s.jsx)(n.mn,{children:"3"})]})}),(0,s.jsx)(n.annotation,{encoding:"application/x-tex",children:"^3"})]})})}),(0,s.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,s.jsxs)(n.span,{className:"base",children:[(0,s.jsx)(n.span,{className:"strut",style:{height:"0.8141em"}}),(0,s.jsxs)(n.span,{className:"mord",children:[(0,s.jsx)(n.span,{}),(0,s.jsx)(n.span,{className:"msupsub",children:(0,s.jsx)(n.span,{className:"vlist-t",children:(0,s.jsx)(n.span,{className:"vlist-r",children:(0,s.jsx)(n.span,{className:"vlist",style:{height:"0.8141em"},children:(0,s.jsxs)(n.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,s.jsx)(n.span,{className:"pstrut",style:{height:"2.7em"}}),(0,s.jsx)(n.span,{className:"sizing reset-size6 size3 mtight",children:(0,s.jsx)(n.span,{className:"mord mtight",children:"3"})})]})})})})})]})]})})]}),"L: Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03715",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] From Brute Force to Semantic Insight: Performance-Guided Data Transformation Design with LLMs ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03808",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] AMIR-GRPO: Inducing Implicit Preference Signals into GRPO ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03661",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] ETR: Outcome-Guided Elastic Trust Regions for Policy Optimization ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03723",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Sensor to Pixels: Decentralized Swarm Gathering via Image-Based Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03413",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03822",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Sandwich Reasoning: An Answer-Reasoning-Answer Approach for Low-Latency Query Correction ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03672",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Exploration Through Introspection: A Self-Aware Reward Model ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03389",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Cells on Autopilot: Adaptive Cell (Re)Selection via Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04083",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] TreeAdv: Tree-Structured Advantage Redistribution for Group-Based RL ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03703",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Mastering the Game of Go with Self-play Experience Replay ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03306",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Ratio-Variance Regularized Policy Optimization for Efficient LLM Fine-tuning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03320",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] PC2P: Multi-Agent Path Finding via Personalized-Enhanced Communication and Crowd Perception ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03301",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] IndexTTS 2.5 Technical Report ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03888",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Adaptive-Boundary-Clipping GRPO: Ensuring Bounded Ratios for Stable and Generalizable Training ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03895",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03948",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Interleaved Tool-Call Reasoning for Protein Function Understanding ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03604",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] VeRPO: Verifiable Dense Reward Policy Optimization for Code Generation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03525",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] EDCO: Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03725",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 9'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Bare-Metal Tensor Virtualization: Overcoming the Memory Wall in Edge-AI Inference on ARM64 ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03324",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Weather-Aware Transformer for Real-Time Route Optimization in Drone-as-a-Service Operations ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03376",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Unsupervised Modular Adaptive Region Growing and RegionMix Classification for Wind Turbine Segmentation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04065",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] ETR: Outcome-Guided Elastic Trust Regions for Policy Optimization ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03723",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] MetagenBERT: a Transformer-based Architecture using Foundational genomic Large Language Models for novel Metagenome Representation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03295",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Provable Acceleration of Distributed Optimization with Local Updates ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03442",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] Learning from Limited Labels: Transductive Graph Label Propagation for Indian Music Analysis ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03626",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] CageDroneRF: A Large-Scale RF Benchmark and Toolkit for Drone Perception ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03302",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260108] A Reinforcement Learning-Based Model for Mapping and Goal-Directed Navigation Using Multiscale Place Fields ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.03520",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"2026-01-09",children:"2026-01-09"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"cs.DC total: 12"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260109] Quantifying Autoscaler Vulnerabilities: An Empirical Study of Resource Misallocation Induced by Cloud Infrastructure Faults"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [cloud computing], [autoscaling, fault injection, simulation, resource management, SLO]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Gijun Park"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Okestro AI Research Center"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04659",children:"https://arxiv.org/pdf/2601.04659"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper uses controlled simulation experiments to measure how different cloud infrastructure faults affect vertical and horizontal autoscaling decisions. It finds that storage-related faults cause the highest cost overhead, while routing anomalies lead to systematic under-provisioning, and horizontal scaling is more sensitive to transient faults near scaling thresholds."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260109] Cognitive Infrastructure: A Unified DCIM Framework for AI Data Centers"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [knowledge graphs, digital twin, thermal modeling, unified device connectivity protocol, semantic reasoning, predictive analytics]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Krishna Chaitanya Sunkara"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Independent Researcher"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04750",children:"https://arxiv.org/pdf/2601.04750"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes DCIM 3.0, a unified framework for AI data center management that integrates semantic reasoning, predictive analytics, and autonomous orchestration using knowledge graphs and digital twins. The main conclusion is that this framework addresses critical challenges in automation, sustainability, and thermal management for next-generation GPU computing infrastructure."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260109] Proof of Commitment: A Human-Centric Resource for Permissionless Consensus"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [consensus protocols], [Proof of Commitment, Sybil resistance, Human Challenge Oracle, weighted-backbone analysis, partial synchrony]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Homayoun Maleki, Nekane Sainz, Jon Legarda"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Deusto"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04813",children:"https://arxiv.org/pdf/2601.04813"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces Proof of Commitment (PoCmt), a consensus primitive that uses real-time human engagement as a non-parallelizable resource to regulate leader election and provide Sybil resistance. It establishes that PoCmt enforces a linear Sybil cost, unlike Proof of Work or Proof of Stake, and achieves safety, liveness, and fairness under partial synchrony."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260109] Sharded Elimination and Combining for Highly-Efficient Concurrent Stacks"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [concurrent data structures], [sharding, elimination, software combining, fetch&increment, linearizability]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Ajay Singh, Nikos Metaxakis, Panagiota Fatourou"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," FORTH ICS, University of Waterloo, University of Crete"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04523",children:"https://arxiv.org/pdf/2601.04523"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents a new concurrent stack implementation that blends a novel elimination mechanism with a new software combining approach, using sharding and fetch&increment to reduce contention. This design enhances parallelism and lowers access contention on the shared stack. Experiments show it outperforms existing concurrent stacks by up to 2x, especially in high-contention scenarios with many threads."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260109] Hybrid Cloud Architectures for Research Computing: Applications and Use Cases"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [cloud computing], [hybrid cloud, federated computing, multi-cloud orchestration, workload scheduling, OpenPBS, SLURM, OpenStack, Kubernetes, Nextflow, Snakemake, CWL]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Xaver Stiensmeier, Alexander Kanitz, Jan Kr\xfcger, Santiago Insua, Adri\xe1n Ro\u0161inec, Vikt\xf3ria Spi\u0161\xe1kov\xe1, Luk\xe1\u0161 Hejtm\xe1nek, David Yuan, Gavin Farrell, Jonathan Tedds, Juha T\xf6rnroos, Harald Wagener, Alex Sczyrba, Nils Hoffmann, Matej Antol"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," ELIXIR"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04349",children:"https://arxiv.org/pdf/2601.04349"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper explores hybrid cloud architectures as a solution for integrating fragmented research computing environments, using platforms like OpenStack and Kubernetes and workflow tools like Nextflow. It concludes by proposing a governance and technical roadmap, developed through the ELIXIR Compute Platform, to accelerate the sustainable adoption of hybrid clouds in scientific research."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260109] MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [multi-queue pipelining, asynchronous gradient sharing, global neighbor sampling with caching, adaptive periodic synchronization, adaptive queue-sizing]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Irfan Ullah, Young-Koo Lee"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Kyung Hee University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04707",children:"https://arxiv.org/pdf/2601.04707"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes MQ-GNN, a multi-queue pipelined framework that improves GNN training efficiency by overlapping mini-batch generation, data transfer, and computation stages. Its key innovations include an asynchronous gradient sharing mechanism with adaptive synchronization and global neighbor sampling with caching. Experiments show MQ-GNN achieves up to 4.6x faster training and 30% better GPU utilization while maintaining model accuracy."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260109] Timeliness-Oriented Scheduling and Resource Allocation in Multi-Region Collaborative Perception"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [Age of Information (AoI), Lyapunov optimization, scheduling algorithm, collaborative perception, resource allocation]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Mengmeng Zhu, Yuxuan Sun, Yukuan Jia, Wei Chen, Bo Ai, Sheng Zhou"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Beijing Jiaotong University, Tsinghua University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04542",children:"https://arxiv.org/pdf/2601.04542"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a Timeliness-Aware Multi-region Prioritized (TAMP) scheduling algorithm, a Lyapunov-based optimization policy, to manage communication and computational resources in multi-region collaborative perception by balancing information timeliness (via Age of Information) and communication volume. The algorithm is validated on real-world datasets, demonstrating significant improvements in perception accuracy over baselines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260109] Mechanism Design for Federated Learning with Non-Monotonic Network Effects"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [mechanism design, federated learning, network effects, social welfare maximization, incentive mechanism, model trading and sharing]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Xiang Li, Bing Luo, Jianwei Huang, Yuan Luo"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," The Chinese University of Hong Kong, Shenzhen; Duke Kunshan University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04648",children:"https://arxiv.org/pdf/2601.04648"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes a Model Trading and Sharing (MoTS) framework and a Social Welfare maximization with Application-aware and Network effects (SWAN) mechanism for federated learning. It addresses non-monotonic network effects and application-specific model requirements by allowing clients to obtain models through participation or purchase. Experimental results show the SWAN mechanism significantly improves social welfare and reduces incentive costs compared to existing approaches."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260109] ParaCodex: A Profiling-Guided Autonomous Coding Agent for Reliable Parallel Code Generation and Translation"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [GPU kernels], [OpenMP GPU offload, autonomous coding agent, profiling-guided refinement, hotspot analysis, data planning, correctness gating]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Erel Kaplan, Tomer Bitan, Lian Ghrayeb, Le Chen, Tom Yotam, Niranjan Hasabnis, Gal Oren"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Technion \u2013 Israel Institute of Technology, Argonne National Laboratory, Code Metal, Stanford University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04327",children:"https://arxiv.org/pdf/2601.04327"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," ParaCodex is an autonomous LLM agent that transforms serial or CUDA code into optimized OpenMP GPU offload kernels using a staged workflow of hotspot analysis, data planning, and iterative refinement guided by compiler tests and profiling. It successfully translated 31 kernels, achieving significant speedups over reference implementations and outperforming a zero-shot baseline, demonstrating reliable parallel code generation through an artifact-driven, tool-verified approach."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260109] Parallel Quadratic Selected Inversion in Quantum Transport Simulation"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sys], [high-performance computing], [selected inversion, recursive Green's function, block-tridiagonal matrices, distributed algorithms, GPU acceleration]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Vincent Maillou, Matthias Bollhofer, Olaf Schenk, Alexandros Nikolaos Ziogas, Mathieu Luisier"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," ETH Zurich, TU Braunschweig, Universit\xe0 della Svizzera italiana"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04904",children:"https://arxiv.org/pdf/2601.04904"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces distributed parallel methods, building on the recursive Green's function technique, for selected inversion and selected solution of quadratic matrix equations in quantum transport simulations. These methods handle block-tridiagonal matrices with arrowhead patterns, enabling the simulation of multi-terminal transistors. The proposed solver, when scaled to 16 GPUs, demonstrates a 5.2x speedup over a baseline sparse direct solver, highlighting its potential to accelerate large-scale nano-device simulations."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260109] Nalar: An agent serving framework"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [agent-serving framework, workflow specification, managed state layer, two-level control architecture, futures, dependency metadata]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Marco Laju, Donghyun Son, Saurabh Agarwal, Nitin Kedia, Myungjin Lee, Jayanth Srinivasa, Aditya Akella"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," UT-Austin, Cisco-Research"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.05109",children:"https://arxiv.org/pdf/2601.05109"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," Nalar is a new framework designed to efficiently serve LLM-driven agentic applications by separating workflow specification from execution. It uses auto-generated stubs to turn invocations into futures with metadata and employs a managed state layer and a two-level control architecture for adaptive resource management. The paper concludes that Nalar significantly reduces latency, improves speed, and scales effectively compared to existing baselines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv260109] Asynchronous Secure Federated Learning with Byzantine aggregators"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [federated averaging, secure aggregation, differential privacy, Byzantine aggregators, asynchronous communication, Gaussian noise, model masking, client verification, replicated servers]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Antonella Del Pozzo, Achille Desreumaux, Mathieu Gestin, Alexandre Rapetti, Sara Tucci-Piergiovanni"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," CEA List (based on author affiliations from arXiv)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04930",children:"https://arxiv.org/pdf/2601.04930"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes a secure federated learning method that combines replicated aggregators, secure aggregation, and differential privacy to protect client data in asynchronous settings with malicious servers. It ensures training liveness and uniform client participation without relying on consensus. The approach maintains performance comparable to state-of-the-art while improving reliability and privacy in Byzantine environments."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 35'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Not All Steps are Informative: On the Linearity of LLMs' RLVR Training ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04537",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Multiagent Reinforcement Learning with Neighbor Action Estimation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04511",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] SCALER",":Synthetic"," Scalable Adaptive Learning Environment for Reasoning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04809",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04686",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Enhanced-FQL(",(0,s.jsxs)(n.span,{className:"katex",children:[(0,s.jsx)(n.span,{className:"katex-mathml",children:(0,s.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,s.jsxs)(n.semantics,{children:[(0,s.jsx)(n.mrow,{children:(0,s.jsx)(n.mi,{children:"\u03bb"})}),(0,s.jsx)(n.annotation,{encoding:"application/x-tex",children:"\u03bb"})]})})}),(0,s.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,s.jsxs)(n.span,{className:"base",children:[(0,s.jsx)(n.span,{className:"strut",style:{height:"0.6944em"}}),(0,s.jsx)(n.span,{className:"mord mathnormal",children:"\u03bb"})]})})]}),"), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04392",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Learning Dynamics in RL Post-Training for Language Models ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04670",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Transformer-based Multi-agent Reinforcement Learning for Separation Assurance in Structured and Unstructured Airspaces ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04401",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] ResMAS: Resilience Optimization in LLM-based Multi-agent Systems ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04694",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] A Method for Constructing a Digital Transformation Driving Mechanism Based on Semantic Understanding of Large Models ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04696",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04521",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Cross-Language Speaker Attribute Prediction Using MIL and RL ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04257",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Optimizing Path Planning using Deep Reinforcement Learning for UGVs in Precision Agriculture ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04668",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Making Tunable Parameters State-Dependent in Weather and Climate Models with Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04268",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] ThinkDrive: Chain-of-Thought Guided Progressive Reinforcement Learning Fine-Tuning for Autonomous Driving ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04714",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] A Future Capabilities Agent for Tactical Air Traffic Control ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04285",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Improving and Accelerating Offline RL in Large Discrete Action Spaces with Structured Policy Initialization ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04441",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Rate or Fate? RLV",(0,s.jsx)(n.span,{className:"katex-error",title:"ParseError: KaTeX parse error: Expected group after '^' at position 1: ^\u0332",style:{color:"#cc0000"},children:"^"}),"R: Reinforcement Learning with Verifiable Noisy Rewards ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04411",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] AT",(0,s.jsxs)(n.span,{className:"katex",children:[(0,s.jsx)(n.span,{className:"katex-mathml",children:(0,s.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,s.jsxs)(n.semantics,{children:[(0,s.jsx)(n.mrow,{children:(0,s.jsxs)(n.msup,{children:[(0,s.jsx)(n.mrow,{}),(0,s.jsx)(n.mn,{children:"2"})]})}),(0,s.jsx)(n.annotation,{encoding:"application/x-tex",children:"^2"})]})})}),(0,s.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,s.jsxs)(n.span,{className:"base",children:[(0,s.jsx)(n.span,{className:"strut",style:{height:"0.8141em"}}),(0,s.jsxs)(n.span,{className:"mord",children:[(0,s.jsx)(n.span,{}),(0,s.jsx)(n.span,{className:"msupsub",children:(0,s.jsx)(n.span,{className:"vlist-t",children:(0,s.jsx)(n.span,{className:"vlist-r",children:(0,s.jsx)(n.span,{className:"vlist",style:{height:"0.8141em"},children:(0,s.jsxs)(n.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,s.jsx)(n.span,{className:"pstrut",style:{height:"2.7em"}}),(0,s.jsx)(n.span,{className:"sizing reset-size6 size3 mtight",children:(0,s.jsx)(n.span,{className:"mord mtight",children:"2"})})]})})})})})]})]})})]}),"PO: Agentic Turn-based Policy Optimization via Tree Search ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04767",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Online Action-Stacking Improves Reinforcement Learning Performance for Air Traffic Control ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04287",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Reasoning Over Space: Enabling Geographic Reasoning for LLM-Based Generative Next POI Recommendation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04562",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] AgentOCR: Reimagining Agent History via Optical Self-Compression ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04786",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] TourPlanner: A Competitive Consensus Framework with Constraint-Gated Reinforcement Learning for Travel Planning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04698",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Flexible Manufacturing Systems Intralogistics: Dynamic Optimization of AGVs and Tool Sharing Using Coloured-Timed Petri Nets and Actor-Critic RL with Actions Masking ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04887",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Thinking-Based Non-Thinking: Solving the Reward Hacking Problem in Training Hybrid Reasoning Models via Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04805",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Survival Dynamics of Neural and Programmatic Policies in Evolutionary Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04365",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04954",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Text as a Universal Interface for Transferable Personalization ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04963",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] ConMax: Confidence-Maximizing Compression for Efficient Chain-of-Thought Reasoning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04973",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] AlgBench: To What Extent Do Large Reasoning Models Understand Algorithms? ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04996",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] On the Hidden Objective Biases of Group-based Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.05002",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] H\xe1n D\u0101n Xu\xe9 B\xf9 (Mimicry) or Q\u012bng Ch\u016b Y\xfa L\xe1n (Mastery)? A Cognitive Perspective on Reasoning Distillation in Large Language Models ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.05019",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Reinforced Efficient Reasoning via Semantically Diverse Exploration ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.05053",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Safe Continual Reinforcement Learning Methods for Nonstationary Environments. Towards a Survey of the State of the Art ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.05152",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.05205",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.05242",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 15'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Learning Dynamics in RL Post-Training for Language Models ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04670",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Prior-Informed Zeroth-Order Optimization with Adaptive Direction Alignment for Memory-Efficient LLM Fine-Tuning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04710",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04719",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] GEnSHIN: Graphical Enhanced Spatio-temporal Hierarchical Inference Network for Traffic Flow Prediction ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04550",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] XGrammar 2: Dynamic and Efficient Structured Generation Engine for Agentic LLMs ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04426",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Sci-Reasoning: A Dataset Decoding AI Innovation Patterns ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04577",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] CRUNet-MR-Univ: A Foundation Model for Diverse Cardiac MRI Reconstruction ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04428",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Higher-Order Knowledge Representations for Agentic Scientific Reasoning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04878",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] TeleTables: A Benchmark for Large Language Models in Telecom Table Interpretation ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04202",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] MPM-LLM4DSE: Reaching the Pareto Frontier in HLS with Multimodal Learning and LLM-Driven Exploration ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04801",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Integrating Multi-Agent Simulation, Behavioral Forensics, and Trust-Aware Machine Learning for Adaptive Insider Threat Detection ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04243",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Conversational AI for Rapid Scientific Prototyping: A Case Study on ESA's ELOPE Competition ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04920",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Arabic Prompts with English Tools: A Benchmark ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.05101",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] SimuAgent: An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.05187",children:"link"})]}),"\n",(0,s.jsxs)(n.li,{children:["[arXiv260109] Crystal Generation using the Fully Differentiable Pipeline and Latent Space Optimization ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.04606",children:"link"})]}),"\n"]})]})}function d(i={}){const{wrapper:n}={...(0,a.R)(),...i.components};return n?(0,s.jsx)(n,{...i,children:(0,s.jsx)(h,{...i})}):h(i)}},8453:(i,n,e)=>{e.d(n,{R:()=>t,x:()=>l});var r=e(6540);const s={},a=r.createContext(s);function t(i){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof i?i(n):{...n,...i}},[n,i])}function l(i){let n;return n=i.disableParentContext?"function"==typeof i.components?i.components(s):i.components||s:t(i.components),r.createElement(a.Provider,{value:n},i.children)}}}]);