"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[513],{4793:(i,e,n)=>{n.r(e),n.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"daily/20251027-20251102","title":"20251027-20251102","description":"2025-10-27","source":"@site/docs/daily/20251027-20251102.md","sourceDirName":"daily","slug":"/daily/20251027-20251102","permalink":"/daily/20251027-20251102","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1761720550000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Daily","permalink":"/category/daily"},"next":{"title":"Paper","permalink":"/category/paper"}}');var s=n(4848),a=n(8453);const t={},o="20251027-20251102",l={},c=[{value:"2025-10-27",id:"2025-10-27",level:2},{value:"2025-10-28",id:"2025-10-28",level:2}];function h(i){const e={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...i.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"20251027-20251102",children:"20251027-20251102"})}),"\n",(0,s.jsx)(e.h2,{id:"2025-10-27",children:"2025-10-27"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv2510] Learning to Schedule: A Supervised Learning Framework for Network-Aware\nScheduling of Data-Intensive Workloads"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [scheduling], [network-aware scheduling, supervised learning, data-intensive workloads, Kubernetes, job completion time prediction]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Sankalpa Timilsina, Susmit Shannigrahi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Tennessee Technological University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"http://arxiv.org/pdf/2510.21419v1",children:"http://arxiv.org/pdf/2510.21419v1"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a network-aware job scheduler using supervised learning to predict job completion times based on real-time cluster telemetry. The system employs a prediction-and-ranking mechanism that evaluates nodes and selects optimal placements for data-intensive workloads. Evaluation on a geo-distributed Kubernetes cluster showed 34-54% higher accuracy in node selection compared to the default Kubernetes scheduler."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv2510] From SLA to vendor-neutral metrics: An intelligent knowledge-based\napproach for multi-cloud SLA-based broker"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [cloud computing, multi-cloud, SLA management, vendor-neutral metrics, intelligent knowledge-based system, auto-scaling]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," V\xedctor Ramp\xe9rez, Javier Soriano, David Lizcano, Shadi Aljawarneh, Juan A. Lara"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Universidad Polit\xe9cnica de Madrid (UPM), Madrid Open University (UDIMA)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"http://arxiv.org/pdf/2510.21173v1",children:"http://arxiv.org/pdf/2510.21173v1"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes an intelligent knowledge-based system that automatically translates high-level SLAs into vendor-neutral metrics for multi-cloud environments. The approach enables cross-provider metric measurement and provides consumer feedback through an intelligent tutoring system. Validation with IaaS and PaaS use cases demonstrates the system allows transparent multi-cloud exploitation across various application domains."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv2510] xMem: A CPU-Based Approach for Accurate Estimation of GPU Memory in Deep\nLearning Training Workloads"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [GPU memory estimation, dynamic analysis, resource management, scheduling]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jiabo Shi, Dimitrios Pezaros, Yehia Elkhatib"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Glasgow"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"http://arxiv.org/pdf/2510.21048v1",children:"http://arxiv.org/pdf/2510.21048v1"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," xMem proposes a CPU-based dynamic analysis framework to accurately estimate peak GPU memory requirements for deep learning training workloads without consuming GPU resources. The method achieves 91% reduction in median relative error and 75% reduction in OOM probability compared to existing solutions. This enables better GPU sharing and scheduling in cluster environments while significantly improving memory conservation potential."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv2510] Lincoln AI Computing Survey (LAICS) and Trends"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [Other models training, Other models inference], [AI accelerators, performance analysis, power consumption, market segmentation, computing architectures]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Albert Reuther, Peter Michaleas, Michael Jones, Vijay Gadepally, Jeremy Kepner"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," MIT Lincoln Laboratory"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"http://arxiv.org/pdf/2510.20931v1",children:"http://arxiv.org/pdf/2510.20931v1"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper updates the Lincoln AI Computing Survey by collecting performance and power consumption data of commercial AI accelerators, plotting them on scatter graphs, and analyzing market trends. It introduces a new categorization of computing architectures and examines how GenAI models have shifted computational demands toward matrix-vector operations and high memory bandwidth. The survey highlights ongoing innovations in AI hardware across various deployment scales from embedded systems to data centers."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv2510] ParaRNN: Unlocking Parallel Training of Nonlinear RNNs for Large\nLanguage Models"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [LLM training], [parallel training, nonlinear RNNs, sequence modeling, Newton's iterations, parallel reductions]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Federico Danieli, Pau Rodriguez, Miguel Sarabia, Xavier Suau, Luca Zappella"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Apple"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"http://arxiv.org/pdf/2510.21450v1",children:"http://arxiv.org/pdf/2510.21450v1"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," ParaRNN enables parallel training of nonlinear RNNs by formulating recurrence relationships as a system of equations and solving them using Newton's iterations with parallel reductions. This approach achieves up to 665x speedup over sequential methods and allows training 7B parameter RNNs with performance comparable to Transformers and Mamba2. The framework is released as open-source to facilitate scalable nonlinear RNN research."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv2510] REVE: A Foundation Model for EEG -- Adapting to Any Setup with\nLarge-Scale Pretraining on 25,000 Subjects"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [Other models training], [EEG foundation model, 4D positional encoding, masked autoencoding, brain-computer interfaces, clinical neuroscience]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yassine El Ouahidi, Jonathan Lys, Philipp Th\xf6lke, Nicolas Farrugia, Bastien Pasdeloup, Vincent Gripon, Karim Jerbi, Giulia Lioi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," IMT Atlantique, Universit\xe9 de Montr\xe9al, Mila, UNIQUE"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"http://arxiv.org/pdf/2510.21585v1",children:"http://arxiv.org/pdf/2510.21585v1"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," REVE introduces a novel 4D positional encoding scheme and uses masked autoencoding pretraining on 60,000 hours of EEG data from 25,000 subjects. The model achieves state-of-the-art performance across 10 EEG tasks including motor imagery and seizure detection. It demonstrates strong generalization with minimal fine-tuning and enables standardized EEG research through released code and weights."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2025-10-28",children:"2025-10-28"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 13"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Simopt-Power: Leveraging Simulation Metadata for Low-Power Design Synthesis"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [FPGA power optimization], [simulation metadata, Shannon Decomposition, activity profiling, truth table duplication, netlist transformation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Eashan Wadhwa, Shanker Shreejith"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Trinity College Dublin"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.21745",children:"https://arxiv.org/pdf/2510.21745"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents Simopt-Power, a framework that uses simulation metadata to identify high-toggle paths in FPGA designs and applies Shannon Decomposition to insert duplicate logic and relocate critical nets. The method achieves approximately 9% reduction in switching-induced power while adding only modest resource overhead. Results demonstrate that coupling simulation insights with targeted optimizations provides an effective approach for dynamic power reduction in FPGA design flows."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Separation of Unconscious Robots with Obstructed Visibility"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed robotics], [opaque robots, semicircle separation, look-compute-move cycle, semi-synchronous scheduler]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Prajyot Pyati, Navjot Kaur, Saswata Jana, Adri Bhattacharya, Partha Sarathi Mandal"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Indian Institute of Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.22434",children:"https://arxiv.org/pdf/2510.22434"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents a collision-free algorithm for unconscious robots with obstructed visibility that separates robots into concentric semicircles. The algorithm operates under a semi-synchronous scheduler and achieves separation in O(n) epochs. The robots coordinate without knowing the total number of robots but agree on one coordinate axis."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] When Agents are Powerful: Black Hole Search in Time-Varying Graphs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed algorithms], [global communication, 1-hop visibility, deterministic algorithms, mobile agents]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Tanvir Kaur, Ashish Saxena"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Indian Institute of Technology Ropar"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.22309",children:"https://arxiv.org/pdf/2510.22309"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper enhances Black Hole Search in dynamic graphs by equipping agents with global communication and 1-hop visibility capabilities. These improvements allow for more efficient solutions compared to previous face-to-face communication approaches. The enhanced agent capabilities reduce the number of agents required to successfully identify the black hole while ensuring at least one agent survives."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] A Feature Engineering Approach for Business Impact-Oriented Failure Detection in Distributed Instant Payment Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [feature engineering, anomaly detection, ISO 20022 message processing, processing time analysis, explainable AI]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Lorenzo Porcelli"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Bank of Italy, University of Salerno"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.21710",children:"https://arxiv.org/pdf/2510.21710"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces a feature engineering approach that computes processing times between consecutive ISO 20022 message exchanges to create system state representations for anomaly detection. The method enables early failure detection and incident classification in distributed instant payment systems. Experimental evaluation on TARGET Instant Payment Settlement demonstrates effectiveness in detecting diverse anomaly patterns while providing interpretable explanations for business impact assessment."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Heaven & Hell II: Scale Laws and Robustness in One-Step Heaven-Hell Consensus"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [ai], [network consensus], [Heaven-Hell dynamics, conservation-law perspective, tie-breaking policies, pointwise bounds, asynchronous updates, Coq proofs]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Nnamdi Daniel Aghanya, Romain Leemans"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Cranfield University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.21950",children:"https://arxiv.org/pdf/2510.21950"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper develops scale laws and operational refinements for Heaven-Hell consensus dynamics, using a conservation-law perspective to derive tighter bounds and robustness guarantees. The research establishes conditions for robust convergence under various scenarios including tie-breaking policies, asynchronous updates, and multiple hubs. All proofs are mechanized in Coq and experiments validate the tightness of the bounds across diverse network types."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Rethinking Inference Placement for Deep Learning across Edge and Cloud Platforms: A Multi-Objective Optimization Perspective and Future Directions"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [model offloading, model compression, model distillation, transmission compression, internal classifiers]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zongshun Zhang, Ibrahim Matta"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Boston University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.22909",children:"https://arxiv.org/pdf/2510.22909"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper surveys methods for optimizing deep learning inference placement across edge and cloud platforms using techniques like model partitioning, compression, and architecture adaptations. It analyzes how these approaches balance multiple objectives including latency, privacy, and monetary cost. The research concludes that effective inference placement requires multi-objective optimization across the computational continuum from devices to cloud."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] CodeAD: Synthesize Code of Rules for Log-based Anomaly Detection with LLMs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [hierarchical clustering, anchor-grounded sampling, agentic workflow, rule synthesis, contrastive log windows]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Junjie Huang, Minghua He, Jinyang Liu, Yintong Huo, Domenico Bianculli, Michael R. Lyu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The Chinese University of Hong Kong, Peking University, Singapore Management University, University of Luxembourg"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.22986",children:"https://arxiv.org/pdf/2510.22986"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," CodeAD automatically synthesizes lightweight Python rule functions for log-based anomaly detection using LLMs through hierarchical clustering and iterative agentic workflows. The framework achieves 3.6% higher F1 score than state-of-the-art methods while processing data 4x faster at minimal cost, providing an interpretable and efficient solution for real-time log analysis."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Power to the Clients: Federated Learning in a Dictatorship Setting"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [federated learning, byzantine clients, dictator clients, model convergence, attack strategies]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Mohammadsajad Alipour, Mohammad Mohammadi Amiri"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Rensselaer Polytechnic Institute"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.22149",children:"https://arxiv.org/pdf/2510.22149"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces dictator clients, a class of malicious participants in federated learning that can erase other clients' contributions while preserving their own. The authors propose attack strategies and analyze their effects on model convergence in various scenarios including collaboration and betrayal between multiple dictator clients. Their theoretical analysis and empirical evaluations demonstrate how these clients can significantly compromise the global model's integrity."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Sentinel: Dynamic Knowledge Distillation for Personalized Federated Intrusion Detection in Heterogeneous IoT Networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [personalized federated learning, knowledge distillation, dual-model architecture, class-balanced loss, gradient aggregation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Gurpreet Singh, Keshav Sood, P. Rajalakshmi, Yong Xiang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Deakin University, Indian Institute of Technology Hyderabad"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23019",children:"https://arxiv.org/pdf/2510.23019"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes Sentinel, a personalized federated intrusion detection system that uses a dual-model architecture with teacher-student knowledge distillation to handle data heterogeneity in IoT networks. It incorporates bidirectional distillation, feature alignment, and balanced loss functions to improve performance. Experiments show Sentinel outperforms existing methods while maintaining communication efficiency."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] AirFed: Federated Graph-Enhanced Multi-Agent Reinforcement Learning for Multi-UAV Cooperative Mobile Edge Computing"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [federated learning, graph attention networks, multi-agent reinforcement learning, trajectory planning, task offloading, resource allocation, gradient quantization]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zhiyu Wang, Suman Raj, Rajkumar Buyya"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The University of Melbourne, Indian Institute of Science"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23053",children:"https://arxiv.org/pdf/2510.23053"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes AirFed, a federated graph-enhanced multi-agent reinforcement learning framework that uses dual-layer Graph Attention Networks and a dual-Actor single-Critic architecture for UAV coordination in mobile edge computing. The system achieves significant improvements including 42.9% cost reduction, over 99% deadline satisfaction, and 54.5% lower communication overhead compared to state-of-the-art methods, demonstrating strong scalability for large-scale UAV deployments."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream Processing Pipelines"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [Hypergraph of Thoughts, multi-agent reasoning, resilient execution strategies, advanced query analysis]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Abolfazl Younesi, Zahra Najafabadi Samani, Thomas Fahringer"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Innsbruck"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23408",children:"https://arxiv.org/pdf/2510.23408"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," AutoStreamPipe uses Large Language Models with Hypergraph of Thoughts to automatically generate data stream processing pipelines from high-level user intents. The framework bridges the semantic gap between user requirements and platform-specific implementations through structured multi-agent reasoning. Experimental results show it significantly reduces development time by 6.3\xd7 and error rates by 5.19\xd7 compared to traditional LLM code-generation methods."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] Bayes-Split-Edge: Bayesian Optimization for Constrained Collaborative Inference in Wireless Edge Systems"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [Bayesian optimization, split learning, collaborative inference, wireless edge computing, constrained optimization, neural network splitting]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Fatemeh Zahra Safaeipour, Jacob Chakareski, Morteza Hashemi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Kansas, New Jersey Institute of Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23503",children:"https://arxiv.org/pdf/2510.23503"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes Bayes-Split-Edge, a Bayesian optimization framework that jointly optimizes transmission power and neural network split points for collaborative inference in wireless edge systems. The method uses a novel hybrid acquisition function to balance inference utility with energy and delay constraints. Results show it achieves 2.4\xd7 evaluation cost reduction compared to standard Bayesian optimization while matching exhaustive search performance under tight constraints."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv251028] The First Star-by-star $N$-body/Hydrodynamics Simulation of Our Galaxy Coupling with a Surrogate Model"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [N-body simulation, smoothed-particle hydrodynamics, surrogate model, deep learning, Fugaku supercomputer]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Keiya Hirashima, Michiko S. Fujii, Takayuki R. Saitoh, Naoto Harada, Kentaro Nomura, Kohji Yoshikawa, Yutaka Hirai, Tetsuro Asano, Kana Moriwaki, Masaki Iwasawa, Takashi Okamoto, Junichiro Makino"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," RIKEN, University of Tokyo, Kobe University, Preferred Networks, University of Tsukuba, Tohoku University of Community Service and Science, Universitat de Barcelona, National Institute of Technology, Hokkaido University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2510.23330",children:"https://arxiv.org/pdf/2510.23330"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents a novel integration scheme combining N-body/hydrodynamics simulations with machine learning surrogate models to bypass computational bottlenecks caused by supernova explosions. The method achieved 300 billion particles using 148,900 nodes, breaking the billion-particle barrier and enabling the first star-by-star galaxy simulation. This represents a major advancement in computational astrophysics by resolving individual stars in Milky Way simulations."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 52'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Transitive RL: Value Learning via Divide and Conquer ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22512",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Predictive Coding Enhances Meta-RL To Achieve Interpretable Bayes-Optimal Belief Representation Under Partial Observability ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22039",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Hazard-Responsive Digital Twin for Climate-Driven Urban Resilience and Equity ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22941",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22740",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22282",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Beyond Reasoning Gains: Mitigating General Capabilities Forgetting in Large Reasoning Models ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21978",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21758",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Advantage Shaping as Surrogate Reward Maximization: Unifying Pass@K Policy Gradients ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23049",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] PACR: Progressively Ascending Confidence Reward for LLM Reasoning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22255",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Is Temporal Difference Learning the Gold Standard for Stitching in RL? ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21995",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23038",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] FlowCritic: Bridging Value Estimation with Flow Matching in Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22686",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Offline Preference Optimization via Maximum Marginal Likelihood Estimation ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22881",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group Sequence Policy Optimization ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22477",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Dopamine-driven synaptic credit assignment in neural networks ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22178",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Activating Visual Context and Commonsense Reasoning through Masked Prediction in VLMs ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21807",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Towards Stable and Effective Reinforcement Learning for Mixture-of-Experts ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23027",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] UCB-type Algorithm for Budget-Constrained Expert Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22654",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Online Optimization for Offline Safe Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22027",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] GAPO: Group Adaptive Policy Optimization for Real-World Code Edit ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21830",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Guardian: Decoupling Exploration from Safety in Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22859",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] STAR-RIS-assisted Collaborative Beamforming for Low-altitude Wireless Networks ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22108",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22570",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Solving Continuous Mean Field Games: Deep Reinforcement Learning for Non-Stationary Dynamics ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22158",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22370",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22798",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Softmax is $1/2$-Lipschitz: A tight bound across all $\\ell_p$ norms ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23012",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22568",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Agentic Reinforcement Learning for Real-World Code Repair ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22075",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Computational Hardness of Reinforcement Learning with Partial $q^\u03c0$-Realizability ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21888",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Toward Agents That Reason About Their Computation ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22833",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable Reasoning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22543",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Do You Trust the Process?: Modeling Institutional Trust for Community Adoption of Reinforcement Learning Policies ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22017",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22832",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22319",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] SynCast: Synergizing Contradictions in Precipitation Nowcasting via Diffusion Sequential Preference Optimization ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21847",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Multi-Agent Conditional Diffusion Model with Mean Field Communication as Wireless Resource Allocation Planner ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22969",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Think before Recommendation: Autonomous Reasoning-enhanced Recommender ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23077",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Adapting Interleaved Encoders with PPO for Language-Guided Reinforcement Learning in BabyAI ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23148",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Guiding Skill Discovery with Foundation Models ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23167",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] TARC: Time-Adaptive Robotic Control ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23176",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23216",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23304",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N Sampling via max@k Optimisation ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23393",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Causal Deep Q Network ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23424",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] An Information-Theoretic Analysis of Out-of-Distribution Generalization in Meta-Learning with Applications to Meta-RL ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23448",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Learning to Reason Efficiently with Discounted Reinforcement Learning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23486",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Sequential Multi-Agent Dynamic Algorithm Configuration ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23535",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Multi-Agent Evolve: LLM Self-Improve through Co-evolution ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23595",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Right Place, Right Time: Market Simulation-based RL for Execution Optimisation ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22206",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Reinforcement learning-guided optimization of critical current in high-temperature superconductors ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22424",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] PASS-Enhanced MEC: Joint Optimization of Task Offloading and Uplink PASS Beamforming ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22948",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerat" total: 23'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21735",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Impact and Implications of Generative AI for Enterprise Architects in Agile Environments: A Systematic Literature Review ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22003",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Step2Motion: Locomotion Reconstruction from Pressure Sensing Insoles ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22712",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Accelerating Materials Design via LLM-Guided Evolutionary Search ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22503",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] PACR: Progressively Ascending Confidence Reward for LLM Reasoning ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22255",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] AI-Enhanced Operator Assistance for UNICOS Applications ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21717",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Dopamine-driven synaptic credit assignment in neural networks ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22178",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] OpenEM: Large-scale multi-structural 3D datasets for electromagnetic methods ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21859",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Encoder-Decoder Diffusion Language Models for Efficient Training and Inference ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22852",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] QuArch: A Benchmark for Evaluating LLM Reasoning in Computer Architecture ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22087",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Residual-guided AI-CFD hybrid method enables stable and scalable simulations: from 2D benchmarks to 3D applications ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21804",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Graph-Coarsening Approach for the Capacitated Vehicle Routing Problem with Time Windows ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22329",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Approximate Gradient Coding for Distributed Learning with Heterogeneous Stragglers ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22539",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.21879",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23127",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Guiding Skill Discovery with Foundation Models ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23167",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Accelerating Eigenvalue Dataset Generation via Chebyshev Subspace Filter ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23215",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Accelerating IC Thermal Simulation Data Generation via Block Krylov and Operator Action ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23221",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Progressive Growing of Patch Size: Curriculum Learning for Accelerated and Improved Medical Image Segmentation ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23241",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] PAHQ: Accelerating Automated Circuit Discovery through Mixed-Precision Inference Optimization ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23264",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Towards a Generalizable AI for Materials Discovery: Validation through Immersion Coolant Screening ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.23371",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] HPC-Driven Modeling with ML-Based Surrogates for Magnon-Photon Dynamics in Hybrid Quantum Systems ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22221",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv251028] Reinforcement learning-guided optimization of critical current in high-temperature superconductors ",(0,s.jsx)(e.a,{href:"http://arxiv.org/abs/2510.22424",children:"link"})]}),"\n"]})]})}function d(i={}){const{wrapper:e}={...(0,a.R)(),...i.components};return e?(0,s.jsx)(e,{...i,children:(0,s.jsx)(h,{...i})}):h(i)}},8453:(i,e,n)=>{n.d(e,{R:()=>t,x:()=>o});var r=n(6540);const s={},a=r.createContext(s);function t(i){const e=r.useContext(a);return r.useMemo(function(){return"function"==typeof i?i(e):{...e,...i}},[e,i])}function o(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(s):i.components||s:t(i.components),r.createElement(a.Provider,{value:e},i.children)}}}]);