"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[945],{594:(n,i,e)=>{e.r(i),e.d(i,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"daily/20260302-20260308","title":"20260302-20260308","description":"2026-03-02","source":"@site/docs/daily/20260302-20260308.md","sourceDirName":"daily","slug":"/daily/20260302-20260308","permalink":"/daily/20260302-20260308","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1772421889000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"20260223-20260301","permalink":"/daily/20260223-20260301"},"next":{"title":"Paper","permalink":"/category/paper"}}');var s=e(4848),t=e(8453);const a={},o="20260302-20260308",l={},c=[{value:"2026-03-02",id:"2026-03-02",level:2}];function d(n){const i={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.header,{children:(0,s.jsx)(i.h1,{id:"20260302-20260308",children:"20260302-20260308"})}),"\n",(0,s.jsx)(i.h2,{id:"2026-03-02",children:"2026-03-02"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"cs.DC total: 12"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260302] QoSFlow: Ensuring Service Quality of Distributed Workflows Using Interpretable Sensitivity Models"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [sys], [distributed workflow scheduling], [performance modeling, configuration space partitioning, statistical sensitivity, QoS-driven scheduling]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Md Hasanur Rashid, Jesun Firoz, Nathan R. Tallent, Luanzheng Guo, Meng Tang, Dong Dai"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," University of Delaware, Pacific Northwest National Laboratory, Illinois Institute of Technology"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23598",children:"https://arxiv.org/pdf/2602.23598"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," QoSFlow is a performance modeling method that partitions a workflow's execution configuration space into regions with similar behavior to enable efficient QoS-driven scheduling. It outperforms the best-performing standard heuristic by 27.38% and its recommended configurations consistently match measured execution outcomes across different QoS constraints."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260302] Mixed Choice in Asynchronous Multiparty Session Types"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [sys], [distributed systems], [multiparty session types, asynchronous communication, mixed choice, protocol verification, Erlang/OTP]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Laura Bocchi, Raymond Hu, Adriana Laura Voinea, Simon Thompson"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," University of Kent, Queen Mary University of London, University of Glasgow"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23927",children:"https://arxiv.org/pdf/2602.23927"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," This paper introduces a multiparty session type framework that supports asynchronous mixed choice, allowing for transient state inconsistencies while guaranteeing eventual consistency among distributed participants. The authors prove the system's correctness and implement a toolchain for specifying and validating such protocols, which they test by reimplementing part of the RabbitMQ broker's client."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260302] nvidia-pcm: A D-Bus-Driven Platform Configuration Manager for OpenBMC Environments"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [sys], [firmware management], [D-Bus, JSON configuration, environment variables, systemd, OpenBMC]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Harinder Singh"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," NVIDIA Corporation"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24237",children:"https://arxiv.org/pdf/2602.24237"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper introduces nvidia-pcm, a D-Bus-driven platform configuration manager for OpenBMC environments that uses JSON files to declaratively define hardware variants. At boot, it queries hardware identity via D-Bus and exports platform-specific configurations as environment variables, enabling a single firmware image to serve multiple server platforms. This approach eliminates the need for separate firmware builds per variant, significantly reducing maintenance overhead."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260302] Green or Fast? Learning to Balance Cold Starts and Idle Carbon in Serverless Computing"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [others], [deep reinforcement learning, serverless computing, cold-start optimization, carbon-aware management, sequential decision problem]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Bowen Sun, Christos D. Antonopoulos, Evgenia Smirni, Bin Ren, Nikolaos Bellas, Spyros Lalis"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," William & Mary, University of Thessaly"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23935",children:"https://arxiv.org/pdf/2602.23935"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper proposes LACE-RL, a framework that uses deep reinforcement learning to dynamically manage serverless function instances, balancing cold-start latency and idle carbon emissions. It formulates pod retention as a sequential decision problem, jointly modeling cold-start probability, latency costs, and real-time carbon intensity. The method significantly reduces both cold starts and idle carbon emissions compared to static policies, achieving a superior latency-carbon trade-off."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260302] 2G2T: Constant-Size, Statistically Sound MSM Outsourcing"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [sys], [cryptography], [multi-scalar multiplication, outsourcing protocol, statistical soundness, Ristretto255, constant-size verification]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Majid Khabbazian"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," University of Alberta"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23464",children:"https://arxiv.org/pdf/2602.23464"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper presents 2G2T, a protocol for verifiably outsourcing multi-scalar multiplication (MSM) computations to an untrusted server. It uses a one-time setup to generate a public merged-bases vector, allowing verification with only a single inner product and constant group operations, while the server performs two MSMs. The method achieves statistical soundness with a constant-size server response, making verification up to ~300x faster than local computation for large inputs."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260302] FedDAG: Clustered Federated Learning via Global Data and Gradient Integration for Heterogeneous Environments"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [clustered federated learning, dual-encoder architecture, weighted class-wise similarity, gradient integration, cross-cluster feature transfer]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Anik Pramanik, Murat Kantarcioglu, Vincent Oria, Shantanu Sharma"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," New Jersey Institute of Technology, Virginia Tech"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23504",children:"https://arxiv.org/pdf/2602.23504"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," FedDAG is a clustered federated learning framework that uses a weighted, class-wise similarity metric combining both data and gradient information for client clustering, and employs a dual-encoder architecture to enable cross-cluster knowledge transfer. This approach provides a more holistic client similarity assessment and allows cluster models to benefit from diverse data across clusters. Experiments show that FedDAG consistently outperforms existing clustered FL methods in accuracy under heterogeneous data settings."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260302] Rudder: Steering Prefetching in Distributed GNN Training using LLM Agents"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [others], [LLM agents, in-context learning, prefetching, distributed GNN training, DistDGL]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Aishwarya Sarkar, Sayan Ghosh, Nathan Tallent, Aman Chadha, Tanya Roosta, Ali Jannesari"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Iowa State University, Pacific Northwest National Laboratory, University of California, Berkeley, Amazon GenAI"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23556",children:"https://arxiv.org/pdf/2602.23556"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper introduces Rudder, a software module that uses LLM agents for adaptive prefetching in distributed Graph Neural Network (GNN) training to minimize communication stalls. It leverages the in-context learning and reasoning capabilities of LLMs to dynamically decide what and when to prefetch, outperforming static methods. Evaluations show up to 91% improvement in training performance over a baseline with no prefetching and an 82% improvement over static prefetching."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260302] Data Driven Optimization of GPU efficiency for Distributed LLM Adapter Serving"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [llm inference], [digital twin, machine learning model, greedy placement algorithm]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Ferran Agullo, Joan Oliveras, Chen Wang, Alberto Gutierrez-Torre, Olivier Tardieu, Alaa Youssef, Jordi Torres, Josep Ll. Berral"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Barcelona Supercomputing Center (BSC), Universitat Polit\xe8cnica de Catalunya - BarcelonaTech (UPC), IBM Research"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24044",children:"https://arxiv.org/pdf/2602.24044"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," This paper introduces a data-driven pipeline to optimize GPU efficiency for distributed LLM adapter serving. The method combines a high-fidelity Digital Twin for performance emulation, a distilled ML model for fast prediction, and a greedy placement algorithm to minimize the number of GPUs needed for a workload. The results show the pipeline significantly improves GPU efficiency and can be adapted for other objectives like latency minimization."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260302] MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [post-training], [machine unlearning, privacy-preserving, server-client framework, perturbed copies, reparameterization, harmonic denoising]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Tiantong Wang, Xinyu Yan, Tiantong Wu, Yurong Hao, Yong Jiang, Fei Huang, Wei Yang Bryan Lim"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Nanyang Technological University, Alibaba-NTU Global e-Sustainability CorpLab, Tongyi Lab, Alibaba Group"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23798",children:"https://arxiv.org/pdf/2602.23798"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper proposes MPU, a privacy-preserving framework for machine unlearning in large language models that addresses dual non-disclosure constraints by distributing perturbed model copies to clients for local unlearning and aggregating updates server-side with denoising. It demonstrates that MPU maintains comparable unlearning performance to noise-free baselines across multiple algorithms, with minimal performance degradation even under added noise."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260302] Hestia: Hyperthread-Level Scheduling for Cloud Microservices with Interference-Aware Attention"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [hyperthread-level scheduling, interference-aware scheduling, self-attention, simultaneous multithreading (SMT), sharing-core (SC), sharing-socket (SS)]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Dingyu Yang, Fanyong Kong, Jie Dai, Shiyou Qian, Shuangwei Li, Jian Cao, Guangtao Xue, Gang Chen"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Zhejiang University, Shanghai Jiao Tong University, Alibaba Group, OKBL Technology Company Limited"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23758",children:"https://arxiv.org/pdf/2602.23758"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper presents Hestia, a scheduling framework that uses a self-attention-based predictor and an interference scoring model to perform hyperthread-level, interference-aware placement of cloud microservices. It identifies and models two key contention patterns (sharing-core and sharing-socket) to mitigate performance interference. The system significantly reduces service latency and CPU consumption, outperforming existing schedulers in production deployments."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260302] The PLUTO Code on GPUs: Offloading Lagrangian Particle Methods"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [sys], [high-performance computing], [OpenACC, MPI, GPU offloading, Lagrangian Particles, weak scaling, strong scaling]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Alessio Suriano, Stefano Truzzi, Agnese Costa, Marco Rossazza, Nitin Shukla, Andrea Mignone, Vittoria Berta, Claudio Zanni"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Universit\xe0 degli Studi di Torino, Istituto Nazionale di Astrofisica, Italian Research Center on High Performance Computing, Big Data and Quantum Computing, CINECA"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23434",children:"https://arxiv.org/pdf/2602.23434"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," This paper presents a GPU-compatible redesign of the Lagrangian Particles module in the PLUTO astrophysics code using OpenACC and MPI for high-performance computing. The implementation demonstrates efficient scaling on up to 1024 GPUs, achieving a 6x speedup compared to CPU nodes. The work verifies the code against analytical solutions and is part of developing gPLUTO, a GPU-ready version of the legacy code."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260302] Advanced Scheduling Strategies for Distributed Quantum Computing Jobs"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [sys], [distributed quantum computing], [job scheduling, makespan, QPU utilization, non-local gate density, reinforcement learning, proximal policy optimization, FIFO, LIST]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Gongyu Ni, Davide Ferrari, Lester Ho, Michele Amoretti"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Tyndall National Institute, University of Parma"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24152",children:"https://arxiv.org/pdf/2602.24152"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper proposes and evaluates several advanced scheduling strategies for distributed quantum computing, including heuristics for resource maximization and a reinforcement learning approach. These methods are benchmarked against traditional schedulers like FIFO and LIST under various network conditions. The study concludes that the proposed strategies can effectively manage novel quantum-specific constraints, such as QPU utilization and entanglement latency, to improve job allocation in quantum networks."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 26'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] The Auton Agentic AI Framework ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23720",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Pacing Opinion Polarization via Graph Reinforcement Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23390",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Multi-Objective Reinforcement Learning for Large-Scale Tote Allocation in Human-Robot Collaborative Fulfillment Centers ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24182",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Foundation World Models for Agents that Learn, Verify, and Adapt Reliably Beyond Static Environments ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23997",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] EMO-R3: Reflective Reinforcement Learning for Emotional Reasoning in Multimodal Large Language Models ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23802",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Bridging Dynamics Gaps via Diffusion Schr\xf6dinger Bridge for Cross-Domain Reinforcement Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23737",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Actor-Critic Pretraining for Proximal Policy Optimization ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23804",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] See, Act, Adapt: Active Perception for Unsupervised Cross-Domain Visual Adaptation via Personalized VLM-Guided Agent ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23806",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Human Supervision as an Information Bottleneck: A Unified Theory of Error Floors in Human-Guided Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23446",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] SafeGen-LLM: Enhancing Safety Generalization in Task Planning for Robotic Systems ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24235",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Construct, Merge, Solve & Adapt with Reinforcement Learning for the min-max Multiple Traveling Salesman Problem ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23579",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Task Complexity Matters: An Empirical Study of Reasoning in LLMs for Sentiment Analysis ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24060",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Adaptive Correlation-Weighted Intrinsic Rewards for Reinforcement Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24081",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] MAGE: Multi-scale Autoregressive Generation for Offline Reinforcement Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23770",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] RUMAD: Reinforcement-Unifying Multi-Agent Debate ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23864",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Bi-level RL-Heuristic Optimization for Real-world Winter Road Maintenance ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24097",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Recycling Failures: Salvaging Exploration in RLVR via Fine-Grained Off-Policy Guidance ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24110",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Beyond State-Wise Mirror Descent: Offline Policy Optimization with Parameteric Policies ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23811",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Learning to Build: Autonomous Robotic Assembly of Stable Structures Without Predefined Plans ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23934",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Learning to maintain safety through expert demonstrations in settings with unknown constraints: A Q-learning perspective ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23816",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Learning to Generate Secure Code via Token-Level Rewards ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23407",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Learning Flexible Job Shop Scheduling under Limited Buffers and Material Kitting Constraints ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24180",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Component Centric Placement Using Deep Reinforcement Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23540",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Pessimistic Auxiliary Policy for Offline Reinforcement Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23974",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] CUDA Agent: Large-Scale Agentic RL for High-Performance CUDA Kernel Generation ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24286",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] DARE-bench: Evaluating Modeling and Instruction Fidelity of LLMs in Data Science ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24288",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 6'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] SenCache: Accelerating Diffusion Model Inference via Sensitivity-Aware Caching ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24208",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] BiKA: Kolmogorov-Arnold-Network-inspired Ultra Lightweight Neural Network Hardware Accelerator ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23455",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] LK Losses: Direct Acceptance Rate Optimization for Speculative Decoding ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23881",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] Task-Centric Acceleration of Small-Language Models ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.24174",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] FedNSAM",":Consistency"," of Local and Global Flatness for Federated Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23827",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260302] A distributed semismooth Newton based augmented Lagrangian method for distributed optimization ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2602.23854",children:"link"})]}),"\n"]})]})}function h(n={}){const{wrapper:i}={...(0,t.R)(),...n.components};return i?(0,s.jsx)(i,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},8453:(n,i,e)=>{e.d(i,{R:()=>a,x:()=>o});var r=e(6540);const s={},t=r.createContext(s);function a(n){const i=r.useContext(t);return r.useMemo(function(){return"function"==typeof n?n(i):{...i,...n}},[i,n])}function o(n){let i;return i=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:a(n.components),r.createElement(t.Provider,{value:i},n.children)}}}]);