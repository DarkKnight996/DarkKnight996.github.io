"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[368],{8263:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"daily/20260202-20260208","title":"20260202-20260208","description":"2026-02-02","source":"@site/docs/daily/20260202-20260208.md","sourceDirName":"daily","slug":"/daily/20260202-20260208","permalink":"/daily/20260202-20260208","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1770003249000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"20260126-20260201","permalink":"/daily/20260126-20260201"},"next":{"title":"Paper","permalink":"/category/paper"}}');var s=n(4848),a=n(8453);const t={},l="20260202-20260208",o={},c=[{value:"2026-02-02",id:"2026-02-02",level:2}];function d(e){const i={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.header,{children:(0,s.jsx)(i.h1,{id:"20260202-20260208",children:"20260202-20260208"})}),"\n",(0,s.jsx)(i.h2,{id:"2026-02-02",children:"2026-02-02"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"cs.DC total: 12"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260202] Towards Resiliency in Large Language Model Serving with KevlarFlow"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [decoupled model parallelism initialization, dynamic traffic rerouting, background KV cache replication, model parallelism, tensor parallelism, pipeline parallelism]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Shangshu Qian, Kipling Liu, P. C. Sruthi, Lin Tan, Yongle Zhang"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Purdue University"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22438",children:"https://arxiv.org/pdf/2601.22438"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper introduces KevlarFlow, a fault-tolerant LLM serving architecture that uses decoupled model parallelism initialization, dynamic traffic rerouting, and background KV cache replication to handle hardware failures. It significantly reduces recovery time and improves latency and time-to-first-token metrics during failures compared to existing systems."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260202] Coordinating Power Grid Frequency Regulation Service with Data Center Load Flexibility"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [Exogenous Carbon, EcoCenter, frequency regulation, GPU data centers, load flexibility]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Ali Jahanshahi, Sara Rashidi Golrouye, Osten Anderson, Nanpeng Yu, Daniel Wong"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," University of California, Riverside"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22487",children:"https://arxiv.org/pdf/2601.22487"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper introduces a framework called EcoCenter and a metric called Exogenous Carbon to enable GPU data centers to provide frequency regulation services to the power grid. It concludes that data center participation in this service can reduce the need for fossil-fueled reserves, and the resulting carbon savings often exceed the data centers' own operational emissions."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260202] AsyncMesh: Fully Asynchronous Optimization for Data and Pipeline Parallelism"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [llm training], [asynchronous optimization, sparse averaging, weight look-ahead, pipeline parallelism, data parallelism]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Thalaiyasingam Ajanthan, Sameera Ramasinghe, Gil Avraham, Hadi Mohaghegh Dolatabadi, Chamin P Hewa Koneputugodage, Violetta Shevchenko, Yan Zuo, Alexander Long"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Pluralis Research"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22442",children:"https://arxiv.org/pdf/2601.22442"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," This paper introduces AsyncMesh, a method that uses fully asynchronous updates for both data and pipeline parallelism to reduce communication overhead in distributed training. It employs weight look-ahead for pipeline stages and asynchronous sparse averaging with an EMA correction for data replicas to mitigate staleness. Experiments on large language models show it matches synchronous baseline performance while significantly cutting communication costs."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260202] SAIR: Cost-Efficient Multi-Stage ML Pipeline Autoscaling via In-Context Reinforcement Learning"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [llm inference], [in-context reinforcement learning, Pareto-dominance reward shaping, surprisal-guided experience retrieval, GPU rate control, CUDA interception]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Jianchang Su, Yifan Zhang, Shengkai Lin, Shizhen Zhao, Yusheng Zheng, Yiwei Yang, Wei Zhang"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," University of Connecticut, Shanghai Jiao Tong University, University of California, Santa Cruz"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22397",children:"https://arxiv.org/pdf/2601.22397"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," SAIR is an autoscaling framework for multi-stage ML inference pipelines that uses a Large Language Model as an in-context reinforcement learning controller to learn scaling policies online without gradient updates. It achieves improved latency and reduces resource cost significantly compared to existing baselines, demonstrating effective bottleneck detection without requiring offline training."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260202] Learning Provably Correct Distributed Protocols Without Human Knowledge"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [Monte Carlo Tree Search, transformer-based action encoder, global depth-first search, model checking, Satisfiability Modulo Theories (SMT)]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Yujie Hui, Xiaoyi Lu, Andrew Perrault, Yang Wang"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," The Ohio State University, University of Florida"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22369",children:"https://arxiv.org/pdf/2601.22369"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper proposes GGMS, a learning framework that combines a specialized Monte Carlo Tree Search with a transformer-based action encoder, global depth-first search, and model checker feedback to automatically design provably correct distributed protocols. It proves the search process is complete and demonstrates that GGMS can learn correct protocols for larger settings than existing methods."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260202] CONCUR: High-Throughput Agentic Batch Inference of LLM via Congestion-Based Concurrency Control"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [llm inference], [KV cache management, admission control, congestion control, batch inference, agentic workloads, middle-phase thrashing]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Qiaoling Chen, Zhisheng Ye, Tian Tang, Peng Sun, Boyu Tian, Guoteng Wang, Shenggui Li, Yonggang Wen, Zhenhua Han, Tianwei Zhang"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Nanyang Technological University, Shanghai Qiji Zhifeng Co., Ltd."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22705",children:"https://arxiv.org/pdf/2601.22705"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper introduces CONCUR, a proactive agent-level admission control system that prevents KV cache thrashing in LLM batch inference by dynamically regulating the number of active agents based on runtime cache pressure. It improves throughput significantly, up to 4.09x on Qwen3-32B, by maintaining cache efficiency for long-lived, asynchronous agentic workloads."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260202] FedAdaVR: Adaptive Variance Reduction for Robust Federated Learning under Limited Client Participation"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [others], [federated learning, variance reduction, adaptive optimizer, quantization, partial client participation]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," S M Ruhul Kabir Howlader, Xiao Chen, Yifei Xie, Lu Liu"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," University of Leicester, University of Edinburgh, University of Exeter"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22204",children:"https://arxiv.org/pdf/2601.22204"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper proposes FedAdaVR, a federated learning algorithm that combines an adaptive optimizer with variance reduction to mitigate errors from sporadic client participation by using stored client updates. It also introduces a quantized version, FedAdaVR-Quant, to reduce memory overhead. The method is proven to eliminate partial participation error and outperforms state-of-the-art baselines in experiments under IID and non-IID data settings."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260202] HetCCL: Accelerating LLM Training with Heterogeneous GPUs"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [llm training], [collective communication, RDMA, NCCL, RCCL, All-Reduce, All-Gather, Reduce-Scatter, data parallelism, model parallelism]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Heehoon Kim, Jaehwan Lee, Taejeoung Kim, Jongwon Park, Jinpyo Kim, Pyongwon Suh, Ryan H. Choi, Sangwoo Lee, Jaejin Lee"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Seoul National University, Moreh Inc., Samsung Research"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22585",children:"https://arxiv.org/pdf/2601.22585"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," The paper introduces HetCCL, a collective communication library that enables high-performance communication across heterogeneous GPUs (e.g., NVIDIA and AMD) by unifying vendor-specific backends like NCCL and RCCL without requiring driver modifications. It matches the performance of vendor libraries in homogeneous setups and uniquely scales in heterogeneous environments, allowing efficient large language model training on mixed GPU clusters without changes to existing deep learning applications."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260202] ZK-HybridFL: Zero-Knowledge Proof-Enhanced Hybrid Ledger for Federated Learning"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [others], [federated learning, directed acyclic graph (DAG) ledger, sidechains, zero-knowledge proofs (ZKPs), event-driven smart contracts, oracle-assisted sidechain, challenge mechanism]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Amirhossein Taherpour, Xiaodong Wang"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Columbia University"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22302",children:"https://arxiv.org/pdf/2601.22302"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," This paper proposes ZK-HybridFL, a secure decentralized federated learning framework that integrates a DAG ledger with sidechains and zero-knowledge proofs for privacy-preserving model validation. The method uses event-driven smart contracts and an oracle-assisted sidechain to verify local updates without exposing data, and includes a challenge mechanism to detect adversarial behavior. Experiments show it achieves faster convergence, higher accuracy, and robust security compared to prior frameworks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260202] SQUAD: Scalable Quorum Adaptive Decisions via ensemble of early exit neural networks"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [llm inference], [early-exit neural networks, ensemble learning, neural architecture search, quorum-based stopping, dynamic inference]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Matteo Gambella, Fabrizio Pittorino, Giuliano Casale, Manuel Roveri"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Politecnico di Milano, Imperial College London"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22711",children:"https://arxiv.org/pdf/2601.22711"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," This paper introduces SQUAD, an inference scheme that combines early-exit neural networks with distributed ensemble learning, using a quorum-based voting mechanism to decide when to stop computation. It also proposes QUEST, a neural architecture search method to optimize the diversity of the ensemble learners. The method improves test accuracy by up to 5.95% over state-of-the-art dynamic solutions and reduces inference latency by up to 70.60% compared to static ensembles."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260202] AscendCraft: Automatic Ascend NPU Kernel Generation via DSL-Guided Transcompilation"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [mlsys], [GPU kernels], [DSL-guided transcompilation, LLM lowering passes, AscendC, kernel generation]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Zhongzhen Wen, Shudi Shao, Zhong Li, Yu Ge, Tongtong Xu, Yuanyi Lin, Tian Zhang"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Nanjing University, Huawei"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22760",children:"https://arxiv.org/pdf/2601.22760"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," This paper introduces AscendCraft, a method that uses a domain-specific language (DSL) and LLM-guided transcompilation to automatically generate correct and performant kernels for Ascend NPUs. The approach achieves high compilation success and functional correctness, with many generated kernels matching or exceeding PyTorch eager execution performance, demonstrating the effectiveness of DSL abstraction for NPU kernel generation."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv260202] ERA: Epoch-Resolved Arbitration for Duelling Admins in Group Management CRDTs"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [sys], [distributed systems], [CRDTs, Byzantine fault tolerance, epoch events, finality, arbitration]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Kegan Dougal"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Element Creations Ltd"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22963",children:"https://arxiv.org/pdf/2601.22963"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"}),' The paper proposes ERA (Epoch-Resolved Arbitration), a method using asynchronous "epoch events" to introduce a bounded total order and arbitrate concurrent events in group management CRDTs. It concludes that this approach prevents Byzantine admins from exploiting concurrency in the "Duelling Admins" problem, improving consistency and providing finality while preserving availability.']}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 39'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Continual Policy Distillation from Distributed Reinforcement Learning Teachers ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22475",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] ShellForge: Adversarial Co-Evolution of Webshell Generation and Multi-View Detection for Robust Webshell Defense ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22182",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Real-Time Aligned Reward Model beyond Semantics ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22664",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Unrewarded Exploration in Large Language Models Reveals Latent Learning from Psychology ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22474",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Action-Sufficient Goal Representations ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22496",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Learn More with Less: Uncertainty Consistency Guided Query Selection for RLVR ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22595",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Aligning Microscopic Vehicle and Macroscopic Traffic Statistics: Reconstructing Driving Behavior from Partial Data ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22242",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Models Under SCOPE: Scalable and Controllable Routing via Pre-hoc Reasoning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22323",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Latent Spherical Flow Policy for Reinforcement Learning with Combinatorial Actions ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22211",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Quantum-Inspired Reinforcement Learning for Secure and Sustainable AIoT-Driven Supply Chain Systems ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22339",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Exo-Plore: Exploring Exoskeleton Control Space through Human-aligned Simulation ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22550",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Detect and Act: Automated Dynamic Optimizer through Meta-Black-Box Optimization ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22542",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] From Self-Evolving Synthetic Data to Verifiable-Reward RL: Post-Training Multi-turn Interactive Tool-Using Agents ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22607",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] RulePlanner: All-in-One Reinforcement Learner for Unifying Design Rules in 3D Floorplanning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22476",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22545",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Learning Reward Functions for Cooperative Resilience in Multi-Agent Systems ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22292",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] A Step Back: Prefix Importance Ratio Stabilizes Policy Optimization ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22718",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] TSPO: Breaking the Double Homogenization Dilemma in Multi-turn Search Policy Optimization ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22776",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Clipping-Free Policy Optimization for Large Language Models ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22801",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] CVeDRL: An Efficient Code Verifier via Difficulty-aware Reinforcement Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22803",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Offline Reinforcement Learning of High-Quality Behaviors Under Robust Style Alignment ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22823",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Degradation-Aware Frequency Regulation of a Heterogeneous Battery Fleet via Reinforcement Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22865",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Reinforcement Learning-Based Co-Design and Operation of Chiller and Thermal Energy Storage for Cost-Optimal HVAC Systems ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22880",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] PlatoLTL: Learning to Generalize Across Symbols in LTL Instructions for Multi-Task RL ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22891",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] MulFeRL: Enhancing Reinforcement Learning with Verbal Feedback in a Multi-turn Loop ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22900",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] MTDrive: Multi-turn Interactive Reinforcement Learning for Autonomous Driving ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22930",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Golden Goose: A Simple Trick to Synthesize Unlimited RLVR Tasks from Unverifiable Internet Text ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22975",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Automatic Constraint Policy Optimization based on Continuous Constraint Interpolation Framework for Offline Reinforcement Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23010",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Mem-T: Densifying Rewards for Long-Horizon Memory Agents ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23014",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Guided by Trajectories: Repairing and Rewarding Tool-Use Trajectories for Tool-Integrated Reasoning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23032",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] From Absolute to Relative: Rethinking Reward Shaping in Group-Based Reinforcement Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23058",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] RN-D: Discretized Categorical Actors with Regularized Networks for On-Policy Reinforcement Learning ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23075",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Why GRPO Needs Normalization: A Local-Curvature Perspective on Adaptive Gradients ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23135",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] THINKSAFE: Self-Generated Safety Alignment for Reasoning Models ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23143",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] On Safer Reinforcement Learning Policies for Sedation and Analgesia in Intensive Care ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23154",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Unsupervised Hierarchical Skill Discovery ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23156",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Med-Scout: Curing MLLMs' Geometric Blindness in Medical Perception via Geometry-Aware RL Post-Training ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23220",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Agile Reinforcement Learning through Separable Neural Architecture ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23225",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23266",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 10'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Predicting Intermittent Job Failure Categories for Diagnosis Using Few-Shot Fine-Tuned Language Models ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22264",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Scalable Topology-Preserving Graph Coarsening with Graph Collapse ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22943",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Why GRPO Needs Normalization: A Local-Curvature Perspective on Adaptive Gradients ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23135",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Unsupervised Hierarchical Skill Discovery ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23156",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23180",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] YuriiFormer: A Suite of Nesterov-Accelerated Transformers ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23236",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Spectral Gradient Descent Mitigates Anisotropy-Driven Misalignment: A Case Study in Phase Retrieval ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22652",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] A Cross-Domain Graph Learning Protocol for Single-Step Molecular Geometry Refinement ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.22723",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Disentangling multispecific antibody function with graph neural networks ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23212",children:"link"})]}),"\n",(0,s.jsxs)(i.li,{children:["[arXiv260202] Nested Slice Sampling: Vectorized Nested Sampling for GPU-Accelerated Inference ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2601.23252",children:"link"})]}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>t,x:()=>l});var r=n(6540);const s={},a=r.createContext(s);function t(e){const i=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),r.createElement(a.Provider,{value:i},e.children)}}}]);