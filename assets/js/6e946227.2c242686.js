"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[786],{8453:(i,e,n)=>{n.d(e,{R:()=>a,x:()=>o});var r=n(6540);const t={},s=r.createContext(t);function a(i){const e=r.useContext(s);return r.useMemo(function(){return"function"==typeof i?i(e):{...e,...i}},[e,i])}function o(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(t):i.components||t:a(i.components),r.createElement(s.Provider,{value:e},i.children)}},9880:(i,e,n)=>{n.r(e),n.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"daily/20260112-20260118","title":"20260112-20260118","description":"2026-01-12","source":"@site/docs/daily/20260112-20260118.md","sourceDirName":"daily","slug":"/daily/20260112-20260118","permalink":"/daily/20260112-20260118","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1768186756000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"20260105-20260111","permalink":"/daily/20260105-20260111"},"next":{"title":"Paper","permalink":"/category/paper"}}');var t=n(4848),s=n(8453);const a={},o="20260112-20260118",l={},d=[{value:"2026-01-12",id:"2026-01-12",level:2}];function c(i){const e={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...i.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"20260112-20260118",children:"20260112-20260118"})}),"\n",(0,t.jsx)(e.h2,{id:"2026-01-12",children:"2026-01-12"}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"cs.DC total: 5"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"[arXiv260112] LACIN: Linearly Arranged Complete Interconnection Networks"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"tags:"})," [sys], [interconnection networks], [complete graph, isoport, wiring, routing, Dragonfly, HyperX]"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"authors:"})," Ram\xf3n Beivide, Crist\xf3bal Camarero, Carmen Mart\xednez, Enrique Vallejo, Mateo Valero"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"institution:"})," Universidad de Cantabria, Barcelona Supercomputing Center"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"link:"})," ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05668",children:"https://arxiv.org/pdf/2601.05668"})]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces LACIN, a method for implementing Complete Interconnection Networks (CINs) by connecting switches using identically indexed ports (isoport). This approach simplifies network cabling and routing complexity. It facilitates the deployment of scalable networks from VLSI systems to large supercomputers."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"[arXiv260112] MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm training], [mixture-of-experts, memory wall, activation checkpointing, kernel co-design, token dispatch, memory-efficient training]"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"authors:"})," Jiyuan Zhang, Yining Liu, Siqi Yan, Lisen Deng, Jennifer Cao, Shuqi Yang, Min Ni, Bi Xue, Shen Li"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"institution:"})," Meta Platforms Inc, Thinking Machines Lab"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"link:"})," ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05296",children:"https://arxiv.org/pdf/2601.05296"})]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces MoEBlaze, a memory-efficient training framework for Mixture-of-Experts models that co-designs an end-to-end token dispatch method and optimized kernels to eliminate intermediate activation buffers and reduce memory footprint. The system achieves significant performance gains and memory savings, demonstrating over 4x speedups and over 50% memory reduction compared to existing frameworks."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"[arXiv260112] Self-Evolving Distributed Memory Architecture for Scalable AI Systems"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [distributed memory architecture, dual memory system, memory-guided matrix processing, memory-aware peer selection, runtime-adaptive deployment]"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"authors:"})," Zixuan Li, Chuanzhen Wang, Haotian Sun"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"institution:"})," Tongji University, Pacific Coast University, Northern Research Laboratory"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"link:"})," ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05569",children:"https://arxiv.org/pdf/2601.05569"})]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a Self-Evolving Distributed Memory Architecture, a three-layer framework that unifies memory management across computation, communication, and deployment layers using techniques like dynamic partitioning and a dual memory system. The experiments show it outperforms baselines like Ray Distributed in memory utilization, operational speed, and communication latency. The main conclusion is that coordinated, adaptive memory management across architectural layers is crucial for scalable and efficient distributed AI systems."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"[arXiv260112] Multi-Modal Style Transfer-based Prompt Tuning for Efficient Federated Domain Generalization"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"tags:"})," [mlsys], [multi-modal training], [federated domain generalization, multi-modal style transfer, prompt tuning, dual-prompt module, domain-aware prompt generation]"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"authors:"})," Yuliang Chen, Xi Lin, Jun Wu, Xiangrui Cai, Qiaolun Zhang, Xichun Fan, Jiapeng Xu, Xiu Su"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"institution:"})," Shanghai Jiao Tong University, Nankai University, Polytechnic Institute of Milan, New York University Shanghai, Central South University"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"link:"})," ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05955",children:"https://arxiv.org/pdf/2601.05955"})]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes FaST-PT, a federated domain generalization framework that uses a lightweight Multi-Modal Style Transfer method for local feature augmentation and a dual-prompt module with Domain-aware Prompt Generation for efficient unseen domain adaptation. The method demonstrates superior performance over state-of-the-art FDG methods on benchmark datasets like PACS and DomainNet, validating its effectiveness and efficiency."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"[arXiv260112] Performance-Portable Optimization and Analysis of Multiple Right-Hand Sides in a Lattice QCD Solver"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"tags:"})," [sys], [high-performance computing], [multiple right-hand sides, SIMD, data layout, auto-vectorization, GMRES, performance portability, SME]"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"authors:"})," Shiting Long, Gustavo Ramirez-Hidalgo, Stepan Nassyr, Jose Jimenez-Merchan, Andreas Frommer, Dirk Pleiter"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"institution:"})," KTH Royal Institute of Technology, Forschungszentrum J\xfclich GmbH, University of Wuppertal, University of Groningen"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"link:"})," ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05816",children:"https://arxiv.org/pdf/2601.05816"})]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper extends a lattice QCD solver to support multiple right-hand sides and optimizes it with a flexible data layout interface for better SIMD utilization. The optimizations are evaluated on x86 and Arm clusters, demonstrating performance portability and revealing insights into architectural constraints and compiler behavior. An early assessment of the Arm SME instruction set is also provided."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 19'})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] WildSci: Advancing Scientific Reasoning from In-the-Wild Literature ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05567",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] On the Limits of Self-Improving in LLMs and Why AGI, ASI and the Singularity Are Not Near Without Symbolic Model Synthesis ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05280",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05836",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05475",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05257",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05870",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] Do LLMs Need Inherent Reasoning Before Reinforcement Learning? A Study in Korean Self-Correction ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05459",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05890",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05432",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05899",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05607",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05593",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] Sequential Bayesian Optimal Experimental Design in Infinite Dimensions via Policy Gradient Reinforcement Learning ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05868",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] Autonomous Discovery of the Ising Model's Critical Parameters with Reinforcement Learning ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05577",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05578",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05465",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05787",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] Dual-Phase LLM Reasoning: Self-Evolved Mathematical Frameworks ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05616",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05808",children:"link"})]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 9'})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05684",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05593",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05407",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05732",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] DNATokenizer: A GPU-First Byte-to-Identifier Tokenizer for High-Throughput DNA Language Models ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05531",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] Influence of Parallelism in Vector-Multiplication Units on Correlation Power Analysis ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05828",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] Tracing Stereotypes in Pre-trained Transformers: From Biased Neurons to Fairer Models ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05663",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] A Survey of Agentic AI and Cybersecurity: Challenges, Opportunities and Use-case Prototypes ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05293",children:"link"})]}),"\n",(0,t.jsxs)(e.li,{children:["[arXiv260112] Can We Predict Before Executing Machine Learning Agents? ",(0,t.jsx)(e.a,{href:"https://arxiv.org/pdf/2601.05930",children:"link"})]}),"\n"]})]})}function h(i={}){const{wrapper:e}={...(0,s.R)(),...i.components};return e?(0,t.jsx)(e,{...i,children:(0,t.jsx)(c,{...i})}):c(i)}}}]);