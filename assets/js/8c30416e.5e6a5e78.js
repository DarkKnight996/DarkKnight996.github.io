"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[143],{5679:(i,e,n)=>{n.r(e),n.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"daily/20260216-20260222","title":"20260216-20260222","description":"2026-02-16","source":"@site/docs/daily/20260216-20260222.md","sourceDirName":"daily","slug":"/daily/20260216-20260222","permalink":"/daily/20260216-20260222","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1771817638000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"20260209-20260215","permalink":"/daily/20260209-20260215"},"next":{"title":"20260223-20260301","permalink":"/daily/20260223-20260301"}}');var s=n(4848),a=n(8453);const t={},o="20260216-20260222",l={},c=[{value:"2026-02-16",id:"2026-02-16",level:2},{value:"2026-02-17",id:"2026-02-17",level:2},{value:"2026-02-18",id:"2026-02-18",level:2},{value:"2026-02-19",id:"2026-02-19",level:2},{value:"2026-02-20",id:"2026-02-20",level:2}];function d(i){const e={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...i.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"20260216-20260222",children:"20260216-20260222"})}),"\n",(0,s.jsx)(e.h2,{id:"2026-02-16",children:"2026-02-16"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 5"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260216] Classification of Local Optimization Problems in Directed Cycles"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed algorithms], [LOCAL model, directed cycles, classification, approximation algorithms, meta-algorithm]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Thomas Boudier, Fabian Kuhn, Augusto Modanese, Ronja Stimpert, Jukka Suomela"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," GSSI, University of Freiburg, CISPA Helmholtz Center for Information Security, Aalto University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13046",children:"https://arxiv.org/pdf/2602.13046"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper provides a complete complexity classification for local optimization problems in directed cycles within the distributed LOCAL model. It shows that for any constant approximation ratio, the problem falls into one of four deterministic and randomized complexity classes. The authors also present an efficient meta-algorithm to determine the class and synthesize an optimal distributed algorithm."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260216] DRAMatic Speedup: Accelerating HE Operations on a Processing-in-Memory System"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [hardware acceleration], [residue number system, number-theoretic transform, processing-in-memory]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Niklas Klinger, Jonas Sander, Peterson Yuhala, Pascal Felber, Thomas Eisenbarth"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Luebeck, University of Neuch\xe2tel"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12433",children:"https://arxiv.org/pdf/2602.12433"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents DRAMatic, a system that implements foundational homomorphic encryption operations on UPMEM's processing-in-memory hardware. It uses arithmetic optimizations like the residue number system and number-theoretic transform to accelerate these operations. The evaluation shows DRAMatic significantly closes the performance gap with a software library like Microsoft SEAL but is still limited by the hardware's multiplication performance and data transfer overhead."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260216] Bloom Filter Look-Up Tables for Private and Secure Distributed Databases in Web3 (Revised Version)"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed databases], [Bloom Filter, BFLUT, OrbitDB, IPFS, IPNS, decentralized key management]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Shlomi Dolev, Ehud Gudes, Daniel Shlomo"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Ben-Gurion University of the Negev"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13167",children:"https://arxiv.org/pdf/2602.13167"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a decentralized database scheme for secure key management in Web3, using the BFLUT algorithm to encode and distribute cryptographic keys without explicit storage. The system integrates OrbitDB, IPFS, and IPNS to ensure privacy and prevent key discovery even if network nodes are compromised. The authors conclude it provides a foundational, secure, and private solution for decentralized applications."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260216] OptiML: An End-to-End Framework for Program Synthesis and CUDA Kernel Optimization"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [GPU kernels], [Monte Carlo Tree Search, Mixture-of-Thoughts, program synthesis, CUDA optimization, search under verification, Nsight Compute]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Arijit Bhattacharjee, Heng Ping, Son Vu Le, Paul Bogdan, Nesreen K. Ahmed, Ali Jannesari"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Iowa State University, University of Southern California, Cisco AI Research"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12305",children:"https://arxiv.org/pdf/2602.12305"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," OptiML is an end-to-end framework that uses a two-stage process to generate and optimize CUDA kernels. It first synthesizes code from natural language using a Mixture-of-Thoughts generator, then refines it via Monte Carlo Tree Search guided by hardware-aware rewards from profiler feedback. The framework consistently produces verified performance improvements over strong LLM baselines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260216] Distance-based certification for leader election in meshed graphs and local recognition of their subclasses"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [graph theory], [proof labeling scheme, leader election, meshed graphs, distance verification, local certification]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," J\xe9r\xe9mie Chalopin, Victor Chepoi, Maria Kokkou"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Aix-Marseille Universit\xe9, Universit\xe9 C\xf4te d'Azur, University of Crete"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12894",children:"https://arxiv.org/pdf/2602.12894"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents a 2-local proof labeling scheme using constant-size labels {0,1,2} to solve leader election in anonymous meshed graphs by verifying distances modulo 3 to a designated root. It also provides 3-local schemes to recognize subclasses of meshed graphs using labels of size O(log D). The main conclusion is that leader election can be certified locally with small labels in this broad class of graphs, and their subclasses can be locally recognized by leveraging distance verification and existing characterizations."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 32'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Synthetic Interaction Data for Scalable Personalization in Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12394",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12705",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Constraint-Rectified Training for Efficient Chain-of-Thought ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12526",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Flow-Factory: A Unified Framework for Reinforcement Learning in Flow-Matching Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12529",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12375",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] FLAC: Maximum Entropy RL via Kinetic Energy Regularized Bridge Matching ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12829",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Provably Convergent Actor-Critic in Risk-averse MARL ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12386",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Safe Reinforcement Learning via Recovery-based Shielding with Gaussian Process Dynamics Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12444",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Amortized Reasoning Tree Search: Decoupling Proposal and Decision in Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12846",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] On Robustness and Chain-of-Thought Consistency of RL-Finetuned VLMs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12506",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Designing RNAs with Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12470",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via Confidence-Guided Variance Reduction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12579",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Look Inward to Explore Outward: Learning Temperature Policy from LLM Internal States via Hierarchical RL ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13035",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] TCRL: Temporal-Coupled Adversarial Training for Robust Constrained Reinforcement Learning in Worst-Case Scenarios ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13040",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Composable Model-Free RL for Navigation with Input-Affine Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12492",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Wireless TokenCom: RL-Based Tokenizer Agreement for Multi-User Wireless Token Communications ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12338",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Dual-Granularity Contrastive Reward via Generated Episodic Guidance for Efficient Embodied RL ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12636",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Abstractive Red-Teaming of Language Model Character ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12318",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] In-Context Autonomous Network Incident Response: An End-to-End Large Language Model Agent Approach ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13156",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Learning to Approximate Uniform Facility Location via Graph Neural Networks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13155",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] ALOE: Action-Level Off-Policy Evaluation for Vision-Language-Action Model Post-Training ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12691",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Unifying Model-Free Efficiency and Model-Based Representations via Latent Dynamics ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12643",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Curriculum-DPO++: Direct Preference Optimization via Data and Model Curricula for Text-to-Image Generation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13055",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] PMG: Parameterized Motion Generator for Human-like Locomotion Control ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12656",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] What does RL improve for Visual Reasoning? A Frankenstein-Style Analysis ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12395",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Energy-Aware Reinforcement Learning for Robotic Manipulation of Articulated Components in Infrastructure Operation and Maintenance ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12288",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] AstRL: Analog and Mixed-Signal Circuit Synthesis with Deep Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12402",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Bench-MFG: A Benchmark Suite for Learning in Stationary Mean Field Games ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12517",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Agent Skills for Large Language Models: Architecture, Acquisition, Security, and the Path Forward ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12430",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12566",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Multi-Agent Model-Based Reinforcement Learning with Joint State-Action Learned Embeddings ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12520",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Intrinsic Credit Assignment for Long Horizon Interaction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12342",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 7'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Multi-Dimensional Visual Data Recovery: Scale-Aware Tensor Modeling and Accelerated Randomized Computation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12982",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Tight Bounds for Logistic Regression with Large Stepsize Gradient Descent in Low Dimension ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12471",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] CoPE-VideoLM: Codec Primitives For Efficient Video Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13191",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] SLA2: Sparse-Linear Attention with Learnable Routing and QAT ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12675",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] Accelerating Feedback-based Algorithms for Quantum Optimization Using Gradient Descent ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12387",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] SWING: Unlocking Implicit Graph Representations for Graph Random Features ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12703",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260216] TriGen: NPU Architecture for End-to-End Acceleration of Large Language Models based on SW-HW Co-Design ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.12962",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2026-02-17",children:"2026-02-17"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 12"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260217] Parallel Sparse and Data-Sparse Factorization-based Linear Solvers"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [numerical linear algebra], [sparse direct solvers, low-rank compression, hierarchical matrix algebra, parallel factorization]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Xiaoye Sherry Li, Yang Liu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Lawrence Berkeley National Laboratory"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14289",children:"https://arxiv.org/pdf/2602.14289"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper reviews recent advances in parallel sparse direct solvers, focusing on reducing communication costs and computational complexity through low-rank and hierarchical compression techniques. It concludes that these methods are crucial for building scalable, robust solver toolchains for large-scale problems on modern heterogeneous machines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260217] Preventing Rank Collapse in Federated Low-Rank Adaptation with Client Heterogeneity"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [post-training], [federated learning, low-rank adaptation, rank collapse, heterogeneous ranks, rank-partitioned aggregation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Exeter"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13486",children:"https://arxiv.org/pdf/2602.13486"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes raFLoRA, a rank-partitioned aggregation method for federated low-rank adaptation (FedLoRA) to address rank collapse in heterogeneous client settings. It prevents performance degradation by aggregating local model updates based on their effective rank contributions. Experiments show that raFLoRA improves model performance and maintains communication efficiency compared to existing FedLoRA baselines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260217] Ask the Expert: Collaborative Inference for Vision Transformers with Near-Edge Accelerators"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [collaborative inference, near-edge accelerator, vision transformer, routing mechanism, progressive specialist training]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Hao Liu, Suhaib A. Fahmy"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," King Abdullah University of Science and Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13334",children:"https://arxiv.org/pdf/2602.13334"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a collaborative inference framework that uses a lightweight Vision Transformer on an edge device and multiple expert ViTs on a near-edge accelerator, with a routing mechanism to select experts for low-confidence samples. The method reduces latency by up to 45% and energy consumption by up to 46% compared to baseline approaches, while improving accuracy through a progressive training strategy."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260217] Intent-driven Diffusion-based Path for Mobile Data Collector in IoT-enabled Dense WSNs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [diffusion inference], [diffusion-based planning, intent-driven networking, mobile data collection, generative diffusion models, path planning, rendezvous point selection]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Uma Mahesh Boda, Mallikharjuna Rao Nuka"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Annamacharya University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13277",children:"https://arxiv.org/pdf/2602.13277"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes ID2P2, an intent-driven diffusion-based path planning framework for mobile data collectors in dense wireless sensor networks. It uses a generative diffusion process to create adaptive data collection trajectories that incorporate high-level operational intents like latency minimization. Simulation results show ID2P2 outperforms baselines with significant improvements in tour completion time, data freshness, and energy efficiency."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260217] ML-ECS: A Collaborative Multimodal Learning Framework for Edge-Cloud Synergies"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [multi-modal training], [cross-modal contrastive learning, adaptive multimodal tuning, modality-aware model aggregation, SLM-enhanced CCL, LoRA, edge-cloud synergy]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yuze Liu, Shibo Chu, Tiehua Zhang, Hao Zhou, Zhishu Shen, Jinze Wang, Jianzhong Qi, Feng Xia"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Tongji University, Swinburne University of Technology, The University of Melbourne, RMIT University, Wuhan University of Technology"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14107",children:"https://arxiv.org/pdf/2602.14107"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes ML-ECS, a collaborative multimodal learning framework for edge-cloud systems that addresses modality and model heterogeneity. Its core method integrates cross-modal contrastive learning, adaptive tuning, and modality-aware aggregation to enable efficient knowledge sharing. The framework improves performance on multimodal tasks and achieves high communication efficiency by transmitting only low-rank LoRA parameters."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260217] TEG: Exascale Cluster Governance via Non-Equilibrium Thermodynamics and Langevin Dynamics"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [thermodynamic governance, langevin agents, holographic potential field, landau phase transition, token evaporation, dual-number damping, glassy states, high-order control barrier functions]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zhengyan Chu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Independent Researcher"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13789",children:"https://arxiv.org/pdf/2602.13789"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes TEG, a decentralized cluster governance architecture that models resource contention using non-equilibrium thermodynamics and Langevin dynamics, replacing a global scheduler with agents performing Brownian motion on a potential field. It argues that this paradigm of emergent order, rather than deterministic orchestration, is necessary for scalability to exascale AI workloads."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260217] MergePipe: A Budget-Aware Parameter Management System for Scalable LLM Merging"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [post-training], [model merging, parameter management, I/O optimization, cost-aware planning, streaming execution, catalog-driven abstraction]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yuanyi Wang, Yanggan Gu, Zihao Wang, Kunxi Li, Yifan Yang, Zhaoyi Yan, Congkai Xie, Jianmin Wu, Hongxia Yang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Hong Kong Polytechnic University, InfiX.ai, Zhejiang University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13273",children:"https://arxiv.org/pdf/2602.13273"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces MergePipe, a system that treats LLM merging as a data management problem, using a catalog-driven abstraction, a cost-aware planner to enforce I/O budgets, and a streaming execution engine. It significantly reduces I/O and speeds up merging by optimizing expert parameter access, achieving up to an order of magnitude less I/O and 11x end-to-end speedup over existing pipelines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260217] Efficient Multi-round LLM Inference over Disaggregated Serving"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [prefill-decode disaggregation, multi-round inference, service level objective, workload scheduling, resource allocation, incremental prefill]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Wenhao He, Youhe Jiang, Penghao Zhao, Quanqing Xu, Eiko Yoneki, Bin Cui, Fangcheng Fu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Southeast University, University of Cambridge, Peking University, Ant Group, Shanghai Jiao Tong University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14516",children:"https://arxiv.org/pdf/2602.14516"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces AMPD, a new disaggregated serving framework that adaptively coordinates and schedules prefill workloads for multi-round LLM inference to maximize SLO attainment. It includes a tailored planning algorithm for optimal resource allocation and parallel strategies. Empirical results show that AMPD significantly improves SLO attainment compared to state-of-the-art baselines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260217] Floe: Federated Specialization for Real-Time LLM-SLM Inference"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [federated learning, edge-cloud collaboration, LoRA, logit-level fusion, privacy-preserving]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Chunlin Tian, Kahou Tam, Yebo Wu, Shuaihang Zhong, Li Li, Nicholas D. Lane, Chengzhong Xu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Science and Technology of China, University of Oxford"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14302",children:"https://arxiv.org/pdf/2602.14302"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," Floe is a hybrid federated learning framework that combines a cloud-based black-box LLM with lightweight SLMs on edge devices for real-time inference. It uses a heterogeneity-aware LoRA adaptation and logit-level fusion to coordinate models. The approach enhances privacy, personalization, and reduces inference latency on edge devices compared to baselines."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260217] SIDSense: Database-Free TV White Space Sensing for Disaster-Resilient Connectivity"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [CNN-based spectrum classification, edge AI framework, GPU-aware scheduling, hybrid sensing-first authorization workflow, compliance-gated controller, TV White Space sensing]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," George M. Gichuru, Zoe Aiyanna M. Cayetano"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Amini"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13542",children:"https://arxiv.org/pdf/2602.13542"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents SIDSense, an edge AI framework that uses CNN-based spectrum classification and a hybrid workflow to enable database-free TV White Space operation for disaster-resilient connectivity. Field experiments in Barbados demonstrated sustained connectivity during simulated outages with high sensing accuracy and low latency, while maintaining 5G performance. The work aims to accelerate resilient connectivity deployments in climate-vulnerable regions by contributing components to open source."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260217] Evaluation of Dynamic Vector Bin Packing for Virtual Machine Placement"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [cloud computing resource management], [dynamic vector bin packing, virtual machine placement, online algorithms, MinUsageTime DVBP, non-clairvoyant, clairvoyant, learning-augmented]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zong Yu Lee, Xueyan Tang"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Nanyang Technological University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14704",children:"https://arxiv.org/pdf/2602.14704"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper formulates virtual machine placement as a MinUsageTime Dynamic Vector Bin Packing problem and evaluates various online algorithms in non-clairvoyant, clairvoyant, and learning-augmented settings. It develops new algorithms and enhancements, testing them empirically on real-world Microsoft Azure datasets. The study provides insights into effective algorithm structures and design elements for practical cloud resource management."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260217] Atomix: Timely, Transactional Tool Use for Reliable Agentic Workflows"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [transactional semantics, speculative execution, epoch tagging, frontier gating, compensation, bufferable effects]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Bardia Mohammadi, Nearchos Potamitis, Lars Klein, Akhil Arora, Laurent Bindschaedler"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," MPI-SWS, Aarhus University, EPFL"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14849",children:"https://arxiv.org/pdf/2602.14849"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces Atomix, a runtime that provides progress-aware transactional semantics for LLM agent tool calls by tagging calls with epochs and using per-resource frontiers to gate commits. This approach isolates speculative branches and manages contention, allowing bufferable effects to be delayed and externalized effects to be compensated on abort. The method improves task success and strengthens isolation under failures, speculation, and contention in agentic workflows."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 54'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Nanbeige4.1-3B: A Small General Model that Reasons, Aligns, and Acts ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13367",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Cast-R1: Learning Tool-Augmented Sequential Decision Policies for Time Series Forecasting ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13802",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Process-Supervised Multi-Agent Reinforcement Learning for Reliable Clinical Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14160",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] AnomaMind: Agentic Time Series Anomaly Detection with Tool-Augmented Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13807",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] An Overlay Multicast Routing Method Based on Network Situational Aware-ness and Hierarchical Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13211",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14322",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] On-Policy Supervised Fine-Tuning for Efficient Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13407",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Scaling the Scaling Logic: Agentic Meta-Synthesis of Logic Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13218",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Deep Dense Exploration for LLM Reinforcement Learning via Pivot-Driven Resampling ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14169",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] You Can Learn Tokenization End-to-End with Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13940",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Train Less, Learn More: Adaptive Efficient Rollout Optimization for Group-Based Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14338",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Large Language Model (LLM)-enabled Reinforcement Learning for Wireless Network Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13210",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Experiential Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13949",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] GeoEyes: On-Demand Visual Focusing for Evidence-Grounded Understanding of Ultra-High-Resolution Remote Sensing Imagery ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14201",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] LACONIC: Length-Aware Constrained Reinforcement Learning for LLM ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14468",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] A Safety-Constrained Reinforcement Learning Framework for Reliable Wireless Autonomy ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13207",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Adaptive Value Decomposition: Coordinating a Varying Number of Agents in Urban Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13309",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Zero-Shot Instruction Following in RL via Structured LTL Representations ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14344",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] QuRL: Efficient Reinforcement Learning with Quantized Rollout ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13953",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] General learned delegation by clones ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13262",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Text Before Vision: Staged Knowledge Injection Matters for Agentic RLVR in Ultra-High-Resolution Remote Sensing Understanding ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14225",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Socially-Weighted Alignment: A Game-Theoretic Framework for Multi-Agent LLM Systems ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14471",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Mean Flow Policy with Instantaneous Velocity Constraint for One-step Action Generation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13810",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Lang2Act: Fine-Grained Visual Reasoning through Self-Emergent Linguistic Toolchains ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13235",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] WIMLE: Uncertainty-Aware World Models with IMLE for Sample-Efficient Continuous Control ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14351",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] WoVR: World Models as Reliable Simulators for Post-Training VLA Policies with RL ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13977",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] REDSearcher: A Scalable and Cost-Efficient Framework for Long-Horizon Search Agents ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14234",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Securing SIM-Assisted Wireless Networks via Quantum Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13238",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Learning Transferability: A Two-Stage Reinforcement Learning Approach for Enhancing Quadruped Robots' Performance in U-Shaped Stair Climbing ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14473",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] AdaptManip: Learning Adaptive Whole-Body Object Lifting and Delivery with Online Recurrent State Estimation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14363",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] GRAIL: Goal Recognition Alignment through Imitation Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14252",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] TikArt: Aperture-Guided Observation for Fine-Grained Visual Reasoning via Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14482",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Why Code, Why Now: Learnability, Computability, and the Real Limits of Machine Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13934",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Policy Gradient with Adaptive Entropy Annealing for Continual Fine-Tuning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14078",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] AuTAgent: A Reinforcement Learning Framework for Tool-Augmented Audio Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13685",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Building Autonomous GUI Navigation via Agentic-Q Estimation and Step-Wise Policy Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13653",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Formally Verifying and Explaining Sepsis Treatment Policies with COOL-MC ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14505",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Enabling Option Learning in Sparse Rewards with Hindsight Experience Replay ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13865",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] From Pixels to Policies: Reinforcing Spatial Reasoning in Language Models for Content-Aware Layout Design ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13912",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] KernelBlaster: Continual Cross-Task CUDA Optimization via Memory-Augmented In-Context Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14293",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] OpAgent: Operator Agent for Web Navigation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13559",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] TWISTED-RL: Hierarchical Skilled Agents for Knot-Tying without Human Demonstrations ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14526",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Fluid-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14559",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] RNM-TD3: N",":M"," Semi-structured Sparse Reinforcement Learning From Scratch ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14578",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Decoupled Continuous-Time Reinforcement Learning via Hamiltonian Flow ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14587",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] GREAT-EER: Graph Edge Attention Network for Emergency Evacuation Responses ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14676",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Evolutionary System Prompt Learning can Facilitate Reinforcement Learning for LLMs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14697",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] ManeuverNet: A Soft Actor-Critic Framework for Precise Maneuvering of Double-Ackermann-Steering Robots with Optimized Reward Functions ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14726",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Interactionless Inverse Reinforcement Learning: A Data-Centric Framework for Durable Alignment ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14844",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Goldilocks RL: Tuning Task Difficulty to Escape Sparse Rewards for Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14868",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] On the Learning Dynamics of RLVR at the Edge of Competence ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14872",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] BFS-PO: Best-First Search for Large Reasoning Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14917",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] MAC-AMP: A Closed-Loop Multi-Agent Collaboration System for Multi-Objective Antimicrobial Peptide Design ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14926",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Cold-Start Personalization via Training-Free Priors from Structured World Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15012",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 19'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Geometry-Aware Physics-Informed PointNets for Modeling Flows Across Porous Structures ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14108",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Why is Normalization Preferred? A Worst-Case Complexity Theory for Stochastically Preconditioned SGD under Heavy-Tailed Noise ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13413",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Accelerated Discovery of Cryoprotectant Cocktails via Multi-Objective Bayesian Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13398",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] On-Policy Supervised Fine-Tuning for Efficient Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13407",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] WiSparse: Boosting LLM Inference Efficiency with Weight-Aware Mixed Activation Sparsity ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14452",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] QuRL: Efficient Reinforcement Learning with Quantized Rollout ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13953",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] IDPruner: Harmonizing Importance and Diversity in Visual Token Pruning for MLLMs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13315",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Discrete Double-Bracket Flows for Isotropic-Noise Invariant Eigendecomposition ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13759",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Responsible AI in Business ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13244",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Decentralized Federated Learning With Energy Harvesting Devices ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14051",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] SpargeAttention2: Trainable Sparse Attention via Hybrid Top-k+Top-p Masking and Distillation Fine-Tuning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13515",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Fast Swap-Based Element Selection for Multiplication-Free Dimension Reduction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13532",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Experimentation Accelerator: Interpretable Insights and Creative Recommendations for A/B Testing with Content-Aware ranking ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13852",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] AdaCorrection: Adaptive Offset Cache Correction for Accurate Diffusion Transformers ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.13357",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] RNM-TD3: N",":M"," Semi-structured Sparse Reinforcement Learning From Scratch ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14578",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] AI Arms and Influence: Frontier Models Exhibit Sophisticated Reasoning in Simulated Nuclear Crises ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14740",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Rethinking Diffusion Models with Symmetries through Canonicalization with Applications to Molecular Graph Generation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15022",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Fast Compute for ML Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14280",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260217] Faster Molecular Dynamics with Neural Network Potentials via Distilled Multiple Time-Stepping and Non-Conservative Forces ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.14975",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2026-02-18",children:"2026-02-18"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 7"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260218] Tight Communication Bounds for Distributed Algorithms in the Quantum Routing Model"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed computing], [quantum routing model, quantum walks, electric networks, message complexity, lower bounds]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Fabien Dufoulon, Fr\xe9d\xe9ric Magniez, Gopal Pandurangan"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Lancaster University, Universit\xe9 Paris Cit\xe9, University of Houston"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15529",children:"https://arxiv.org/pdf/2602.15529"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces new distributed quantum algorithms for fundamental problems like leader election and MST, using quantum walks based on electric networks to reduce communication. It shows these algorithms achieve near-optimal message complexities, significantly improving over prior quantum work and demonstrating a quadratic communication advantage over classical distributed algorithms."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260218] On the Geometric Coherence of Global Aggregation in Federated GNN"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [federated learning, graph neural networks, geometric coherence, global aggregation, cross-domain federated GNN, GGRS]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Chethana Prasad Kabgere, Shylaja SS"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," PES University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15510",children:"https://arxiv.org/pdf/2602.15510"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes GGRS, a server-side framework that regulates client updates based on geometric criteria to address destructive interference in federated GNN aggregation. It concludes that this geometry-aware approach is necessary to preserve global message-passing coherence in cross-domain federated graph learning, which is not captured by conventional metrics like loss or accuracy."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260218] SCENE OTA-FD: Self-Centering Noncoherent Estimator for Over-the-Air Federated Distillation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [over-the-air federated distillation, noncoherent energy aggregation, constant-envelope signaling, self-centering estimator, pilot-free aggregation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Hao Chen, Zavareh Bozorgasl"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Boise State University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15326",children:"https://arxiv.org/pdf/2602.15326"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces SCENE, a pilot-free and phase-invariant method for aggregating soft labels in over-the-air federated distillation. It uses noncoherent energy transmission and a self-centering estimator to avoid channel state information overhead. The method is designed for short-coherence or hardware-constrained regimes and can outperform coherent designs when pilot overhead is significant."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260218] FlashMem: Supporting Modern DNN Workloads on Mobile with GPU Memory Hierarchy Optimizations"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [memory streaming, weight preloading, 2.5D texture memory, multi-DNN workloads, on-device inference, mobile GPU]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zhihao Shu, Md Musfiqur Rahman Sanim, Hangyu Zheng, Kunxiong Zhu, Miao Yin, Gagan Agrawal, Wei Niu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Georgia, University of Texas at Arlington"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15379",children:"https://arxiv.org/pdf/2602.15379"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," FlashMem is a memory streaming framework for mobile GPUs that statically schedules and dynamically streams model weights on-demand, instead of fully preloading them. It leverages 2.5D texture memory to reduce data transformations. The framework significantly reduces memory usage and speeds up inference for large-scale and multi-DNN workloads compared to existing approaches."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260218] Service Orchestration in the Computing Continuum: Structural Challenges and Vision"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [service orchestration], [computing continuum, edge computing, cloud computing, active inference, service placement, quality of experience]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Boris Sedlak, V\xedctor Casamayor Pujol, Ildefons Magrans de Abril, Praveen Kumar Donta, Adel N. Toosi, Schahram Dustdar"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Universitat Pompeu Fabra, Stockholm University, University of Melbourne, ICREA, TU Wien"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15794",children:"https://arxiv.org/pdf/2602.15794"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper analyzes structural challenges for service orchestration in the heterogeneous and dynamic Computing Continuum, proposing autonomous orchestration as an ideal solution and illustrating Active Inference as a potential approach. It concludes that no existing solution fully achieves this vision and identifies key research challenges, most notably the need for standardized simulation environments to compare orchestration mechanisms."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260218] Distributed Semi-Speculative Parallel Anisotropic Mesh Adaptation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [high-performance computing, mesh adaptation], [distributed memory, speculative execution, anisotropic mesh adaptation, parallel runtime, cc-NUMA]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Kevin Garner, Polykarpos Thomadakis, Nikos Chrisochoides"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Old Dominion University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15204",children:"https://arxiv.org/pdf/2602.15204"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents a distributed memory method for anisotropic mesh adaptation that separates meshing functionality from performance aspects, using a shared memory mesh generator and a parallel runtime system. The method avoids collective communication by first adapting interface elements on a single node and then adapting interior elements in parallel while keeping interfaces frozen. It is shown to generate large meshes (up to ~1 billion elements) with quality and performance comparable to state-of-the-art HPC meshing software."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260218] Co-Design and Evaluation of a CPU-Free MPI GPU Communication Abstraction and Implementation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [high-performance computing], [MPI, GPU communication, CPU-free communication, stream-triggered communication, halo exchange, Cabana/Kokkos]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Patrick G. Bridges, Derek Schafer, Jack Lange, James B. White III, Anthony Skjellum, Evan Suggs, Thomas Hines, Purushotham Bangalore, Matthew G. F. Dosanjh, Whit Schonbein"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of New Mexico, Oak Ridge National Laboratory, Tennessee Tech University, University of Alabama, Sandia National Laboratories"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15356",children:"https://arxiv.org/pdf/2602.15356"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper introduces an MPI-based GPU communication API designed to enable CPU-free, high-performance communication by leveraging HPE Slingshot 11 network capabilities. The API supports two-sided communication and integrates with the Cabana/Kokkos framework for halo exchange primitives. Evaluation on Frontier and Tuolumne supercomputers shows up to 50% latency reduction in GPU ping-pong exchanges and a 28% speedup when scaling to 8,192 GPUs."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 13'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Recursive Concept Evolution for Compositional Reasoning in Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15725",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15733",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15640",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15817",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Near-Optimal Sample Complexity for Online Constrained MDPs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15076",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] CDRL: A Reinforcement Learning Framework Inspired by Cerebellar Circuits and Dendritic Computational Strategies ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15367",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15564",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15827",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Fairness over Equality: Correcting Social Incentives in Asymmetric Sequential Social Dilemmas ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15407",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] CLOT: Closed-Loop Global Motion Tracking for Whole-Body Humanoid Teleoperation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15060",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] MyoInteract: A Framework for Fast Prototyping of Biomechanical HCI Tasks using Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15245",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] GLM-5: from Vibe Coding to Agentic Engineering ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15763",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15620",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 10'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Sparrow: Text-Anchored Window Attention with Visual-Semantic Glimpsing for Speculative Decoding in Video LLMs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15318",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15799",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Multi-Objective Coverage via Constraint Active Search ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15595",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Transforming Computational Lithography with AC and AI -- Faster, More Accurate, and Energy-efficient ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15036",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Fractional-Order Federated Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15380",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Safe-SDL",":Establishing"," Safety Boundaries and Control Mechanisms for AI-Driven Self-Driving Laboratories ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15061",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Stabilizing Test-Time Adaptation of High-Dimensional Simulation Surrogates via D-Optimal Statistics ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15820",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Molecular Design beyond Training Data with Novel Extended Objective Functionals of Generative AI Models Driven by Quantum Annealing Computer ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15451",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] MyoInteract: A Framework for Fast Prototyping of Biomechanical HCI Tasks using Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15245",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260218] Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15277",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2026-02-19",children:"2026-02-19"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 11"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260219] DistributedEstimator: Distributed Training of Quantum Neural Networks via Circuit Cutting"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [circuit cutting, distributed training, quantum neural networks, estimator pipeline, classical reconstruction, subcircuit execution]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Prabhjot Singh, Adel N. Toosi, Rajkumar Buyya"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The University of Melbourne"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16233",children:"https://arxiv.org/pdf/2602.16233"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a distributed training pipeline for Quantum Neural Networks that uses circuit cutting to decompose large quantum circuits into smaller, parallelizable subcircuits. The main conclusion is that while this method preserves model accuracy, it introduces significant system overhead dominated by classical reconstruction, which limits the achievable speedup from parallelism."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260219] SRFed: Mitigating Poisoning Attacks in Privacy-Preserving Federated Learning with Heterogeneous Data"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [functional encryption, decentralized efficient functional encryption (DEFE), layer-wise projection, clustering-based analysis, Byzantine-robust aggregation, Non-IID data]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Yiwen Lu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Nanjing University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16480",children:"https://arxiv.org/pdf/2602.16480"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes SRFed, a federated learning framework that uses a novel decentralized efficient functional encryption (DEFE) scheme to protect client privacy and a defensive aggregation mechanism based on layer-wise projection and clustering to filter out poisoning attacks, especially under Non-IID data. It concludes that SRFed outperforms existing methods in privacy protection, robustness against Byzantine attacks, and efficiency."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260219] How Reliable is Your Service at the Extreme Edge? Analytical Modeling of Computational Reliability"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [analytical modeling, computational reliability, distributed inference, quality of service, maximum likelihood estimation, workload allocation, extreme edge computing]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," MHD Saria Allahham, Hossam S. Hassanein"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Queen's University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16362",children:"https://arxiv.org/pdf/2602.16362"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents an analytical framework to quantify computational reliability in Extreme Edge Computing, deriving closed-form probability expressions for whether device capacity meets service demand under different information regimes. It extends the model to multi-device deployments and provides optimal workload allocation rules. The framework is validated through experiments with a YOLO-based object detection workload, showing close agreement between analytical predictions and empirical measurements."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260219] Load Balanced Parallel Node Generation for Meshless Numerical Methods"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [parallel computing], [meshless methods, Poisson disc sampling, hypertrees, parallel node generation, advancing front]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jon Vehovar, Miha Rot, Matja\u017e Depolli, Gregor Kosec"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"}),' Jozef Stefan International Postgraduate School, Institut "Jo\u017eef Stefan"']}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16347",children:"https://arxiv.org/pdf/2602.16347"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes a parallel algorithm for generating nodes for meshless numerical methods using coupled spatial indexing and work distribution hypertrees. It modifies a Poisson disc sampling-based method to enable load-balanced parallel execution by prebuilding work units and managing thread collisions at the leaf level. The approach reduces mutex contention and improves performance compared to existing parallelization attempts."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260219] push0: Scalable and Fault-Tolerant Orchestration for Zero-Knowledge Proof Generation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [blockchain orchestration], [event-driven dispatcher-collector architecture, persistent priority queues, Kubernetes, fault-tolerant task reassignment, prover-agnostic workflow]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Mohsen Ahmadvand, Rok Pajni\u010d, Ching-Lun Chiu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Zircuit"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16338",children:"https://arxiv.org/pdf/2602.16338"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents push0, a cloud-native orchestration system for zero-knowledge proof generation that uses an event-driven dispatcher-collector architecture over persistent queues to enforce ordering and enable parallelism. It demonstrates low orchestration overhead (5 ms median) and high scaling efficiency in production experiments, enabling reliable, real-time proof generation for blockchain applications like ZK-rollups and Ethereum's zkEVM."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260219] Near-optimal population protocols on bounded-degree trees"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed computing], [population protocols, self-stabilising algorithms, tree orientation, 2-hop colouring, stochastic drift, leader election, exact majority]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Joel Rybicki, Jakob Solnerzik, Robin Vacus"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Humboldt-Universit\xe4t zu Berlin, Sorbonne Universit\xe9, CNRS, LIP6"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16222",children:"https://arxiv.org/pdf/2602.16222"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces new constant-space population protocols for leader election and exact majority on bounded-degree trees, based on a fast self-stabilising 2-hop colouring protocol and a tree orientation algorithm. It concludes that, unlike in complete graphs, these sparse graphs do not exhibit significant space-time trade-offs, allowing for near-optimal time with minimal space."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260219] Scrutinizing Variables for Checkpoint Using Automatic Differentiation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [fault-tolerance], [checkpoint/restart, automatic differentiation, Enzyme, storage optimization]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Xin Huang, Weiping Zhang, Shiman Meng, Wubiao Xu, Xiang Fu, Luanzheng Guo, Kento Sato"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Nanchang Hangkong University, Pacific Northwest National Laboratory, RIKEN"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16010",children:"https://arxiv.org/pdf/2602.16010"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes a method that uses automatic differentiation (specifically the Enzyme tool) to analyze variables in HPC applications, identifying and excluding data elements that do not affect the final output from checkpointing. The approach was validated on NAS Parallel Benchmarks, showing it can reduce checkpoint storage by up to 20%. The distribution of critical and uncritical elements was found to align with the underlying physical logic of the algorithms."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260219] FlowPrefill: Decoupling Preemption from Prefill Scheduling Granularity to Mitigate Head-of-Line Blocking in LLM Serving"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [prefill scheduling, operator-level preemption, event-driven scheduling, head-of-line blocking mitigation, SLO-aware scheduling]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Chia-chi Hsieh, Zan Zong, Xinyang Chen, Jianjiang Li, Jidong Zhai, Lijie Wen"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Tsinghua University, University of Science and Technology Beijing"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16603",children:"https://arxiv.org/pdf/2602.16603"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes FlowPrefill, an LLM serving system that decouples preemption granularity from scheduling frequency to mitigate head-of-line blocking during the prefill phase. Its core innovations are operator-level preemption for fine-grained interruption and event-driven scheduling to minimize overhead. Evaluation shows it improves maximum goodput by up to 5.6x while meeting heterogeneous SLOs compared to state-of-the-art systems."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260219] LLM-Driven Intent-Based Privacy-Aware Orchestration Across the Cloud-Edge Continuum"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [intent-based orchestration, Kubernetes, SDN, GPT-4o, pipeline reconfiguration, serverless computing]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zijie Su, Muhammed Tawfiqul Islam, Mohammad Goudarzi, Adel N. Toosi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," The University of Melbourne, Monash University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16100",children:"https://arxiv.org/pdf/2602.16100"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes an LLM-driven framework that uses GPT-4o to automatically translate natural-language privacy intents into enforcement-ready policies for Kubernetes and SDN controllers across the cloud-edge continuum. It also introduces a dynamic pipeline reconfiguration approach for LLM serving to adapt to changing workloads in heterogeneous GPU environments. Experimental results show high accuracy in policy generation and low overhead for service reconfiguration."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260219] Distributed Order Recording Techniques for Efficient Record-and-Replay of Multi-threaded Programs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [parallel computing, debugging], [Distributed Clock, Distributed Epoch, ReOMP, ReMPI, record-and-replay]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Xiang Fu, Shiman Meng, Weiping Zhang, Luanzheng Guo, Kento Sato, Dong H. Ahn, Ignacio Laguna, Gregory L. Lee, Martin Schulz"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Nanchang Hangkong University, Pacific Northwest National Laboratory, RIKEN R-CCS, NVIDIA, Lawrence Livermore National Laboratory, Technical University of Munich"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15995",children:"https://arxiv.org/pdf/2602.15995"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes two novel techniques, Distributed Clock (DC) and Distributed Epoch (DE), to efficiently record and replay non-deterministic OpenMP programs by eliminating excessive thread synchronization. The evaluation shows these techniques, implemented in ReOMP, are 2-5x more efficient than traditional methods and can be integrated with MPI replay tools for hybrid applications. The approach enables scalable debugging and testing of complex MPI+OpenMP HPC applications with minimal overhead."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260219] ROIX-Comp: Optimizing X-ray Computed Tomography Imaging Strategy for Data Reduction and Reconstruction"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [data compression], [region-of-interest extraction, error-bounded quantization, lossless/lossy compression, object extraction]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Amarjit Singh, Kento Sato, Kohei Yoshida, Kentaro Uesugi, Yasumasa Joti, Takaki Hatsui, Andr\xe8s Rubio Proa\xf1o"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," RIKEN, The University of Electro-Communications, Japan Synchrotron Radiation Research Institute, Universidad Tecnol\xf3gica Indoam\xe9rica"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15917",children:"https://arxiv.org/pdf/2602.15917"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces ROIX-Comp, a framework that compresses X-ray Computed Tomography data by identifying and extracting essential regions-of-interest and applying error-bounded quantization and advanced compressors. It significantly reduces data volume while preserving critical information, achieving a 12.34x improvement in compression ratio compared to standard methods."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 17'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Balancing Faithfulness and Performance in Reasoning via Multi-Listener Soft Execution ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16154",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Multi-agent cooperation through in-context co-player inference ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16301",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Learning to Drive in New Cities Without Human Demonstrations ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15891",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] A Scalable Approach to Solving Simulation-Based Network Security Games ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16564",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] RIDER: 3D RNA Inverse Design with Reinforcement Learning-Guided Diffusion ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16548",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Vulnerability Analysis of Safe Reinforcement Learning via Inverse Constrained Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16543",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16435",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16196",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] MARVL: Multi-Stage Guidance for Robotic Manipulation via Vision-Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15872",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16165",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Decoupling Strategy and Execution in Task-Focused Dialogue via Goal-Oriented Preference Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15854",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Capacity-constrained demand response in smart grids using deep reinforcement learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16525",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Edge Learning via Federated Split Decision Transformers for Metaverse Resource Allocation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16174",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16179",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16523",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16062",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Almost Sure Convergence of Differential Temporal Difference Learning for Average Reward Markov Decision Processes ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16629",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 14'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Distributed physics-informed neural networks via domain decomposition for fast flow reconstruction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15883",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] CLAA: Cross-Layer Attention Aggregation for Accelerating LLM Prefill ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16054",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Graph neural network for colliding particles with an application to sea ice floe modeling ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16213",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] MoE-Spec: Expert Budgeting for Efficient Speculative Decoding ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16052",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Easy Data Unlearning Bench ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16400",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] MolCrystalFlow: Molecular Crystal Structure Prediction via Flow Matching ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16020",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] FEKAN: Feature-Enriched Kolmogorov-Arnold Networks ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16530",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16442",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] HAWX: A Hardware-Aware FrameWork for Fast and Scalable ApproXimation of DNNs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16336",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] B-DENSE: Branching For Dense Ensemble Network Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15971",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Statistical-Geometric Degeneracy in UAV Search: A Physics-Aware Asymmetric Filtering Approach ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15893",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Optimizer choice matters for the emergence of Neural Collapse ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16642",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Steering Dynamical Regimes of Diffusion Models by Breaking Detailed Balance ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.15914",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260219] Local adapt-then-combine algorithms for distributed nonsmooth optimization: Achieving provable communication acceleration ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16148",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"2026-02-20",children:"2026-02-20"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"cs.DC total: 12"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260220] Evaluating Malleable Job Scheduling in HPC Clusters using Real-World Workloads"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [HPC job scheduling], [malleable jobs, resource elasticity, ElastiSim, job scheduling strategies, workload simulation]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Patrick Zojer, Jonas Posner, Taylan \xd6zden"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Kassel, Technical University of Darmstadt"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17318",children:"https://arxiv.org/pdf/2602.17318"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper evaluates the benefits of malleable job scheduling in HPC clusters by simulating varying proportions of malleable jobs using real-world supercomputer workload traces and the ElastiSim software. It finds that malleable scheduling significantly improves key metrics like job turnaround time and node utilization, with substantial gains even at low adoption rates, demonstrating its potential to address inefficiencies in current HPC practices."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260220] Do GPUs Really Need New Tabular File Formats?"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [GPU kernels], [Parquet, columnar storage, GPU scan, file configuration, row group, page encoding, compression, bandwidth optimization]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Jigao Luo, Qi Chen, Carsten Binnig"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," TU Darmstadt, hessian.AI, DFKI"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17335",children:"https://arxiv.org/pdf/2602.17335"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper systematically studies how Parquet file configurations, such as row group size and page encoding, affect GPU scan performance. It concludes that Parquet's poor GPU performance is not inherent to the format but results from CPU-centric defaults, and by applying GPU-aware configurations, read bandwidth can be dramatically increased without needing a new file format."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260220] Read-Modify-Writable Snapshots from Read/Write operations"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [concurrent algorithms], [linearizability, wait-freedom, lock-freedom, read/write operations, RMWable snapshots]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Armando Casta\xf1eda, Braulio Ramses Hern\xe1ndez Mart\xednez"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Universidad Nacional Aut\xf3noma de M\xe9xico (UNAM)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16903",children:"https://arxiv.org/pdf/2602.16903"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents two read/write RMWable snapshot algorithms for asynchronous concurrent shared-memory systems. The first algorithm works in the standard model with a finite, known number of processes, while the second operates in a model with unbounded concurrency. The main conclusion is that RMWable snapshots are possible using only simple read/write operations, without relying on more powerful primitives like compare&swap."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260220] Heterogeneous Federated Fine-Tuning with Parallel One-Rank Adaptation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm training], [federated learning, low-rank adaptation, heterogeneous clients, parallel one-rank adaptation, select-n-fold, federated fine-tuning]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Zikai Zhang, Rui Hu, Jiahao Xu"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Nevada, Reno"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16936",children:"https://arxiv.org/pdf/2602.16936"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper proposes Fed-PLoRA, a federated fine-tuning framework that introduces Parallel One-Rank Adaptation (PLoRA) and a Select-N-Fold strategy to handle heterogeneous client resources by allowing different LoRA ranks. This approach reduces initialization and aggregation noise compared to standard methods. Experiments show that Fed-PLoRA outperforms existing methods in both accuracy and efficiency for LLM fine-tuning tasks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260220] Informative Trains: A Memory-Efficient Journey to a Self-Stabilizing Leader Election Algorithm in Anonymous Graphs"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [distributed algorithms], [self-stabilization, leader election, anonymous networks, information train, probabilistic algorithm, state model, synchronous scheduler]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Lelia Blin, Sylvain Gay, Isabella Ziccardi"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Universit\xe9 Paris Cit\xe9, CNRS, IRIF, \xc9cole Normale Sup\xe9rieure"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17541",children:"https://arxiv.org/pdf/2602.17541"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"}),' The paper presents a probabilistic self-stabilizing leader election algorithm for arbitrary anonymous networks that uses only O(log log n) bits of memory per node. It introduces an "information train" mechanism to propagate information efficiently while maintaining low local memory. The algorithm converges almost surely to a unique leader and stabilizes within polynomial rounds, achieving space-optimal memory complexity for general graphs.']}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260220] Visual Insights into Agentic Optimization of Pervasive Stream Processing Services"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [autoscaling, service level objectives (SLOs), multi-dimensional elasticity, regression analysis, edge computing, stream processing]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Boris Sedlak, V\xedctor Casamayor Pujol, Schahram Dustdar"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Universitat Pompeu Fabra, TU Wien"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17282",children:"https://arxiv.org/pdf/2602.17282"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents a platform (MUDAP) and an agent (RASK) for context-aware, multi-dimensional autoscaling of stream processing services at the edge. The agent uses regression analysis to understand the impact of different service parameters on performance and dynamically optimizes service execution to meet fluctuating demands and resource constraints. This approach enables services to autonomously adjust their operation to sustain critical Service Level Objectives like latency in pervasive applications."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260220] Trivance: Latency-Optimal AllReduce by Shortcutting Multiport Networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [AllReduce, torus networks, latency-optimal, congestion reduction, bidirectional ring, Bruck's algorithm, Swing, collective communication]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Anton Juerss, Vamsi Addanki, Stefan Schmid"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Weizenbaum Institute, TU Berlin, Purdue University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17254",children:"https://arxiv.org/pdf/2602.17254"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper introduces Trivance, a novel AllReduce algorithm that achieves latency-optimal performance in log3 n steps on bidirectional ring and torus networks while reducing congestion compared to prior methods. It exploits both transmission ports per step to triple communication distance and uses joint reductions to improve steps and congestion. Empirical evaluation shows Trivance outperforms state-of-the-art approaches by 5-30% across various message sizes and network topologies."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260220] TopoSZp: Lightweight Topology-Aware Error-controlled Compression for Scientific Data"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [scientific data compression], [error-bounded lossy compression, topology preservation, critical point detection, SZp compressor, local ordering preservation, saddle-point refinement]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Tripti Agarwal, Sheng Di, Xin Liang, Zhaoyuan Su, Yuxiao Li, Ganesh Gopalakrishnan, Hanqi Guo, Franck Cappello"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Utah, Argonne National Laboratory, University of Kentucky, University of Virginia, The Ohio State University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17552",children:"https://arxiv.org/pdf/2602.17552"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," The paper presents TopoSZp, a lightweight, topology-aware lossy compressor built on SZp that integrates critical point detection and local ordering preservation within a strict error bound. It demonstrates that TopoSZp significantly better preserves topological features like minima and saddle points compared to standard compressors, while offering orders-of-magnitude faster compression and decompression than prior topology-aware methods."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260220] Privacy-Aware Split Inference with Speculative Decoding for Large Language Models over Wide-Area Networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [llm inference], [split inference, speculative decoding, lookahead decoding, privacy-aware inference, wide-area networks, inversion attack, n-gram speculation, greedy argmax]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Michael Cunningham"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Not explicitly provided; author name only (Michael Cunningham). Unable to infer institution from given content."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16760",children:"https://arxiv.org/pdf/2602.16760"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper presents a privacy-aware LLM inference system that splits a transformer model between a local trusted device and an untrusted cloud GPU, using speculative (lookahead) decoding to mitigate the latency of wide-area networks. The system ensures raw tokens never leave the local device and demonstrates a tunable privacy-performance tradeoff, achieving practical throughput (e.g., 8.7-9.3 tok/s for Mistral 7B) over an ~80ms WAN link while maintaining output identical to standard greedy decoding."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260220] Exploring Novel Data Storage Approaches for Large-Scale Numerical Weather Prediction"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [sys], [high-performance computing storage], [DAOS, Ceph, Lustre, object storage, POSIX, I/O benchmarking, NVMe SSDs]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Nicolau Manubens Gil"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," University of Edinburgh, ECMWF"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17610",children:"https://arxiv.org/pdf/2602.17610"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper evaluates the performance of DAOS and Ceph object storage systems for large-scale Numerical Weather Prediction (NWP) and HPC applications by developing new software adapters and conducting extensive I/O benchmarks against Lustre file systems. The study finds that both object stores perform well, but DAOS demonstrates superior scalability and flexibility for large-scale I/O workloads, suggesting promising potential for broader adoption in HPC centers."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260220] Catastrophic Forgetting Resilient One-Shot Incremental Federated Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [diffusion training], [one-shot federated learning, incremental learning, catastrophic forgetting, vision-language model, diffusion model, selective sample retention]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Obaidullah Zaland, Zulfiqar Ahmad Khan, Monowar Bhuyan"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Ume\xe5 University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17625",children:"https://arxiv.org/pdf/2602.17625"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes OSI-FL, a one-shot incremental federated learning framework that uses a vision-language model to generate client embeddings and a diffusion model to synthesize training data at the server, augmented with a selective sample retention strategy to mitigate catastrophic forgetting. The method addresses communication overhead and forgetting in incremental data scenarios. Experiments show it outperforms traditional and one-shot FL baselines on class- and domain-incremental tasks across multiple datasets."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"[arXiv260220] Guarding the Middle: Protecting Intermediate Representations in Federated Split Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"tags:"})," [mlsys], [others], [federated split learning, differential privacy, microaggregation, data reconstruction attack, k-anonymity]"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"authors:"})," Obaidullah Zaland, Sajib Mistry, Monowar Bhuyan"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"institution:"})," Ume\xe5 University, Curtin University"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"link:"})," ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17614",children:"https://arxiv.org/pdf/2602.17614"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simple LLM Summary:"})," This paper proposes KD-UFSL, a method that combines k-anonymity via microaggregation and differential privacy to protect intermediate data (smashed data) in U-shaped federated split learning from reconstruction attacks. The experiments show that KD-UFSL significantly increases reconstruction error and reduces similarity between original and reconstructed data while preserving the utility of the global model. The method is suitable for balancing privacy and utility in large-scale, privacy-sensitive applications."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 21'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16953",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] References Improve LLM Alignment in Non-Verifiable Domains ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16802",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17062",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Action-Graph Policies: Learning Action Co-dependencies in Multi-Agent Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17009",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] RLGT: A reinforcement learning framework for extremal graph theory ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17276",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] DeepVision-103K: A Visually Diverse, Broad-Coverage, and Verifiable Mathematical Dataset for Multimodal Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16742",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Phase-Aware Mixture of Experts for Agentic Reinforcement Learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17038",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] LexiSafe: Offline Safe Reinforcement Learning with Lexicographic Safety-Reward Hierarchy ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17312",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] SimToolReal: An Object-Centric Policy for Zero-Shot Dexterous Tool Manipulation ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16863",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Training Large Reasoning Models Efficiently via Progressive Thought Encoding ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16839",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] A Unified Framework for Locality in Scalable MARL ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16966",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Discovering Multiagent Learning Algorithms with Large Language Models ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16928",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Adapting Actively on the Fly: Relevance-Guided Online Meta-Learning with Latent Concepts for Geospatial Discovery ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17605",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Spatio-temporal dual-stage hypergraph MARL for human-centric multimodal corridor traffic signal control ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17068",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] MASPO: Unifying Gradient Utilization, Probability Mass, and Signal Reliability for Robust and Sample-Efficient LLM Reasoning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17550",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] VAM: Verbalized Action Masking for Controllable Exploration in RL Post-Training -- A Chess Case Study ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16833",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Continual uncertainty learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17174",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Stable Asynchrony: Variance-Controlled Off-Policy RL for LLMs ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17616",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] SMAC: Score-Matched Actor-Critics for Robust Offline-to-Online Transfer ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17632",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Dynamic Decision-Making under Model Misspecification: A Stochastic Stability Approach ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17086",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Deep Reinforcement Learning for Optimal Portfolio Allocation: A Comparative Study with Mean-Variance Optimization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17098",children:"link"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 14'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Shortcut learning in geometric knot classification ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17350",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Linear Convergence in Games with Delayed Feedback via Extra Prediction ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17486",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Transforming Behavioral Neuroscience Discovery with In-Context Learning and AI-Enhanced Tensor Methods ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17027",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Greedy Multi-Path Block Verification for Faster Decoding in Speculative Sampling ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16961",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Early-Warning Signals of Grokking via Loss-Landscape Geometry ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16967",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] SubQuad: Near-Quadratic-Free Structure Inference with Distribution-Balanced Objectives in Adaptive Receptor framework ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17330",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] MMCAformer: Macro-Micro Cross-Attention Transformer for Traffic Speed Prediction with Microscopic Connected Vehicle Driving Behavior ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16730",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Predictive Batch Scheduling: Accelerating Language Model Training Through Loss-Aware Sample Prioritization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17066",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] GPU-Accelerated Algorithms for Graph Vector Search: Taxonomy, Empirical Study, and Research Directions ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16719",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Powering Up Zeroth-Order Training via Subspace Gradient Orthogonalization ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17155",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] One-step Language Modeling via Continuous Denoising ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16813",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Dynamic Delayed Tree Expansion For Improved Multi-Path Speculative Decoding ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.16994",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Continual uncertainty learning ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17174",children:"link"})]}),"\n",(0,s.jsxs)(e.li,{children:["[arXiv260220] Toward a Fully Autonomous, AI-Native Particle Accelerator ",(0,s.jsx)(e.a,{href:"https://arxiv.org/pdf/2602.17536",children:"link"})]}),"\n"]})]})}function h(i={}){const{wrapper:e}={...(0,a.R)(),...i.components};return e?(0,s.jsx)(e,{...i,children:(0,s.jsx)(d,{...i})}):d(i)}},8453:(i,e,n)=>{n.d(e,{R:()=>t,x:()=>o});var r=n(6540);const s={},a=r.createContext(s);function t(i){const e=r.useContext(a);return r.useMemo(function(){return"function"==typeof i?i(e):{...e,...i}},[e,i])}function o(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(s):i.components||s:t(i.components),r.createElement(a.Provider,{value:e},i.children)}}}]);