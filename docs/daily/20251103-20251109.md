# 20251103-20251109

## 2025-11-03

**cs.DC total: 11**

- **[arXiv251103] Glia: A Human-Inspired AI for Automated Systems Design and Optimization**
  - **tags:** [mlsys], [llm inference], [multi-agent workflow, large language models, interpretable designs, request routing, scheduling, auto-scaling]
  - **authors:** Pouya Hamadanian, Pantea Karimi, Arash Nasr-Esfahany, Kimia Noorbakhsh, Joseph Chandler, Ali ParandehGheibi, Mohammad Alizadeh, Hari Balakrishnan
  - **institution:** MIT CSAIL
  - **link:** https://arxiv.org/pdf/2510.27176
  - **Simple LLM Summary:** Glia uses a human-inspired multi-agent architecture with LLMs that specialize in reasoning, experimentation, and analysis to automate systems design. It generates interpretable algorithms for distributed GPU clusters performing LLM inference. The system produces human-expert level designs in less time while providing novel insights into workload behavior.

- **[arXiv251103] Dynamic Service Scheduling and Resource Management in Energy-Harvesting Multi-access Edge Computing**
  - **tags:** [sys], [edge computing], [energy harvesting, online scheduling, DAG, DVFS, service module migration]
  - **authors:** Shuyi Chen, Panagiotis Oikonomou, Zhengchang Hua, Nikos Tziritas, Karim Djemame, Nan Zhang, Georgios Theodoropoulos
  - **institution:** University of Leeds, Southern University of Science and Technology, University of Thessaly
  - **link:** https://arxiv.org/pdf/2510.27317
  - **Simple LLM Summary:** This paper proposes an online strategy for energy-harvesting MEC systems that dynamically schedules computational tasks with dependencies and manages energy consumption through server frequency scaling and service module migration. The method efficiently utilizes harvested energy while maintaining low service latency, as demonstrated through experiments with real-world datasets.

- **[arXiv251103] Synergistic Tensor and Pipeline Parallelism**
  - **tags:** [mlsys], [llm training], [tensor parallelism, pipeline parallelism, hybrid model parallelism, scheduling, communication optimization]
  - **authors:** Mengshi Qi, Jiaxuan Peng, Jie Zhang, Juan Zhu, Yong Li, Huadong Ma
  - **institution:** Beijing University of Posts and Telecommunications
  - **link:** https://arxiv.org/pdf/2510.27257
  - **Simple LLM Summary:** The paper proposes a synergistic tensor and pipeline parallelism schedule that decouples forward and backward passes into fine-grained computation units and braids them into a composite sequence. This approach simultaneously reduces both tensor parallelism communication bubbles and pipeline parallelism synchronization bubbles. Experimental results show throughput improvements of up to 12% for LLMs and 16% for MLLMs compared to existing methods.

- **[arXiv251103] A Cloud-Based Spatio-Temporal GNN-Transformer Hybrid Model for Traffic Flow Forecasting with External Feature Integration**
  - **tags:** [mlsys], [others], [Spatio-Temporal Graph Neural Networks, Transformer, Cloud Computing, Feature Fusion]
  - **authors:** Zhuo Zheng, Lingran Meng, Ziyu Lin
  - **institution:** Nanchang University, University of Washington, Google
  - **link:** https://arxiv.org/pdf/2510.27039
  - **Simple LLM Summary:** This paper proposes a cloud-based hybrid model combining Spatio-Temporal Graph Neural Networks with Transformer architecture for traffic flow forecasting, integrating external features like weather and holidays. The model leverages GNNs for spatial correlations and Transformers for long-term temporal dependencies. Experimental results show it outperforms baseline methods with RMSE of 17.92 and MAE of 10.53, demonstrating effectiveness for intelligent transportation systems.

- **[arXiv251103] SERFLOW: A Cross-Service Cost Optimization Framework for SLO-Aware Dynamic ML Inference**
  - **tags:** [mlsys], [llm inference], [dynamic offloading, FaaS, IaaS, stage-specific resource provisioning, adaptive load balancing, serverless functions, cost optimization]
  - **authors:** Zongshun Zhang, Ibrahim Matta
  - **institution:** Boston University
  - **link:** https://arxiv.org/pdf/2510.27182
  - **Simple LLM Summary:** SERFLOW proposes a cross-service optimization framework that dynamically offloads ML model partitions between IaaS VMs and FaaS serverless functions using stage-specific resource provisioning and adaptive load balancing. The framework accounts for variable request exit rates across model stages and real-world factors like VM cold starts. This approach reduces cloud costs by over 23% while maintaining service level objectives for dynamic ML inference workloads.

- **[arXiv251103] Secure Communication in the Presence of an RIS-Enhanced Eavesdropper in MIMO Networks**
  - **tags:** [sys], [wireless communication security], [reconfigurable intelligent surface, MIMO, singular value decomposition, bit-flipping, physical layer security]
  - **authors:** Gaoyuan Zhang, Ruisong Si, Boyuan Li, Zijian Li, Baofeng Ji, Chenqi Zhu, Tony Q.S. Quek
  - **institution:** Henan University of Science and Technology, Zhengzhou University, Dalian Maritime University, Singapore University of Technology and Design
  - **link:** https://arxiv.org/pdf/2510.27147
  - **Simple LLM Summary:** This paper proposes a secure communication scheme using random bit-flipping and SVD-based precoding to protect MIMO wireless networks against RIS-enhanced eavesdroppers. The method minimizes mutual information between secret messages and eavesdropper data without requiring full channel state information. Results demonstrate the scheme's effectiveness and robustness across various attacking scenarios.

- **[arXiv251103] FlowMesh: A Service Fabric for Composable LLM Workflows**
  - **tags:** [mlsys], [post-training], [workflow optimization, multi-tenant service fabric, content-addressable store, operator lineage, batch scheduling]
  - **authors:** Junyi Shen, Noppanat Wadlom, Lingfeng Zhou, Dequan Wang, Xu Miao, Lei Fang, Yao Lu
  - **institution:** National University of Singapore, Shanghai Jiao Tong University, DataCanvas
  - **link:** https://arxiv.org/pdf/2510.26913
  - **Simple LLM Summary:** FlowMesh is a service fabric that decomposes LLM workflows into fine-grained operators and optimizes execution across multiple users through deduplication and intelligent batching. It uses a global control plane for scheduling and stateless workers with content-addressable storage for elasticity. The system achieves up to 3.8× cost reduction and maintains efficiency under dynamic conditions compared to baseline solutions.

- **[arXiv251103] ML-Based Optimum Sub-system Size Heuristic for the GPU Implementation of the Tridiagonal Partition Method**
  - **tags:** [mlsys], [GPU kernels], [k-nearest neighbors, parallel partition algorithm, CUDA implementation, tridiagonal matrices, recursive algorithm]
  - **authors:** Milena Veneva
  - **institution:** RIKEN Center for Computational Science
  - **link:** https://arxiv.org/pdf/2510.27351
  - **Simple LLM Summary:** This paper develops a machine learning-based heuristic using k-nearest neighbors classification to determine optimal sub-system sizes for GPU implementations of parallel partition algorithms solving tridiagonal systems. The method was empirically validated through computational experiments on various SLAE sizes and extended to recursive variants. Results showed the algorithm performed acceptably well in predicting optimal parameters for GPU performance optimization.

- **[arXiv251103] A Digital Twin-based Multi-Agent Reinforcement Learning Framework for Vehicle-to-Grid Coordination**
  - **tags:** [mlsys], [others], [Digital Twin, Multi-Agent Reinforcement Learning, MADDPG, Vehicle-to-Grid, privacy-preserving]
  - **authors:** Zhengchang Hua, Panagiotis Oikonomou, Karim Djemame, Nikos Tziritas, Georgios Theodoropoulos
  - **institution:** Southern University of Science and Technology, University of Leeds, University of Thessaly, Research Institute of Trustworthy Autonomous Systems
  - **link:** https://arxiv.org/pdf/2510.27289
  - **Simple LLM Summary:** This paper proposes DT-MADDPG, a hybrid framework combining multi-agent reinforcement learning with collaborative Digital Twins for Vehicle-to-Grid coordination. The method enhances the centralized critic with a predictive global model built from privacy-preserving data shared by individual Digital Twins. Experimental results show the approach achieves coordination performance comparable to standard MADDPG while providing significant advantages in data privacy and architectural decentralization.

- **[arXiv251103] Byzantine Attacks in RIS-Enhanced Cooperative Spectrum Sensing: A Decision Fusion Perspective**
  - **tags:** [sys], [wireless security], [cooperative spectrum sensing, Byzantine attacks, decision fusion, reconfigurable intelligent surface, decode-and-forward relay]
  - **authors:** Gaoyuan Zhang, Gaolei Song, Boyuan Li, Zijian Li, Baofeng Ji, Ruijuan Zheng, Guoqiang Zheng, Tony Q.S. Quek
  - **institution:** Henan University of Science and Technology, Zhengzhou University, Dalian Maritime University, Singapore University of Technology and Design
  - **link:** https://arxiv.org/pdf/2510.27175
  - **Simple LLM Summary:** This paper investigates Byzantine attacks in RIS-enhanced cooperative spectrum sensing systems from a decision fusion perspective. The authors develop channel-aware attack strategies and show that optimal Byzantine attacks don't require global instantaneous channel state information and effectiveness primarily depends on the fraction of compromised nodes rather than channel dynamics. Their counterintuitive findings demonstrate that heavy reliance on global ICSI and decision fusion rules can be successfully relaxed for practical implementation.

- **[arXiv251103] RDMA Point-to-Point Communication for LLM Systems**
  - **tags:** [mlsys], [llm inference], [RDMA, point-to-point communication, TransferEngine, one-sided WriteImm, ImmCounter, disaggregated inference, Mixture-of-Experts]
  - **authors:** Nandor Licker, Kevin Hu, Vladimir Zaytsev, Lequn Chen
  - **institution:** Perplexity AI
  - **link:** https://arxiv.org/pdf/2510.27656
  - **Simple LLM Summary:** The paper presents TransferEngine, a portable RDMA communication library that provides uniform point-to-point communication across different network hardware. It enables high-performance communication for LLM systems through one-sided WriteImm operations with ImmCounter completion notification. The system achieves 400 Gbps throughput and demonstrates practical benefits in disaggregated inference, RL fine-tuning, and MoE routing while avoiding vendor lock-in.


**cs.AI/cs.LG contains "reinforcement learning" total: 18**
- [arXiv251103] A Framework for Fair Evaluation of Variance-Aware Bandit Algorithms [link](https://arxiv.org/pdf/2510.27001)
- [arXiv251103] Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning [link](https://arxiv.org/pdf/2510.27044)
- [arXiv251103] Reinforcement Learning for Long-Horizon Unordered Tasks: From Boolean to Coupled Reward Machines [link](https://arxiv.org/pdf/2510.27329)
- [arXiv251103] e1: Learning Adaptive Control of Reasoning Effort [link](https://arxiv.org/pdf/2510.27042)
- [arXiv251103] GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation [link](https://arxiv.org/pdf/2510.27210)
- [arXiv251103] Reasoning Models Sometimes Output Illegible Chains of Thought [link](https://arxiv.org/pdf/2510.27338)
- [arXiv251103] MedCalc-Eval and MedCalc-Env: Advancing Medical Calculation Capabilities of Large Language Models [link](https://arxiv.org/pdf/2510.27267)
- [arXiv251103] Towards Understanding Self-play for LLM Reasoning [link](https://arxiv.org/pdf/2510.27072)
- [arXiv251103] Do Vision-Language Models Measure Up? Benchmarking Visual Measurement Reading with MeasureBench [link](https://arxiv.org/pdf/2510.26865)
- [arXiv251103] AURA: A Reinforcement Learning Framework for AI-Driven Adaptive Conversational Surveys [link](https://arxiv.org/pdf/2510.27126)
- [arXiv251103] Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints [link](https://arxiv.org/pdf/2510.27383)
- [arXiv251103] DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains [link](https://arxiv.org/pdf/2510.27419)
- [arXiv251103] Learning Soft Robotic Dynamics with Active Exploration [link](https://arxiv.org/pdf/2510.27428)
- [arXiv251103] VCORE: Variance-Controlled Optimization-based Reweighting for Chain-of-Thought Supervision [link](https://arxiv.org/pdf/2510.27462)
- [arXiv251103] Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning [link](https://arxiv.org/pdf/2510.27606)
- [arXiv251103] Challenges in Credit Assignment for Multi-Agent Reinforcement Learning in Open Agent Systems [link](https://arxiv.org/pdf/2510.27659)
- [arXiv251103] Reinforcement Learning for Accelerator Beamline Control: a simulation-based approach [link](https://arxiv.org/pdf/2510.26805)
- [arXiv251103] When AI Trading Agents Compete: Adverse Selection of Meta-Orders by Reinforcement Learning-Based Market Making [link](https://arxiv.org/pdf/2510.27334)

**cs.AI/cs.LG contains "accelerate" total: 12**
- [arXiv251103] CAS-Spec: Cascade Adaptive Self-Speculative Decoding for On-the-Fly Lossless Inference Acceleration of LLMs [link](https://arxiv.org/pdf/2510.26843)
- [arXiv251103] H2-Cache: A Novel Hierarchical Dual-Stage Cache for High-Performance Acceleration of Generative Diffusion Models [link](https://arxiv.org/pdf/2510.27171)
- [arXiv251103] Sparse Model Inversion: Efficient Inversion of Vision Transformers for Data-Free Applications [link](https://arxiv.org/pdf/2510.27186)
- [arXiv251103] MLPerf Automotive [link](https://arxiv.org/pdf/2510.27065)
- [arXiv251103] HiF-DTA: Hierarchical Feature Learning Network for Drug-Target Affinity Prediction [link](https://arxiv.org/pdf/2510.27281)
- [arXiv251103] Jasmine: A Simple, Performant and Scalable JAX-based World Modeling Codebase [link](https://arxiv.org/pdf/2510.27002)
- [arXiv251103] FPS: Feedforward-based Parameter Selection For Efficient Fine-Tuning [link](https://arxiv.org/pdf/2510.27359)
- [arXiv251103] Fine-Tuning Open Video Generators for Cinematic Scene Synthesis: A Small-Data Pipeline with LoRA and Wan2.1 I2V [link](https://arxiv.org/pdf/2510.27364)
- [arXiv251103] FedMuon: Accelerating Federated Learning with Matrix Orthogonalization [link](https://arxiv.org/pdf/2510.27403)
- [arXiv251103] InnovatorBench: Evaluating Agents' Ability to Conduct Innovative LLM Research [link](https://arxiv.org/pdf/2510.27598)
- [arXiv251103] Best Practices for Biorisk Evaluations on Open-Weight Bio-Foundation Models [link](https://arxiv.org/pdf/2510.27629)
- [arXiv251103] Reinforcement Learning for Accelerator Beamline Control: a simulation-based approach [link](https://arxiv.org/pdf/2510.26805)

## 2025-11-04

**cs.DC total: 25**

- **[arXiv251104] Tetris: An SLA-aware Application Placement Strategy in the Edge-Cloud Continuum**
  - **tags:** [sys], [edge-cloud resource management], [heuristic algorithm, SLA-aware placement, resource efficiency, latency-sensitive applications]
  - **authors:** Lucas Almeida, Maycon Peixoto
  - **institution:** Federal University of Bahia
  - **link:** https://arxiv.org/pdf/2511.00294
  - **Simple LLM Summary:** The paper proposes Tetris, a heuristic-based application placement strategy that prioritizes services based on SLA urgencies and resource efficiency in Edge-Cloud Continuum environments. The method reduces SLA violations by approximately 76% compared to baseline approaches, demonstrating improved Quality of Service for latency-sensitive applications.

- **[arXiv251104] Fix: externalizing network I/O in serverless computing**
  - **tags:** [sys], [serverless computing], [externalized I/O, deterministic procedures, dataflow scheduling]
  - **authors:** Yuhan Deng, Akshay Srivatsan, Sebastian Ingino, Francis Chua, Yasmine Mitchell, Matthew Vilaysack, Keith Winstein
  - **institution:** Stanford University
  - **link:** https://arxiv.org/pdf/2511.00205
  - **Simple LLM Summary:** This paper proposes a serverless computing system where computations are represented as deterministic procedures with explicit data dependencies, enabling the platform to externalize network I/O. By making data requirements explicit, the system allows better scheduling of tasks and network transfers to reduce starvation. The approach suggests shifting cloud computing from a "pay-for-effort" to a "pay-for-results" service model.

- **[arXiv251104] AReaL-Hex: Accommodating Asynchronous RL Training over Heterogeneous GPUs**
  - **tags:** [mlsys], [llm training], [asynchronous RL training, heterogeneous GPU scheduling, mixed-integer linear programming, graph partitioning, data staleness bounds]
  - **authors:** Ran Yan, Youhe Jiang, Tianyuan Wu, Jiaxuan Gao, Zhiyu Mei, Wei Fu, Haohui Mai, Wei Wang, Yi Wu, Binhang Yuan
  - **institution:** HKUST, Tsinghua University, Ant Group
  - **link:** https://arxiv.org/pdf/2511.00796
  - **Simple LLM Summary:** AReaL-Hex is a heterogeneity-aware asynchronous RL training system that uses a two-phase scheduler with MILP optimization and graph partitioning to efficiently deploy RL training across heterogeneous GPUs. The system achieves up to 1.50× higher training throughput at the same budget and reduces training costs by up to 1.46× while maintaining the same throughput compared to homogeneous deployments.

- **[arXiv251104] Split Learning-Enabled Framework for Secure and Light-weight Internet of Medical Things Systems**
  - **tags:** [mlsys], [others], [split learning, federated learning, game-theoretic optimization, image-based classification, malware detection]
  - **authors:** Siva Sai, Manish Prasad, Animesh Bhargava, Vinay Chamola, Rajkumar Buyya
  - **institution:** The University of Melbourne, BITS-Pilani
  - **link:** https://arxiv.org/pdf/2511.00336
  - **Simple LLM Summary:** The paper proposes a split learning framework for IoT malware detection that divides neural network training between clients and an edge server to reduce computational burden while maintaining data privacy. Experimental results show the framework outperforms federated learning methods with higher accuracy (+6.35%), faster convergence (+14.96%), and lower resource consumption (33.83%), establishing split learning as a scalable and secure paradigm for IoT security.

- **[arXiv251104] Benchmarking Federated Learning Frameworks for Medical Imaging Deployment: A Comparative Study of NVIDIA FLARE, Flower, and Owkin Substra**
  - **tags:** [mlsys], [cluster infrastructure], [federated learning, medical imaging, PathMNIST, model convergence, communication overhead, scalability assessment]
  - **authors:** Riya Gupta, Alexander Chowdhury, Sahil Nalawade
  - **institution:** Harvard T.H. Chan School of Public Health, Dana-Farber Cancer Institute
  - **link:** https://arxiv.org/pdf/2511.00037
  - **Simple LLM Summary:** This paper benchmarks three federated learning frameworks (NVIDIA FLARE, Flower, and Owkin Substra) using the PathMNIST medical imaging dataset to evaluate performance, scalability, and deployment features. The study found that each framework has distinct strengths: NVIDIA FLARE excels in production scalability, Flower offers research flexibility, and Owkin Substra provides superior privacy compliance for healthcare applications.

- **[arXiv251104] EPARA: Parallelizing Categorized AI Inference in Edge Clouds**
  - **tags:** [mlsys], [llm inference], [task categorization, parallel inference, edge computing, distributed scheduling, resource allocation]
  - **authors:** Yubo Wang, Yubo Cui, Tuo Shi, Danyang Li, Wenxin Li, Lide Suo, Tao Wang, Xin Xie
  - **institution:** Tianjin University, Aalto University, Nankai University
  - **link:** https://arxiv.org/pdf/2511.00603
  - **Simple LLM Summary:** EPARA introduces a parallel AI inference framework that categorizes tasks based on latency sensitivity and GPU requirements to optimize resource allocation in edge clouds. The system employs task-categorized parallelism allocation, distributed request handling, and state-aware scheduling to improve serving capability. Experimental results show EPARA achieves up to 2.1× higher goodput compared to prior frameworks while adapting to various edge AI inference tasks.

- **[arXiv251104] LongCat-Flash-Omni Technical Report**
  - **tags:** [mlsys], [multi-modal training], [Mixture-of-Experts, modality-decoupled parallelism, curriculum-inspired progressive training, multimodal perception, speech reconstruction]
  - **authors:** Meituan LongCat Team, Bairui Wang, Bayan, Bin Xiao, Bo Zhang, Bolin Rong, Borun Chen, Chang Wan, Chao Zhang, Chen Huang, Chen Chen, Chen Chen, Chengxu Yang, Chengzuo Yang, Cong Han, Dandan Peng, Delian Ruan, Detai Xin, Disong Wang, Dongchao Yang, Fanfan Liu, Fengjiao Chen, Fengyu Yang, Gan Dong, Gang Huang, Gang Xu, Guanglu Wan, Guoqiang Tan, Guoqiao Yu, Haibo Qiu, Hao Lu, Hongbo Liu, Hongyu Xiang, Jiaheng Wu, Jian Yang, Jiaxing Liu, Jing Huang, Jingang Wang, Jinrui Ding, Juchao Jiang, Jun Kuang, Jun Wang, Junhui Mei, Ke Ding, Kefeng Zhang, Lei Chen, Liang Shi, Limeng Qiao, Liming Zheng, Lin Ma, Liuyang Guo, Liya Ma, Luying Sun, Man Gao, Mengshen Zhu, Miao Cao, Minliang Lin, Nuo Xu, Peng Shi, Qi Zhang, Qian Fang, Qian Wang, Qian Yang, Quanxiu Wang, Rongxiang Weng, Rongxin Guo, Ruoxuan Liang, Senbin Yang, Shanbo Xu, Shanglin Lei, Shengze Ye, Shimin Chen, Shuaiqi Chen, Shujie Hu, Shuo Li, Siqi Yang, Siyu Xu, Siyu Ren, Song Li, Songxiang Liu, Tianhao Bai, Tianye Dai, Wei Hong, Wei Wang, Weixiao Zhao, Wengang Cao, Wenlong Zhu, Wenlong He, Xi Su, Xi Nan, Xiaohan Zhao, Xiaohao Wang, Xiaoyu Zhao, Xiaoyu Wang, Xiaoyu Li, Xin Pan, Xin Chen, Xiusong Sun, Xu Xiang, Xudong Xing
  - **institution:** Meituan
  - **link:** https://arxiv.org/pdf/2511.00279
  - **Simple LLM Summary:** LongCat-Flash-Omni is a 560B parameter omni-modal model that uses a Mixture-of-Experts architecture with modality-decoupled parallelism and progressive training strategy. It achieves state-of-the-art performance on multimodal benchmarks while maintaining efficient real-time audio-visual interaction despite its large parameter count. The model demonstrates competitive results across text, image, video, and audio tasks while sustaining over 90% of text-only training throughput.

- **[arXiv251104] COOL Is Optimal in Error-Free Asynchronous Byzantine Agreement**
  - **tags:** [sys], [distributed systems], [Byzantine agreement, error correction codes, asynchronous consensus, information-theoretic security]
  - **authors:** Jinyuan Chen
  - **institution:** Unknown (author: Jinyuan Chen)
  - **link:** https://arxiv.org/pdf/2511.00263
  - **Simple LLM Summary:** This paper presents OciorACOOL, an adaptive variant of the COOL protocol that extends Byzantine agreement to asynchronous settings while maintaining error-free information-theoretic security. The protocol achieves consensus with O(max{nℓ, nt log q}) communication bits, O(1) rounds, and a single binary BA invocation under optimal resilience n ≥ 3t+1. It preserves the same low-complexity error-correction encoding and decoding as the original COOL protocol.

- **[arXiv251104] AeroResQ: Edge-Accelerated UAV Framework for Scalable, Resilient and Collaborative Escape Route Planning in Wildfire Scenarios**
  - **tags:** [mlsys], [fault-tolerance], [weighted A* search, edge accelerators, Apache IoTDB, geo-fenced re-partitioning, multi-layer orchestration]
  - **authors:** Suman Raj, Radhika Mittal, Rajiv Mayani, Pawel Zuk, Anirban Mandal, Michael Zink, Yogesh Simmhan, Ewa Deelman
  - **institution:** Indian Institute of Science, University of Southern California, University of North Carolina, University of Massachusetts Amherst
  - **link:** https://arxiv.org/pdf/2511.00038
  - **Simple LLM Summary:** AeroResQ proposes an edge-accelerated UAV framework using service drones for real-time detection and coordinator drones with weighted A* search for escape route planning. The system incorporates resilient mechanisms like automated data redistribution and workload reassignment to handle drone failures. Experimental results show it achieves ≤500ms latency and over 98% task completion, demonstrating feasibility for real-time wildfire emergency response.

- **[arXiv251104] Agentic Auto-Scheduling: An Experimental Study of LLM-Guided Loop Optimization**
  - **tags:** [mlsys], [GPU kernels], [loop optimization, polyhedral methods, compiler feedback, code transformation, tiling, fusion, parallelization]
  - **authors:** Massinissa Merouani, Islem Kara Bernou, Riyadh Baghdadi
  - **institution:** New York University Abu Dhabi
  - **link:** https://arxiv.org/pdf/2511.00592
  - **Simple LLM Summary:** This paper introduces ComPilot, a framework that uses Large Language Models as interactive optimization agents to guide loop nest transformations through a closed-loop feedback system with a compiler. The LLM proposes code transformations, receives compiler feedback on legality and performance, and iteratively refines its optimization strategy. The approach achieves significant speedups (2.66x-3.54x) on PolyBench benchmarks and demonstrates competitive performance against the state-of-the-art Pluto polyhedral optimizer.

- **[arXiv251104] Scalable Maxflow Processing for Dynamic Graphs**
  - **tags:** [sys], [graph algorithms], [push-relabel algorithm, GPU parallelization, CUDA optimizations, dynamic graph processing]
  - **authors:** Shruthi Kannappan, Ashwina Kumar, Rupesh Nasre
  - **institution:** Indian Institute of Technology Madras
  - **link:** https://arxiv.org/pdf/2511.01235
  - **Simple LLM Summary:** This paper presents novel GPU-parallel Max-Flow algorithms for both static and dynamic graphs, building on the Push-Relabel method. The authors introduce CUDA-specific optimizations to enhance performance and scalability. Their approach efficiently handles incremental updates to dynamic graphs without recomputing from scratch.

- **[arXiv251104] Boosting performance of computer vision applications through embedded GPUs on the edge**
  - **tags:** [mlsys], [GPU kernels], [edge computing, embedded GPUs, computer vision, performance optimization]
  - **authors:** Fabio Diniz Rossi
  - **institution:** Federal Institute of Education, Science, and Technology Farroupilha (IFFar)
  - **link:** https://arxiv.org/pdf/2511.01129
  - **Simple LLM Summary:** This paper proposes using embedded GPUs in edge computing devices to accelerate computer vision applications. Experimental results show that GPUs achieve performance gains of up to 820.36% compared to CPUs alone. This approach improves user experience by overcoming the resource limitations of traditional edge devices.

- **[arXiv251104] Design of quasi phase matching crystal based on differential gray wolf algorithm**
  - **tags:** [mlsys], [GPU kernels], [differential evolution algorithm, gray wolf optimization, GPU parallel computing, quasi-phase matching crystal design]
  - **authors:** He Chen, ZiHua Zheng, JingHua Sun
  - **institution:** Dongguan University of Technology
  - **link:** https://arxiv.org/pdf/2511.01255
  - **Simple LLM Summary:** This paper proposes a hybrid optimization algorithm combining differential evolution and gray wolf optimization with GPU parallel acceleration for quasi-phase matching crystal design. The method achieves hundreds to thousands of times efficiency improvement compared to traditional CPU serial computing while enhancing crystal domain control accuracy. This breakthrough enables better performance in nonlinear optical devices for quantum optics and laser processing applications.

- **[arXiv251104] Gradient Clock Synchronization with Practically Constant Local Skew**
  - **tags:** [sys], [distributed systems], [gradient clock synchronization, local skew, offset estimation, frequency deviation, self-stabilization, external synchronization]
  - **authors:** Christoph Lenzen
  - **institution:** CISPA Helmholtz Center for Information Security
  - **link:** https://arxiv.org/pdf/2511.01420
  - **Simple LLM Summary:** This paper presents a refined model for gradient clock synchronization that leverages stability of measurement and frequency errors rather than worst-case bounds. The approach achieves local skew bounds of O(Δ+δ log D) by adapting to actual link performance and frequency changes, effectively breaking previous lower bounds. The method also ensures self-stabilization and extends to external synchronization scenarios.

- **[arXiv251104] TINC: Trusted Intelligent NetChain**
  - **tags:** [sys], [blockchain sharding], [multi-plane sharding, adaptive node assignment, dynamic workload balancing, control-data plane decoupling, Dynamic Decentralized Identifiers (DDIDs)]
  - **authors:** Qi Xia, Hu Xia, Isaac Amankona Obiri, Adjei-Arthur Bonsu, Grace Mupoyi Ntuala, Ansu Badjie, Tienin Bole Wilfried, Jiaqin Liu, Lan Ma, Jianbin Gao, Feng Yao
  - **institution:** University of Electronic Science and Technology of China, National University of Defense Technology
  - **link:** https://arxiv.org/pdf/2511.00823
  - **Simple LLM Summary:** The paper proposes TINC, a multi-plane sharding architecture for consortium blockchains that uses intelligent mechanisms for adaptive node assignment and workload balancing. By decoupling control and data planes, TINC improves scalability while maintaining security guarantees. Experimental results show it achieves higher throughput, lower latency, and better load balancing compared to existing sharding frameworks.

- **[arXiv251104] Towards Portability at Scale: A Cross-Architecture Performance Evaluation of a GPU-enabled Shallow Water Solver**
  - **tags:** [sys], [HPC Performance Evaluation], [Kokkos, GPU acceleration, roofline analysis, strong scaling, weak scaling, performance portability]
  - **authors:** Johansell Villalobos, Daniel Caviedes-Voullième, Silvio Rizzi, Esteban Meneses
  - **institution:** National High Technology Center Costa Rica, Jülich Supercomputing Center, Argonne National Laboratory, Costa Rica Technological Institute
  - **link:** https://arxiv.org/pdf/2511.01001
  - **Simple LLM Summary:** This paper evaluates the SERGHEI-SWE shallow water solver using Kokkos for performance portability across four HPC systems with different GPU architectures. The study demonstrates strong scalability up to 1024 GPUs and identifies memory bandwidth as the primary performance bottleneck through roofline analysis. Results show the solver achieves good performance portability but requires further kernel optimization for improved efficiency across architectures.

- **[arXiv251104] Neuro-Inspired Task Offloading in Edge-IoT Networks Using Spiking Neural Networks**
  - **tags:** [mlsys], [others], [Spiking Neural Networks, task offloading, edge computing, IoT networks, Brian2 simulator, YAFS]
  - **authors:** Fabio Diniz Rossi
  - **institution:** Federal Institute Farroupilha
  - **link:** https://arxiv.org/pdf/2511.01127
  - **Simple LLM Summary:** This paper proposes a neuro-inspired task offloading framework using Spiking Neural Networks for edge-IoT networks. The SNN-based approach enables real-time, energy-efficient task orchestration by leveraging event-driven computation and temporal pattern processing. Experimental results show the framework achieves significant improvements with up to 26% lower latency, 32% reduced energy consumption, and 25% higher success rate compared to traditional methods.

- **[arXiv251104] Real-time Continual Learning on Intel Loihi 2**
  - **tags:** [mlsys], [others], [spiking neural networks, neuromorphic computing, continual learning, online learning, catastrophic forgetting, neurogenesis, metaplasticity]
  - **authors:** Elvin Hajizada, Danielle Rager, Timothy Shea, Leobardo Campos-Macias, Andreas Wild, Eyke Hüllermeier, Yulia Sandamirskaya, Mike Davies
  - **institution:** Intel Labs, University of Munich (LMU), Zurich University of Applied Sciences (ZHAW)
  - **link:** https://arxiv.org/pdf/2511.01553
  - **Simple LLM Summary:** This paper presents CLP-SNN, a spiking neural network architecture implemented on Intel's Loihi 2 neuromorphic chip for online continual learning. The method uses event-driven sparse learning, self-normalizing learning rules, and integrated neurogenesis to achieve competitive accuracy without rehearsal. The results show dramatic efficiency improvements with 70× faster inference and 5,600× better energy efficiency compared to edge GPU implementations.

- **[arXiv251104] Transformer-Based Sparse CSI Estimation for Non-Stationary Channels**
  - **tags:** [mlsys], [others], [Flash-Attention Transformer, patch-wise self-attention, composite loss function, pilot-aided estimation]
  - **authors:** Muhammad Ahmed Mohsin, Muhammad Umer, Ahsan Bilal, Hassan Rizwan, Sagnik Bhattacharya, Muhammad Ali Jamshed, John M. Cioffi
  - **institution:** Stanford University, University of Oklahoma, University of California Riverside, University of Glasgow
  - **link:** https://arxiv.org/pdf/2511.01333
  - **Simple LLM Summary:** This paper proposes a Flash-Attention Transformer framework that combines model-driven pilot acquisition with data-driven CSI reconstruction for non-stationary wireless channels. The method uses patch-wise self-attention and a physics-aware composite loss function to achieve accurate channel estimation. Results show it outperforms traditional methods by 13 dB NMSE while reducing pilot overhead by 16 times, demonstrating reliable CSI recovery for 5G and beyond-5G networks.

- **[arXiv251104] FREESH: Fair, Resource- and Energy-Efficient Scheduling for LLM Serving on Heterogeneous GPUs**
  - **tags:** [mlsys], [llm inference], [joint routing and scheduling, dynamic GPU frequency scaling, Least-Laxity-First (LLF), spatiotemporal computation optimization, heterogeneous GPU clusters]
  - **authors:** Xuan He, Zequan Fang, Jinzhao Lian, Danny H.K. Tsang, Baosen Zhang, Yize Chen
  - **institution:** Hong Kong University of Science and Technology (Guangzhou), Huazhong University of Science and Technology, Renmin University of China, University of Washington, University of Alberta
  - **link:** https://arxiv.org/pdf/2511.00807
  - **Simple LLM Summary:** FREESH proposes a joint routing and scheduling system that optimizes LLM serving across heterogeneous GPU clusters by leveraging spatiotemporal computation flexibility and dynamic GPU frequency scaling. The system matches GPU power-throughput characteristics with query workloads while ensuring latency and fairness through LLF scheduling. Experimental results show FREESH reduces energy consumption by 28.6% and carbon emissions by 45.45% while improving SLO attainment and fairness.

- **[arXiv251104] Federated Cyber Defense: Privacy-Preserving Ransomware Detection Across Distributed Systems**
  - **tags:** [mlsys], [others], [federated learning, ransomware detection, privacy-preserving AI, distributed systems]
  - **authors:** Daniel M. Jimenez-Gutierrez, Enrique Zuazua, Joaquin Del Rio, Oleksii Sliusarenko, Xabi Uribe-Etxebarria
  - **institution:** Sherpa.ai
  - **link:** https://arxiv.org/pdf/2511.01583
  - **Simple LLM Summary:** This paper proposes using Federated Learning with the Sherpa.ai platform to train ransomware detection models across distributed systems while keeping data local. The approach improves detection accuracy by 9% compared to server-local models and achieves performance comparable to centralized training. This demonstrates FL provides a scalable, privacy-preserving framework for cybersecurity across organizational boundaries.

- **[arXiv251104] LARK - Linearizability Algorithms for Replicated Keys in Aerospike**
  - **tags:** [sys], [distributed databases], [linearizability, synchronous replication, partition availability conditions, log-free replication, TLA+ specification]
  - **authors:** Andrew Goodng, Kevin Porter, Thomas Lopatic, Ashish Shinde, Sunil Sayyaparaju, Srinivasan Seshadri, V. Srinivasan
  - **institution:** Aerospike
  - **link:** https://arxiv.org/pdf/2511.01843
  - **Simple LLM Summary:** LARK introduces a log-free synchronous replication protocol using Partition Availability Conditions that reason across the entire database cluster rather than fixed replica sets. This approach achieves linearizability while providing significantly higher availability than traditional quorum-log consensus protocols like Raft and Paxos, enabling continued commits during node failures and zero-downtime rolling restarts with minimal replication factors.

- **[arXiv251104] Edge AI in Highly Volatile Environments: Is Fairness Worth the Accuracy Trade-off?**
  - **tags:** [mlsys], [others], [federated learning, client selection, fairness algorithms, RBFF, RBCSF, edge computing]
  - **authors:** Obaidullah Zaland, Feras M. Awaysheh, Sawsan Al Zubi, Abdul Rahman Safi, Monowar Bhuyan
  - **institution:** Umeå University, University of Santiago de Compostela, Kabul University
  - **link:** https://arxiv.org/pdf/2511.01737
  - **Simple LLM Summary:** This paper evaluates fairness-based client selection algorithms (RBFF and RBCSF) in federated learning for volatile edge environments. The study finds that while equitable client selection provides better participation opportunities, it results in slower global training convergence. The research highlights the fundamental trade-off between fairness and performance in edge AI systems.

- **[arXiv251104] Adaptive Multidimensional Quadrature on Multi-GPU Systems**
  - **tags:** [sys], [high-performance computing], [adaptive quadrature, domain decomposition, load balancing, CUDA-aware MPI, multi-GPU systems]
  - **authors:** Melanie Tonarelli, Simone Riva, Pietro Benedusi, Fabrizio Ferrandi, Rolf Krause
  - **institution:** Università della Svizzera Italiana, Politecnico di Milano, King Abdullah University of Science and Technology
  - **link:** https://arxiv.org/pdf/2511.01573
  - **Simple LLM Summary:** This paper presents a distributed adaptive quadrature method that performs multidimensional integration through hierarchical domain decomposition on multi-GPU systems. The method uses decentralized load redistribution with cyclic round-robin policy and non-blocking MPI communication to handle load imbalance. Compared to state-of-the-art GPU packages, it achieves higher efficiency in high dimensions and improved robustness regarding integrand regularity and target accuracy.

- **[arXiv251104] A Distributed Plug-and-Play MCMC Algorithm for High-Dimensional Inverse Problems**
  - **tags:** [mlsys], [cluster infrastructure], [MCMC, Plug-and-Play ULA, distributed computing, denoising neural network, Single Program Multiple Data]
  - **authors:** Maxime Bouton, Pierre-Antoine Thouvenin, Audrey Repetti, Pierre Chainais
  - **institution:** University of Lille, Heriot-Watt University
  - **link:** https://arxiv.org/pdf/2511.00870
  - **Simple LLM Summary:** This paper proposes a distributed Plug-and-Play Markov Chain Monte Carlo algorithm that uses lightweight denoising neural networks and approximate data augmentation to solve high-dimensional imaging inverse problems. The method efficiently leverages multiple GPUs through a Single Program Multiple Data architecture to address scalability challenges. The approach achieves comparable reconstruction performance to other PnP methods while being scalable and enabling uncertainty quantification for large-scale imaging problems.


**cs.AI/cs.LG contains "reinforcement learning" total: 46**
- [arXiv251104] Robust Single-Agent Reinforcement Learning for Regional Traffic Signal Control Under Demand Fluctuations [link](https://arxiv.org/pdf/2511.00549)
- [arXiv251104] Study on Supply Chain Finance Decision-Making Model and Enterprise Economic Performance Prediction Based on Deep Reinforcement Learning [link](https://arxiv.org/pdf/2511.00166)
- [arXiv251104] Who Can We Trust? Scope-Aware Video Moment Retrieval with Multi-Agent Conflict [link](https://arxiv.org/pdf/2511.00370)
- [arXiv251104] Single-agent Reinforcement Learning Model for Regional Adaptive Traffic Signal Control [link](https://arxiv.org/pdf/2511.00551)
- [arXiv251104] GraphChain: Large Language Models for Large-scale Graph Analysis via Tool Chaining [link](https://arxiv.org/pdf/2511.00457)
- [arXiv251104] UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings [link](https://arxiv.org/pdf/2511.00405)
- [arXiv251104] Bootstrap Off-policy with World Model [link](https://arxiv.org/pdf/2511.00423)
- [arXiv251104] DCcluster-Opt: Benchmarking Dynamic Multi-Objective Optimization for Geo-Distributed Data Center Workloads [link](https://arxiv.org/pdf/2511.00117)
- [arXiv251104] Real-DRL: Teach and Learn in Reality [link](https://arxiv.org/pdf/2511.00112)
- [arXiv251104] PreferThinker: Reasoning-based Personalized Image Preference Assessment [link](https://arxiv.org/pdf/2511.00609)
- [arXiv251104] Efficient Reinforcement Learning for Large Language Models with Intrinsic Exploration [link](https://arxiv.org/pdf/2511.00794)
- [arXiv251104] Iterative Foundation Model Fine-Tuning on Multiple Rewards [link](https://arxiv.org/pdf/2511.00220)
- [arXiv251104] Consistently Simulating Human Personas with Multi-Turn Reinforcement Learning [link](https://arxiv.org/pdf/2511.00222)
- [arXiv251104] End-to-End Framework Integrating Generative AI and Deep Reinforcement Learning for Autonomous Ultrasound Scanning [link](https://arxiv.org/pdf/2511.00114)
- [arXiv251104] World Simulation with Video Foundation Models for Physical AI [link](https://arxiv.org/pdf/2511.00062)
- [arXiv251104] LC-Opt: Benchmarking Reinforcement Learning and Agentic AI for End-to-End Liquid Cooling Optimization in Data Centers [link](https://arxiv.org/pdf/2511.00116)
- [arXiv251104] Token-Regulated Group Relative Policy Optimization for Stable Reinforcement Learning in Large Language Models [link](https://arxiv.org/pdf/2511.00066)
- [arXiv251104] On the Fundamental Limitations of Decentralized Learnable Reward Shaping in Cooperative Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2511.00034)
- [arXiv251104] Improving the Robustness of Control of Chaotic Convective Flows with Domain-Informed Reinforcement Learning [link](https://arxiv.org/pdf/2511.00272)
- [arXiv251104] Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries [link](https://arxiv.org/pdf/2511.00710)
- [arXiv251104] Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail [link](https://arxiv.org/pdf/2511.00088)
- [arXiv251104] SpatialTraceGen: High-Fidelity Traces for Efficient VLM Spatial Reasoning Distillation [link](https://arxiv.org/pdf/2511.00054)
- [arXiv251104] A Dual Large Language Models Architecture with Herald Guided Prompts for Parallel Fine Grained Traffic Signal Control [link](https://arxiv.org/pdf/2511.00136)
- [arXiv251104] Graph-Attentive MAPPO for Dynamic Retail Pricing [link](https://arxiv.org/pdf/2511.00039)
- [arXiv251104] GrowthHacker: Automated Off-Policy Evaluation Optimization Using Code-Modifying LLM Agents [link](https://arxiv.org/pdf/2511.00802)
- [arXiv251104] Logic-informed reinforcement learning for cross-domain optimization of large-scale cyber-physical systems [link](https://arxiv.org/pdf/2511.00806)
- [arXiv251104] Do Math Reasoning LLMs Help Predict the Impact of Public Transit Events? [link](https://arxiv.org/pdf/2511.00808)
- [arXiv251104] Equilibrium Policy Generalization: A Reinforcement Learning Framework for Cross-Graph Zero-Shot Generalization in Pursuit-Evasion Games [link](https://arxiv.org/pdf/2511.00811)
- [arXiv251104] KFCPO: Kronecker-Factored Approximated Constrained Policy Optimization [link](https://arxiv.org/pdf/2511.00880)
- [arXiv251104] SLAP: Shortcut Learning for Abstract Planning [link](https://arxiv.org/pdf/2511.01107)
- [arXiv251104] DART: Difficulty-Adaptive Reasoning Truncation for Efficient Large Language Models [link](https://arxiv.org/pdf/2511.01170)
- [arXiv251104] Self-Harmony: Learning to Harmonize Self-Supervision and Self-Play in Test-Time Reinforcement Learning [link](https://arxiv.org/pdf/2511.01191)
- [arXiv251104] Thought-For-Food: Reasoning Chain Induced Food Visual Question Answering [link](https://arxiv.org/pdf/2511.01213)
- [arXiv251104] Optimizing Electric Vehicle Charging Station Placement Using Reinforcement Learning and Agent-Based Simulations [link](https://arxiv.org/pdf/2511.01218)
- [arXiv251104] RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models [link](https://arxiv.org/pdf/2511.01331)
- [arXiv251104] Diffusion-Based Solver for CNF Placement on the Cloud-Continuum [link](https://arxiv.org/pdf/2511.01343)
- [arXiv251104] Thinking with DistilQwen: A Tale of Four Distilled Reasoning and Reward Model Series [link](https://arxiv.org/pdf/2511.01354)
- [arXiv251104] Learning Intractable Multimodal Policies with Reparameterization and Diversity Regularization [link](https://arxiv.org/pdf/2511.01374)
- [arXiv251104] Modulation of temporal decision-making in a deep reinforcement learning agent under the dual-task paradigm [link](https://arxiv.org/pdf/2511.01415)
- [arXiv251104] Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis [link](https://arxiv.org/pdf/2511.01425)
- [arXiv251104] TPS-Bench: Evaluating AI Agents' Tool Planning \& Scheduling Abilities in Compounding Tasks [link](https://arxiv.org/pdf/2511.01527)
- [arXiv251104] Learning what to say and how precisely: Efficient Communication via Differentiable Discrete Communication Learning [link](https://arxiv.org/pdf/2511.01554)
- [arXiv251104] L2T-Tune:LLM-Guided Hybrid Database Tuning with LHS and TD3 [link](https://arxiv.org/pdf/2511.01602)
- [arXiv251104] Collaborative Large Language Model Inference via Resource-Aware Parallel Speculative Decoding [link](https://arxiv.org/pdf/2511.01695)
- [arXiv251104] RLAC: Reinforcement Learning with Adversarial Critic for Free-Form Generation Tasks [link](https://arxiv.org/pdf/2511.01758)
- [arXiv251104] GenDexHand: Generative Simulation for Dexterous Hands [link](https://arxiv.org/pdf/2511.01791)

**cs.AI/cs.LG contains "accelerate" total: 25**
- [arXiv251104] LeMiCa: Lexicographic Minimax Path Caching for Efficient Diffusion-Based Video Generation [link](https://arxiv.org/pdf/2511.00090)
- [arXiv251104] QuantumBench: A Benchmark for Quantum Problem Solving [link](https://arxiv.org/pdf/2511.00092)
- [arXiv251104] Structure-Preserving Physics-Informed Neural Network for the Korteweg--de Vries (KdV) Equation [link](https://arxiv.org/pdf/2511.00418)
- [arXiv251104] Efficient Generation of Binary Magic Squares [link](https://arxiv.org/pdf/2511.00547)
- [arXiv251104] DCcluster-Opt: Benchmarking Dynamic Multi-Objective Optimization for Geo-Distributed Data Center Workloads [link](https://arxiv.org/pdf/2511.00117)
- [arXiv251104] World Simulation with Video Foundation Models for Physical AI [link](https://arxiv.org/pdf/2511.00062)
- [arXiv251104] Chain of Time: In-Context Physical Simulation with Image Generation Models [link](https://arxiv.org/pdf/2511.00110)
- [arXiv251104] Reliable Curation of EHR Dataset via Large Language Models under Environmental Constraints [link](https://arxiv.org/pdf/2511.00772)
- [arXiv251104] Advancing AI Challenges for the United States Department of the Air Force [link](https://arxiv.org/pdf/2511.00267)
- [arXiv251104] FeNN-DMA: A RISC-V SoC for SNN acceleration [link](https://arxiv.org/pdf/2511.00732)
- [arXiv251104] Position Paper: If Innovation in AI Systematically Violates Fundamental Rights, Is It Innovation at All? [link](https://arxiv.org/pdf/2511.00027)
- [arXiv251104] Cross-fluctuation phase transitions reveal sampling dynamics in diffusion models [link](https://arxiv.org/pdf/2511.00124)
- [arXiv251104] Scalable Processing-Near-Memory for 1M-Token LLM Inference: CXL-Enabled KV-Cache Management Beyond GPU Limits [link](https://arxiv.org/pdf/2511.00321)
- [arXiv251104] Leveraging Multi-Agent System (MAS) and Fine-Tuned Small Language Models (SLMs) for Automated Telecom Network Troubleshooting [link](https://arxiv.org/pdf/2511.00651)
- [arXiv251104] Diffusion Models at the Drug Discovery Frontier: A Review on Generating Small Molecules versus Therapeutic Peptides [link](https://arxiv.org/pdf/2511.00209)
- [arXiv251104] LL-ViT: Edge Deployable Vision Transformers with Look Up Table Neurons [link](https://arxiv.org/pdf/2511.00812)
- [arXiv251104] Transformers as Intrinsic Optimizers: Forward Inference through the Energy Principle [link](https://arxiv.org/pdf/2511.00907)
- [arXiv251104] Keys in the Weights: Transformer Authentication Using Model-Bound Latent Representations [link](https://arxiv.org/pdf/2511.00973)
- [arXiv251104] DART: Difficulty-Adaptive Reasoning Truncation for Efficient Large Language Models [link](https://arxiv.org/pdf/2511.01170)
- [arXiv251104] When, What, and How: Rethinking Retrieval-Enhanced Speculative Decoding [link](https://arxiv.org/pdf/2511.01282)
- [arXiv251104] Estimation of Toeplitz Covariance Matrices using Overparameterized Gradient Descent [link](https://arxiv.org/pdf/2511.01605)
- [arXiv251104] Bridging Lifelong and Multi-Task Representation Learning via Algorithm and Complexity Measure [link](https://arxiv.org/pdf/2511.01847)
- [arXiv251104] Transfer learning discovery of molecular modulators for perovskite solar cells [link](https://arxiv.org/pdf/2511.00204)
- [arXiv251104] Quantum Deep Learning Still Needs a Quantum Leap [link](https://arxiv.org/pdf/2511.01253)
- [arXiv251104] Split-Flows: Measure Transport and Information Loss Across Molecular Resolutions [link](https://arxiv.org/pdf/2511.01464)
