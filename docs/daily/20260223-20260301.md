# 20260223-20260301

## 2026-02-23

**cs.DC total: 13**

- **[arXiv260223] Message-Oriented Middleware Systems: Technology Overview**
  - **tags:** [sys], [distributed systems], [message-oriented middleware, publish/subscribe, brokers, multi-tenancy, flow control]
  - **authors:** Wael Al-Manasrah, Zuhair AlSader, Tim Brecht, Ahmed Alquraan, Samer Al-Kiswany
  - **institution:** University of Waterloo
  - **link:** https://arxiv.org/pdf/2602.17774
  - **Simple LLM Summary:** This paper presents a comprehensive characterization study of ten open-source message-oriented middleware (MOM) systems, analyzing 42 features across them. The main conclusion is that MOM systems have evolved into flexible frameworks for cloud applications, and the authors identify an opportunity for the community to consolidate efforts on fewer open-source projects.

- **[arXiv260223] Distributed Triangle Enumeration in Hypergraphs**
  - **tags:** [sys], [distributed algorithms], [CONGEST model, hypergraph, triangle enumeration, computational models, sparse hypergraphs]
  - **authors:** Duncan Adamson, Will Rosenbaum, Paul G. Spirakis
  - **institution:** University of St Andrews, University of Liverpool
  - **link:** https://arxiv.org/pdf/2602.17834
  - **Simple LLM Summary:** This paper introduces new computational models for distributed algorithms on hypergraphs, generalizing the CONGEST model. It presents algorithms for distributed triangle enumeration in these models, proves their optimality in some cases, and develops efficient methods for sparse hypergraph classes. The work establishes a foundational framework for distributed sub-hypergraph enumeration.

- **[arXiv260223] Collaborative Processing for Multi-Tenant Inference on Memory-Constrained Edge TPUs**
  - **tags:** [mlsys], [llm inference], [collaborative processing, model partitioning, queueing model, memory swapping, adaptive scheduling, Edge TPU]
  - **authors:** Nathan Ng, Walid A. Hanafy, Prashanthi Kadambi, Balachandra Sunil, Ayush Gupta, David Irwin, Yogesh Simmhan, Prashant Shenoy
  - **institution:** University of Massachusetts Amherst, Indian Institute of Science
  - **link:** https://arxiv.org/pdf/2602.17808
  - **Simple LLM Summary:** The paper presents SwapLess, a system that uses an analytic queueing model to adaptively partition AI model inference between CPU and Edge TPU resources and allocate CPU cores online, minimizing end-to-end latency. It demonstrates that this approach significantly reduces mean latency for both single-tenant and multi-tenant workloads compared to default compiler strategies.

- **[arXiv260223] It's Not Just Timestamps: A Study on Docker Reproducibility**
  - **tags:** [sys], [container security], [Docker, reproducible builds, software supply chain, Dockerfile, OCI images, bitwise reproducibility, timestamps, metadata, caching]
  - **authors:** Oreofe Solarin
  - **institution:** Case Western Reserve University
  - **link:** https://arxiv.org/pdf/2602.17678
  - **Simple LLM Summary:** The paper builds a measurement pipeline to analyze the bitwise reproducibility of Docker container images built from Dockerfiles in a sample of 2,000 GitHub repositories. It concludes that very few Docker builds are reproducible, and the primary causes are developer-controlled factors like uncleaned caches and floating software versions, not just timestamps.

- **[arXiv260223] Distributed Security: From Isolated Properties to Synergistic Trust**
  - **tags:** [sys], [distributed systems security], [Byzantine fault tolerance, consensus protocols, secure multi-party computation, cryptographic primitives, agreement, consistency, privacy, verifiability, accountability]
  - **authors:** Minghui Xu
  - **institution:** Shandong University, Quan Cheng Laboratory
  - **link:** https://arxiv.org/pdf/2602.18063
  - **Simple LLM Summary:** This vision paper argues for a paradigm shift in distributed security research, moving from the isolated study of foundational properties like agreement and privacy to understanding their synergistic combinations. The core method involves analyzing the convergence of these properties to create a unified fabric of trust. The main conclusion is that the future of the field lies in harnessing these synergies rather than optimizing individual properties in isolation.

- **[arXiv260223] Faster Parallel Batch-Dynamic Algorithms for Low Out-Degree Orientation**
  - **tags:** [sys], [graph algorithms], [parallel batch-dynamic algorithms, low out-degree orientation, arboricity, polylogarithmic span]
  - **authors:** Guy Blelloch, Andrew Brady, Laxman Dhulipala, Jeremy Fineman, Kishen Gowda, Chase Hutton
  - **institution:** Carnegie Mellon University, University of Maryland, Georgetown University
  - **link:** https://arxiv.org/pdf/2602.17811
  - **Simple LLM Summary:** This paper presents new parallel batch-dynamic algorithms for maintaining a low out-degree orientation of an undirected graph. The algorithms achieve polylogarithmic span and improve upon prior work by reducing the work per edge update, offering results with asymptotically optimal expected work, expected worst-case work of O(√log n), and O(log² n) expected worst-case work for different orientation bounds.

- **[arXiv260223] Joint Training on AMD and NVIDIA GPUs**
  - **tags:** [mlsys], [llm training], [heterogeneous training, CPU-Forwarding Communication, Device-Direct Communication, GPUDirect RDMA, CPU-offloading P2P, multi-NIC parallel data transfer]
  - **authors:** Jon Hu, Thomas Jia, Jing Zhu, Zhendong Yu
  - **institution:** Zettabyte AI, Inc.
  - **link:** https://arxiv.org/pdf/2602.18007
  - **Simple LLM Summary:** This paper proposes two methods for joint training of large language models on heterogeneous clusters containing both AMD and NVIDIA GPUs. The core contribution is a high-performance Device-Direct Communication approach that enables direct data transfer between different vendor GPUs, eliminating host-memory staging. Experiments show this method achieves up to 98% of the throughput of a homogeneous NVIDIA system while maintaining training stability.

- **[arXiv260223] GPU Memory and Utilization Estimation for Training-Aware Resource Management: Opportunities and Limitations**
  - **tags:** [mlsys], [cluster infrastructure], [memory estimation, utilization estimation, analytical models, ML-based estimators, PyTorch FakeTensor, Horus, interference-aware scheduling]
  - **authors:** Ehsan Yousefzadeh-Asl-Miandoab, Reza Karimzadeh, Danyal Yorulmaz, Bulat Ibragimov, Pınar Tözün
  - **institution:** IT University of Copenhagen, University of Copenhagen
  - **link:** https://arxiv.org/pdf/2602.17817
  - **Simple LLM Summary:** This paper systematically analyzes three paradigms for estimating GPU memory and utilization—analytical models, CPU-side libraries, and ML-based estimators—to improve resource management for collocated deep learning training. The evaluation reveals key trade-offs: analytical models are hardware-dependent, libraries impose integration costs, and ML estimators struggle with generalization. The authors release datasets and tools to support further research in this area.

- **[arXiv260223] Closing Africa's Early Warning Gap: AI Weather Forecasting for Disaster Prevention**
  - **tags:** [mlsys], [cluster infrastructure], [NVIDIA Earth-2, PostgreSQL, ProcessPoolExecutor, aiobotocore, async Python, database-backed serving, coordinate management, WhatsApp distribution]
  - **authors:** Qness Ndlovu
  - **institution:** Dimension Research Lab
  - **link:** https://arxiv.org/pdf/2602.17726
  - **Simple LLM Summary:** This paper presents a low-cost, production-grade architecture using NVIDIA Earth-2 AI weather models and PostgreSQL caching to deliver national-scale weather forecasts in Africa. The system reduces deployment costs by over 2,000x compared to traditional radar, enabling effective early warning systems via widely accessible channels like WhatsApp. The main conclusion is that this AI-driven approach makes continent-scale disaster prevention economically viable, potentially reducing disaster death rates significantly.

- **[arXiv260223] Mind the Boundary: Stabilizing Gemini Enterprise A2A via a Cloud Run Hub Across Projects and Accounts**
  - **tags:** [mlsys], [llm inference], [agent-to-agent (A2A) protocol, JSON-RPC, Cloud Run, retrieval-augmented generation (RAG), Vertex AI, Google Cloud Storage, IAM authentication]
  - **authors:** Takao Morita
  - **institution:** Independent Researcher
  - **link:** https://arxiv.org/pdf/2602.17675
  - **Simple LLM Summary:** This paper implements an A2A Hub orchestrator on Cloud Run to route queries from the Gemini Enterprise UI to various backend agents and tools across different Google Cloud projects and accounts. It identifies and addresses a key interoperability gap where the UI's text-only input constraints cause errors with structured JSON-RPC responses, solved by enforcing a text-only compatibility mode. The main conclusion is that practical, stable multi-agent orchestration requires managing not just protocol compliance but also UI constraints and cross-boundary authentication.

- **[arXiv260223] A reliability- and latency-driven task allocation framework for workflow applications in the edge-hub-cloud continuum**
  - **tags:** [sys], [edge computing], [binary integer linear programming, multi-objective optimization, task allocation, time redundancy]
  - **authors:** Andreas Kouloumpris, Georgios L. Stavrinides, Maria K. Michael, Theocharis Theocharides
  - **institution:** University of Cyprus, KIOS Research and Innovation Center of Excellence
  - **link:** https://arxiv.org/pdf/2602.18158
  - **Simple LLM Summary:** The paper proposes an exact multi-objective task allocation framework using binary integer linear programming to jointly optimize reliability and latency for workflow applications in an edge-hub-cloud architecture. The method incorporates time redundancy and key constraints, demonstrating significant improvements in reliability and latency over baselines in experiments with real-world and synthetic workflows.

- **[arXiv260223] It does not matter how you define locally checkable labelings**
  - **tags:** [sys], [distributed graph algorithms], [locally checkable labeling, LOCAL model, round elimination, symmetry-breaking oracle, node-edge checkable]
  - **authors:** Antonio Cruciani, Avinandan Das, Alesya Raevskaya, Jukka Suomela
  - **institution:** Aalto University
  - **link:** https://arxiv.org/pdf/2602.18188
  - **Simple LLM Summary:** The paper shows that the family of Locally Checkable Labeling (LCL) problems is robust to definitional variations by proving local reductions between a standard LCL formalism and a more restricted "node-edge checkable" formalism. The main conclusion is that even with a stricter definition, LCL problems retain counterintuitive properties, indicating these properties are inherent to the problem family and not artifacts of the original definition.

- **[arXiv260223] Green by Design: Constraint-Based Adaptive Deployment in the Cloud Continuum**
  - **tags:** [sys], [cloud-edge deployment], [green constraints, adaptive orchestration, energy-aware scheduling, cloud continuum, deployment plans]
  - **authors:** Andrea D'Iapico, Monica Vitali
  - **institution:** Politecnico di Milano
  - **link:** https://arxiv.org/pdf/2602.18287
  - **Simple LLM Summary:** This paper proposes a methodology for generating environmentally sustainable deployment plans for cloud-native applications across the cloud-edge continuum. The core method involves automatically learning and updating "green constraints" from monitoring data on energy consumption and infrastructure carbon intensity to guide an adaptive scheduler. The approach is validated to effectively reduce energy usage and associated emissions in realistic deployment scenarios.


**cs.AI/cs.LG contains "reinforcement learning" total: 17**
- [arXiv260223] Whole-Brain Connectomic Graph Model Enables Whole-Body Locomotion Control in Fruit Fly [link](https://arxiv.org/pdf/2602.17997)
- [arXiv260223] Gradient Regularization Prevents Reward Hacking in Reinforcement Learning from Human Feedback and Verifiable Rewards [link](https://arxiv.org/pdf/2602.18037)
- [arXiv260223] MePoly: Max Entropy Polynomial Policy Optimization [link](https://arxiv.org/pdf/2602.17832)
- [arXiv260223] Epistemic Traps: Rational Misalignment Driven by Model Misspecification [link](https://arxiv.org/pdf/2602.17676)
- [arXiv260223] Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets [link](https://arxiv.org/pdf/2602.18025)
- [arXiv260223] Optimal Multi-Debris Mission Planning in LEO: A Deep Reinforcement Learning Approach with Co-Elliptic Transfers and Refueling [link](https://arxiv.org/pdf/2602.17685)
- [arXiv260223] CodeScaler: Scaling Code LLM Training and Test-Time Inference via Execution-Free Reward Models [link](https://arxiv.org/pdf/2602.17684)
- [arXiv260223] Flow Actor-Critic for Offline Reinforcement Learning [link](https://arxiv.org/pdf/2602.18015)
- [arXiv260223] Mean-Field Reinforcement Learning without Synchrony [link](https://arxiv.org/pdf/2602.18026)
- [arXiv260223] MIRA: Memory-Integrated Reinforcement Learning Agent with Limited LLM Guidance [link](https://arxiv.org/pdf/2602.17930)
- [arXiv260223] Learning Optimal and Sample-Efficient Decision Policies with Guarantees [link](https://arxiv.org/pdf/2602.17978)
- [arXiv260223] Memory-Based Advantage Shaping for LLM-Guided Reinforcement Learning [link](https://arxiv.org/pdf/2602.17931)
- [arXiv260223] Interacting safely with cyclists using Hamilton-Jacobi reachability and reinforcement learning [link](https://arxiv.org/pdf/2602.18097)
- [arXiv260223] TempoNet: Slack-Quantized Transformer-Guided Reinforcement Scheduler for Adaptive Deadline-Centric Real-Time Dispatchs [link](https://arxiv.org/pdf/2602.18109)
- [arXiv260223] Flow Matching with Injected Noise for Offline-to-Online Reinforcement Learning [link](https://arxiv.org/pdf/2602.18117)
- [arXiv260223] PRISM: Parallel Reward Integration with Symmetry for MORL [link](https://arxiv.org/pdf/2602.18277)
- [arXiv260223] Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies [link](https://arxiv.org/pdf/2602.18291)

**cs.AI/cs.LG contains "accelerate" total: 9**
- [arXiv260223] Solving and learning advective multiscale Darcian dynamics with the Neural Basis Method [link](https://arxiv.org/pdf/2602.17776)
- [arXiv260223] Hardware-Friendly Input Expansion for Accelerating Function Approximation [link](https://arxiv.org/pdf/2602.17952)
- [arXiv260223] Multi-material Multi-physics Topology Optimization with Physics-informed Gaussian Process Priors [link](https://arxiv.org/pdf/2602.17783)
- [arXiv260223] A Case Study of Selected PTQ Baselines for Reasoning LLMs on Ascend NPU [link](https://arxiv.org/pdf/2602.17693)
- [arXiv260223] Balancing Symmetry and Efficiency in Graph Flow Matching [link](https://arxiv.org/pdf/2602.18084)
- [arXiv260223] A Probabilistic Framework for LLM-Based Model Discovery [link](https://arxiv.org/pdf/2602.18266)
- [arXiv260223] PRISM: Parallel Reward Integration with Symmetry for MORL [link](https://arxiv.org/pdf/2602.18277)
- [arXiv260223] Clever Materials: When Models Identify Good Materials for the Wrong Reasons [link](https://arxiv.org/pdf/2602.17730)
- [arXiv260223] AgriVariant: Variant Effect Prediction using DeepChem-Variant for Precision Breeding in Rice [link](https://arxiv.org/pdf/2602.17747)
