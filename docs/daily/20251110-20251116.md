# 20251110-20251116

## 2025-11-10

**cs.DC total: 5**

- **[arXiv251110] GPU Under Pressure: Estimating Application's Stress via Telemetry and Performance Counters**
  - **tags:** [mlsys], [fault-tolerance], [telemetry parameters, hardware performance counters, throughput measurement, instruction count, stall events]
  - **authors:** Giuseppe Esposito, Juan-David Guerrero-Balaguera, Josie Esteban Rodriguez Condia, Matteo Sonza Reorda, Marco Barbiero, Rossella Fortuna
  - **institution:** Politecnico di Torino, Intesa Sanpaolo S.p.A.
  - **link:** https://arxiv.org/pdf/2511.05067
  - **Simple LLM Summary:** This paper proposes combining online telemetry parameters and hardware performance counters to estimate GPU stress caused by applications. The method focuses on measuring throughput, issued instructions, and stall events to assess workload efficiency. Results show this approach can effectively predict reliability issues and aging effects in GPUs under sustained parallel workloads.

- **[arXiv251110] The Future of Fully Homomorphic Encryption System: from a Storage I/O Perspective**
  - **tags:** [sys], [storage systems], [Fully Homomorphic Encryption, ASIC, GPU, storage I/O, performance analysis]
  - **authors:** Lei Chen, Erci Xu, Yiming Sun, Shengyu Fan, Xianglong Deng, Guiming Shi, Guang Fan, Liang Kong, Yilan Zhu, Shoumeng Yan, Mingzhe Zhang
  - **institution:** Ant Group, Shanghai Jiaotong University, University of Chinese Academy of Sciences, Tsinghua University
  - **link:** https://arxiv.org/pdf/2511.04946
  - **Simple LLM Summary:** This paper analyzes the impact of storage I/O on Fully Homomorphic Encryption (FHE) application performance. The research finds that storage I/O significantly degrades performance, reducing ASIC performance by up to 357× and GPU performance by up to 22×, highlighting a critical bottleneck in FHE deployment.

- **[arXiv251110] Accelerating HDC-CNN Hybrid Models Using Custom Instructions on RISC-V GPUs**
  - **tags:** [mlsys], [GPU kernels], [hyperdimensional computing, custom GPU instructions, RISC-V GPU, HDC-CNN hybrid models, microbenchmark testing]
  - **authors:** Wakuto Matsumi, Riaz-Ul-Haque Mian
  - **institution:** Shimane University
  - **link:** https://arxiv.org/pdf/2511.05053
  - **Simple LLM Summary:** This paper proposes custom GPU instructions for RISC-V GPUs to accelerate hybrid HDC-CNN models. The researchers implemented four specialized instructions optimized for hyperdimensional computing operations, achieving up to 56.2x performance improvement in microbenchmark tests. The work demonstrates RISC-V GPUs' potential for energy-efficient, high-performance computing through domain-specific instruction customization.

- **[arXiv251110] CUNQA: a Distributed Quantum Computing emulator for HPC**
  - **tags:** [sys], [quantum computing simulation], [distributed quantum computing, quantum phase estimation, HPC emulation, quantum processing units]
  - **authors:** Jorge Vázquez-Pérez, Daniel Expósito-Patiño, Marta Losada, Álvaro Carballido, Andrés Gómez, Tomás F. Pena
  - **institution:** Galicia Supercomputing Center (CESGA), Universidad de Santiago de Compostela
  - **link:** https://arxiv.org/pdf/2511.05209
  - **Simple LLM Summary:** The paper presents CUNQA, an open-source distributed quantum computing emulator designed for HPC environments that implements three communication models: no-communication, classical-communication, and quantum-communication. The tool uses the Quantum Phase Estimation algorithm to demonstrate and analyze these distributed quantum computing schemes. CUNQA represents the first emulator capable of modeling all three distributed quantum computing approaches in HPC environments, enabling research and testing before physical quantum hardware becomes available.

- **[arXiv251110] Marionette: Data Structure Description and Management for Heterogeneous Computing**
  - **tags:** [sys], [heterogeneous computing], [C++17 library, data layout abstraction, compile-time abstractions, memory management strategies, CUDA]
  - **authors:** Nuno dos Santos Fernandes, Pedro Tomás, Nuno Roma, Frank Winklmeier, Patricia Conde-Muíño
  - **institution:** Instituto Superior Técnico, INESC-ID, LIP, CERN, University of Oregon
  - **link:** https://arxiv.org/pdf/2511.04853
  - **Simple LLM Summary:** Marionette is a C++17 library that decouples data layout from interface descriptions to enable flexible and portable data structures for heterogeneous computing platforms. It provides efficient data transfers across devices with minimal runtime overhead through compile-time abstractions. The paper demonstrates that Marionette successfully addresses the challenges of adapting object-oriented C++ codebases for hardware acceleration while maintaining compatibility with existing code.


**cs.AI/cs.LG contains "reinforcement learning" total: 14**
- [arXiv251110] QUESTER: Query Specification for Generative Retrieval [link](https://arxiv.org/pdf/2511.05301)
- [arXiv251110] TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning [link](https://arxiv.org/pdf/2511.05489)
- [arXiv251110] DeepEyesV2: Toward Agentic Multimodal Model [link](https://arxiv.org/pdf/2511.05271)
- [arXiv251110] Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction [link](https://arxiv.org/pdf/2511.05396)
- [arXiv251110] Quantum Boltzmann Machines for Sample-Efficient Reinforcement Learning [link](https://arxiv.org/pdf/2511.04856)
- [arXiv251110] You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models [link](https://arxiv.org/pdf/2511.04902)
- [arXiv251110] Self-Interest and Systemic Benefits: Emergence of Collective Rationality in Mixed Autonomy Traffic Through Deep Reinforcement Learning [link](https://arxiv.org/pdf/2511.04883)
- [arXiv251110] FoodRL: A Reinforcement Learning Ensembling Framework For In-Kind Food Donation Forecasting [link](https://arxiv.org/pdf/2511.04865)
- [arXiv251110] Reasoning Up the Instruction Ladder for Controllable Language Models [link](https://arxiv.org/pdf/2511.04694)
- [arXiv251110] TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework [link](https://arxiv.org/pdf/2511.05385)
- [arXiv251110] Multi-agent Coordination via Flow Matching [link](https://arxiv.org/pdf/2511.05005)
- [arXiv251110] DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning [link](https://arxiv.org/pdf/2511.04949)
- [arXiv251110] Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale [link](https://arxiv.org/pdf/2511.04904)
- [arXiv251110] An End-to-End Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drones [link](https://arxiv.org/pdf/2511.05265)

**cs.AI/cs.LG contains "accelerate" total: 11**
- [arXiv251110] When Data Falls Short: Grokking Below the Critical Threshold [link](https://arxiv.org/pdf/2511.04760)
- [arXiv251110] ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling [link](https://arxiv.org/pdf/2511.04758)
- [arXiv251110] Building Specialized Software-Assistant ChatBot with Graph-Based Retrieval-Augmented Generation [link](https://arxiv.org/pdf/2511.05297)
- [arXiv251110] LiveStar: Live Streaming Assistant for Real-World Online Video Understanding [link](https://arxiv.org/pdf/2511.05299)
- [arXiv251110] Efficient Deployment of CNN Models on Multiple In-Memory Computing Units [link](https://arxiv.org/pdf/2511.04682)
- [arXiv251110] APP: Accelerated Path Patching with Task-Specific Pruning [link](https://arxiv.org/pdf/2511.05442)
- [arXiv251110] Diffusion-Based Electromagnetic Inverse Design of Scattering Structured Media [link](https://arxiv.org/pdf/2511.05357)
- [arXiv251110] Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning [link](https://arxiv.org/pdf/2511.04831)
- [arXiv251110] Deep Progressive Training: scaling up depth capacity of zero/one-layer models [link](https://arxiv.org/pdf/2511.04981)
- [arXiv251110] MDM: Manhattan Distance Mapping of DNN Weights for Parasitic-Resistance-Resilient Memristive Crossbars [link](https://arxiv.org/pdf/2511.04798)
- [arXiv251110] A Gate-Based Quantum Genetic Algorithm for Real-Valued Global Optimization [link](https://arxiv.org/pdf/2511.05254)

## 2025-11-11

**cs.DC total: 27**

- **[arXiv251111] MT4G: A Tool for Reliable Auto-Discovery of NVIDIA and AMD GPU Compute and Memory Topologies**
  - **tags:** TBD
  - **authors:** Stepan Vanecek, Manuel Walter Mussbacher, Dominik Groessler, Urvij Saroliya, Martin Schulz
  - **institution:** 
  - **link:** https://arxiv.org/pdf/2511.05958

- **[arXiv251111] DWM-RO: Decentralized World Models with Reasoning Offloading for SWIPT-enabled Satellite-Terrestrial HetNets**
  - **tags:** TBD
  - **authors:** Guangyuan Liu, Yinqiu Liu, Ruichen Zhang, Dusit Niyato, Jiawen Kang, Sumei Sun, Abbas Jamalipour, Ping Zhang
  - **institution:** 
  - **link:** https://arxiv.org/pdf/2511.05972

- **[arXiv251111] Efficient Dynamic MaxFlow Computation on GPUs**
  - **tags:** [sys], [graph algorithms], [Push-Relabel, GPU parallelization, dynamic graphs, batch updates]
  - **authors:** Shruthi Kannappan, Ashwina Kumar, Rupesh Nasre
  - **institution:** Indian Institute of Technology Madras
  - **link:** https://arxiv.org/pdf/2511.05895
  - **Simple LLM Summary:** This paper proposes two Push-Relabel based algorithms for dynamic MaxFlow computation on GPUs that efficiently handle both increments and decrements in edge capacities in batches. The algorithms are designed to process evolving real-world graphs without full recomputation. The results show that for small updates, dynamic recomputation is significantly faster than static GPU-based MaxFlow approaches.

- **[arXiv251111] Kunlun Anomaly Troubleshooter: Enabling Kernel-Level Anomaly Detection and Causal Reasoning for Large Model Distributed Inference**
  - **tags:** [mlsys], [llm inference], [function trace data, kernel-level anomaly detection, domain-adapted LLM, causal reasoning, nanosecond resolution]
  - **authors:** Yuyang Liu, Jingjing Cai, Jiayi Ren, Peng Zhou, Danyang Zhang, Yin Du, Shijian Li
  - **institution:** Zhejiang University, Alibaba Cloud
  - **link:** https://arxiv.org/pdf/2511.05978
  - **Simple LLM Summary:** KAT introduces a framework that uses function trace data to detect kernel-level anomalies at nanosecond resolution and integrates these detections with a domain-adapted LLM for causal reasoning. The system achieved high precision (0.884) and recall (0.936) in production evaluations. This significantly improves troubleshooting efficiency and success rates for large model distributed inference systems.

- **[arXiv251111] LLMs as Packagers of HPC Software**
  - **tags:** [mlsys], [others], [retrieval-augmented generation, iterative refinement, repository analysis, diagnostic feedback]
  - **authors:** Caetano Melone, Daniel Nichols, Konstantinos Parasyris, Todd Gamblin, Harshitha Menon
  - **institution:** Lawrence Livermore National Laboratory
  - **link:** https://arxiv.org/pdf/2511.05626
  - **Simple LLM Summary:** The paper introduces SpackIt, an end-to-end framework that uses LLMs with repository analysis, retrieval of relevant examples, and iterative refinement through diagnostic feedback to generate Spack recipes for HPC software. Results show this approach increases installation success rates from 20% in zero-shot settings to over 80%, demonstrating the value of retrieval and structured feedback for reliable package synthesis.

- **[arXiv251111] Distributed Recoverable Sketches (Extended Version)**
  - **tags:** [sys], [network monitoring], [Count-Min Sketch, distributed recovery, incremental updates, sketch partitioning, frequency estimation]
  - **authors:** Diana Cohen, Roy Friedman, Rana Shahout
  - **institution:** Technion, Harvard University
  - **link:** https://arxiv.org/pdf/2511.05762
  - **Simple LLM Summary:** This paper proposes a distributed framework for recovering sketch data after node crashes in network environments, focusing on frequency estimation sketches like Count-Min Sketch. The system explores trade-offs between space consumption, runtime overheads, and recovery traffic while comparing periodic full updates versus incremental updates. The framework is designed to be modular and generic, allowing other data structures to be integrated via an abstract API.

- **[arXiv251111] CoEdge-RAG: Optimizing Hierarchical Scheduling for Retrieval-Augmented LLMs in Collaborative Edge Computing**
  - **tags:** [mlsys], [llm inference], [retrieval-augmented generation, proximal policy optimization, online convex optimization, hierarchical scheduling, collaborative edge computing]
  - **authors:** Guihang Hong, Tao Ouyang, Kongyange Zhao, Zhi Zhou, Xu Chen
  - **institution:** Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2511.05915
  - **Simple LLM Summary:** This paper proposes CoEdge-RAG, a hierarchical scheduling framework that optimizes retrieval-augmented LLMs in collaborative edge environments. The method uses PPO for online query identification, dynamic inter-node workload balancing, and intra-node resource allocation via online convex optimization. Comprehensive evaluations show the framework achieves significant performance gains of 4.23% to 91.39% over baseline methods across various QA tasks.

- **[arXiv251111] Inductive Loop Analysis for Practical HPC Application Optimization**
  - **tags:** [sys], [compiler optimization], [symbolic analysis, loop optimization, software prefetching, pointer incrementation, automatic parallelization]
  - **authors:** Philipp Schaad, Tal Ben-Nun, Patrick Iff, Torsten Hoefler
  - **institution:** ETH Zurich, Lawrence Livermore National Laboratory
  - **link:** https://arxiv.org/pdf/2511.06052
  - **Simple LLM Summary:** The paper introduces SILO, a symbolic inductive loop optimization technique that models data accesses and dependencies as functions of loop nest strides. This approach enables automatic parallelization of sequentially-dependent loops and data movement optimizations. The method achieves up to 12× speedup over state-of-the-art approaches on scientific computing kernels from atmospheric models and numerical solvers.

- **[arXiv251111] An Efficient Gradient-Aware Error-Bounded Lossy Compressor for Federated Learning**
  - **tags:** [mlsys], [others], [error-bounded lossy compression, gradient compression, temporal correlation, convolutional kernels, exponential moving average, sign prediction]
  - **authors:** Zhijing Ye, Sheng Di, Jiamin Wang, Zhiqing Zhong, Zhaorui Zhang, Xiaodong Yu
  - **institution:** Stevens Institute of Technology, Argonne National Laboratory, Hong Kong Polytechnic University
  - **link:** https://arxiv.org/pdf/2511.05770
  - **Simple LLM Summary:** This paper proposes a gradient-aware error-bounded lossy compression method for federated learning that exploits temporal correlations across training rounds and structural patterns in convolutional kernels. The method achieves up to 1.53× higher compression ratios than existing approaches while maintaining model accuracy. When integrated into a real FL framework, it reduces communication time by 76.1%-96.2% under bandwidth-constrained scenarios.

- **[arXiv251111] HYDRA: Breaking the Global Ordering Barrier in Multi-BFT Consensus**
  - **tags:** [sys], [distributed consensus], [multi-BFT consensus, object-centric execution, lock-based coordination, deadlock resolution]
  - **authors:** Hanzheng Lyu, Shaokang Xie, Jianyu Niu, Mohammad Sadoghi, Yinqian Zhang, Cong Wang, Ivan Beschastnikh, Chen Feng
  - **institution:** University of British Columbia, University of California Davis, City University of Hong Kong, Southern University of Science and Technology
  - **link:** https://arxiv.org/pdf/2511.05843
  - **Simple LLM Summary:** HYDRA introduces an object-centric execution model that eliminates global ordering in Multi-BFT consensus by partitioning transactions and using lightweight lock-based coordination with deadlock resolution. Experimental results show it outperforms state-of-the-art Multi-BFT protocols, especially in the presence of stragglers. This demonstrates that removing global ordering enables both strong consistency and high performance in scalable consensus systems.

- **[arXiv251111] MoSKA: Mixture of Shared KV Attention for Efficient Long-Sequence LLM Inference**
  - **tags:** [mlsys], [llm inference], [shared kv attention, sparse attention, disaggregated infrastructure, kv cache optimization, memory bandwidth optimization]
  - **authors:** Myunghyun Rhee, Sookyung Choi, Euiseok Kim, Joonseop Sim, Youngpyo Joo, Hoshik Kim
  - **institution:** SK hynix Inc.
  - **link:** https://arxiv.org/pdf/2511.06010
  - **Simple LLM Summary:** This paper introduces MoSKA, a novel architecture that addresses KV cache bottlenecks in long-sequence LLM inference by differentiating between unique and shared context data. The core innovation is Shared KV Attention, which transforms memory-bound operations into compute-bound GEMM operations through request batching. This approach achieves up to 538.7x throughput improvement in high-sharing workloads, providing a scalable path for efficient LLM inference.

- **[arXiv251111] Distributed Deep Learning for Medical Image Denoising with Data Obfuscation**
  - **tags:** [mlsys], [others], [DistributedDataParallel, Automatic Mixed Precision, U-Net, U-Net++, multi-GPU training, data obfuscation]
  - **authors:** Sulaimon Oyeniyi Adebayo, Ayaz H. Khan
  - **institution:** King Fahd University of Petroleum and Minerals, SDAIA-KFUPM Joint Research Center for Artificial Intelligence
  - **link:** https://arxiv.org/pdf/2511.06006
  - **Simple LLM Summary:** This paper implements distributed deep learning for medical image denoising using U-Net and U-Net++ architectures with Gaussian noise obfuscation. The optimized training pipeline combining DistributedDataParallel and Automatic Mixed Precision reduced training time by over 60% compared to single-GPU training. Results show U-Net++ achieved superior denoising performance with enhanced structural fidelity while maintaining practical viability for clinical applications.

- **[arXiv251111] Elastic Data Transfer Optimization with Hybrid Reinforcement Learning**
  - **tags:** [mlsys], [cluster infrastructure], [deep reinforcement learning, heuristic-based parallelism, infinite pipelining, network simulator]
  - **authors:** Rasman Mubtasim Swargo, Md Arifuzzaman
  - **institution:** Missouri University of Science and Technology
  - **link:** https://arxiv.org/pdf/2511.06159
  - **Simple LLM Summary:** The paper presents LDM, an adaptive data transfer method that combines heuristic-based parallelism, infinite pipelining, and deep reinforcement learning to optimize multiple transfer parameters simultaneously. It introduces a lightweight network simulator that reduces training time from days to minutes. Experimental results show the method achieves up to 9.5× higher throughput compared to state-of-the-art solutions across diverse datasets.

- **[arXiv251111] LiteCast: A Lightweight Forecaster for Carbon Optimizations**
  - **tags:** [mlsys], [others], [time series forecasting, carbon intensity prediction, lightweight forecasting, energy mix modeling]
  - **authors:** Mathew Joseph, Tanush Savadi, Abel Souza
  - **institution:** Unknown
  - **link:** https://arxiv.org/pdf/2511.06187
  - **Simple LLM Summary:** LiteCast is a lightweight time series forecasting method that uses minimal historical energy and weather data to predict grid carbon intensity. The paper demonstrates that preserving forecast rankings rather than achieving high precision drives most carbon savings. Evaluation across 50 regions shows LiteCast achieves 97% of maximum attainable savings while being computationally efficient and adaptive to grid changes.

- **[arXiv251111] PRAGMA: A Profiling-Reasoned Multi-Agent Framework for Automatic Kernel Optimization**
  - **tags:** [mlsys], [GPU kernels], [profile-guided optimization, multi-agent framework, hardware profiling, kernel generation, iterative refinement]
  - **authors:** Kelun Lei, Hailong Yang, Huaitao Zhang, Xin You, Kaige Zhang, Zhongzhi Luan, Yi Liu, Depei Qian
  - **institution:** Beihang University
  - **link:** https://arxiv.org/pdf/2511.06345
  - **Simple LLM Summary:** PRAGMA introduces a profile-guided multi-agent framework that integrates fine-grained hardware profiling into the kernel optimization loop, enabling LLMs to identify performance bottlenecks and iteratively refine code. The system consistently outperforms baseline approaches without profiling and achieves significant speedups (2.81× on CPU, 2.30× on GPU) compared to Torch implementations.

- **[arXiv251111] Reliablocks: Developing Reliability Scores for Optimistic Rollups**
  - **tags:** [sys], [blockchain scalability], [optimistic rollups, reliability scores, smart contracts, AVS components, WASMI]
  - **authors:** Souradeep Das, Ethan Lam, Varun Vaidya, Sanjay Amirthraj
  - **institution:** EigenLayer
  - **link:** https://arxiv.org/pdf/2511.06130
  - **Simple LLM Summary:** The paper introduces Reliablocks, an on-chain reliability index that assesses non-finalized blocks in Optimistic Rollups to help users determine transaction finality. It was developed during the EigenLayer Infinite Hackathon and includes working AVS components, smart contracts, and a dashboard interface. The system aims to provide transparency about block reliability during the 7-day finalization period, benefiting L2 users who cannot run validators themselves.

- **[arXiv251111] Towards Optimal Constellation Design for Digital Over-the-Air Computation**
  - **tags:** [sys], [wireless communications], [digital modulation, constellation design, mean-squared error minimization, additive mapping, generalized Lambert function]
  - **authors:** Saeed Razavikia, Deniz Gündüz, Carlo Fischione
  - **institution:** KTH Royal Institute of Technology, Imperial College London
  - **link:** https://arxiv.org/pdf/2511.06372
  - **Simple LLM Summary:** This paper proposes a digital modulation framework for over-the-air computation that optimizes constellation design to minimize mean-squared error under power constraints. The authors formulate the problem as a system of nonlinear equations and derive closed-form solutions using the generalized Lambert function in high SNR regimes. The framework provides analytical insights and can be extended to multi-dimensional grids, non-Gaussian noise, and hybrid digital-analog modulation.

- **[arXiv251111] FPGA or GPU? Analyzing comparative research for application-specific guidance**
  - **tags:** [mlsys], [others], [hardware accelerators, FPGA, GPU, performance metrics, energy efficiency, programmability]
  - **authors:** Arnab A Purkayastha, Jay Tharwani, Shobhit Aggarwal
  - **institution:** Western New England University, The Citadel
  - **link:** https://arxiv.org/pdf/2511.06565
  - **Simple LLM Summary:** This paper synthesizes insights from comparative research studies to analyze FPGA and GPU performance across different application domains. By categorizing studies and analyzing key metrics, it provides application-specific guidance for selecting appropriate hardware accelerators. The main conclusion is that FPGAs excel in real-time, power-sensitive tasks while GPUs are better suited for data-intensive parallel processing with mature programming frameworks.

- **[arXiv251111] Optimizing Long-context LLM Serving via Fine-grained Sequence Parallelism**
  - **tags:** [mlsys], [llm inference], [sequence parallelism, chunkwise dynamic sequence parallelism, ring attention, tensor parallelism, disaggregated cluster]
  - **authors:** Cong Li, Yuzhe Yang, Xuegui Zheng, Qifan Yang, Yijin Guan, Size Zheng, Li-Wen Chang, Shufan Liu, Xin Liu, Guangyu Sun
  - **institution:** Peking University, Bytedance
  - **link:** https://arxiv.org/pdf/2511.06247
  - **Simple LLM Summary:** The paper proposes Chunkwise Dynamic Sequence Parallelism (CDSP), a fine-grained parallelism strategy that assigns SP sizes across intra-request token segments, and builds Tetris, an LLM serving system based on CDSP. Tetris achieves significantly better performance than state-of-the-art systems, reducing time-to-first-token by up to 4.35× and increasing maximum request capacity by up to 45% while optimizing resource utilization in long-context LLM serving.

- **[arXiv251111] DMA Collectives for Efficient ML Communication Offloads**
  - **tags:** [mlsys], [cluster infrastructure], [DMA collectives, all-gather, all-to-all, RCCL, synchronization optimization, AMD MI300X]
  - **authors:** Suchita Pati, Mahzabeen Islam, Shaizeen Aga, Mohamed Assem Ibrahim
  - **institution:** Advanced Micro Devices, Inc.
  - **link:** https://arxiv.org/pdf/2511.06605
  - **Simple LLM Summary:** This paper analyzes offloading machine learning communication collectives to DMA engines on AMD MI300X GPUs, comparing performance against RCCL libraries. The research shows DMA collectives perform well for large data transfers but lag for small sizes due to synchronization overheads. Through optimized implementations leveraging DMA architecture innovations, the authors significantly close this performance gap, making DMA collectives more suitable for mainstream adoption.

- **[arXiv251111] Saarthi: An End-to-End Intelligent Platform for Optimising Distributed Serverless Workloads**
  - **tags:** [mlsys], [fault-tolerance], [input-aware resource allocation, function right-sizing, multi-objective Integer Linear Programming, proactive fault-tolerant redundancy, smart request orchestration]
  - **authors:** Siddharth Agarwal, Maria A. Rodriguez, Rajkumar Buyya
  - **institution:** The University of Melbourne
  - **link:** https://arxiv.org/pdf/2511.06599
  - **Simple LLM Summary:** Saarthi is an end-to-end serverless framework that uses input-aware resource prediction and multi-objective optimization to dynamically manage function workloads. It achieves up to 1.45x better throughput and 1.84x reduced costs while maintaining 98.3% service level targets compared to baseline OpenFaaS. The system demonstrates significant improvements in serverless computing efficiency through intelligent resource allocation and request orchestration.

- **[arXiv251111] Argus: Quality-Aware High-Throughput Text-to-Image Inference Serving System**
  - **tags:** [mlsys], [diffusion inference], [approximate computing, quality-aware scheduling, model switching, throughput optimization]
  - **authors:** Shubham Agarwal, Subrata Mitra, Saud Iqbal
  - **institution:** UC Berkeley, Adobe Research
  - **link:** https://arxiv.org/pdf/2511.06724
  - **Simple LLM Summary:** Argus is a text-to-image inference serving system that intelligently selects appropriate approximation levels for each prompt to balance quality and throughput. The system dynamically switches between different approximation strategies to meet both quality requirements and throughput targets. Compared to baselines, Argus achieves 10x fewer latency violations, 10% higher quality, and 40% higher throughput on real-world workloads.

- **[arXiv251111] Wireless Sensor Networks Nodes Clustering and Optimization Based on Fuzzy C-Means and Water Strider Algorithms**
  - **tags:** [mlsys], [cluster infrastructure], [Water Strider Algorithm, Fuzzy C-Means, clustering optimization, energy efficiency, network lifetime, hybrid metaheuristics]
  - **authors:** Raya Majid Alsharfa, Mahmood Mohassel Feghhi, Majid Hameed Majeed
  - **institution:** Middle Technical University, University of Tabriz, Al-Mustaqbal University
  - **link:** https://arxiv.org/pdf/2511.06735
  - **Simple LLM Summary:** This paper proposes a hybrid clustering protocol that combines Water Strider Algorithm for global optimization of cluster-head positions with Fuzzy C-Means for refined node membership assignment. The method significantly improves energy efficiency and network lifetime in wireless sensor networks, outperforming existing hybrid approaches across all performance metrics with statistical validation.

- **[arXiv251111] Resilient by Design - Active Inference for Distributed Continuum Intelligence**
  - **tags:** [mlsys], [fault-tolerance], [active inference, free-energy principle, Markov blanket, causal fault graph, Bayesian network structure learning]
  - **authors:** Praveen Kumar Donta, Alfreds Lapkovskis, Enzo Mingozzi, Schahram Dustdar
  - **institution:** Stockholm University, University of Pisa, TU Wien, ICREA
  - **link:** https://arxiv.org/pdf/2511.07202
  - **Simple LLM Summary:** This paper introduces a Probabilistic Active Inference Resilience Agent (PAIR-Agent) that uses causal fault graphs and the free-energy principle to autonomously detect and heal faults in distributed computing continuum systems. The framework continuously monitors system components and performs adaptive reconfiguration to maintain service stability under diverse failure conditions. Theoretical validations confirm the reliability and effectiveness of the proposed resilience approach.

- **[arXiv251111] Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields**
  - **tags:** [ai], [robotic manipulation], [contact fields, procedural grasp synthesis, geometric computation decoupling]
  - **authors:** Zhao-Heng Yin, Pieter Abbeel
  - **institution:** UC Berkeley
  - **link:** https://arxiv.org/pdf/2511.07418
  - **Simple LLM Summary:** Lightning Grasp introduces a procedural grasp synthesis algorithm that uses Contact Fields to decouple geometric computation from the search process. This approach achieves orders-of-magnitude speed improvements over state-of-the-art methods while generating diverse grasps for irregular objects. The method eliminates the need for manually tuned energy functions and enables real-time grasp synthesis for dexterous robotic hands.

- **[arXiv251111] A GPU-boosted high-performance multi-working condition joint analysis framework for predicting dynamics of textured axial piston pump**
  - **tags:** [sys], [computational fluid dynamics], [GPU acceleration, Preconditioned Conjugate Gradient method, Approximate Symmetric Successive Over-Relaxation preconditioner, synchronized convergence strategy, finite volume method]
  - **authors:** Xin Yao, Yang Liu, Jin Jiang, Yesen Chen, Zhilong Chen, Hongkang Dong, Xiaofeng Wei, Teng Zhang, Dongyun Wang
  - **institution:** Zhejiang Normal University
  - **link:** https://arxiv.org/pdf/2511.06824
  - **Simple LLM Summary:** This paper presents a GPU-accelerated framework (GMAF) that uses Preconditioned Conjugate Gradient method with ASSOR preconditioner to efficiently simulate axial piston pump dynamics. The framework enables analysis of both smooth and textured pumps across multiple periods by accelerating pressure field computations and numerical integration. Results show that textured surfaces improve pressure capacity and torsion resistance, with pressure fields exhibiting step-like patterns corresponding to surface textures.

- **[arXiv251111] LLMServingSim2.0: A Unified Simulator for Heterogeneous Hardware and Serving Techniques in LLM Infrastructure**
  - **tags:** [mlsys], [llm inference], [trace-driven performance modeling, operator-level latency profiler, heterogeneous hardware integration, request routing, cache management, scheduling policies]
  - **authors:** Jaehong Cho, Hyunmin Choi, Jongse Park
  - **institution:** Korea Advanced Institute of Science and Technology (KAIST)
  - **link:** https://arxiv.org/pdf/2511.07229
  - **Simple LLM Summary:** LLMServingSim2.0 introduces a unified simulator using trace-driven performance modeling and operator-level profiling to enable easy integration of heterogeneous hardware with modern LLM serving techniques. The system demonstrates 18.5× fewer lines of code for hardware integration and achieves only 1.9% error in reproducing GPU-based LLM serving. This makes it a comprehensive platform for both hardware developers and LLM service providers to evaluate heterogeneous systems efficiently.


**cs.AI/cs.LG contains "reinforcement learning" total: 48**
- [arXiv251111] Revisiting Entropy in Reinforcement Learning for Large Reasoning Models [link](https://arxiv.org/pdf/2511.05993)
- [arXiv251111] Distributionally Robust Self Paced Curriculum Reinforcement Learning [link](https://arxiv.org/pdf/2511.05694)
- [arXiv251111] Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs [link](https://arxiv.org/pdf/2511.05933)
- [arXiv251111] CoPRIS: Efficient and Stable Reinforcement Learning via Concurrency-Controlled Partial Rollout with Importance Sampling [link](https://arxiv.org/pdf/2511.05589)
- [arXiv251111] Lookahead Unmasking Elicits Accurate Decoding in Diffusion Language Models [link](https://arxiv.org/pdf/2511.05563)
- [arXiv251111] WAR-Re: Web API Recommendation with Semantic Reasoning [link](https://arxiv.org/pdf/2511.05820)
- [arXiv251111] Policy Gradient-Based EMT-in-the-Loop Learning to Mitigate Sub-Synchronous Control Interactions [link](https://arxiv.org/pdf/2511.05822)
- [arXiv251111] Klear-AgentForge: Forging Agentic Intelligence through Posttraining Scaling [link](https://arxiv.org/pdf/2511.05951)
- [arXiv251111] EGG-SR: Embedding Symbolic Equivalence into Symbolic Regression via Equality Graph [link](https://arxiv.org/pdf/2511.05849)
- [arXiv251111] SymLight: Exploring Interpretable and Deployable Symbolic Policies for Traffic Signal Control [link](https://arxiv.org/pdf/2511.05790)
- [arXiv251111] Adaptive Agent Selection and Interaction Network for Image-to-point cloud Registration [link](https://arxiv.org/pdf/2511.05965)
- [arXiv251111] ScRPO: From Errors to Insights [link](https://arxiv.org/pdf/2511.06065)
- [arXiv251111] Approximating Shapley Explanations in Reinforcement Learning [link](https://arxiv.org/pdf/2511.06094)
- [arXiv251111] Guardian-regularized Safe Offline Reinforcement Learning for Smart Weaning of Mechanical Circulatory Devices [link](https://arxiv.org/pdf/2511.06111)
- [arXiv251111] A Deep Learning Model for Predicting Transformation Legality [link](https://arxiv.org/pdf/2511.06120)
- [arXiv251111] Maestro: Learning to Collaborate via Conditional Listwise Policy Optimization for Multi-Agent LLMs [link](https://arxiv.org/pdf/2511.06134)
- [arXiv251111] When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks [link](https://arxiv.org/pdf/2511.06136)
- [arXiv251111] MALinZero: Efficient Low-Dimensional Search for Mastering Complex Multi-Agent Planning [link](https://arxiv.org/pdf/2511.06142)
- [arXiv251111] Deep Reinforcement Learning for Dynamic Origin-Destination Matrix Estimation in Microscopic Traffic Simulations Considering Credit Assignment [link](https://arxiv.org/pdf/2511.06229)
- [arXiv251111] MrCoM: A Meta-Regularized World-Model Generalizing Across Multi-Scenarios [link](https://arxiv.org/pdf/2511.06252)
- [arXiv251111] What Makes Reasoning Invalid: Echo Reflection Mitigation for Large Language Models [link](https://arxiv.org/pdf/2511.06380)
- [arXiv251111] SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization [link](https://arxiv.org/pdf/2511.06411)
- [arXiv251111] CG-TTRL: Context-Guided Test-Time Reinforcement Learning for On-Device Large Language Models [link](https://arxiv.org/pdf/2511.06430)
- [arXiv251111] Brain-Inspired Planning for Better Generalization in Reinforcement Learning [link](https://arxiv.org/pdf/2511.06470)
- [arXiv251111] Zooming into Comics: Region-Aware RL Improves Fine-Grained Comic Understanding in Vision-Language Models [link](https://arxiv.org/pdf/2511.06490)
- [arXiv251111] Practical Policy Distillation for Reinforcement Learning in Radio Access Networks [link](https://arxiv.org/pdf/2511.06563)
- [arXiv251111] GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with Group Relative Policy Optimization [link](https://arxiv.org/pdf/2511.06618)
- [arXiv251111] Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View [link](https://arxiv.org/pdf/2511.06722)
- [arXiv251111] Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning [link](https://arxiv.org/pdf/2511.06745)
- [arXiv251111] OntoTune: Ontology-Driven Learning for Query Optimization with Convolutional Models [link](https://arxiv.org/pdf/2511.06780)
- [arXiv251111] Controllable Flow Matching for Online Reinforcement Learning [link](https://arxiv.org/pdf/2511.06816)
- [arXiv251111] On The Presence of Double-Descent in Deep Reinforcement Learning [link](https://arxiv.org/pdf/2511.06895)
- [arXiv251111] Fine-Tuning Diffusion-Based Recommender Systems via Reinforcement Learning with Reward Function Optimization [link](https://arxiv.org/pdf/2511.06937)
- [arXiv251111] Learning to Focus: Prioritizing Informative Histories with Structured Attention Mechanisms in Partially Observable Reinforcement Learning [link](https://arxiv.org/pdf/2511.06946)
- [arXiv251111] Learning Quantized Continuous Controllers for Integer Hardware [link](https://arxiv.org/pdf/2511.07046)
- [arXiv251111] Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture [link](https://arxiv.org/pdf/2511.07110)
- [arXiv251111] Dynamics-Decoupled Trajectory Alignment for Sim-to-Real Transfer in Reinforcement Learning for Autonomous Driving [link](https://arxiv.org/pdf/2511.07155)
- [arXiv251111] Guiding Generative Models to Uncover Diverse and Novel Crystals via Reinforcement Learning [link](https://arxiv.org/pdf/2511.07158)
- [arXiv251111] Enabling Off-Policy Imitation Learning with Deep Actor Critic Stabilization [link](https://arxiv.org/pdf/2511.07288)
- [arXiv251111] Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search [link](https://arxiv.org/pdf/2511.07312)
- [arXiv251111] RLVE: Scaling Up Reinforcement Learning for Language Models with Adaptive Verifiable Environments [link](https://arxiv.org/pdf/2511.07317)
- [arXiv251111] FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation [link](https://arxiv.org/pdf/2511.07322)
- [arXiv251111] IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction [link](https://arxiv.org/pdf/2511.07327)
- [arXiv251111] Q-RAG: Long Context Multi-step Retrieval via Value-based Embedder Training [link](https://arxiv.org/pdf/2511.07328)
- [arXiv251111] Grounding Computer Use Agents on Human Demonstrations [link](https://arxiv.org/pdf/2511.07332)
- [arXiv251111] Provable Benefit of Curriculum in Transformer Tree-Reasoning Post-Training [link](https://arxiv.org/pdf/2511.07372)
- [arXiv251111] Robot Learning from a Physical World Model [link](https://arxiv.org/pdf/2511.07416)
- [arXiv251111] Convergence of Actor-Critic Learning for Mean Field Games and Mean Field Control in Continuous Spaces [link](https://arxiv.org/pdf/2511.06812)

**cs.AI/cs.LG contains "accelerate" total: 21**
- [arXiv251111] GastroDL-Fusion: A Dual-Modal Deep Learning Framework Integrating Protein-Ligand Complexes and Gene Sequences for Gastrointestinal Disease Drug Discovery [link](https://arxiv.org/pdf/2511.05726)
- [arXiv251111] Physics-Informed Neural Networks for Real-Time Gas Crossover Prediction in PEM Electrolyzers: First Application with Multi-Membrane Validation [link](https://arxiv.org/pdf/2511.05879)
- [arXiv251111] wa-hls4ml: A Benchmark and Surrogate Models for hls4ml Resource and Latency Estimation [link](https://arxiv.org/pdf/2511.05615)
- [arXiv251111] Hilbert-Guided Block-Sparse Local Attention [link](https://arxiv.org/pdf/2511.05832)
- [arXiv251111] EGG-SR: Embedding Symbolic Equivalence into Symbolic Regression via Equality Graph [link](https://arxiv.org/pdf/2511.05849)
- [arXiv251111] 10 Open Challenges Steering the Future of Vision-Language-Action Models [link](https://arxiv.org/pdf/2511.05936)
- [arXiv251111] AutoHood3D: A Multi-Modal Benchmark for Automotive Hood Design and Fluid-Structure Interaction [link](https://arxiv.org/pdf/2511.05596)
- [arXiv251111] LUT-LLM: Efficient Large Language Model Inference with Memory-based Computations on FPGAs [link](https://arxiv.org/pdf/2511.06174)
- [arXiv251111] Practical Policy Distillation for Reinforcement Learning in Radio Access Networks [link](https://arxiv.org/pdf/2511.06563)
- [arXiv251111] SteganoSNN: SNN-Based Audio-in-Image Steganography with Encryption [link](https://arxiv.org/pdf/2511.06573)
- [arXiv251111] Optimistic Online-to-Batch Conversions for Accelerated Convergence and Universality [link](https://arxiv.org/pdf/2511.06597)
- [arXiv251111] ML-EcoLyzer: Quantifying the Environmental Cost of Machine Learning Inference Across Frameworks and Hardware [link](https://arxiv.org/pdf/2511.06694)
- [arXiv251111] QUARK: Quantization-Enabled Circuit Sharing for Transformer Acceleration by Exploiting Common Patterns in Nonlinear Operations [link](https://arxiv.org/pdf/2511.06767)
- [arXiv251111] Neural-Initialized Newton: Accelerating Nonlinear Finite Elements via Operator Learning [link](https://arxiv.org/pdf/2511.06802)
- [arXiv251111] DeepRWCap: Neural-Guided Random-Walk Capacitance Solver for IC Design [link](https://arxiv.org/pdf/2511.06831)
- [arXiv251111] P3-LLM: An Integrated NPU-PIM Accelerator for LLM Inference Using Hybrid Numerical Formats [link](https://arxiv.org/pdf/2511.06838)
- [arXiv251111] TNT: Improving Chunkwise Training for Test-Time Memorization [link](https://arxiv.org/pdf/2511.07343)
- [arXiv251111] Inference-Time Scaling of Diffusion Models for Infrared Data Generation [link](https://arxiv.org/pdf/2511.07362)
- [arXiv251111] DigiData: Training and Evaluating General-Purpose Mobile Control Agents [link](https://arxiv.org/pdf/2511.07413)
- [arXiv251111] AIRMap - AI-Generated Radio Maps for Wireless Digital Twins [link](https://arxiv.org/pdf/2511.05522)
- [arXiv251111] Machine-Learning Accelerated Calculations of Reduced Density Matrices [link](https://arxiv.org/pdf/2511.07367)
