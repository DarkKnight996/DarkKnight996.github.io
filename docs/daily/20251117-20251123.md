# 20251117-20251123

## 2025-11-17

**cs.DC total: 9**

- **[arXiv251117] HPCAgentTester: A Multi-Agent LLM Approach for Enhanced HPC Unit Test Generation**
  - **tags:** [mlsys], [others], [multi-agent LLM, OpenMP, MPI, unit test generation, parallel computing, critique loop]
  - **authors:** Rabimba Karanjai, Lei Xu, Weidong Shi
  - **institution:** University of Houston, Kent State University
  - **link:** https://arxiv.org/pdf/2511.10860
  - **Simple LLM Summary:** This paper introduces HPCAgentTester, a multi-agent LLM framework that uses specialized agents working collaboratively through a critique loop to generate unit tests for HPC software. The system specifically targets parallel execution constructs in OpenMP and MPI applications. Evaluation shows it significantly improves test compilation rates and correctness compared to standalone LLMs, effectively identifying subtle bugs in parallel software.

- **[arXiv251117] A Unified Convergence Analysis for Semi-Decentralized Learning: Sampled-to-Sampled vs. Sampled-to-All Communication**
  - **tags:** [mlsys], [others], [semi-decentralized federated learning, device-to-device communication, local SGD, model aggregation, convergence analysis]
  - **authors:** Angelo Rodio, Giovanni Neglia, Zheng Chen, Erik G. Larsson
  - **institution:** Linköping University, Inria Université Côte d'Azur
  - **link:** https://arxiv.org/pdf/2511.11560
  - **Simple LLM Summary:** This paper analyzes two communication strategies (sampled-to-sampled vs sampled-to-all) in semi-decentralized federated learning where devices primarily use device-to-device communication with periodic server interactions. The unified convergence framework reveals that the optimal strategy depends primarily on data heterogeneity across devices, providing concrete design guidelines for practical deployments.

- **[arXiv251117] Beyond Exascale: Dataflow Domain Translation on a Cerebras Cluster**
  - **tags:** [sys], [high performance computing], [Domain Translation, shallow-water equations, stencil computations, finite difference methods, cluster computing]
  - **authors:** Tomas Oppelstrup, Nicholas Giamblanco, Delyan Z. Kalchev, Ilya Sharapov, Mark Taylor, Dirk Van Essendelft, Sivasankaran Rajamanickam, Michael James
  - **institution:** Cerebras Systems, Sandia National Laboratories, National Energy Technology Laboratory
  - **link:** https://arxiv.org/pdf/2511.11542
  - **Simple LLM Summary:** This paper introduces the Domain Translation algorithm to overcome performance limitations of traditional domain decomposition methods in physical system simulations. The method achieves 1.6 million time steps per second and 84 PFLOP/s while maintaining 90% of peak performance on Cerebras CS-3 clusters. The approach was demonstrated by modeling planetary-scale tsunami simulations at 460m-resolution using shallow-water equations.

- **[arXiv251117] SMART: A Surrogate Model for Predicting Application Runtime in Dragonfly Systems**
  - **tags:** [mlsys], [others], [graph neural networks, large language models, parallel discrete event simulation, hybrid simulation, Dragonfly networks]
  - **authors:** Xin Wang, Pietro Lodi Rizzini, Sourav Medya, Zhiling Lan
  - **institution:** University of Illinois Chicago, Argonne National Laboratory
  - **link:** https://arxiv.org/pdf/2511.11111
  - **Simple LLM Summary:** This paper presents SMART, a surrogate model that combines graph neural networks and large language models to predict application runtime in Dragonfly network systems. The model captures both spatial and temporal patterns from router data to address workload interference challenges. SMART outperforms existing statistical and machine learning baselines, enabling accurate runtime prediction and supporting efficient hybrid simulation of Dragonfly networks.

- **[arXiv251117] Cascading Bandits With Feedback**
  - **tags:** [mlsys], [llm inference], [cascade bandits, explore-then-commit, action elimination, lower confidence bound, thompson sampling, edge inference]
  - **authors:** R Sri Prakash, Nikhil Karamchandani, Sharayu Moharir
  - **institution:** IIITDM Kancheepuram, IIT Bombay
  - **link:** https://arxiv.org/pdf/2511.10938
  - **Simple LLM Summary:** This paper analyzes four bandit algorithms for optimizing cascade model ordering in edge inference systems. The study finds that LCB and Thompson Sampling achieve constant regret by continuously adapting to feedback, while Explore-then-Commit and Action Elimination incur suboptimal regret due to fixed ordering commitments. Adaptive policies are shown to be crucial for efficient edge inference under uncertainty.

- **[arXiv251117] SemanticNN: Compressive and Error-Resilient Semantic Offloading for Extremely Weak Devices**
  - **tags:** [mlsys], [others], [semantic codec, bit error rate-aware decoder, soft quantization, feature-augmentation learning, XAI-based asymmetry compensation]
  - **authors:** Jiaming Huang, Yi Gao, Fuchang Pan, Renjie Li, Wei Dong
  - **institution:** Zhejiang University
  - **link:** https://arxiv.org/pdf/2511.11038
  - **Simple LLM Summary:** This paper proposes SemanticNN, a semantic codec system that tolerates bit-level transmission errors while maintaining semantic-level correctness for collaborative inference offloading on weak IoT devices. The method incorporates BER-aware decoding, soft quantization encoding, and novel training strategies to handle asymmetric device-edge capabilities. Experimental results show SemanticNN reduces feature transmission volume by 56.82-344.83x while maintaining superior inference accuracy under varying error conditions.

- **[arXiv251117] EarthSight: A Distributed Framework for Low-Latency Satellite Intelligence**
  - **tags:** [mlsys], [others], [multi-task inference, ground-station query scheduler, dynamic filter ordering, distributed decision problem, resource-aware adaptive decisions]
  - **authors:** Ansel Kaplan Erol, Seungjun Lee, Divya Mahajan
  - **institution:** Georgia Institute of Technology, KAIST
  - **link:** https://arxiv.org/pdf/2511.10834
  - **Simple LLM Summary:** EarthSight introduces a distributed framework that coordinates satellite constellations and ground stations to perform intelligent image analysis. The system uses multi-task inference, query scheduling, and dynamic filtering to prioritize valuable images while conserving onboard resources. Evaluation shows it reduces compute time by 1.9x and cuts 90th percentile latency from 51 to 21 minutes compared to state-of-the-art baselines.

- **[arXiv251117] FengHuang: Next-Generation Memory Orchestration for AI Inferencing**
  - **tags:** [mlsys], [llm inference], [memory disaggregation, multi-tier shared-memory, active tensor paging, near-memory compute]
  - **authors:** Jiamin Li, Lei Qu, Tao Zhang, Grigory Chirkov, Shuotao Xu, Peng Cheng, Lidong Zhou
  - **institution:** Microsoft Research
  - **link:** https://arxiv.org/pdf/2511.10753
  - **Simple LLM Summary:** FengHuang proposes a disaggregated AI infrastructure platform with multi-tier shared-memory architecture and active tensor paging to overcome memory and communication scaling limits for AI inference. The platform achieves significant reductions in local memory capacity (up to 93%) and GPU requirements (up to 50%) while maintaining performance across large language models like GPT-3 and Grok-1. This provides a scalable, cost-effective solution for AI inference infrastructure with open, heterogeneous design that eliminates vendor lock-in.

- **[arXiv251117] UFO$^3$: Weaving the Digital Agent Galaxy**
  - **tags:** [mlsys], [fault-tolerance], [TaskConstellation, distributed DAG, asynchronous execution, adaptive recovery, dynamic optimization]
  - **authors:** Chaoyun Zhang, Liqun Li, He Huang, Chiming Ni, Bo Qiao, Si Qin, Yu Kang, Minghua Ma, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang
  - **institution:** Microsoft, ZJU-UIUC Institute
  - **link:** https://arxiv.org/pdf/2511.11332
  - **Simple LLM Summary:** UFO3 introduces a system that models user requests as mutable TaskConstellations - distributed DAGs of atomic subtasks executed across heterogeneous devices. The system enables asynchronous execution, adaptive recovery, and dynamic optimization through its Constellation Orchestrator and Agent Interaction Protocol. Evaluation shows UFO3 achieves efficient cross-device task orchestration with 70.9% task success rate and 31% latency reduction while maintaining graceful degradation under failures.


**cs.AI/cs.LG contains "reinforcement learning" total: 18**
- [arXiv251117] Understanding the Nature of Depth-1 Equivariant Quantum Circuit [link](https://arxiv.org/pdf/2511.10756)
- [arXiv251117] Multi-Phase Spacecraft Trajectory Optimization via Transformer-Based Reinforcement Learning [link](https://arxiv.org/pdf/2511.11402)
- [arXiv251117] From Efficiency to Adaptivity: A Deeper Look at Adaptive Reasoning in Large Language Models [link](https://arxiv.org/pdf/2511.10788)
- [arXiv251117] Context-aware Adaptive Visualizations for Critical Decision Making [link](https://arxiv.org/pdf/2511.11476)
- [arXiv251117] STaR: Towards Cognitive Table Reasoning via Slow-Thinking Large Language Models [link](https://arxiv.org/pdf/2511.11233)
- [arXiv251117] LoRaCompass: Robust Reinforcement Learning to Efficiently Search for a LoRa Tag [link](https://arxiv.org/pdf/2511.11190)
- [arXiv251117] Honesty over Accuracy: Trustworthy Language Models through Reinforced Hesitation [link](https://arxiv.org/pdf/2511.11500)
- [arXiv251117] Incorporating Spatial Information into Goal-Conditioned Hierarchical Reinforcement Learning via Graph Representations [link](https://arxiv.org/pdf/2511.10872)
- [arXiv251117] RLSLM: A Hybrid Reinforcement Learning Framework Aligning Rule-Based Social Locomotion Model with Human Social Norms [link](https://arxiv.org/pdf/2511.11323)
- [arXiv251117] ARCTraj: A Dataset and Benchmark of Human Reasoning Trajectories for Abstract Problem Solving [link](https://arxiv.org/pdf/2511.11079)
- [arXiv251117] When Data is the Algorithm: A Systematic Study and Curation of Preference Optimization Datasets [link](https://arxiv.org/pdf/2511.10985)
- [arXiv251117] Scalable Population Training for Zero-Shot Coordination [link](https://arxiv.org/pdf/2511.11083)
- [arXiv251117] Data Poisoning Vulnerabilities Across Healthcare AI Architectures: A Security Threat Analysis [link](https://arxiv.org/pdf/2511.11020)
- [arXiv251117] VIDEOP2R: Video Understanding from Perception to Reasoning [link](https://arxiv.org/pdf/2511.11113)
- [arXiv251117] Aligning Machiavellian Agents: Behavior Steering via Test-Time Policy Shaping [link](https://arxiv.org/pdf/2511.11551)
- [arXiv251117] MarsRL: Advancing Multi-Agent Reasoning System via Reinforcement Learning with Agentic Pipeline Parallelism [link](https://arxiv.org/pdf/2511.11373)
- [arXiv251117] Behaviour Policy Optimization: Provably Lower Variance Return Estimates for Off-Policy Reinforcement Learning [link](https://arxiv.org/pdf/2511.10843)
- [arXiv251117] Robust and Efficient Communication in Multi-Agent Reinforcement Learning [link](https://arxiv.org/pdf/2511.11393)

**cs.AI/cs.LG contains "accelerate" total: 9**
- [arXiv251117] Virtual Width Networks [link](https://arxiv.org/pdf/2511.11238)
- [arXiv251117] Benchmarking Quantum Kernels Across Diverse and Complex Data [link](https://arxiv.org/pdf/2511.10831)
- [arXiv251117] Human-AI collaborative autonomous synthesis with pulsed laser deposition for remote epitaxy [link](https://arxiv.org/pdf/2511.11558)
- [arXiv251117] LiteAttention: A Temporal Sparse Attention for Diffusion Transformers [link](https://arxiv.org/pdf/2511.11062)
- [arXiv251117] LAD-BNet: Lag-Aware Dual-Branch Networks for Real-Time Energy Forecasting on Edge Devices [link](https://arxiv.org/pdf/2511.10680)
- [arXiv251117] FarSkip-Collective: Unhobbling Blocking Communication in Mixture of Experts Models [link](https://arxiv.org/pdf/2511.11505)
- [arXiv251117] Improving Continual Learning of Knowledge Graph Embeddings via Informed Initialization [link](https://arxiv.org/pdf/2511.11118)
- [arXiv251117] AIonopedia: an LLM agent orchestrating multimodal learning for ionic liquid discovery [link](https://arxiv.org/pdf/2511.11257)
- [arXiv251117] MMA-Sim: Bit-Accurate Reference Model of Tensor Cores and Matrix Cores [link](https://arxiv.org/pdf/2511.10909)
