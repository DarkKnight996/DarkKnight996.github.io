# 20251208-20251214

## 2025-12-08

**cs.DC total: 7**

- **[arXiv251208] NVLang: Unified Static Typing for Actor-Based Concurrency on the BEAM**
  - **tags:** [sys], [programming languages], [algebraic data types, Hindley-Milner type inference, typed process identifiers, typed futures, actor model, static typing, Core Erlang]
  - **authors:** Miguel de Oliveira Guerreiro
  - **institution:** University of Lisbon
  - **link:** https://arxiv.org/pdf/2512.05224
  - **Simple LLM Summary:** NVLang introduces a statically typed functional language for the BEAM virtual machine that uses algebraic data types to encode actor message protocols and extends Hindley-Milner type inference to enforce them at compile time. The main conclusion is that this approach eliminates message-passing errors while preserving the actor model's simplicity and maintains interoperability with the existing Erlang ecosystem.

- **[arXiv251208] Metronome: Differentiated Delay Scheduling for Serverless Functions**
  - **tags:** [mlsys], [cluster infrastructure], [delay scheduling, random forest regression, locality-aware scheduling, SLA compliance]
  - **authors:** Zhuangbin Chen, Juzheng Zheng, Zibin Zheng
  - **institution:** Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.05703
  - **Simple LLM Summary:** This paper proposes Metronome, a differentiated delay scheduling framework for serverless functions that uses an online Random Forest Regression model to predict function execution times and identify optimal locality-aware nodes. The implementation on OpenLambda demonstrates that Metronome significantly reduces mean function execution time by 64.88%-95.83% compared to baselines while maintaining SLA compliance under high concurrency.

- **[arXiv251208] Model Gateway: Model Management Platform for Model-Driven Drug Discovery**
  - **tags:** [mlsys], [others], [MLOps, LLM Agents, Generative AI, model registry, dynamic consensus model, asynchronous execution, cloud computing]
  - **authors:** Yan-Shiun Wu, Nathan A. Morin
  - **institution:** Eli Lilly and Company
  - **link:** https://arxiv.org/pdf/2512.05462
  - **Simple LLM Summary:** The paper presents Model Gateway, a cloud-based MLOps platform for managing machine learning and scientific computational models in drug discovery. It integrates LLM Agents and Generative AI tools to handle tasks like model registration and asynchronous execution. The platform demonstrated scalability with a 0% failure rate under high load and is concluded to be a fundamental component for accelerating model-driven drug development.

- **[arXiv251208] FedGMR: Federated Learning with Gradual Model Restoration under Asynchrony and Model Heterogeneity**
  - **tags:** [mlsys], [others], [federated learning, model heterogeneity, gradual model restoration, mask-aware aggregation, asynchronous training, bandwidth-constrained clients]
  - **authors:** Chengjie Ma, Seungeun Oh, Jihong Park, Seong-Lyun Kim
  - **institution:** Yonsei University
  - **link:** https://arxiv.org/pdf/2512.05372
  - **Simple LLM Summary:** The paper proposes FedGMR, a federated learning method that progressively increases the density of clients' sub-models during training to keep bandwidth-constrained clients effective. It introduces a mask-aware aggregation rule for asynchronous, model-heterogeneous settings and provides convergence guarantees. Experiments show FedGMR achieves faster convergence and higher accuracy, especially under high heterogeneity and non-IID data.

- **[arXiv251208] Compiler-supported reduced precision and AoS-SoA transformations for heterogeneous hardware**
  - **tags:** [sys], [compiler optimization], [AoS-SoA transformation, reduced precision, GPU offloading, compiler annotations, unified memory]
  - **authors:** Pawel K. Radtke, Tobias Weinzierl
  - **institution:** Durham University
  - **link:** https://arxiv.org/pdf/2512.05516
  - **Simple LLM Summary:** This paper introduces compiler annotations to support AoS-to-SoA data layout transformations and reduced precision for particle simulation codes on heterogeneous GPU platforms. It evaluates strategies for orchestrating these conversions between CPU and GPU, finding that NVIDIA's G200 platform achieved a speedup of around 2.6, while AMD's MI300A showed more robust but less pronounced benefits. The authors conclude that their compiler-based techniques are broadly applicable to Lagrangian codes and other domains.

- **[arXiv251208] Are Bus-Mounted Edge Servers Feasible?**
  - **tags:** [sys], [edge computing, vehicular networks], [bus-mounted edge servers, server placement, greedy heuristic algorithm, trace-driven simulation, coverage optimization]
  - **authors:** Xuezhi Li, Jiancong He, Ming Xie, Xuyang Chen, Le Chang, Li Jiang, Gui Gui
  - **institution:** Guangdong University of Technology, Central South University
  - **link:** https://arxiv.org/pdf/2512.05543
  - **Simple LLM Summary:** This paper studies the feasibility of deploying edge servers on public buses to serve vehicular networks, using real-world mobility traces and a greedy algorithm to select buses that maximize coverage of demand points under budget constraints. The trace-driven simulations show that bus-mounted servers can effectively handle dynamic user demand, leading to the conclusion that they are a feasible, beneficial, and valuable solution for urban areas.

- **[arXiv251208] InvarDiff: Cross-Scale Invariance Caching for Accelerated Diffusion Models**
  - **tags:** [mlsys], [diffusion inference], [invariance caching, deterministic sampling, quantile-based change metrics, re-sampling correction, step-first caching, layer-wise caching]
  - **authors:** Zihao Wu
  - **institution:** Peking University
  - **link:** https://arxiv.org/pdf/2512.05134
  - **Simple LLM Summary:** The paper introduces InvarDiff, a training-free acceleration method for diffusion models that exploits temporal invariance across timesteps and layers to cache and reuse intermediate features. It uses a pre-computed binary cache plan and re-sampling correction to reduce redundant computation. Experiments show the method achieves 2–3× speed-ups on models like DiT and FLUX with minimal impact on output quality.


**cs.AI/cs.LG contains "reinforcement learning" total: 9**
- [arXiv251208] Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem [link](https://arxiv.org/pdf/2512.05946)
- [arXiv251208] Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity [link](https://arxiv.org/pdf/2512.05962)
- [arXiv251208] Bayesian Active Inference for Intelligent UAV Anti-Jamming and Adaptive Trajectory Planning [link](https://arxiv.org/pdf/2512.05711)
- [arXiv251208] Hierarchical Reinforcement Learning for the Dynamic VNE with Alternatives Problem [link](https://arxiv.org/pdf/2512.05207)
- [arXiv251208] Bridging Interpretability and Optimization: Provably Attribution-Weighted Actor-Critic in Reproducing Kernel Hilbert Spaces [link](https://arxiv.org/pdf/2512.05291)
- [arXiv251208] Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning [link](https://arxiv.org/pdf/2512.05172)
- [arXiv251208] A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning [link](https://arxiv.org/pdf/2512.05753)
- [arXiv251208] Entropy Ratio Clipping as a Soft Global Constraint for Stable Reinforcement Learning [link](https://arxiv.org/pdf/2512.05591)
- [arXiv251208] Enhancing Deep Deterministic Policy Gradients on Continuous Control Tasks with Decoupled Prioritized Experience Replay [link](https://arxiv.org/pdf/2512.05320)

**cs.AI/cs.LG contains "accelerate" total: 9**
- [arXiv251208] When Forgetting Builds Reliability: LLM Unlearning for Reliable Hardware Code Generation [link](https://arxiv.org/pdf/2512.05341)
- [arXiv251208] Documenting SME Processes with Conversational AI: From Tacit Knowledge to BPMN [link](https://arxiv.org/pdf/2512.05122)
- [arXiv251208] Trusted AI Agents in the Cloud [link](https://arxiv.org/pdf/2512.05951)
- [arXiv251208] Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models [link](https://arxiv.org/pdf/2512.05887)
- [arXiv251208] Coefficient of Variation Masking: A Volatility-Aware Strategy for EHR Foundation Models [link](https://arxiv.org/pdf/2512.05216)
- [arXiv251208] AI & Human Co-Improvement for Safer Co-Superintelligence [link](https://arxiv.org/pdf/2512.05356)
- [arXiv251208] KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity [link](https://arxiv.org/pdf/2512.05916)
- [arXiv251208] UniFS: Unified Multi-Contrast MRI Reconstruction via Frequency-Spatial Fusion [link](https://arxiv.org/pdf/2512.05481)
- [arXiv251208] To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis [link](https://arxiv.org/pdf/2512.05925)
