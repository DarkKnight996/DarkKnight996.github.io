<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20251110-20251116" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251110-20251116 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20251110-20251116"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251110-20251116 | DarkKnight Note"><meta data-rh="true" name="description" content="2025-11-10"><meta data-rh="true" property="og:description" content="2025-11-10"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20251110-20251116"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20251110-20251116" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20251110-20251116" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20251110-20251116","item":"https://darkknight996.github.io/daily/20251110-20251116"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.f702760a.js" defer="defer"></script>
<script src="/assets/js/main.c2c5759f.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251110-20251116</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251110-20251116</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-11-10">2025-11-10<a href="#2025-11-10" class="hash-link" aria-label="Direct link to 2025-11-10" title="Direct link to 2025-11-10" translate="no">​</a></h2>
<p><strong>cs.DC total: 5</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251110] GPU Under Pressure: Estimating Application&#x27;s Stress via Telemetry and Performance Counters</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [telemetry parameters, hardware performance counters, throughput measurement, instruction count, stall events]</li>
<li class=""><strong>authors:</strong> Giuseppe Esposito, Juan-David Guerrero-Balaguera, Josie Esteban Rodriguez Condia, Matteo Sonza Reorda, Marco Barbiero, Rossella Fortuna</li>
<li class=""><strong>institution:</strong> Politecnico di Torino, Intesa Sanpaolo S.p.A.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.05067" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.05067</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes combining online telemetry parameters and hardware performance counters to estimate GPU stress caused by applications. The method focuses on measuring throughput, issued instructions, and stall events to assess workload efficiency. Results show this approach can effectively predict reliability issues and aging effects in GPUs under sustained parallel workloads.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251110] The Future of Fully Homomorphic Encryption System: from a Storage I/O Perspective</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [storage systems], [Fully Homomorphic Encryption, ASIC, GPU, storage I/O, performance analysis]</li>
<li class=""><strong>authors:</strong> Lei Chen, Erci Xu, Yiming Sun, Shengyu Fan, Xianglong Deng, Guiming Shi, Guang Fan, Liang Kong, Yilan Zhu, Shoumeng Yan, Mingzhe Zhang</li>
<li class=""><strong>institution:</strong> Ant Group, Shanghai Jiaotong University, University of Chinese Academy of Sciences, Tsinghua University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.04946" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.04946</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper analyzes the impact of storage I/O on Fully Homomorphic Encryption (FHE) application performance. The research finds that storage I/O significantly degrades performance, reducing ASIC performance by up to 357× and GPU performance by up to 22×, highlighting a critical bottleneck in FHE deployment.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251110] Accelerating HDC-CNN Hybrid Models Using Custom Instructions on RISC-V GPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [hyperdimensional computing, custom GPU instructions, RISC-V GPU, HDC-CNN hybrid models, microbenchmark testing]</li>
<li class=""><strong>authors:</strong> Wakuto Matsumi, Riaz-Ul-Haque Mian</li>
<li class=""><strong>institution:</strong> Shimane University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.05053" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.05053</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes custom GPU instructions for RISC-V GPUs to accelerate hybrid HDC-CNN models. The researchers implemented four specialized instructions optimized for hyperdimensional computing operations, achieving up to 56.2x performance improvement in microbenchmark tests. The work demonstrates RISC-V GPUs&#x27; potential for energy-efficient, high-performance computing through domain-specific instruction customization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251110] CUNQA: a Distributed Quantum Computing emulator for HPC</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [quantum computing simulation], [distributed quantum computing, quantum phase estimation, HPC emulation, quantum processing units]</li>
<li class=""><strong>authors:</strong> Jorge Vázquez-Pérez, Daniel Expósito-Patiño, Marta Losada, Álvaro Carballido, Andrés Gómez, Tomás F. Pena</li>
<li class=""><strong>institution:</strong> Galicia Supercomputing Center (CESGA), Universidad de Santiago de Compostela</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.05209" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.05209</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents CUNQA, an open-source distributed quantum computing emulator designed for HPC environments that implements three communication models: no-communication, classical-communication, and quantum-communication. The tool uses the Quantum Phase Estimation algorithm to demonstrate and analyze these distributed quantum computing schemes. CUNQA represents the first emulator capable of modeling all three distributed quantum computing approaches in HPC environments, enabling research and testing before physical quantum hardware becomes available.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251110] Marionette: Data Structure Description and Management for Heterogeneous Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [heterogeneous computing], [C++17 library, data layout abstraction, compile-time abstractions, memory management strategies, CUDA]</li>
<li class=""><strong>authors:</strong> Nuno dos Santos Fernandes, Pedro Tomás, Nuno Roma, Frank Winklmeier, Patricia Conde-Muíño</li>
<li class=""><strong>institution:</strong> Instituto Superior Técnico, INESC-ID, LIP, CERN, University of Oregon</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.04853" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.04853</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Marionette is a C++17 library that decouples data layout from interface descriptions to enable flexible and portable data structures for heterogeneous computing platforms. It provides efficient data transfers across devices with minimal runtime overhead through compile-time abstractions. The paper demonstrates that Marionette successfully addresses the challenges of adapting object-oriented C++ codebases for hardware acceleration while maintaining compatibility with existing code.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 14</strong></p>
<ul>
<li class="">[arXiv251110] QUESTER: Query Specification for Generative Retrieval <a href="https://arxiv.org/pdf/2511.05301" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning <a href="https://arxiv.org/pdf/2511.05489" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] DeepEyesV2: Toward Agentic Multimodal Model <a href="https://arxiv.org/pdf/2511.05271" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction <a href="https://arxiv.org/pdf/2511.05396" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] Quantum Boltzmann Machines for Sample-Efficient Reinforcement Learning <a href="https://arxiv.org/pdf/2511.04856" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models <a href="https://arxiv.org/pdf/2511.04902" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] Self-Interest and Systemic Benefits: Emergence of Collective Rationality in Mixed Autonomy Traffic Through Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2511.04883" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] FoodRL: A Reinforcement Learning Ensembling Framework For In-Kind Food Donation Forecasting <a href="https://arxiv.org/pdf/2511.04865" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] Reasoning Up the Instruction Ladder for Controllable Language Models <a href="https://arxiv.org/pdf/2511.04694" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework <a href="https://arxiv.org/pdf/2511.05385" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] Multi-agent Coordination via Flow Matching <a href="https://arxiv.org/pdf/2511.05005" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning <a href="https://arxiv.org/pdf/2511.04949" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale <a href="https://arxiv.org/pdf/2511.04904" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] An End-to-End Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drones <a href="https://arxiv.org/pdf/2511.05265" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 11</strong></p>
<ul>
<li class="">[arXiv251110] When Data Falls Short: Grokking Below the Critical Threshold <a href="https://arxiv.org/pdf/2511.04760" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning &amp; Scheduling <a href="https://arxiv.org/pdf/2511.04758" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] Building Specialized Software-Assistant ChatBot with Graph-Based Retrieval-Augmented Generation <a href="https://arxiv.org/pdf/2511.05297" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] LiveStar: Live Streaming Assistant for Real-World Online Video Understanding <a href="https://arxiv.org/pdf/2511.05299" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] Efficient Deployment of CNN Models on Multiple In-Memory Computing Units <a href="https://arxiv.org/pdf/2511.04682" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] APP: Accelerated Path Patching with Task-Specific Pruning <a href="https://arxiv.org/pdf/2511.05442" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] Diffusion-Based Electromagnetic Inverse Design of Scattering Structured Media <a href="https://arxiv.org/pdf/2511.05357" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning <a href="https://arxiv.org/pdf/2511.04831" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] Deep Progressive Training: scaling up depth capacity of zero/one-layer models <a href="https://arxiv.org/pdf/2511.04981" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] MDM: Manhattan Distance Mapping of DNN Weights for Parasitic-Resistance-Resilient Memristive Crossbars <a href="https://arxiv.org/pdf/2511.04798" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251110] A Gate-Based Quantum Genetic Algorithm for Real-Valued Global Optimization <a href="https://arxiv.org/pdf/2511.05254" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-11-11">2025-11-11<a href="#2025-11-11" class="hash-link" aria-label="Direct link to 2025-11-11" title="Direct link to 2025-11-11" translate="no">​</a></h2>
<p><strong>cs.DC total: 27</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251111] MT4G: A Tool for Reliable Auto-Discovery of NVIDIA and AMD GPU Compute and Memory Topologies</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Stepan Vanecek, Manuel Walter Mussbacher, Dominik Groessler, Urvij Saroliya, Martin Schulz</li>
<li class=""><strong>institution:</strong></li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.05958" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.05958</a></li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] DWM-RO: Decentralized World Models with Reasoning Offloading for SWIPT-enabled Satellite-Terrestrial HetNets</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Guangyuan Liu, Yinqiu Liu, Ruichen Zhang, Dusit Niyato, Jiawen Kang, Sumei Sun, Abbas Jamalipour, Ping Zhang</li>
<li class=""><strong>institution:</strong></li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.05972" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.05972</a></li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Efficient Dynamic MaxFlow Computation on GPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [graph algorithms], [Push-Relabel, GPU parallelization, dynamic graphs, batch updates]</li>
<li class=""><strong>authors:</strong> Shruthi Kannappan, Ashwina Kumar, Rupesh Nasre</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology Madras</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.05895" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.05895</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes two Push-Relabel based algorithms for dynamic MaxFlow computation on GPUs that efficiently handle both increments and decrements in edge capacities in batches. The algorithms are designed to process evolving real-world graphs without full recomputation. The results show that for small updates, dynamic recomputation is significantly faster than static GPU-based MaxFlow approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Kunlun Anomaly Troubleshooter: Enabling Kernel-Level Anomaly Detection and Causal Reasoning for Large Model Distributed Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [function trace data, kernel-level anomaly detection, domain-adapted LLM, causal reasoning, nanosecond resolution]</li>
<li class=""><strong>authors:</strong> Yuyang Liu, Jingjing Cai, Jiayi Ren, Peng Zhou, Danyang Zhang, Yin Du, Shijian Li</li>
<li class=""><strong>institution:</strong> Zhejiang University, Alibaba Cloud</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.05978" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.05978</a></li>
<li class=""><strong>Simple LLM Summary:</strong> KAT introduces a framework that uses function trace data to detect kernel-level anomalies at nanosecond resolution and integrates these detections with a domain-adapted LLM for causal reasoning. The system achieved high precision (0.884) and recall (0.936) in production evaluations. This significantly improves troubleshooting efficiency and success rates for large model distributed inference systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] LLMs as Packagers of HPC Software</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [retrieval-augmented generation, iterative refinement, repository analysis, diagnostic feedback]</li>
<li class=""><strong>authors:</strong> Caetano Melone, Daniel Nichols, Konstantinos Parasyris, Todd Gamblin, Harshitha Menon</li>
<li class=""><strong>institution:</strong> Lawrence Livermore National Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.05626" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.05626</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces SpackIt, an end-to-end framework that uses LLMs with repository analysis, retrieval of relevant examples, and iterative refinement through diagnostic feedback to generate Spack recipes for HPC software. Results show this approach increases installation success rates from 20% in zero-shot settings to over 80%, demonstrating the value of retrieval and structured feedback for reliable package synthesis.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Distributed Recoverable Sketches (Extended Version)</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [network monitoring], [Count-Min Sketch, distributed recovery, incremental updates, sketch partitioning, frequency estimation]</li>
<li class=""><strong>authors:</strong> Diana Cohen, Roy Friedman, Rana Shahout</li>
<li class=""><strong>institution:</strong> Technion, Harvard University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.05762" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.05762</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a distributed framework for recovering sketch data after node crashes in network environments, focusing on frequency estimation sketches like Count-Min Sketch. The system explores trade-offs between space consumption, runtime overheads, and recovery traffic while comparing periodic full updates versus incremental updates. The framework is designed to be modular and generic, allowing other data structures to be integrated via an abstract API.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] CoEdge-RAG: Optimizing Hierarchical Scheduling for Retrieval-Augmented LLMs in Collaborative Edge Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [retrieval-augmented generation, proximal policy optimization, online convex optimization, hierarchical scheduling, collaborative edge computing]</li>
<li class=""><strong>authors:</strong> Guihang Hong, Tao Ouyang, Kongyange Zhao, Zhi Zhou, Xu Chen</li>
<li class=""><strong>institution:</strong> Sun Yat-sen University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.05915" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.05915</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes CoEdge-RAG, a hierarchical scheduling framework that optimizes retrieval-augmented LLMs in collaborative edge environments. The method uses PPO for online query identification, dynamic inter-node workload balancing, and intra-node resource allocation via online convex optimization. Comprehensive evaluations show the framework achieves significant performance gains of 4.23% to 91.39% over baseline methods across various QA tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Inductive Loop Analysis for Practical HPC Application Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [compiler optimization], [symbolic analysis, loop optimization, software prefetching, pointer incrementation, automatic parallelization]</li>
<li class=""><strong>authors:</strong> Philipp Schaad, Tal Ben-Nun, Patrick Iff, Torsten Hoefler</li>
<li class=""><strong>institution:</strong> ETH Zurich, Lawrence Livermore National Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06052" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06052</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces SILO, a symbolic inductive loop optimization technique that models data accesses and dependencies as functions of loop nest strides. This approach enables automatic parallelization of sequentially-dependent loops and data movement optimizations. The method achieves up to 12× speedup over state-of-the-art approaches on scientific computing kernels from atmospheric models and numerical solvers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] An Efficient Gradient-Aware Error-Bounded Lossy Compressor for Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [error-bounded lossy compression, gradient compression, temporal correlation, convolutional kernels, exponential moving average, sign prediction]</li>
<li class=""><strong>authors:</strong> Zhijing Ye, Sheng Di, Jiamin Wang, Zhiqing Zhong, Zhaorui Zhang, Xiaodong Yu</li>
<li class=""><strong>institution:</strong> Stevens Institute of Technology, Argonne National Laboratory, Hong Kong Polytechnic University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.05770" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.05770</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a gradient-aware error-bounded lossy compression method for federated learning that exploits temporal correlations across training rounds and structural patterns in convolutional kernels. The method achieves up to 1.53× higher compression ratios than existing approaches while maintaining model accuracy. When integrated into a real FL framework, it reduces communication time by 76.1%-96.2% under bandwidth-constrained scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] HYDRA: Breaking the Global Ordering Barrier in Multi-BFT Consensus</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed consensus], [multi-BFT consensus, object-centric execution, lock-based coordination, deadlock resolution]</li>
<li class=""><strong>authors:</strong> Hanzheng Lyu, Shaokang Xie, Jianyu Niu, Mohammad Sadoghi, Yinqian Zhang, Cong Wang, Ivan Beschastnikh, Chen Feng</li>
<li class=""><strong>institution:</strong> University of British Columbia, University of California Davis, City University of Hong Kong, Southern University of Science and Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.05843" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.05843</a></li>
<li class=""><strong>Simple LLM Summary:</strong> HYDRA introduces an object-centric execution model that eliminates global ordering in Multi-BFT consensus by partitioning transactions and using lightweight lock-based coordination with deadlock resolution. Experimental results show it outperforms state-of-the-art Multi-BFT protocols, especially in the presence of stragglers. This demonstrates that removing global ordering enables both strong consistency and high performance in scalable consensus systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] MoSKA: Mixture of Shared KV Attention for Efficient Long-Sequence LLM Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [shared kv attention, sparse attention, disaggregated infrastructure, kv cache optimization, memory bandwidth optimization]</li>
<li class=""><strong>authors:</strong> Myunghyun Rhee, Sookyung Choi, Euiseok Kim, Joonseop Sim, Youngpyo Joo, Hoshik Kim</li>
<li class=""><strong>institution:</strong> SK hynix Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06010" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06010</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MoSKA, a novel architecture that addresses KV cache bottlenecks in long-sequence LLM inference by differentiating between unique and shared context data. The core innovation is Shared KV Attention, which transforms memory-bound operations into compute-bound GEMM operations through request batching. This approach achieves up to 538.7x throughput improvement in high-sharing workloads, providing a scalable path for efficient LLM inference.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Distributed Deep Learning for Medical Image Denoising with Data Obfuscation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [DistributedDataParallel, Automatic Mixed Precision, U-Net, U-Net++, multi-GPU training, data obfuscation]</li>
<li class=""><strong>authors:</strong> Sulaimon Oyeniyi Adebayo, Ayaz H. Khan</li>
<li class=""><strong>institution:</strong> King Fahd University of Petroleum and Minerals, SDAIA-KFUPM Joint Research Center for Artificial Intelligence</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06006" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06006</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper implements distributed deep learning for medical image denoising using U-Net and U-Net++ architectures with Gaussian noise obfuscation. The optimized training pipeline combining DistributedDataParallel and Automatic Mixed Precision reduced training time by over 60% compared to single-GPU training. Results show U-Net++ achieved superior denoising performance with enhanced structural fidelity while maintaining practical viability for clinical applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Elastic Data Transfer Optimization with Hybrid Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [deep reinforcement learning, heuristic-based parallelism, infinite pipelining, network simulator]</li>
<li class=""><strong>authors:</strong> Rasman Mubtasim Swargo, Md Arifuzzaman</li>
<li class=""><strong>institution:</strong> Missouri University of Science and Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06159" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06159</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents LDM, an adaptive data transfer method that combines heuristic-based parallelism, infinite pipelining, and deep reinforcement learning to optimize multiple transfer parameters simultaneously. It introduces a lightweight network simulator that reduces training time from days to minutes. Experimental results show the method achieves up to 9.5× higher throughput compared to state-of-the-art solutions across diverse datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] LiteCast: A Lightweight Forecaster for Carbon Optimizations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [time series forecasting, carbon intensity prediction, lightweight forecasting, energy mix modeling]</li>
<li class=""><strong>authors:</strong> Mathew Joseph, Tanush Savadi, Abel Souza</li>
<li class=""><strong>institution:</strong> Unknown</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06187" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06187</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LiteCast is a lightweight time series forecasting method that uses minimal historical energy and weather data to predict grid carbon intensity. The paper demonstrates that preserving forecast rankings rather than achieving high precision drives most carbon savings. Evaluation across 50 regions shows LiteCast achieves 97% of maximum attainable savings while being computationally efficient and adaptive to grid changes.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] PRAGMA: A Profiling-Reasoned Multi-Agent Framework for Automatic Kernel Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [profile-guided optimization, multi-agent framework, hardware profiling, kernel generation, iterative refinement]</li>
<li class=""><strong>authors:</strong> Kelun Lei, Hailong Yang, Huaitao Zhang, Xin You, Kaige Zhang, Zhongzhi Luan, Yi Liu, Depei Qian</li>
<li class=""><strong>institution:</strong> Beihang University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06345" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06345</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PRAGMA introduces a profile-guided multi-agent framework that integrates fine-grained hardware profiling into the kernel optimization loop, enabling LLMs to identify performance bottlenecks and iteratively refine code. The system consistently outperforms baseline approaches without profiling and achieves significant speedups (2.81× on CPU, 2.30× on GPU) compared to Torch implementations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Reliablocks: Developing Reliability Scores for Optimistic Rollups</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain scalability], [optimistic rollups, reliability scores, smart contracts, AVS components, WASMI]</li>
<li class=""><strong>authors:</strong> Souradeep Das, Ethan Lam, Varun Vaidya, Sanjay Amirthraj</li>
<li class=""><strong>institution:</strong> EigenLayer</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06130" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06130</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Reliablocks, an on-chain reliability index that assesses non-finalized blocks in Optimistic Rollups to help users determine transaction finality. It was developed during the EigenLayer Infinite Hackathon and includes working AVS components, smart contracts, and a dashboard interface. The system aims to provide transparency about block reliability during the 7-day finalization period, benefiting L2 users who cannot run validators themselves.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Towards Optimal Constellation Design for Digital Over-the-Air Computation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [wireless communications], [digital modulation, constellation design, mean-squared error minimization, additive mapping, generalized Lambert function]</li>
<li class=""><strong>authors:</strong> Saeed Razavikia, Deniz Gündüz, Carlo Fischione</li>
<li class=""><strong>institution:</strong> KTH Royal Institute of Technology, Imperial College London</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06372" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06372</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a digital modulation framework for over-the-air computation that optimizes constellation design to minimize mean-squared error under power constraints. The authors formulate the problem as a system of nonlinear equations and derive closed-form solutions using the generalized Lambert function in high SNR regimes. The framework provides analytical insights and can be extended to multi-dimensional grids, non-Gaussian noise, and hybrid digital-analog modulation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] FPGA or GPU? Analyzing comparative research for application-specific guidance</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [hardware accelerators, FPGA, GPU, performance metrics, energy efficiency, programmability]</li>
<li class=""><strong>authors:</strong> Arnab A Purkayastha, Jay Tharwani, Shobhit Aggarwal</li>
<li class=""><strong>institution:</strong> Western New England University, The Citadel</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06565" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06565</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper synthesizes insights from comparative research studies to analyze FPGA and GPU performance across different application domains. By categorizing studies and analyzing key metrics, it provides application-specific guidance for selecting appropriate hardware accelerators. The main conclusion is that FPGAs excel in real-time, power-sensitive tasks while GPUs are better suited for data-intensive parallel processing with mature programming frameworks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Optimizing Long-context LLM Serving via Fine-grained Sequence Parallelism</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [sequence parallelism, chunkwise dynamic sequence parallelism, ring attention, tensor parallelism, disaggregated cluster]</li>
<li class=""><strong>authors:</strong> Cong Li, Yuzhe Yang, Xuegui Zheng, Qifan Yang, Yijin Guan, Size Zheng, Li-Wen Chang, Shufan Liu, Xin Liu, Guangyu Sun</li>
<li class=""><strong>institution:</strong> Peking University, Bytedance</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06247" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06247</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Chunkwise Dynamic Sequence Parallelism (CDSP), a fine-grained parallelism strategy that assigns SP sizes across intra-request token segments, and builds Tetris, an LLM serving system based on CDSP. Tetris achieves significantly better performance than state-of-the-art systems, reducing time-to-first-token by up to 4.35× and increasing maximum request capacity by up to 45% while optimizing resource utilization in long-context LLM serving.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] DMA Collectives for Efficient ML Communication Offloads</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [DMA collectives, all-gather, all-to-all, RCCL, synchronization optimization, AMD MI300X]</li>
<li class=""><strong>authors:</strong> Suchita Pati, Mahzabeen Islam, Shaizeen Aga, Mohamed Assem Ibrahim</li>
<li class=""><strong>institution:</strong> Advanced Micro Devices, Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06605" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06605</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper analyzes offloading machine learning communication collectives to DMA engines on AMD MI300X GPUs, comparing performance against RCCL libraries. The research shows DMA collectives perform well for large data transfers but lag for small sizes due to synchronization overheads. Through optimized implementations leveraging DMA architecture innovations, the authors significantly close this performance gap, making DMA collectives more suitable for mainstream adoption.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Saarthi: An End-to-End Intelligent Platform for Optimising Distributed Serverless Workloads</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [input-aware resource allocation, function right-sizing, multi-objective Integer Linear Programming, proactive fault-tolerant redundancy, smart request orchestration]</li>
<li class=""><strong>authors:</strong> Siddharth Agarwal, Maria A. Rodriguez, Rajkumar Buyya</li>
<li class=""><strong>institution:</strong> The University of Melbourne</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06599" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06599</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Saarthi is an end-to-end serverless framework that uses input-aware resource prediction and multi-objective optimization to dynamically manage function workloads. It achieves up to 1.45x better throughput and 1.84x reduced costs while maintaining 98.3% service level targets compared to baseline OpenFaaS. The system demonstrates significant improvements in serverless computing efficiency through intelligent resource allocation and request orchestration.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Argus: Quality-Aware High-Throughput Text-to-Image Inference Serving System</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [approximate computing, quality-aware scheduling, model switching, throughput optimization]</li>
<li class=""><strong>authors:</strong> Shubham Agarwal, Subrata Mitra, Saud Iqbal</li>
<li class=""><strong>institution:</strong> UC Berkeley, Adobe Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06724" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06724</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Argus is a text-to-image inference serving system that intelligently selects appropriate approximation levels for each prompt to balance quality and throughput. The system dynamically switches between different approximation strategies to meet both quality requirements and throughput targets. Compared to baselines, Argus achieves 10x fewer latency violations, 10% higher quality, and 40% higher throughput on real-world workloads.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Wireless Sensor Networks Nodes Clustering and Optimization Based on Fuzzy C-Means and Water Strider Algorithms</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [Water Strider Algorithm, Fuzzy C-Means, clustering optimization, energy efficiency, network lifetime, hybrid metaheuristics]</li>
<li class=""><strong>authors:</strong> Raya Majid Alsharfa, Mahmood Mohassel Feghhi, Majid Hameed Majeed</li>
<li class=""><strong>institution:</strong> Middle Technical University, University of Tabriz, Al-Mustaqbal University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06735" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06735</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a hybrid clustering protocol that combines Water Strider Algorithm for global optimization of cluster-head positions with Fuzzy C-Means for refined node membership assignment. The method significantly improves energy efficiency and network lifetime in wireless sensor networks, outperforming existing hybrid approaches across all performance metrics with statistical validation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Resilient by Design - Active Inference for Distributed Continuum Intelligence</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [active inference, free-energy principle, Markov blanket, causal fault graph, Bayesian network structure learning]</li>
<li class=""><strong>authors:</strong> Praveen Kumar Donta, Alfreds Lapkovskis, Enzo Mingozzi, Schahram Dustdar</li>
<li class=""><strong>institution:</strong> Stockholm University, University of Pisa, TU Wien, ICREA</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.07202" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.07202</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a Probabilistic Active Inference Resilience Agent (PAIR-Agent) that uses causal fault graphs and the free-energy principle to autonomously detect and heal faults in distributed computing continuum systems. The framework continuously monitors system components and performs adaptive reconfiguration to maintain service stability under diverse failure conditions. Theoretical validations confirm the reliability and effectiveness of the proposed resilience approach.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [robotic manipulation], [contact fields, procedural grasp synthesis, geometric computation decoupling]</li>
<li class=""><strong>authors:</strong> Zhao-Heng Yin, Pieter Abbeel</li>
<li class=""><strong>institution:</strong> UC Berkeley</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.07418" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.07418</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Lightning Grasp introduces a procedural grasp synthesis algorithm that uses Contact Fields to decouple geometric computation from the search process. This approach achieves orders-of-magnitude speed improvements over state-of-the-art methods while generating diverse grasps for irregular objects. The method eliminates the need for manually tuned energy functions and enables real-time grasp synthesis for dexterous robotic hands.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] A GPU-boosted high-performance multi-working condition joint analysis framework for predicting dynamics of textured axial piston pump</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [computational fluid dynamics], [GPU acceleration, Preconditioned Conjugate Gradient method, Approximate Symmetric Successive Over-Relaxation preconditioner, synchronized convergence strategy, finite volume method]</li>
<li class=""><strong>authors:</strong> Xin Yao, Yang Liu, Jin Jiang, Yesen Chen, Zhilong Chen, Hongkang Dong, Xiaofeng Wei, Teng Zhang, Dongyun Wang</li>
<li class=""><strong>institution:</strong> Zhejiang Normal University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.06824" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.06824</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a GPU-accelerated framework (GMAF) that uses Preconditioned Conjugate Gradient method with ASSOR preconditioner to efficiently simulate axial piston pump dynamics. The framework enables analysis of both smooth and textured pumps across multiple periods by accelerating pressure field computations and numerical integration. Results show that textured surfaces improve pressure capacity and torsion resistance, with pressure fields exhibiting step-like patterns corresponding to surface textures.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251111] LLMServingSim2.0: A Unified Simulator for Heterogeneous Hardware and Serving Techniques in LLM Infrastructure</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [trace-driven performance modeling, operator-level latency profiler, heterogeneous hardware integration, request routing, cache management, scheduling policies]</li>
<li class=""><strong>authors:</strong> Jaehong Cho, Hyunmin Choi, Jongse Park</li>
<li class=""><strong>institution:</strong> Korea Advanced Institute of Science and Technology (KAIST)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2511.07229" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2511.07229</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LLMServingSim2.0 introduces a unified simulator using trace-driven performance modeling and operator-level profiling to enable easy integration of heterogeneous hardware with modern LLM serving techniques. The system demonstrates 18.5× fewer lines of code for hardware integration and achieves only 1.9% error in reproducing GPU-based LLM serving. This makes it a comprehensive platform for both hardware developers and LLM service providers to evaluate heterogeneous systems efficiently.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 48</strong></p>
<ul>
<li class="">[arXiv251111] Revisiting Entropy in Reinforcement Learning for Large Reasoning Models <a href="https://arxiv.org/pdf/2511.05993" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Distributionally Robust Self Paced Curriculum Reinforcement Learning <a href="https://arxiv.org/pdf/2511.05694" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs <a href="https://arxiv.org/pdf/2511.05933" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] CoPRIS: Efficient and Stable Reinforcement Learning via Concurrency-Controlled Partial Rollout with Importance Sampling <a href="https://arxiv.org/pdf/2511.05589" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Lookahead Unmasking Elicits Accurate Decoding in Diffusion Language Models <a href="https://arxiv.org/pdf/2511.05563" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] WAR-Re: Web API Recommendation with Semantic Reasoning <a href="https://arxiv.org/pdf/2511.05820" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Policy Gradient-Based EMT-in-the-Loop Learning to Mitigate Sub-Synchronous Control Interactions <a href="https://arxiv.org/pdf/2511.05822" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Klear-AgentForge: Forging Agentic Intelligence through Posttraining Scaling <a href="https://arxiv.org/pdf/2511.05951" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] EGG-SR: Embedding Symbolic Equivalence into Symbolic Regression via Equality Graph <a href="https://arxiv.org/pdf/2511.05849" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] SymLight: Exploring Interpretable and Deployable Symbolic Policies for Traffic Signal Control <a href="https://arxiv.org/pdf/2511.05790" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Adaptive Agent Selection and Interaction Network for Image-to-point cloud Registration <a href="https://arxiv.org/pdf/2511.05965" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] ScRPO: From Errors to Insights <a href="https://arxiv.org/pdf/2511.06065" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Approximating Shapley Explanations in Reinforcement Learning <a href="https://arxiv.org/pdf/2511.06094" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Guardian-regularized Safe Offline Reinforcement Learning for Smart Weaning of Mechanical Circulatory Devices <a href="https://arxiv.org/pdf/2511.06111" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] A Deep Learning Model for Predicting Transformation Legality <a href="https://arxiv.org/pdf/2511.06120" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Maestro: Learning to Collaborate via Conditional Listwise Policy Optimization for Multi-Agent LLMs <a href="https://arxiv.org/pdf/2511.06134" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks <a href="https://arxiv.org/pdf/2511.06136" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] MALinZero: Efficient Low-Dimensional Search for Mastering Complex Multi-Agent Planning <a href="https://arxiv.org/pdf/2511.06142" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Deep Reinforcement Learning for Dynamic Origin-Destination Matrix Estimation in Microscopic Traffic Simulations Considering Credit Assignment <a href="https://arxiv.org/pdf/2511.06229" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] MrCoM: A Meta-Regularized World-Model Generalizing Across Multi-Scenarios <a href="https://arxiv.org/pdf/2511.06252" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] What Makes Reasoning Invalid: Echo Reflection Mitigation for Large Language Models <a href="https://arxiv.org/pdf/2511.06380" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization <a href="https://arxiv.org/pdf/2511.06411" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] CG-TTRL: Context-Guided Test-Time Reinforcement Learning for On-Device Large Language Models <a href="https://arxiv.org/pdf/2511.06430" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Brain-Inspired Planning for Better Generalization in Reinforcement Learning <a href="https://arxiv.org/pdf/2511.06470" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Zooming into Comics: Region-Aware RL Improves Fine-Grained Comic Understanding in Vision-Language Models <a href="https://arxiv.org/pdf/2511.06490" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Practical Policy Distillation for Reinforcement Learning in Radio Access Networks <a href="https://arxiv.org/pdf/2511.06563" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with Group Relative Policy Optimization <a href="https://arxiv.org/pdf/2511.06618" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View <a href="https://arxiv.org/pdf/2511.06722" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning <a href="https://arxiv.org/pdf/2511.06745" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] OntoTune: Ontology-Driven Learning for Query Optimization with Convolutional Models <a href="https://arxiv.org/pdf/2511.06780" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Controllable Flow Matching for Online Reinforcement Learning <a href="https://arxiv.org/pdf/2511.06816" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] On The Presence of Double-Descent in Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2511.06895" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Fine-Tuning Diffusion-Based Recommender Systems via Reinforcement Learning with Reward Function Optimization <a href="https://arxiv.org/pdf/2511.06937" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Learning to Focus: Prioritizing Informative Histories with Structured Attention Mechanisms in Partially Observable Reinforcement Learning <a href="https://arxiv.org/pdf/2511.06946" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Learning Quantized Continuous Controllers for Integer Hardware <a href="https://arxiv.org/pdf/2511.07046" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture <a href="https://arxiv.org/pdf/2511.07110" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Dynamics-Decoupled Trajectory Alignment for Sim-to-Real Transfer in Reinforcement Learning for Autonomous Driving <a href="https://arxiv.org/pdf/2511.07155" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Guiding Generative Models to Uncover Diverse and Novel Crystals via Reinforcement Learning <a href="https://arxiv.org/pdf/2511.07158" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Enabling Off-Policy Imitation Learning with Deep Actor Critic Stabilization <a href="https://arxiv.org/pdf/2511.07288" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search <a href="https://arxiv.org/pdf/2511.07312" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] RLVE: Scaling Up Reinforcement Learning for Language Models with Adaptive Verifiable Environments <a href="https://arxiv.org/pdf/2511.07317" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation <a href="https://arxiv.org/pdf/2511.07322" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction <a href="https://arxiv.org/pdf/2511.07327" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Q-RAG: Long Context Multi-step Retrieval via Value-based Embedder Training <a href="https://arxiv.org/pdf/2511.07328" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Grounding Computer Use Agents on Human Demonstrations <a href="https://arxiv.org/pdf/2511.07332" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Provable Benefit of Curriculum in Transformer Tree-Reasoning Post-Training <a href="https://arxiv.org/pdf/2511.07372" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Robot Learning from a Physical World Model <a href="https://arxiv.org/pdf/2511.07416" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Convergence of Actor-Critic Learning for Mean Field Games and Mean Field Control in Continuous Spaces <a href="https://arxiv.org/pdf/2511.06812" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 21</strong></p>
<ul>
<li class="">[arXiv251111] GastroDL-Fusion: A Dual-Modal Deep Learning Framework Integrating Protein-Ligand Complexes and Gene Sequences for Gastrointestinal Disease Drug Discovery <a href="https://arxiv.org/pdf/2511.05726" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Physics-Informed Neural Networks for Real-Time Gas Crossover Prediction in PEM Electrolyzers: First Application with Multi-Membrane Validation <a href="https://arxiv.org/pdf/2511.05879" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] wa-hls4ml: A Benchmark and Surrogate Models for hls4ml Resource and Latency Estimation <a href="https://arxiv.org/pdf/2511.05615" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Hilbert-Guided Block-Sparse Local Attention <a href="https://arxiv.org/pdf/2511.05832" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] EGG-SR: Embedding Symbolic Equivalence into Symbolic Regression via Equality Graph <a href="https://arxiv.org/pdf/2511.05849" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] 10 Open Challenges Steering the Future of Vision-Language-Action Models <a href="https://arxiv.org/pdf/2511.05936" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] AutoHood3D: A Multi-Modal Benchmark for Automotive Hood Design and Fluid-Structure Interaction <a href="https://arxiv.org/pdf/2511.05596" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] LUT-LLM: Efficient Large Language Model Inference with Memory-based Computations on FPGAs <a href="https://arxiv.org/pdf/2511.06174" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Practical Policy Distillation for Reinforcement Learning in Radio Access Networks <a href="https://arxiv.org/pdf/2511.06563" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] SteganoSNN: SNN-Based Audio-in-Image Steganography with Encryption <a href="https://arxiv.org/pdf/2511.06573" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Optimistic Online-to-Batch Conversions for Accelerated Convergence and Universality <a href="https://arxiv.org/pdf/2511.06597" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] ML-EcoLyzer: Quantifying the Environmental Cost of Machine Learning Inference Across Frameworks and Hardware <a href="https://arxiv.org/pdf/2511.06694" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] QUARK: Quantization-Enabled Circuit Sharing for Transformer Acceleration by Exploiting Common Patterns in Nonlinear Operations <a href="https://arxiv.org/pdf/2511.06767" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Neural-Initialized Newton: Accelerating Nonlinear Finite Elements via Operator Learning <a href="https://arxiv.org/pdf/2511.06802" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] DeepRWCap: Neural-Guided Random-Walk Capacitance Solver for IC Design <a href="https://arxiv.org/pdf/2511.06831" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] P3-LLM: An Integrated NPU-PIM Accelerator for LLM Inference Using Hybrid Numerical Formats <a href="https://arxiv.org/pdf/2511.06838" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] TNT: Improving Chunkwise Training for Test-Time Memorization <a href="https://arxiv.org/pdf/2511.07343" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Inference-Time Scaling of Diffusion Models for Infrared Data Generation <a href="https://arxiv.org/pdf/2511.07362" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] DigiData: Training and Evaluating General-Purpose Mobile Control Agents <a href="https://arxiv.org/pdf/2511.07413" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] AIRMap - AI-Generated Radio Maps for Wireless Digital Twins <a href="https://arxiv.org/pdf/2511.05522" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251111] Machine-Learning Accelerated Calculations of Reduced Density Matrices <a href="https://arxiv.org/pdf/2511.07367" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-11-11T04:14:21.000Z" itemprop="dateModified">Nov 11, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20251103-20251109"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251103-20251109</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-11-10" class="table-of-contents__link toc-highlight">2025-11-10</a></li><li><a href="#2025-11-11" class="table-of-contents__link toc-highlight">2025-11-11</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>