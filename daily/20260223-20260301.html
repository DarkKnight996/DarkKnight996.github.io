<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20260223-20260301" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20260223-20260301 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20260223-20260301"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20260223-20260301 | DarkKnight Note"><meta data-rh="true" name="description" content="2026-02-23"><meta data-rh="true" property="og:description" content="2026-02-23"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20260223-20260301"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260223-20260301" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260223-20260301" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20260223-20260301","item":"https://darkknight996.github.io/daily/20260223-20260301"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.6cdbb34f.js" defer="defer"></script>
<script src="/assets/js/main.c7401d40.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260105-20260111"><span title="20260105-20260111" class="linkLabel_WmDU">20260105-20260111</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260112-20260118"><span title="20260112-20260118" class="linkLabel_WmDU">20260112-20260118</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260119-20260125"><span title="20260119-20260125" class="linkLabel_WmDU">20260119-20260125</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260126-20260201"><span title="20260126-20260201" class="linkLabel_WmDU">20260126-20260201</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260202-20260208"><span title="20260202-20260208" class="linkLabel_WmDU">20260202-20260208</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260209-20260215"><span title="20260209-20260215" class="linkLabel_WmDU">20260209-20260215</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260216-20260222"><span title="20260216-20260222" class="linkLabel_WmDU">20260216-20260222</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20260223-20260301"><span title="20260223-20260301" class="linkLabel_WmDU">20260223-20260301</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20260223-20260301</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20260223-20260301</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-23">2026-02-23<a href="#2026-02-23" class="hash-link" aria-label="Direct link to 2026-02-23" title="Direct link to 2026-02-23" translate="no">​</a></h2>
<p><strong>cs.DC total: 13</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260223] Message-Oriented Middleware Systems: Technology Overview</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems], [message-oriented middleware, publish/subscribe, brokers, multi-tenancy, flow control]</li>
<li class=""><strong>authors:</strong> Wael Al-Manasrah, Zuhair AlSader, Tim Brecht, Ahmed Alquraan, Samer Al-Kiswany</li>
<li class=""><strong>institution:</strong> University of Waterloo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17774" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17774</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a comprehensive characterization study of ten open-source message-oriented middleware (MOM) systems, analyzing 42 features across them. The main conclusion is that MOM systems have evolved into flexible frameworks for cloud applications, and the authors identify an opportunity for the community to consolidate efforts on fewer open-source projects.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260223] Distributed Triangle Enumeration in Hypergraphs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed algorithms], [CONGEST model, hypergraph, triangle enumeration, computational models, sparse hypergraphs]</li>
<li class=""><strong>authors:</strong> Duncan Adamson, Will Rosenbaum, Paul G. Spirakis</li>
<li class=""><strong>institution:</strong> University of St Andrews, University of Liverpool</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17834" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17834</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces new computational models for distributed algorithms on hypergraphs, generalizing the CONGEST model. It presents algorithms for distributed triangle enumeration in these models, proves their optimality in some cases, and develops efficient methods for sparse hypergraph classes. The work establishes a foundational framework for distributed sub-hypergraph enumeration.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260223] Collaborative Processing for Multi-Tenant Inference on Memory-Constrained Edge TPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [collaborative processing, model partitioning, queueing model, memory swapping, adaptive scheduling, Edge TPU]</li>
<li class=""><strong>authors:</strong> Nathan Ng, Walid A. Hanafy, Prashanthi Kadambi, Balachandra Sunil, Ayush Gupta, David Irwin, Yogesh Simmhan, Prashant Shenoy</li>
<li class=""><strong>institution:</strong> University of Massachusetts Amherst, Indian Institute of Science</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17808" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17808</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents SwapLess, a system that uses an analytic queueing model to adaptively partition AI model inference between CPU and Edge TPU resources and allocate CPU cores online, minimizing end-to-end latency. It demonstrates that this approach significantly reduces mean latency for both single-tenant and multi-tenant workloads compared to default compiler strategies.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260223] It&#x27;s Not Just Timestamps: A Study on Docker Reproducibility</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [container security], [Docker, reproducible builds, software supply chain, Dockerfile, OCI images, bitwise reproducibility, timestamps, metadata, caching]</li>
<li class=""><strong>authors:</strong> Oreofe Solarin</li>
<li class=""><strong>institution:</strong> Case Western Reserve University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17678" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17678</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper builds a measurement pipeline to analyze the bitwise reproducibility of Docker container images built from Dockerfiles in a sample of 2,000 GitHub repositories. It concludes that very few Docker builds are reproducible, and the primary causes are developer-controlled factors like uncleaned caches and floating software versions, not just timestamps.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260223] Distributed Security: From Isolated Properties to Synergistic Trust</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems security], [Byzantine fault tolerance, consensus protocols, secure multi-party computation, cryptographic primitives, agreement, consistency, privacy, verifiability, accountability]</li>
<li class=""><strong>authors:</strong> Minghui Xu</li>
<li class=""><strong>institution:</strong> Shandong University, Quan Cheng Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.18063" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.18063</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This vision paper argues for a paradigm shift in distributed security research, moving from the isolated study of foundational properties like agreement and privacy to understanding their synergistic combinations. The core method involves analyzing the convergence of these properties to create a unified fabric of trust. The main conclusion is that the future of the field lies in harnessing these synergies rather than optimizing individual properties in isolation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260223] Faster Parallel Batch-Dynamic Algorithms for Low Out-Degree Orientation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [graph algorithms], [parallel batch-dynamic algorithms, low out-degree orientation, arboricity, polylogarithmic span]</li>
<li class=""><strong>authors:</strong> Guy Blelloch, Andrew Brady, Laxman Dhulipala, Jeremy Fineman, Kishen Gowda, Chase Hutton</li>
<li class=""><strong>institution:</strong> Carnegie Mellon University, University of Maryland, Georgetown University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17811" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17811</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents new parallel batch-dynamic algorithms for maintaining a low out-degree orientation of an undirected graph. The algorithms achieve polylogarithmic span and improve upon prior work by reducing the work per edge update, offering results with asymptotically optimal expected work, expected worst-case work of O(√log n), and O(log² n) expected worst-case work for different orientation bounds.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260223] Joint Training on AMD and NVIDIA GPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [heterogeneous training, CPU-Forwarding Communication, Device-Direct Communication, GPUDirect RDMA, CPU-offloading P2P, multi-NIC parallel data transfer]</li>
<li class=""><strong>authors:</strong> Jon Hu, Thomas Jia, Jing Zhu, Zhendong Yu</li>
<li class=""><strong>institution:</strong> Zettabyte AI, Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.18007" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.18007</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes two methods for joint training of large language models on heterogeneous clusters containing both AMD and NVIDIA GPUs. The core contribution is a high-performance Device-Direct Communication approach that enables direct data transfer between different vendor GPUs, eliminating host-memory staging. Experiments show this method achieves up to 98% of the throughput of a homogeneous NVIDIA system while maintaining training stability.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260223] GPU Memory and Utilization Estimation for Training-Aware Resource Management: Opportunities and Limitations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [memory estimation, utilization estimation, analytical models, ML-based estimators, PyTorch FakeTensor, Horus, interference-aware scheduling]</li>
<li class=""><strong>authors:</strong> Ehsan Yousefzadeh-Asl-Miandoab, Reza Karimzadeh, Danyal Yorulmaz, Bulat Ibragimov, Pınar Tözün</li>
<li class=""><strong>institution:</strong> IT University of Copenhagen, University of Copenhagen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17817" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17817</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper systematically analyzes three paradigms for estimating GPU memory and utilization—analytical models, CPU-side libraries, and ML-based estimators—to improve resource management for collocated deep learning training. The evaluation reveals key trade-offs: analytical models are hardware-dependent, libraries impose integration costs, and ML estimators struggle with generalization. The authors release datasets and tools to support further research in this area.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260223] Closing Africa&#x27;s Early Warning Gap: AI Weather Forecasting for Disaster Prevention</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [NVIDIA Earth-2, PostgreSQL, ProcessPoolExecutor, aiobotocore, async Python, database-backed serving, coordinate management, WhatsApp distribution]</li>
<li class=""><strong>authors:</strong> Qness Ndlovu</li>
<li class=""><strong>institution:</strong> Dimension Research Lab</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17726" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17726</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a low-cost, production-grade architecture using NVIDIA Earth-2 AI weather models and PostgreSQL caching to deliver national-scale weather forecasts in Africa. The system reduces deployment costs by over 2,000x compared to traditional radar, enabling effective early warning systems via widely accessible channels like WhatsApp. The main conclusion is that this AI-driven approach makes continent-scale disaster prevention economically viable, potentially reducing disaster death rates significantly.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260223] Mind the Boundary: Stabilizing Gemini Enterprise A2A via a Cloud Run Hub Across Projects and Accounts</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [agent-to-agent (A2A) protocol, JSON-RPC, Cloud Run, retrieval-augmented generation (RAG), Vertex AI, Google Cloud Storage, IAM authentication]</li>
<li class=""><strong>authors:</strong> Takao Morita</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17675" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17675</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper implements an A2A Hub orchestrator on Cloud Run to route queries from the Gemini Enterprise UI to various backend agents and tools across different Google Cloud projects and accounts. It identifies and addresses a key interoperability gap where the UI&#x27;s text-only input constraints cause errors with structured JSON-RPC responses, solved by enforcing a text-only compatibility mode. The main conclusion is that practical, stable multi-agent orchestration requires managing not just protocol compliance but also UI constraints and cross-boundary authentication.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260223] A reliability- and latency-driven task allocation framework for workflow applications in the edge-hub-cloud continuum</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [edge computing], [binary integer linear programming, multi-objective optimization, task allocation, time redundancy]</li>
<li class=""><strong>authors:</strong> Andreas Kouloumpris, Georgios L. Stavrinides, Maria K. Michael, Theocharis Theocharides</li>
<li class=""><strong>institution:</strong> University of Cyprus, KIOS Research and Innovation Center of Excellence</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.18158" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.18158</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes an exact multi-objective task allocation framework using binary integer linear programming to jointly optimize reliability and latency for workflow applications in an edge-hub-cloud architecture. The method incorporates time redundancy and key constraints, demonstrating significant improvements in reliability and latency over baselines in experiments with real-world and synthetic workflows.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260223] It does not matter how you define locally checkable labelings</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed graph algorithms], [locally checkable labeling, LOCAL model, round elimination, symmetry-breaking oracle, node-edge checkable]</li>
<li class=""><strong>authors:</strong> Antonio Cruciani, Avinandan Das, Alesya Raevskaya, Jukka Suomela</li>
<li class=""><strong>institution:</strong> Aalto University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.18188" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.18188</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper shows that the family of Locally Checkable Labeling (LCL) problems is robust to definitional variations by proving local reductions between a standard LCL formalism and a more restricted &quot;node-edge checkable&quot; formalism. The main conclusion is that even with a stricter definition, LCL problems retain counterintuitive properties, indicating these properties are inherent to the problem family and not artifacts of the original definition.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260223] Green by Design: Constraint-Based Adaptive Deployment in the Cloud Continuum</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud-edge deployment], [green constraints, adaptive orchestration, energy-aware scheduling, cloud continuum, deployment plans]</li>
<li class=""><strong>authors:</strong> Andrea D&#x27;Iapico, Monica Vitali</li>
<li class=""><strong>institution:</strong> Politecnico di Milano</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.18287" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.18287</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a methodology for generating environmentally sustainable deployment plans for cloud-native applications across the cloud-edge continuum. The core method involves automatically learning and updating &quot;green constraints&quot; from monitoring data on energy consumption and infrastructure carbon intensity to guide an adaptive scheduler. The approach is validated to effectively reduce energy usage and associated emissions in realistic deployment scenarios.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 17</strong></p>
<ul>
<li class="">[arXiv260223] Whole-Brain Connectomic Graph Model Enables Whole-Body Locomotion Control in Fruit Fly <a href="https://arxiv.org/pdf/2602.17997" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Gradient Regularization Prevents Reward Hacking in Reinforcement Learning from Human Feedback and Verifiable Rewards <a href="https://arxiv.org/pdf/2602.18037" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] MePoly: Max Entropy Polynomial Policy Optimization <a href="https://arxiv.org/pdf/2602.17832" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Epistemic Traps: Rational Misalignment Driven by Model Misspecification <a href="https://arxiv.org/pdf/2602.17676" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets <a href="https://arxiv.org/pdf/2602.18025" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Optimal Multi-Debris Mission Planning in LEO: A Deep Reinforcement Learning Approach with Co-Elliptic Transfers and Refueling <a href="https://arxiv.org/pdf/2602.17685" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] CodeScaler: Scaling Code LLM Training and Test-Time Inference via Execution-Free Reward Models <a href="https://arxiv.org/pdf/2602.17684" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Flow Actor-Critic for Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2602.18015" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Mean-Field Reinforcement Learning without Synchrony <a href="https://arxiv.org/pdf/2602.18026" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] MIRA: Memory-Integrated Reinforcement Learning Agent with Limited LLM Guidance <a href="https://arxiv.org/pdf/2602.17930" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Learning Optimal and Sample-Efficient Decision Policies with Guarantees <a href="https://arxiv.org/pdf/2602.17978" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Memory-Based Advantage Shaping for LLM-Guided Reinforcement Learning <a href="https://arxiv.org/pdf/2602.17931" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Interacting safely with cyclists using Hamilton-Jacobi reachability and reinforcement learning <a href="https://arxiv.org/pdf/2602.18097" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] TempoNet: Slack-Quantized Transformer-Guided Reinforcement Scheduler for Adaptive Deadline-Centric Real-Time Dispatchs <a href="https://arxiv.org/pdf/2602.18109" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Flow Matching with Injected Noise for Offline-to-Online Reinforcement Learning <a href="https://arxiv.org/pdf/2602.18117" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] PRISM: Parallel Reward Integration with Symmetry for MORL <a href="https://arxiv.org/pdf/2602.18277" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies <a href="https://arxiv.org/pdf/2602.18291" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 9</strong></p>
<ul>
<li class="">[arXiv260223] Solving and learning advective multiscale Darcian dynamics with the Neural Basis Method <a href="https://arxiv.org/pdf/2602.17776" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Hardware-Friendly Input Expansion for Accelerating Function Approximation <a href="https://arxiv.org/pdf/2602.17952" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Multi-material Multi-physics Topology Optimization with Physics-informed Gaussian Process Priors <a href="https://arxiv.org/pdf/2602.17783" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] A Case Study of Selected PTQ Baselines for Reasoning LLMs on Ascend NPU <a href="https://arxiv.org/pdf/2602.17693" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Balancing Symmetry and Efficiency in Graph Flow Matching <a href="https://arxiv.org/pdf/2602.18084" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] A Probabilistic Framework for LLM-Based Model Discovery <a href="https://arxiv.org/pdf/2602.18266" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] PRISM: Parallel Reward Integration with Symmetry for MORL <a href="https://arxiv.org/pdf/2602.18277" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] Clever Materials: When Models Identify Good Materials for the Wrong Reasons <a href="https://arxiv.org/pdf/2602.17730" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260223] AgriVariant: Variant Effect Prediction using DeepChem-Variant for Precision Breeding in Rice <a href="https://arxiv.org/pdf/2602.17747" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-24">2026-02-24<a href="#2026-02-24" class="hash-link" aria-label="Direct link to 2026-02-24" title="Direct link to 2026-02-24" translate="no">​</a></h2>
<p><strong>cs.DC total: 19</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260224] WANSpec: Leveraging Global Compute Capacity for LLM Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [speculative decoding, wide area network, load balancing, redundancy, auto-regressive decoding]</li>
<li class=""><strong>authors:</strong> Noah Martin, Fahad Dogar</li>
<li class=""><strong>institution:</strong> Tufts University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.18931" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.18931</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces WANSpec, a method that leverages speculative decoding to offload the draft model&#x27;s forward passes to under-utilized data centers across a wide area network. This approach reduces the computational load on high-demand data centers by over 50% while using judicious redundancy to avoid increasing request latency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] When Coordination Is Avoidable: A Monotonicity Analysis of Organizational Tasks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [multi-agent systems], [monotonicity, interdependence taxonomy, coordination tax, multi-agent simulation, O*NET]</li>
<li class=""><strong>authors:</strong> Harang Ju</li>
<li class=""><strong>institution:</strong> Johns Hopkins University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.18673" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.18673</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper applies a monotonicity criterion from distributed systems theory to organizational tasks, showing coordination is only necessary for non-monotonic tasks. It classifies enterprise workflows and occupational tasks, finding a significant portion are monotonic, implying much coordination spending is unnecessary for correctness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] A Formal Framework for Predicting Distributed System Performance under Faults</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems, fault tolerance], [Maude, formal methods, fault injection, performance prediction, statistical analysis]</li>
<li class=""><strong>authors:</strong> Ziwei Zhou, Si Liu, Zhou Zhou, Peixin Wang, MIn Zhang</li>
<li class=""><strong>institution:</strong> East China Normal University, Texas A&amp;M University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.19088" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.19088</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents a formal framework that integrates a fault injector library with system models to predict the performance (e.g., throughput, latency) of distributed systems under various fault scenarios. The framework is formalized in Maude and implemented as an automated tool called PerF. The authors demonstrate that PerF accurately predicts performance, with results consistent with evaluations on real deployments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] Deep Reinforcement Learning for Optimizing Energy Consumption in Smart Grid Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [deep reinforcement learning, physics-informed neural networks, optimal power flow, surrogate models, smart grid]</li>
<li class=""><strong>authors:</strong> Abeer Alsheikhi, Amirfarhad Farhadi, Azadeh Zamanifar</li>
<li class=""><strong>institution:</strong> Iran University of Science and Technology, Islamic Azad University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.18531" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.18531</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using Physics-Informed Neural Networks (PINNs) as a surrogate model to accelerate Deep Reinforcement Learning training for smart grid energy management. The PINN-based approach, which incorporates knowledge of physical laws, significantly improves sample efficiency and reduces the need for costly simulator interactions. The results show that this method achieves 50% faster training while maintaining performance comparable to using the original simulator.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] What Distributed Computing Got Wrong: The Category Mistake That Turned Design Choices into Laws of Nature</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [FITO, bilateral transactions, category mistake, impossibility theorems, FLP, CAP, Two Generals]</li>
<li class=""><strong>authors:</strong> Paul Borrill</li>
<li class=""><strong>institution:</strong> DÆDÆLUS</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.18723" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.18723</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper argues that foundational impossibility results in distributed computing, such as FLP and CAP, are not physical laws but consequences of the design choice of Forward-In-Time-Only (FITO) information flow. It proposes replacing unidirectional message passing with atomic bilateral transactions as an alternative model. The conclusion is that distributed computing has been optimizing within an unnecessarily constrained design space.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] Asymptotic Subspace Consensus in Dynamic Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [asymptotic subspace consensus, oblivious message adversaries, convex hull, dynamic networks, averaging algorithms]</li>
<li class=""><strong>authors:</strong> Matthias Függer, Thomas Nowak</li>
<li class=""><strong>institution:</strong> Université Paris-Saclay, CNRS, ENS Paris-Saclay, LMF, Institut Universitaire de France</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.19121" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.19121</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces the asymptotic subspace consensus problem, a relaxation of classic asymptotic consensus where process outputs converge to a common subspace rather than a single point. The authors provide a complete characterization of its solvability under oblivious message adversaries and show that many existing consensus algorithms degrade gracefully to solve this problem in weaker network conditions. They also present bounds on the rate of dimension reduction during convergence.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] ucTrace: A Multi-Layer Profiling Tool for UCX-driven Communication</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [HPC communication profiling], [UCX, MPI, GPU-aware communication, transport-layer profiling, interactive visualization]</li>
<li class=""><strong>authors:</strong> Emir Gencer, Mohammad Kefah Taha Issa, Ilyas Turimbetov, James D. Trotter, Didem Unat</li>
<li class=""><strong>institution:</strong> Koc University, Simula Research Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.19084" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.19084</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces ucTrace, a multi-layer profiling tool that captures and visualizes fine-grained communication at the UCX transport layer in HPC systems, linking operations to their originating MPI functions. It demonstrates the tool&#x27;s utility in analyzing and optimizing communication patterns for large-scale, GPU-accelerated workloads. The main conclusion is that ucTrace effectively addresses the gap in existing tools by providing detailed, actionable insights into UCX-driven communication for performance tuning and debugging.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] BiScale: Energy-Efficient Disaggregated LLM Serving via Phase-Aware Placement and DVFS</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [prefill/decode disaggregation, DVFS, model predictive control, slack-aware adaptation, phase-aware placement]</li>
<li class=""><strong>authors:</strong> Omar Basit, Yunzhao Liu, Z. Jonny Kong, Y. Charlie Hu</li>
<li class=""><strong>institution:</strong> Purdue University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.18755" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.18755</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces BiScale, a two-tier energy optimization framework for disaggregated LLM serving that jointly optimizes GPU placement and frequency scaling (DVFS). It uses coarse-grained phase-aware placement and fine-grained, stage-specific frequency control (MPC for prefill, slack-aware for decode) to minimize energy while meeting latency SLOs. Evaluation shows it reduces energy by up to 39% in prefill and 48% in decode compared to DistServe while maintaining SLOs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] Carbon-aware decentralized dynamic task offloading in MIMO-MEC networks via multi-agent reinforcement learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-agent proximal policy optimization (PPO), decentralized execution with parameter sharing (DEPS), Decentralized Partially Observable Markov Decision Process (DEC-POMDP), carbon-aware computing, power control, task offloading]</li>
<li class=""><strong>authors:</strong> Mubshra Zulfiqar, Muhammad Ayzed Mirza, Basit Qureshi</li>
<li class=""><strong>institution:</strong> Wuhan University of Technology, Qilu Institute of Technology, Prince Sultan University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.18797" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.18797</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes CADDTO-PPO, a carbon-aware decentralized dynamic task offloading framework using multi-agent proximal policy optimization for MIMO-MEC networks. It models the system as a DEC-POMDP and employs decentralized execution with parameter sharing to enable autonomous agents to make local decisions on power control and offloading. The method achieves lower carbon intensity and near-zero packet overflow compared to baselines, with constant inference complexity suitable for sustainable IoT deployments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] The Category Mistake of Cislunar Time: Why NASA Cannot Synchronize What Doesn&#x27;t Exist</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [time synchronization, distributed systems], [Coordinated Lunar Time (LTC), atomic clocks, relativistic corrections, LunaNet, category mistake, ontic vs epistemic, Forward-In-Time-Only (FITO), Leibnizian operationalism, Wood-Spekkens fine-tuning argument]</li>
<li class=""><strong>authors:</strong> Paul Borrill</li>
<li class=""><strong>institution:</strong> DÆDÆLUS</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.18641" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.18641</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper argues that NASA&#x27;s Coordinated Lunar Time (LTC) program is based on a philosophical category mistake, treating synchronized time as an independent ontic entity rather than an epistemic, model-dependent construct. It analyzes the program using concepts from quantum foundations, such as the ontic-epistemic distinction and Spekkens&#x27; operationalism, to conclude that the project is conceptually incoherent. The author proposes a transactional alternative based on bilateral atomic interactions instead of unidirectional time distribution.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] Semantic Conflict Model for Collaborative Data Structures</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems], [CRDT, semantic conflicts, three-way merge, eventual consistency, optimistic concurrency control, replicated journal]</li>
<li class=""><strong>authors:</strong> Georgii Semenov, Vitaly Aksenov</li>
<li class=""><strong>institution:</strong> ITMO University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.19231" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.19231</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a semantic conflict model for collaborative data structures that identifies conflicts using semantic dependencies between operations and resolves them by rebasing operations via a three-way merge over a replicated journal. The model enables explicit, local-first conflict resolution without central coordination, as demonstrated on collaborative registers like a Last-Writer-Wins Register.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] Health+: Empowering Individuals via Unifying Health Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [multimodal data management, data fusion, user-centric privacy, cloud storage, information retrieval]</li>
<li class=""><strong>authors:</strong> Sujaya Maiyya, Shantanu Sharma, Avinash Kumar</li>
<li class=""><strong>institution:</strong> University of Waterloo, New Jersey Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.19319" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.19319</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This vision paper proposes Health+, a user-centric system designed to unify and manage an individual&#x27;s fragmented multimodal health data (e.g., images, reports, EHRs) through ingestion, storage, fusion, and querying. It emphasizes intuitive interfaces and privacy-aware sharing to empower patients. The main conclusion is that such a system can lay the foundation for a more connected and user-controlled health information ecosystem without requiring an institutional overhaul.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] Complex Event Processing in the Edge: A Combined Optimization Approach for Data and Code Placement</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [edge computing], [complex event processing, constrained programming optimization, critical path performance, virtual shared memory, task graph, code and data placement]</li>
<li class=""><strong>authors:</strong> Halit Uyanık, Tolga Ovatman</li>
<li class=""><strong>institution:</strong> Istanbul Technical University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.19338" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.19338</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a constrained programming optimization approach to balance execution costs and improve the critical path performance in Complex Event Processing (CEP) task graphs for IoT edge devices. It is implemented as a Python library that optimizes code and I/O assignments, virtualizing shared memory between devices. The results show that this optimization increases throughput and reduces delay during CEP operations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] A Context-Aware Knowledge Graph Platform for Stream Processing in Industrial IoT</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [industrial IoT systems], [knowledge graph, Apache Kafka, Apache Flink, SPARQL, SWRL, context-aware reasoning, stream processing]</li>
<li class=""><strong>authors:</strong> Monica Marconi Sciarroni, Emanuele Storti</li>
<li class=""><strong>institution:</strong> Polytechnic University of Marche</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.19990" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.19990</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a semantic platform that uses a Knowledge Graph to unify heterogeneous Industrial IoT data streams, enabling context-aware reasoning and dynamic access control. It relies on Apache Kafka and Flink for real-time processing and SPARQL/SWRL for stream discovery. The experimental evaluation demonstrates the effectiveness of this approach for creating interoperable data workflows in Industry 5.0 environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] Mitigating Artifacts in Pre-quantization Based Scientific Data Compressors with Quantization-aware Interpolation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing, data compression], [pre-quantization, error-bounded lossy compression, quantization-aware interpolation, artifact mitigation, parallel computing]</li>
<li class=""><strong>authors:</strong> Pu Jiao, Sheng Di, Jiannan Tian, Mingze Xia, Xuan Wu, Yang Zhang, Xin Liang, Franck Cappello</li>
<li class=""><strong>institution:</strong> University of Kentucky, Argonne National Laboratory, Oakland University, Oregon State University, Miami University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.20097" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.20097</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a novel quantization-aware interpolation algorithm to mitigate artifacts in pre-quantization based scientific data compressors. The method improves decompressed data quality while maintaining high compression throughput. Experiments on real-world datasets validate its effectiveness with leading compressors.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] GPU-Resident Gaussian Process Regression Leveraging Asynchronous Tasks with HPX</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [Gaussian Process Regression, Cholesky Decomposition, Asynchronous Many-task Runtimes, Tiled Algorithms, HPX, CUDA]</li>
<li class=""><strong>authors:</strong> Henrik Möllmann, Dirk Pflüger, Alexander Strack</li>
<li class=""><strong>institution:</strong> Institute of Parallel and Distributed Systems, University of Stuttgart</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.19683" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.19683</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper extends the GPRat library by implementing a fully GPU-resident Gaussian Process prediction pipeline using tiled algorithms and optimized CUDA libraries, managed asynchronously by the HPX runtime. The results show that the GPU implementation provides significant speedups for datasets larger than 128 samples, with performance gains of up to 4.6x for prediction and even surpassing cuSOLVER by up to 11% for large datasets when combining HPX with multiple CUDA streams.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] Why iCloud Fails: The Category Mistake of Cloud Synchronization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems, cloud storage], [cloud synchronization, POSIX semantics, network partitioning, causal graph, Open Atomic Ethernet (OAE), transactional semantics]</li>
<li class=""><strong>authors:</strong> Paul Borrill</li>
<li class=""><strong>institution:</strong> DAEDAELUS</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.19433" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.19433</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper analyzes iCloud Drive&#x27;s failures, arguing they stem from a &quot;Category Mistake&quot; where its synchronization semantics (based on Forward-In-Time-Only assumptions) fundamentally conflict with POSIX filesystem expectations. It concludes that Open Atomic Ethernet&#x27;s bilateral, reversible transactional semantics provide a structural foundation to resolve these issues by aligning protocol behavior with physical reality.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] Linear Reservoir: A Diagonalization-Based Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [diagonalization, eigenvalue decomposition, eigenbasis transformation, computational complexity reduction, linear echo state networks]</li>
<li class=""><strong>authors:</strong> Romain de Coudenhove, Yannis Bendi-Ouis, Anthony Strock, Xavier Hinaut</li>
<li class=""><strong>institution:</strong> ENS PSL, Inria, LaBRI, IMN, Stanford University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.19802" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.19802</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a diagonalization-based optimization for Linear Echo State Networks that reformulates reservoir dynamics in the eigenbasis of the recurrent matrix, reducing the per-step computational complexity from O(N²) to O(N). The proposed methods preserve predictive accuracy while offering significant computational speedups, suggesting a paradigm shift towards direct eigenvalue selection for linear ESNs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260224] A Risk-Aware UAV-Edge Service Framework for Wildfire Monitoring and Emergency Response</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [fire-history-weighted clustering, QoS-aware edge assignment, 2-opt route optimization, dynamic emergency rerouting, adaptive fleet sizing]</li>
<li class=""><strong>authors:</strong> Yulun Huang, Zhiyu Wang, Rajkumar Buyya</li>
<li class=""><strong>institution:</strong> The University of Melbourne</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.19742" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.19742</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes an integrated UAV-edge service framework that co-optimizes route planning, fleet sizing, and edge service provisioning using risk-aware clustering and dynamic rerouting for wildfire monitoring. Experiments show the framework significantly reduces response time, energy consumption, and fleet size compared to baseline methods, while its emergency mechanism meets strict deadlines with minimal operational disruption.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 42</strong></p>
<ul>
<li class="">[arXiv260224] Learning to Detect Language Model Training Data via Active Reconstruction <a href="https://arxiv.org/pdf/2602.19020" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Toward AI Autonomous Navigation for Mechanical Thrombectomy using Hierarchical Modular Multi-agent Reinforcement Learning (HM-MARL) <a href="https://arxiv.org/pdf/2602.18663" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] 1D-Bench: A Benchmark for Iterative UI Code Generation with Visual Feedback in Real-World <a href="https://arxiv.org/pdf/2602.18548" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Issues with Measuring Task Complexity via Random Policies in Robotic Tasks <a href="https://arxiv.org/pdf/2602.18856" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] TAG: Thinking with Action Unit Grounding for Facial Expression Recognition <a href="https://arxiv.org/pdf/2602.18763" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Learning to Remember: End-to-End Training of Memory Agents for Long-Context Reasoning <a href="https://arxiv.org/pdf/2602.18493" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] DeepInterestGR: Mining Deep Multi-Interest Using Multi-Modal LLMs for Generative Recommendation <a href="https://arxiv.org/pdf/2602.18907" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] VariBASed: Variational Bayes-Adaptive Sequential Monte-Carlo Planning for Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2602.18857" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] TPRU: Advancing Temporal and Procedural Understanding in Large Multimodal Models <a href="https://arxiv.org/pdf/2602.18884" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Hierarchical Reward Design from Language: Enhancing Alignment of Agent Behavior with Human Specifications <a href="https://arxiv.org/pdf/2602.18582" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] FineRef: Fine-Grained Error Reflection and Correction for Long-Form Generation with Citations <a href="https://arxiv.org/pdf/2602.18437" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] In-Context Planning with Latent Temporal Abstractions <a href="https://arxiv.org/pdf/2602.18694" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Task-Aware Exploration via a Predictive Bisimulation Metric <a href="https://arxiv.org/pdf/2602.18724" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Adaptive Time Series Reasoning via Segment Selection <a href="https://arxiv.org/pdf/2602.18645" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] MagicAgent: Towards Generalized Agent Planning <a href="https://arxiv.org/pdf/2602.19000" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] HONEST-CAV: Hierarchical Optimization of Network Signals and Trajectories for Connected and Automated Vehicles with Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.18740" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Adaptive Problem Generation via Symbolic Representations <a href="https://arxiv.org/pdf/2602.19187" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] How to Allocate, How to Learn? Dynamic Rollout Allocation and Advantage Modulation for Policy Optimization <a href="https://arxiv.org/pdf/2602.19208" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Characterizing MARL for Energy Control: A Multi-KPI Benchmark on the CityLearn Environment <a href="https://arxiv.org/pdf/2602.19223" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Robust Exploration in Directed Controller Synthesis via Reinforcement Learning with Soft Mixture-of-Experts <a href="https://arxiv.org/pdf/2602.19244" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] DGPO: RL-Steered Graph Diffusion for Neural Architecture Generation <a href="https://arxiv.org/pdf/2602.19261" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] ALPACA: A Reinforcement Learning Environment for Medication Repurposing and Treatment Optimization in Alzheimer&#x27;s Disease <a href="https://arxiv.org/pdf/2602.19298" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] TOPReward: Token Probabilities as Hidden Zero-Shot Rewards for Robotics <a href="https://arxiv.org/pdf/2602.19313" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Learning to Reason for Multi-Step Retrieval of Personal Context in Personalized Question Answering <a href="https://arxiv.org/pdf/2602.19317" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Soft Sequence Policy Optimization: Bridging GMPO and SAPO <a href="https://arxiv.org/pdf/2602.19327" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] LLMs Can Learn to Reason Via Off-Policy RL <a href="https://arxiv.org/pdf/2602.19362" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Stable Deep Reinforcement Learning via Isotropic Gaussian Representations <a href="https://arxiv.org/pdf/2602.19373" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] IR<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>: Contrastive Inverse Reinforcement Learning for Interpretable Detection and Mitigation of Reward Hacking <a href="https://arxiv.org/pdf/2602.19416" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] RAmmStein: Regime Adaptation in Mean-reverting Markets with Stein Thresholds -- Optimal Impulse Control in Concentrated AMMs <a href="https://arxiv.org/pdf/2602.19419" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] SenTSR-Bench: Thinking with Injected Knowledge for Time-Series Reasoning <a href="https://arxiv.org/pdf/2602.19455" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Cost-Aware Diffusion Active Search <a href="https://arxiv.org/pdf/2602.19538" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Advantage-based Temporal Attack in Reinforcement Learning <a href="https://arxiv.org/pdf/2602.19582" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Meta-Learning and Meta-Reinforcement Learning - Tracing the Path towards DeepMind&#x27;s Adaptive Agent <a href="https://arxiv.org/pdf/2602.19837" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] DSDR: Dual-Scale Diversity Regularization for Exploration in LLM Reasoning <a href="https://arxiv.org/pdf/2602.19895" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Uncertainty-Aware Rank-One MIMO Q Network Framework for Accelerated Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2602.19917" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Janus-Q: End-to-End Event-Driven Trading via Hierarchical-Gated Reward Modeling <a href="https://arxiv.org/pdf/2602.19919" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Sparse Masked Attention Policies for Reliable Generalization <a href="https://arxiv.org/pdf/2602.19956" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] A Secure and Private Distributed Bayesian Federated Learning Design <a href="https://arxiv.org/pdf/2602.20003" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Descent-Guided Policy Gradient for Scalable Cooperative Multi-Agent Learning <a href="https://arxiv.org/pdf/2602.20078" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] ReSyn: Autonomously Scaling Synthetic Environments for Reasoning Models <a href="https://arxiv.org/pdf/2602.20117" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] LAD: Learning Advantage Distribution for Reasoning <a href="https://arxiv.org/pdf/2602.20132" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] AAVGen: Precision Engineering of Adeno-associated Viral Capsids for Renal Selective Targeting <a href="https://arxiv.org/pdf/2602.18915" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 27</strong></p>
<ul>
<li class="">[arXiv260224] Can Multimodal LLMs See Science Instruction? Benchmarking Pedagogical Reasoning in K-12 Classroom Videos <a href="https://arxiv.org/pdf/2602.18466" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] DeepInnovator: Triggering the Innovative Capabilities of LLMs <a href="https://arxiv.org/pdf/2602.18920" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] IDLM: Inverse-distilled Diffusion Language Models <a href="https://arxiv.org/pdf/2602.19066" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Vectorized Bayesian Inference for Latent Dirichlet-Tree Allocation <a href="https://arxiv.org/pdf/2602.18795" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] VariBASed: Variational Bayes-Adaptive Sequential Monte-Carlo Planning for Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2602.18857" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Habilis-<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">β</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span>: A Fast-Motion and Long-Lasting On-Device Vision-Language-Action Model <a href="https://arxiv.org/pdf/2602.18813" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Learning from Complexity: Exploring Dynamic Sample Pruning of Spatio-Temporal Training <a href="https://arxiv.org/pdf/2602.19113" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] ConfSpec: Efficient Step-Level Speculative Reasoning via Confidence-Gated Verification <a href="https://arxiv.org/pdf/2602.18447" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Exponential Convergence of (Stochastic) Gradient Descent for Separable Logistic Regression <a href="https://arxiv.org/pdf/2602.18946" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] InfEngine: A Self-Verifying and Self-Optimizing Intelligent Engine for Infrared Radiation Computing <a href="https://arxiv.org/pdf/2602.18985" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Task-Aware Exploration via a Predictive Bisimulation Metric <a href="https://arxiv.org/pdf/2602.18724" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] LLM-Assisted Replication for Quantitative Social Science <a href="https://arxiv.org/pdf/2602.18453" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] CORVET: A CORDIC-Powered, Resource-Frugal Mixed-Precision Vector Processing Engine for High-Throughput AIoT applications <a href="https://arxiv.org/pdf/2602.19268" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Taming Preconditioner Drift: Unlocking the Potential of Second-Order Optimizers for Federated Learning on Non-IID Data <a href="https://arxiv.org/pdf/2602.19271" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] CTS-Bench: Benchmarking Graph Coarsening Trade-offs for GNNs in Clock Tree Synthesis <a href="https://arxiv.org/pdf/2602.19330" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Laplacian Multi-scale Flow Matching for Generative Modeling <a href="https://arxiv.org/pdf/2602.19461" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Relational Feature Caching for Accelerating Diffusion Transformers <a href="https://arxiv.org/pdf/2602.19506" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Leap+Verify: Regime-Adaptive Speculative Weight Prediction for Accelerating Neural Network Training <a href="https://arxiv.org/pdf/2602.19580" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Rules or Weights? Comparing User Understanding of Explainable AI Techniques with the Cognitive XAI-Adaptive Model <a href="https://arxiv.org/pdf/2602.19620" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Iconographic Classification and Content-Based Recommendation for Digitized Artworks <a href="https://arxiv.org/pdf/2602.19698" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Hexagon-MLIR: An AI Compilation Stack For Qualcomm&#x27;s Neural Processing Units (NPUs) <a href="https://arxiv.org/pdf/2602.19762" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Fully Convolutional Spatiotemporal Learning for Microstructure Evolution Prediction <a href="https://arxiv.org/pdf/2602.19915" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] DP-FedAdamW: An Efficient Optimizer for Differentially Private Federated Large Models <a href="https://arxiv.org/pdf/2602.19945" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] A Secure and Private Distributed Bayesian Federated Learning Design <a href="https://arxiv.org/pdf/2602.20003" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Adaptation to Intrinsic Dependence in Diffusion Language Models <a href="https://arxiv.org/pdf/2602.20126" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] AAVGen: Precision Engineering of Adeno-associated Viral Capsids for Renal Selective Targeting <a href="https://arxiv.org/pdf/2602.18915" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260224] Kaiwu-PyTorch-Plugin: Bridging Deep Learning and Photonic Quantum Computing for Energy-Based Models and Active Sample Selection <a href="https://arxiv.org/pdf/2602.19114" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-26">2026-02-26<a href="#2026-02-26" class="hash-link" aria-label="Direct link to 2026-02-26" title="Direct link to 2026-02-26" translate="no">​</a></h2>
<p><strong>cs.DC total: 16</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260226] Lamport&#x27;s Arrow of Time: The Category Mistake in Logical Clocks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems theory], [logical clocks, happens-before relation, directed acyclic graph (DAG), mutual information conservation, indefinite causal order, CAP theorem, Fischer-Lynch-Paterson]</li>
<li class=""><strong>authors:</strong> Paul Borrill</li>
<li class=""><strong>institution:</strong> DÆDÆLUS</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.21730" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.21730</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper critiques Lamport&#x27;s logical clocks, arguing they embed a &quot;forward-in-time-only&quot; assumption that conflates epistemic ordering with an ontic claim of global causal acyclicity. It traces this conflation through impossibility results and modern physics, which only permits local causal structure. The authors propose mutual information conservation as a more fundamental primitive for distributed consistency than temporal precedence.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] DualPath: Breaking the Storage Bandwidth Bottleneck in Agentic LLM Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [KV-Cache, disaggregated architecture, RDMA, dual-path loading, global scheduler]</li>
<li class=""><strong>authors:</strong> Yongtong Wu, Shaoyuan Chen, Yinmin Zhong, Rilin Huang, Yixuan Tan, Wentao Zhang, Liyue Zhang, Shangyan Zhou, Yuxuan Liu, Shunfeng Zhou, Mingxing Zhang, Xin Jin, Panpan Huang</li>
<li class=""><strong>institution:</strong> Peking University, Tsinghua University, DeepSeek-AI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.21548" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.21548</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces DualPath, a system that breaks the KV-Cache storage bandwidth bottleneck in agentic LLM inference by enabling a novel storage-to-decode loading path alongside the traditional storage-to-prefill path, combined with a global scheduler. It demonstrates that this approach significantly improves both offline and online inference throughput without violating service-level objectives.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] Type-Based Enforcement of Non-Interference for Choreographic Programming</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [programming languages, security], [type system, non-interference, choreographic programming, constraint generation, program-counter discipline]</li>
<li class=""><strong>authors:</strong> Marco Bertoni, Saverio Giallorenzo, Marco Peressotti</li>
<li class=""><strong>institution:</strong> Inria Paris, Université di Bologna, Inria Sophia Antipolis, University of Southern Denmark</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.21630" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.21630</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper develops a policy-parametric type system for choreographic programming to enforce information flow security. The method handles both explicit and implicit flows via a program-counter discipline and supports recursive procedures through constraint-based context reconstruction. The main conclusion is a proof of termination-insensitive non-interference, ensuring that secret data is not leaked to public observers in distributed protocols.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] Multi-Layer Scheduling for MoE-Based LLM Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [multi-layer scheduling, mixture-of-experts (MoE), Shortest-Job-First (SJF), priority-aware aging, load-aware dispatching, KV cache, expert hotspots]</li>
<li class=""><strong>authors:</strong> Yifan Sun, Gholamreza Haffar, Minxian Xu, Rajkumar Buyya, Adel N. Toosi</li>
<li class=""><strong>institution:</strong> The University of Melbourne, Monash University, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.21626" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.21626</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a multi-layer scheduling framework for efficient Mixture-of-Experts (MoE) based LLM serving, operating at the request, engine, and expert levels. It demonstrates that this approach outperforms the vLLM framework, achieving significant reductions in both Time To First Token and Time-Per-Output-Token latency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] JSAM: Privacy Straggler-Resilient Joint Client Selection and Incentive Mechanism Design in Differentially Private Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [differential privacy, federated learning, incentive mechanism design, client selection, Bayesian-optimal framework]</li>
<li class=""><strong>authors:</strong> Ruichen Xu, Ying-Jun Angela Zhang, Jianwei Huang</li>
<li class=""><strong>institution:</strong> The Chinese University of Hong Kong, Shenzhen Institute of Artificial Intelligence and Robotics for Society</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.21844" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.21844</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes JSAM, a framework that jointly optimizes client selection and privacy compensation in differentially private federated learning to maximize training effectiveness under a budget. It shows that servers should preferentially select privacy-tolerant clients and reveals that clients with minimal privacy sensitivity may incur the highest cumulative costs due to frequent participation. Evaluations demonstrate that JSAM achieves up to 15% higher test accuracy compared to unbiased selection mechanisms.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] General Convex Agreement with Near-Optimal Communication</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed consensus], [convex agreement, Byzantine agreement, extractor graphs, deterministic committees, communication complexity, Helly number]</li>
<li class=""><strong>authors:</strong> Marc Dufay, Diana Ghinea, Anton Paramonov</li>
<li class=""><strong>institution:</strong> ETH Zurich, Lucerne University of Applied Sciences and Arts</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.21411" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.21411</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents deterministic synchronous Convex Agreement protocols for abstract convexity spaces, using extractor graphs to assign parties to committees resilient against adaptive adversaries. It achieves near-optimal communication complexity and round complexity, with resilience depending on the Helly number of the convexity space and whether input length bounds are known.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] Make Every Draft Count: Hidden State based Speculative Decoding</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [speculative decoding, hidden state reuse, auto-regressive hidden states, token tree, draft model]</li>
<li class=""><strong>authors:</strong> Yuetao Chen, Xuliang Wang, Xinzhou Zheng, Ming Li, Peng Wang, Hong Xu</li>
<li class=""><strong>institution:</strong> The Chinese University of Hong Kong, University of Waterloo, University of Science and Technology of China</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.21224" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.21224</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a novel speculative decoding system that reuses the hidden states from discarded draft tokens to improve computational efficiency. The core method involves performing auto-regressive prediction at the hidden state level and injecting token information later, enabling the construction of high-quality draft token trees from verification failures. The system achieves up to 3.3x speedup compared to standard speculative decoding by transforming wasted computation into reusable tokens.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] PiPNN: Ultra-Scalable Graph-Based Nearest Neighbor Indexing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [graph-based indexing, approximate nearest neighbor search, HashPrune, beam search, dense matrix multiplication, online pruning]</li>
<li class=""><strong>authors:</strong> Tobias Rubel, Richard Wen, Laxman Dhulipala, Lars Gottesbüren, Rajesh Jayaram, Jakub Łącki</li>
<li class=""><strong>institution:</strong> University of Maryland, Google Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.21247" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.21247</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces PiPNN, a new graph construction algorithm for approximate nearest neighbor search that uses a core component called HashPrune to dynamically prune edges and perform bulk distance comparisons. This method avoids the search bottleneck of traditional graph-based indexes like HNSW and Vamana, enabling much faster construction. The authors demonstrate that PiPNN builds high-quality indexes up to 12.9x faster than prior methods and can construct billion-scale indexes in under 20 minutes on a single machine.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] Epoch-based Optimistic Concurrency Control in Geo-replicated Databases</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed databases], [epoch-based replication, optimistic concurrency control, deterministic re-execution, conflict graph, maximum weight independent set, multi-leader replication]</li>
<li class=""><strong>authors:</strong> Yunhao Mao, Harunari Takata, Michail Bachras, Yuqiu Zhang, Shiquan Zhang, Gengrui Zhang, Hans-Arno Jacobsen</li>
<li class=""><strong>institution:</strong> University of Toronto, Keio University, Concordia University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.21566" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.21566</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Minerva, a geo-replicated database system that uses an epoch-based optimistic concurrency control protocol with deterministic re-execution and a conflict graph algorithm to resolve transaction conflicts. It decouples data propagation from commitment to enable high concurrency in multi-leader settings. The evaluation shows it significantly outperforms existing systems in throughput under high latency and scalability.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] DHP: Efficient Scaling of MLLM Training with Dynamic Hybrid Parallelism</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [dynamic hybrid parallelism, non-power-of-two parallelism, polynomial-time algorithm, data parallelism, tensor parallelism, pipeline parallelism, sequence parallelism]</li>
<li class=""><strong>authors:</strong> Yifan Niu, Han Xiao, Dongyi Liu, Wei Zhou, Jia Li</li>
<li class=""><strong>institution:</strong> The Hong Kong University of Science and Technology (Guangzhou), Huawei Technologies Co., Ltd., The Hong Kong University of Science and Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.21788" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.21788</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Dynamic Hybrid Parallelism (DHP), a method that adaptively reconfigures communication groups and parallelism degrees during Multimodal Large Language Model (MLLM) training to handle heterogeneous data efficiently. It introduces a polynomial-time algorithm to generate near-optimal parallelism strategies with minimal overhead. The results show that DHP significantly outperforms existing frameworks like Megatron-LM and DeepSpeed, achieving up to 1.36x speedup in training throughput while maintaining near-linear scaling efficiency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] Energy Efficient Federated Learning with Hyperdimensional Computing over Wireless Communication Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [hyperdimensional computing, differential privacy, resource allocation, alternating optimization, energy efficiency]</li>
<li class=""><strong>authors:</strong> Yahao Ding, Yinchao Yang, Jiaxiang Wang, Zhaohui Yang, Dusit Niyato, Zhu Han, Mohammad Shikh-Bahaei</li>
<li class=""><strong>institution:</strong> King&#x27;s College London, Zhejiang University, Nanyang Technological University, University of Houston, Kyung Hee University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.21949" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.21949</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a federated learning framework that uses hyperdimensional computing for lightweight local training and applies differential privacy for security, jointly optimizing resource allocation to minimize total energy consumption. The method significantly reduces energy usage and communication rounds compared to neural network baselines while maintaining model accuracy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] PASTA: A Modular Program Analysis Tool Framework for Accelerators</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [performance analysis, profiling, modular framework, GPU-accelerated backend, deep learning workloads]</li>
<li class=""><strong>authors:</strong> Mao Lin, Hyeran Jeon, Keren Zhou</li>
<li class=""><strong>institution:</strong> University of California, Merced, George Mason University, OpenAI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.22103" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.22103</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents PASTA, a modular and low-overhead program analysis tool framework for hardware accelerators. It abstracts low-level profiling APIs and deep learning frameworks to provide a unified interface for performance analysis. The evaluation shows PASTA offers detailed insights with significantly lower overhead than conventional tools, making it suitable for modern accelerator environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] LLMTailor: A Layer-wise Tailoring Tool for Efficient Checkpointing of Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [checkpointing, layer-wise tailoring, selective checkpointing, checkpoint merging]</li>
<li class=""><strong>authors:</strong> Minqiu Sun, Xin Huang, Luanzheng Guo, Nathan R. Tallent, Kento Sato, Dong Dai</li>
<li class=""><strong>institution:</strong> University of Delaware, RIKEN Center for Computational Science, Pacific Northwest National Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.22158" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.22158</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes LLMTailor, a checkpoint-merging framework that selectively saves only the layers of a large language model that have undergone significant updates, rather than the entire model state. This method significantly reduces checkpoint storage size and I/O time while maintaining model quality, as demonstrated in evaluations with models like Llama3.1-8B and Qwen2.5-7B.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] Hybrid Consensus with Quantum Sybil Resistance</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [quantum cryptography, consensus protocols], [quantum position verification, hybrid consensus, Sybil resistance, Proof-of-Work, Proof-of-Stake]</li>
<li class=""><strong>authors:</strong> Dar Gilboa, Siddhartha Jain, Or Sattath</li>
<li class=""><strong>institution:</strong> Google Quantum AI, University of Texas at Austin, Ben-Gurion University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.22195" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.22195</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a decentralized consensus protocol that uses quantum position verification as a Sybil resistance mechanism, combining it with classical hybrid consensus. The method improves energy efficiency compared to Proof-of-Work-based hybrid protocols and offers faster confirmation times while avoiding the compounding wealth issue of Proof-of-Stake. The protocol is secure in the standard model and includes a spam prevention mechanism in the Random Oracle model.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [RAG, tree-based merger, module-based pre-processor, Darshan, TraceBench]</li>
<li class=""><strong>authors:</strong> Chris Egersdoerfer, Arnav Sareen, Jean Luca Bez, Suren Byna, Dongkuan, Dong Dai</li>
<li class=""><strong>institution:</strong> University of Delaware, University of North Carolina at Charlotte, Lawrence Berkeley National Laboratory, The Ohio State University, North Carolina State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.22017" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.22017</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes IOAgent, a tool that uses LLMs to automate the diagnosis of I/O performance issues in HPC systems by analyzing Darshan trace files. It integrates a pre-processor, a RAG-based knowledge module, and a tree-based merger to provide accurate, referenced diagnoses. The evaluation shows it matches or outperforms existing tools and works with various LLMs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260226] A task-based data-flow methodology for programming heterogeneous systems with multiple accelerator APIs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [task-based data-flow, directed acyclic graph (DAG), OpenMP/OmpSs-2, task-aware APIs (TA-libs), TACUDA, TASYCL, nOS-V, runtime interoperability]</li>
<li class=""><strong>authors:</strong> Aleix Boné, Alejandro Aguirre, David Álvarez, Pedro J. Martinez-Ferrer, Vicenç Beltran</li>
<li class=""><strong>institution:</strong> Barcelona Supercomputing Center (BSC), Universitat Politècnica de Catalunya - BarcelonaTech (UPC)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.21897" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.21897</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a task-based data-flow methodology using task-aware libraries (e.g., TACUDA, TASYCL) and the nOS-V threading library to seamlessly integrate multiple accelerator programming models (like CUDA and SYCL) within a single application. This approach manages computations as a DAG via a runtime system to avoid manual orchestration and thread contention. The results show that this method enables efficient and transparent use of diverse accelerators, mitigating performance interference and is applicable to current and future heterogeneous systems.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 17</strong></p>
<ul>
<li class="">[arXiv260226] On the Structural Non-Preservation of Epistemic Behaviour under Policy Transformation <a href="https://arxiv.org/pdf/2602.21424" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] CCCaption: Dual-Reward Reinforcement Learning for Complete and Correct Image Captioning <a href="https://arxiv.org/pdf/2602.21655" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Overconfident Errors Need Stronger Correction: Asymmetric Confidence Penalties for Reinforcement Learning <a href="https://arxiv.org/pdf/2602.21420" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Self-Correcting VLA: Online Action Refinement via Sparse World Imagination <a href="https://arxiv.org/pdf/2602.21633" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Generalisation of RLHF under Reward Shift and Clipped KL Regularisation <a href="https://arxiv.org/pdf/2602.21765" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Hierarchical Lead Critic based Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.21680" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Two-Stage Active Distribution Network Voltage Control via LLM-RL Collaboration: A Hybrid Knowledge-Data-Driven Approach <a href="https://arxiv.org/pdf/2602.21715" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Alignment-Weighted DPO: A principled reasoning approach to improve safety alignment <a href="https://arxiv.org/pdf/2602.21346" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Tool-R0: Self-Evolving LLM Agents for Tool-Learning from Zero Data <a href="https://arxiv.org/pdf/2602.21320" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Evaluating the relationship between regularity and learnability in recursive numeral systems using Reinforcement Learning <a href="https://arxiv.org/pdf/2602.21720" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning <a href="https://arxiv.org/pdf/2602.21534" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] GradAlign: Gradient-Aligned Data Selection for LLM Reinforcement Learning <a href="https://arxiv.org/pdf/2602.21492" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] ImpRIF: Stronger Implicit Reasoning Leads to Better Complex Instruction Following <a href="https://arxiv.org/pdf/2602.21228" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Training Generalizable Collaborative Agents via Strategic Risk Aversion <a href="https://arxiv.org/pdf/2602.21515" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Distill and Align Decomposition for Enhanced Claim Verification <a href="https://arxiv.org/pdf/2602.21857" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] SWE-Protégé: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents <a href="https://arxiv.org/pdf/2602.22124" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual <a href="https://arxiv.org/pdf/2602.22146" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 8</strong></p>
<ul>
<li class="">[arXiv260226] SymTorch: A Framework for Symbolic Distillation of Deep Neural Networks <a href="https://arxiv.org/pdf/2602.21307" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Error-awareness Accelerates Active Automata Learning <a href="https://arxiv.org/pdf/2602.21674" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Excitation: Momentum For Experts <a href="https://arxiv.org/pdf/2602.21798" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] AngelSlim: A more accessible, comprehensive, and efficient toolkit for large model compression <a href="https://arxiv.org/pdf/2602.21233" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Asymptotically Fast Clebsch-Gordan Tensor Products with Vector Spherical Harmonics <a href="https://arxiv.org/pdf/2602.21466" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] The Error of Deep Operator Networks Is the Sum of Its Parts: Branch-Trunk and Mode Error Decompositions <a href="https://arxiv.org/pdf/2602.21910" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Counterdiabatic Hamiltonian Monte Carlo <a href="https://arxiv.org/pdf/2602.21272" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260226] Towards single-shot coherent imaging via overlap-free ptychography <a href="https://arxiv.org/pdf/2602.21361" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2026-02-26T03:26:47.000Z" itemprop="dateModified">Feb 26, 2026</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20260216-20260222"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20260216-20260222</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2026-02-23" class="table-of-contents__link toc-highlight">2026-02-23</a></li><li><a href="#2026-02-24" class="table-of-contents__link toc-highlight">2026-02-24</a></li><li><a href="#2026-02-26" class="table-of-contents__link toc-highlight">2026-02-26</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>