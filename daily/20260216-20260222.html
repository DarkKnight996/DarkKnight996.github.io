<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20260216-20260222" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20260216-20260222 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20260216-20260222"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20260216-20260222 | DarkKnight Note"><meta data-rh="true" name="description" content="2026-02-16"><meta data-rh="true" property="og:description" content="2026-02-16"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20260216-20260222"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260216-20260222" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260216-20260222" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20260216-20260222","item":"https://darkknight996.github.io/daily/20260216-20260222"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.d93820e3.js" defer="defer"></script>
<script src="/assets/js/main.d752cdc3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260105-20260111"><span title="20260105-20260111" class="linkLabel_WmDU">20260105-20260111</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260112-20260118"><span title="20260112-20260118" class="linkLabel_WmDU">20260112-20260118</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260119-20260125"><span title="20260119-20260125" class="linkLabel_WmDU">20260119-20260125</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260126-20260201"><span title="20260126-20260201" class="linkLabel_WmDU">20260126-20260201</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260202-20260208"><span title="20260202-20260208" class="linkLabel_WmDU">20260202-20260208</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260209-20260215"><span title="20260209-20260215" class="linkLabel_WmDU">20260209-20260215</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20260216-20260222"><span title="20260216-20260222" class="linkLabel_WmDU">20260216-20260222</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20260216-20260222</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20260216-20260222</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-16">2026-02-16<a href="#2026-02-16" class="hash-link" aria-label="Direct link to 2026-02-16" title="Direct link to 2026-02-16" translate="no">​</a></h2>
<p><strong>cs.DC total: 5</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260216] Classification of Local Optimization Problems in Directed Cycles</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed algorithms], [LOCAL model, directed cycles, classification, approximation algorithms, meta-algorithm]</li>
<li class=""><strong>authors:</strong> Thomas Boudier, Fabian Kuhn, Augusto Modanese, Ronja Stimpert, Jukka Suomela</li>
<li class=""><strong>institution:</strong> GSSI, University of Freiburg, CISPA Helmholtz Center for Information Security, Aalto University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13046" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13046</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper provides a complete complexity classification for local optimization problems in directed cycles within the distributed LOCAL model. It shows that for any constant approximation ratio, the problem falls into one of four deterministic and randomized complexity classes. The authors also present an efficient meta-algorithm to determine the class and synthesize an optimal distributed algorithm.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260216] DRAMatic Speedup: Accelerating HE Operations on a Processing-in-Memory System</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [hardware acceleration], [residue number system, number-theoretic transform, processing-in-memory]</li>
<li class=""><strong>authors:</strong> Niklas Klinger, Jonas Sander, Peterson Yuhala, Pascal Felber, Thomas Eisenbarth</li>
<li class=""><strong>institution:</strong> University of Luebeck, University of Neuchâtel</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.12433" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.12433</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents DRAMatic, a system that implements foundational homomorphic encryption operations on UPMEM&#x27;s processing-in-memory hardware. It uses arithmetic optimizations like the residue number system and number-theoretic transform to accelerate these operations. The evaluation shows DRAMatic significantly closes the performance gap with a software library like Microsoft SEAL but is still limited by the hardware&#x27;s multiplication performance and data transfer overhead.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260216] Bloom Filter Look-Up Tables for Private and Secure Distributed Databases in Web3 (Revised Version)</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed databases], [Bloom Filter, BFLUT, OrbitDB, IPFS, IPNS, decentralized key management]</li>
<li class=""><strong>authors:</strong> Shlomi Dolev, Ehud Gudes, Daniel Shlomo</li>
<li class=""><strong>institution:</strong> Ben-Gurion University of the Negev</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13167" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13167</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a decentralized database scheme for secure key management in Web3, using the BFLUT algorithm to encode and distribute cryptographic keys without explicit storage. The system integrates OrbitDB, IPFS, and IPNS to ensure privacy and prevent key discovery even if network nodes are compromised. The authors conclude it provides a foundational, secure, and private solution for decentralized applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260216] OptiML: An End-to-End Framework for Program Synthesis and CUDA Kernel Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [Monte Carlo Tree Search, Mixture-of-Thoughts, program synthesis, CUDA optimization, search under verification, Nsight Compute]</li>
<li class=""><strong>authors:</strong> Arijit Bhattacharjee, Heng Ping, Son Vu Le, Paul Bogdan, Nesreen K. Ahmed, Ali Jannesari</li>
<li class=""><strong>institution:</strong> Iowa State University, University of Southern California, Cisco AI Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.12305" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.12305</a></li>
<li class=""><strong>Simple LLM Summary:</strong> OptiML is an end-to-end framework that uses a two-stage process to generate and optimize CUDA kernels. It first synthesizes code from natural language using a Mixture-of-Thoughts generator, then refines it via Monte Carlo Tree Search guided by hardware-aware rewards from profiler feedback. The framework consistently produces verified performance improvements over strong LLM baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260216] Distance-based certification for leader election in meshed graphs and local recognition of their subclasses</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [graph theory], [proof labeling scheme, leader election, meshed graphs, distance verification, local certification]</li>
<li class=""><strong>authors:</strong> Jérémie Chalopin, Victor Chepoi, Maria Kokkou</li>
<li class=""><strong>institution:</strong> Aix-Marseille Université, Université Côte d&#x27;Azur, University of Crete</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.12894" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.12894</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents a 2-local proof labeling scheme using constant-size labels {0,1,2} to solve leader election in anonymous meshed graphs by verifying distances modulo 3 to a designated root. It also provides 3-local schemes to recognize subclasses of meshed graphs using labels of size O(log D). The main conclusion is that leader election can be certified locally with small labels in this broad class of graphs, and their subclasses can be locally recognized by leveraging distance verification and existing characterizations.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 32</strong></p>
<ul>
<li class="">[arXiv260216] Synthetic Interaction Data for Scalable Personalization in Large Language Models <a href="https://arxiv.org/pdf/2602.12394" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs <a href="https://arxiv.org/pdf/2602.12705" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Constraint-Rectified Training for Efficient Chain-of-Thought <a href="https://arxiv.org/pdf/2602.12526" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Flow-Factory: A Unified Framework for Reinforcement Learning in Flow-Matching Models <a href="https://arxiv.org/pdf/2602.12529" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning <a href="https://arxiv.org/pdf/2602.12375" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] FLAC: Maximum Entropy RL via Kinetic Energy Regularized Bridge Matching <a href="https://arxiv.org/pdf/2602.12829" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Provably Convergent Actor-Critic in Risk-averse MARL <a href="https://arxiv.org/pdf/2602.12386" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Safe Reinforcement Learning via Recovery-based Shielding with Gaussian Process Dynamics Models <a href="https://arxiv.org/pdf/2602.12444" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Amortized Reasoning Tree Search: Decoupling Proposal and Decision in Large Language Models <a href="https://arxiv.org/pdf/2602.12846" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] On Robustness and Chain-of-Thought Consistency of RL-Finetuned VLMs <a href="https://arxiv.org/pdf/2602.12506" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Designing RNAs with Language Models <a href="https://arxiv.org/pdf/2602.12470" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via Confidence-Guided Variance Reduction <a href="https://arxiv.org/pdf/2602.12579" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Look Inward to Explore Outward: Learning Temperature Policy from LLM Internal States via Hierarchical RL <a href="https://arxiv.org/pdf/2602.13035" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] TCRL: Temporal-Coupled Adversarial Training for Robust Constrained Reinforcement Learning in Worst-Case Scenarios <a href="https://arxiv.org/pdf/2602.13040" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Composable Model-Free RL for Navigation with Input-Affine Systems <a href="https://arxiv.org/pdf/2602.12492" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Wireless TokenCom: RL-Based Tokenizer Agreement for Multi-User Wireless Token Communications <a href="https://arxiv.org/pdf/2602.12338" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Dual-Granularity Contrastive Reward via Generated Episodic Guidance for Efficient Embodied RL <a href="https://arxiv.org/pdf/2602.12636" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Abstractive Red-Teaming of Language Model Character <a href="https://arxiv.org/pdf/2602.12318" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] In-Context Autonomous Network Incident Response: An End-to-End Large Language Model Agent Approach <a href="https://arxiv.org/pdf/2602.13156" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Learning to Approximate Uniform Facility Location via Graph Neural Networks <a href="https://arxiv.org/pdf/2602.13155" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] ALOE: Action-Level Off-Policy Evaluation for Vision-Language-Action Model Post-Training <a href="https://arxiv.org/pdf/2602.12691" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Unifying Model-Free Efficiency and Model-Based Representations via Latent Dynamics <a href="https://arxiv.org/pdf/2602.12643" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Curriculum-DPO++: Direct Preference Optimization via Data and Model Curricula for Text-to-Image Generation <a href="https://arxiv.org/pdf/2602.13055" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] PMG: Parameterized Motion Generator for Human-like Locomotion Control <a href="https://arxiv.org/pdf/2602.12656" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] What does RL improve for Visual Reasoning? A Frankenstein-Style Analysis <a href="https://arxiv.org/pdf/2602.12395" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Energy-Aware Reinforcement Learning for Robotic Manipulation of Articulated Components in Infrastructure Operation and Maintenance <a href="https://arxiv.org/pdf/2602.12288" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] AstRL: Analog and Mixed-Signal Circuit Synthesis with Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2602.12402" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Bench-MFG: A Benchmark Suite for Learning in Stationary Mean Field Games <a href="https://arxiv.org/pdf/2602.12517" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Agent Skills for Large Language Models: Architecture, Acquisition, Security, and the Path Forward <a href="https://arxiv.org/pdf/2602.12430" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models <a href="https://arxiv.org/pdf/2602.12566" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Multi-Agent Model-Based Reinforcement Learning with Joint State-Action Learned Embeddings <a href="https://arxiv.org/pdf/2602.12520" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Intrinsic Credit Assignment for Long Horizon Interaction <a href="https://arxiv.org/pdf/2602.12342" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 7</strong></p>
<ul>
<li class="">[arXiv260216] Multi-Dimensional Visual Data Recovery: Scale-Aware Tensor Modeling and Accelerated Randomized Computation <a href="https://arxiv.org/pdf/2602.12982" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Tight Bounds for Logistic Regression with Large Stepsize Gradient Descent in Low Dimension <a href="https://arxiv.org/pdf/2602.12471" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] CoPE-VideoLM: Codec Primitives For Efficient Video Language Models <a href="https://arxiv.org/pdf/2602.13191" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] SLA2: Sparse-Linear Attention with Learnable Routing and QAT <a href="https://arxiv.org/pdf/2602.12675" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Accelerating Feedback-based Algorithms for Quantum Optimization Using Gradient Descent <a href="https://arxiv.org/pdf/2602.12387" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] SWING: Unlocking Implicit Graph Representations for Graph Random Features <a href="https://arxiv.org/pdf/2602.12703" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] TriGen: NPU Architecture for End-to-End Acceleration of Large Language Models based on SW-HW Co-Design <a href="https://arxiv.org/pdf/2602.12962" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-17">2026-02-17<a href="#2026-02-17" class="hash-link" aria-label="Direct link to 2026-02-17" title="Direct link to 2026-02-17" translate="no">​</a></h2>
<p><strong>cs.DC total: 12</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260217] Parallel Sparse and Data-Sparse Factorization-based Linear Solvers</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [numerical linear algebra], [sparse direct solvers, low-rank compression, hierarchical matrix algebra, parallel factorization]</li>
<li class=""><strong>authors:</strong> Xiaoye Sherry Li, Yang Liu</li>
<li class=""><strong>institution:</strong> Lawrence Berkeley National Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.14289" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.14289</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper reviews recent advances in parallel sparse direct solvers, focusing on reducing communication costs and computational complexity through low-rank and hierarchical compression techniques. It concludes that these methods are crucial for building scalable, robust solver toolchains for large-scale problems on modern heterogeneous machines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Preventing Rank Collapse in Federated Low-Rank Adaptation with Client Heterogeneity</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [federated learning, low-rank adaptation, rank collapse, heterogeneous ranks, rank-partitioned aggregation]</li>
<li class=""><strong>authors:</strong> Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang</li>
<li class=""><strong>institution:</strong> University of Exeter</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13486" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13486</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes raFLoRA, a rank-partitioned aggregation method for federated low-rank adaptation (FedLoRA) to address rank collapse in heterogeneous client settings. It prevents performance degradation by aggregating local model updates based on their effective rank contributions. Experiments show that raFLoRA improves model performance and maintains communication efficiency compared to existing FedLoRA baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Ask the Expert: Collaborative Inference for Vision Transformers with Near-Edge Accelerators</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [collaborative inference, near-edge accelerator, vision transformer, routing mechanism, progressive specialist training]</li>
<li class=""><strong>authors:</strong> Hao Liu, Suhaib A. Fahmy</li>
<li class=""><strong>institution:</strong> King Abdullah University of Science and Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13334" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13334</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a collaborative inference framework that uses a lightweight Vision Transformer on an edge device and multiple expert ViTs on a near-edge accelerator, with a routing mechanism to select experts for low-confidence samples. The method reduces latency by up to 45% and energy consumption by up to 46% compared to baseline approaches, while improving accuracy through a progressive training strategy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Intent-driven Diffusion-based Path for Mobile Data Collector in IoT-enabled Dense WSNs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [diffusion-based planning, intent-driven networking, mobile data collection, generative diffusion models, path planning, rendezvous point selection]</li>
<li class=""><strong>authors:</strong> Uma Mahesh Boda, Mallikharjuna Rao Nuka</li>
<li class=""><strong>institution:</strong> Annamacharya University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13277" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13277</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ID2P2, an intent-driven diffusion-based path planning framework for mobile data collectors in dense wireless sensor networks. It uses a generative diffusion process to create adaptive data collection trajectories that incorporate high-level operational intents like latency minimization. Simulation results show ID2P2 outperforms baselines with significant improvements in tour completion time, data freshness, and energy efficiency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] ML-ECS: A Collaborative Multimodal Learning Framework for Edge-Cloud Synergies</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [cross-modal contrastive learning, adaptive multimodal tuning, modality-aware model aggregation, SLM-enhanced CCL, LoRA, edge-cloud synergy]</li>
<li class=""><strong>authors:</strong> Yuze Liu, Shibo Chu, Tiehua Zhang, Hao Zhou, Zhishu Shen, Jinze Wang, Jianzhong Qi, Feng Xia</li>
<li class=""><strong>institution:</strong> Tongji University, Swinburne University of Technology, The University of Melbourne, RMIT University, Wuhan University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.14107" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.14107</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ML-ECS, a collaborative multimodal learning framework for edge-cloud systems that addresses modality and model heterogeneity. Its core method integrates cross-modal contrastive learning, adaptive tuning, and modality-aware aggregation to enable efficient knowledge sharing. The framework improves performance on multimodal tasks and achieves high communication efficiency by transmitting only low-rank LoRA parameters.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] TEG: Exascale Cluster Governance via Non-Equilibrium Thermodynamics and Langevin Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [thermodynamic governance, langevin agents, holographic potential field, landau phase transition, token evaporation, dual-number damping, glassy states, high-order control barrier functions]</li>
<li class=""><strong>authors:</strong> Zhengyan Chu</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13789" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13789</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes TEG, a decentralized cluster governance architecture that models resource contention using non-equilibrium thermodynamics and Langevin dynamics, replacing a global scheduler with agents performing Brownian motion on a potential field. It argues that this paradigm of emergent order, rather than deterministic orchestration, is necessary for scalability to exascale AI workloads.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] MergePipe: A Budget-Aware Parameter Management System for Scalable LLM Merging</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [model merging, parameter management, I/O optimization, cost-aware planning, streaming execution, catalog-driven abstraction]</li>
<li class=""><strong>authors:</strong> Yuanyi Wang, Yanggan Gu, Zihao Wang, Kunxi Li, Yifan Yang, Zhaoyi Yan, Congkai Xie, Jianmin Wu, Hongxia Yang</li>
<li class=""><strong>institution:</strong> Hong Kong Polytechnic University, InfiX.ai, Zhejiang University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13273" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13273</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MergePipe, a system that treats LLM merging as a data management problem, using a catalog-driven abstraction, a cost-aware planner to enforce I/O budgets, and a streaming execution engine. It significantly reduces I/O and speeds up merging by optimizing expert parameter access, achieving up to an order of magnitude less I/O and 11x end-to-end speedup over existing pipelines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Efficient Multi-round LLM Inference over Disaggregated Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [prefill-decode disaggregation, multi-round inference, service level objective, workload scheduling, resource allocation, incremental prefill]</li>
<li class=""><strong>authors:</strong> Wenhao He, Youhe Jiang, Penghao Zhao, Quanqing Xu, Eiko Yoneki, Bin Cui, Fangcheng Fu</li>
<li class=""><strong>institution:</strong> Southeast University, University of Cambridge, Peking University, Ant Group, Shanghai Jiao Tong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.14516" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.14516</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces AMPD, a new disaggregated serving framework that adaptively coordinates and schedules prefill workloads for multi-round LLM inference to maximize SLO attainment. It includes a tailored planning algorithm for optimal resource allocation and parallel strategies. Empirical results show that AMPD significantly improves SLO attainment compared to state-of-the-art baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Floe: Federated Specialization for Real-Time LLM-SLM Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [federated learning, edge-cloud collaboration, LoRA, logit-level fusion, privacy-preserving]</li>
<li class=""><strong>authors:</strong> Chunlin Tian, Kahou Tam, Yebo Wu, Shuaihang Zhong, Li Li, Nicholas D. Lane, Chengzhong Xu</li>
<li class=""><strong>institution:</strong> University of Science and Technology of China, University of Oxford</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.14302" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.14302</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Floe is a hybrid federated learning framework that combines a cloud-based black-box LLM with lightweight SLMs on edge devices for real-time inference. It uses a heterogeneity-aware LoRA adaptation and logit-level fusion to coordinate models. The approach enhances privacy, personalization, and reduces inference latency on edge devices compared to baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] SIDSense: Database-Free TV White Space Sensing for Disaster-Resilient Connectivity</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [CNN-based spectrum classification, edge AI framework, GPU-aware scheduling, hybrid sensing-first authorization workflow, compliance-gated controller, TV White Space sensing]</li>
<li class=""><strong>authors:</strong> George M. Gichuru, Zoe Aiyanna M. Cayetano</li>
<li class=""><strong>institution:</strong> Amini</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13542" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13542</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents SIDSense, an edge AI framework that uses CNN-based spectrum classification and a hybrid workflow to enable database-free TV White Space operation for disaster-resilient connectivity. Field experiments in Barbados demonstrated sustained connectivity during simulated outages with high sensing accuracy and low latency, while maintaining 5G performance. The work aims to accelerate resilient connectivity deployments in climate-vulnerable regions by contributing components to open source.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Evaluation of Dynamic Vector Bin Packing for Virtual Machine Placement</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud computing resource management], [dynamic vector bin packing, virtual machine placement, online algorithms, MinUsageTime DVBP, non-clairvoyant, clairvoyant, learning-augmented]</li>
<li class=""><strong>authors:</strong> Zong Yu Lee, Xueyan Tang</li>
<li class=""><strong>institution:</strong> Nanyang Technological University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.14704" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.14704</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper formulates virtual machine placement as a MinUsageTime Dynamic Vector Bin Packing problem and evaluates various online algorithms in non-clairvoyant, clairvoyant, and learning-augmented settings. It develops new algorithms and enhancements, testing them empirically on real-world Microsoft Azure datasets. The study provides insights into effective algorithm structures and design elements for practical cloud resource management.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Atomix: Timely, Transactional Tool Use for Reliable Agentic Workflows</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [transactional semantics, speculative execution, epoch tagging, frontier gating, compensation, bufferable effects]</li>
<li class=""><strong>authors:</strong> Bardia Mohammadi, Nearchos Potamitis, Lars Klein, Akhil Arora, Laurent Bindschaedler</li>
<li class=""><strong>institution:</strong> MPI-SWS, Aarhus University, EPFL</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.14849" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.14849</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Atomix, a runtime that provides progress-aware transactional semantics for LLM agent tool calls by tagging calls with epochs and using per-resource frontiers to gate commits. This approach isolates speculative branches and manages contention, allowing bufferable effects to be delayed and externalized effects to be compensated on abort. The method improves task success and strengthens isolation under failures, speculation, and contention in agentic workflows.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 54</strong></p>
<ul>
<li class="">[arXiv260217] Nanbeige4.1-3B: A Small General Model that Reasons, Aligns, and Acts <a href="https://arxiv.org/pdf/2602.13367" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Cast-R1: Learning Tool-Augmented Sequential Decision Policies for Time Series Forecasting <a href="https://arxiv.org/pdf/2602.13802" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Process-Supervised Multi-Agent Reinforcement Learning for Reliable Clinical Reasoning <a href="https://arxiv.org/pdf/2602.14160" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] AnomaMind: Agentic Time Series Anomaly Detection with Tool-Augmented Reasoning <a href="https://arxiv.org/pdf/2602.13807" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] An Overlay Multicast Routing Method Based on Network Situational Aware-ness and Hierarchical Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.13211" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study <a href="https://arxiv.org/pdf/2602.14322" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] On-Policy Supervised Fine-Tuning for Efficient Reasoning <a href="https://arxiv.org/pdf/2602.13407" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Scaling the Scaling Logic: Agentic Meta-Synthesis of Logic Reasoning <a href="https://arxiv.org/pdf/2602.13218" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Deep Dense Exploration for LLM Reinforcement Learning via Pivot-Driven Resampling <a href="https://arxiv.org/pdf/2602.14169" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] You Can Learn Tokenization End-to-End with Reinforcement Learning <a href="https://arxiv.org/pdf/2602.13940" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Train Less, Learn More: Adaptive Efficient Rollout Optimization for Group-Based Reinforcement Learning <a href="https://arxiv.org/pdf/2602.14338" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Large Language Model (LLM)-enabled Reinforcement Learning for Wireless Network Optimization <a href="https://arxiv.org/pdf/2602.13210" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Experiential Reinforcement Learning <a href="https://arxiv.org/pdf/2602.13949" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] GeoEyes: On-Demand Visual Focusing for Evidence-Grounded Understanding of Ultra-High-Resolution Remote Sensing Imagery <a href="https://arxiv.org/pdf/2602.14201" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] LACONIC: Length-Aware Constrained Reinforcement Learning for LLM <a href="https://arxiv.org/pdf/2602.14468" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] A Safety-Constrained Reinforcement Learning Framework for Reliable Wireless Autonomy <a href="https://arxiv.org/pdf/2602.13207" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Adaptive Value Decomposition: Coordinating a Varying Number of Agents in Urban Systems <a href="https://arxiv.org/pdf/2602.13309" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Zero-Shot Instruction Following in RL via Structured LTL Representations <a href="https://arxiv.org/pdf/2602.14344" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] QuRL: Efficient Reinforcement Learning with Quantized Rollout <a href="https://arxiv.org/pdf/2602.13953" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] General learned delegation by clones <a href="https://arxiv.org/pdf/2602.13262" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Text Before Vision: Staged Knowledge Injection Matters for Agentic RLVR in Ultra-High-Resolution Remote Sensing Understanding <a href="https://arxiv.org/pdf/2602.14225" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Socially-Weighted Alignment: A Game-Theoretic Framework for Multi-Agent LLM Systems <a href="https://arxiv.org/pdf/2602.14471" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Mean Flow Policy with Instantaneous Velocity Constraint for One-step Action Generation <a href="https://arxiv.org/pdf/2602.13810" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Lang2Act: Fine-Grained Visual Reasoning through Self-Emergent Linguistic Toolchains <a href="https://arxiv.org/pdf/2602.13235" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] WIMLE: Uncertainty-Aware World Models with IMLE for Sample-Efficient Continuous Control <a href="https://arxiv.org/pdf/2602.14351" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] WoVR: World Models as Reliable Simulators for Post-Training VLA Policies with RL <a href="https://arxiv.org/pdf/2602.13977" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] REDSearcher: A Scalable and Cost-Efficient Framework for Long-Horizon Search Agents <a href="https://arxiv.org/pdf/2602.14234" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Securing SIM-Assisted Wireless Networks via Quantum Reinforcement Learning <a href="https://arxiv.org/pdf/2602.13238" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Learning Transferability: A Two-Stage Reinforcement Learning Approach for Enhancing Quadruped Robots&#x27; Performance in U-Shaped Stair Climbing <a href="https://arxiv.org/pdf/2602.14473" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] AdaptManip: Learning Adaptive Whole-Body Object Lifting and Delivery with Online Recurrent State Estimation <a href="https://arxiv.org/pdf/2602.14363" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] GRAIL: Goal Recognition Alignment through Imitation Learning <a href="https://arxiv.org/pdf/2602.14252" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] TikArt: Aperture-Guided Observation for Fine-Grained Visual Reasoning via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.14482" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Why Code, Why Now: Learnability, Computability, and the Real Limits of Machine Learning <a href="https://arxiv.org/pdf/2602.13934" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Policy Gradient with Adaptive Entropy Annealing for Continual Fine-Tuning <a href="https://arxiv.org/pdf/2602.14078" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] AuTAgent: A Reinforcement Learning Framework for Tool-Augmented Audio Reasoning <a href="https://arxiv.org/pdf/2602.13685" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Building Autonomous GUI Navigation via Agentic-Q Estimation and Step-Wise Policy Optimization <a href="https://arxiv.org/pdf/2602.13653" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Formally Verifying and Explaining Sepsis Treatment Policies with COOL-MC <a href="https://arxiv.org/pdf/2602.14505" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Enabling Option Learning in Sparse Rewards with Hindsight Experience Replay <a href="https://arxiv.org/pdf/2602.13865" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] From Pixels to Policies: Reinforcing Spatial Reasoning in Language Models for Content-Aware Layout Design <a href="https://arxiv.org/pdf/2602.13912" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] KernelBlaster: Continual Cross-Task CUDA Optimization via Memory-Augmented In-Context Reinforcement Learning <a href="https://arxiv.org/pdf/2602.14293" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] OpAgent: Operator Agent for Web Navigation <a href="https://arxiv.org/pdf/2602.13559" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] TWISTED-RL: Hierarchical Skilled Agents for Knot-Tying without Human Demonstrations <a href="https://arxiv.org/pdf/2602.14526" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Fluid-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.14559" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] RNM-TD3: N<!-- -->:M<!-- --> Semi-structured Sparse Reinforcement Learning From Scratch <a href="https://arxiv.org/pdf/2602.14578" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Decoupled Continuous-Time Reinforcement Learning via Hamiltonian Flow <a href="https://arxiv.org/pdf/2602.14587" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] GREAT-EER: Graph Edge Attention Network for Emergency Evacuation Responses <a href="https://arxiv.org/pdf/2602.14676" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Evolutionary System Prompt Learning can Facilitate Reinforcement Learning for LLMs <a href="https://arxiv.org/pdf/2602.14697" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] ManeuverNet: A Soft Actor-Critic Framework for Precise Maneuvering of Double-Ackermann-Steering Robots with Optimized Reward Functions <a href="https://arxiv.org/pdf/2602.14726" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Interactionless Inverse Reinforcement Learning: A Data-Centric Framework for Durable Alignment <a href="https://arxiv.org/pdf/2602.14844" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Goldilocks RL: Tuning Task Difficulty to Escape Sparse Rewards for Reasoning <a href="https://arxiv.org/pdf/2602.14868" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] On the Learning Dynamics of RLVR at the Edge of Competence <a href="https://arxiv.org/pdf/2602.14872" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] BFS-PO: Best-First Search for Large Reasoning Models <a href="https://arxiv.org/pdf/2602.14917" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] MAC-AMP: A Closed-Loop Multi-Agent Collaboration System for Multi-Objective Antimicrobial Peptide Design <a href="https://arxiv.org/pdf/2602.14926" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Cold-Start Personalization via Training-Free Priors from Structured World Models <a href="https://arxiv.org/pdf/2602.15012" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 19</strong></p>
<ul>
<li class="">[arXiv260217] Geometry-Aware Physics-Informed PointNets for Modeling Flows Across Porous Structures <a href="https://arxiv.org/pdf/2602.14108" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Why is Normalization Preferred? A Worst-Case Complexity Theory for Stochastically Preconditioned SGD under Heavy-Tailed Noise <a href="https://arxiv.org/pdf/2602.13413" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Accelerated Discovery of Cryoprotectant Cocktails via Multi-Objective Bayesian Optimization <a href="https://arxiv.org/pdf/2602.13398" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] On-Policy Supervised Fine-Tuning for Efficient Reasoning <a href="https://arxiv.org/pdf/2602.13407" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] WiSparse: Boosting LLM Inference Efficiency with Weight-Aware Mixed Activation Sparsity <a href="https://arxiv.org/pdf/2602.14452" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] QuRL: Efficient Reinforcement Learning with Quantized Rollout <a href="https://arxiv.org/pdf/2602.13953" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] IDPruner: Harmonizing Importance and Diversity in Visual Token Pruning for MLLMs <a href="https://arxiv.org/pdf/2602.13315" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Discrete Double-Bracket Flows for Isotropic-Noise Invariant Eigendecomposition <a href="https://arxiv.org/pdf/2602.13759" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Responsible AI in Business <a href="https://arxiv.org/pdf/2602.13244" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Decentralized Federated Learning With Energy Harvesting Devices <a href="https://arxiv.org/pdf/2602.14051" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] SpargeAttention2: Trainable Sparse Attention via Hybrid Top-k+Top-p Masking and Distillation Fine-Tuning <a href="https://arxiv.org/pdf/2602.13515" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Fast Swap-Based Element Selection for Multiplication-Free Dimension Reduction <a href="https://arxiv.org/pdf/2602.13532" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Experimentation Accelerator: Interpretable Insights and Creative Recommendations for A/B Testing with Content-Aware ranking <a href="https://arxiv.org/pdf/2602.13852" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] AdaCorrection: Adaptive Offset Cache Correction for Accurate Diffusion Transformers <a href="https://arxiv.org/pdf/2602.13357" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] RNM-TD3: N<!-- -->:M<!-- --> Semi-structured Sparse Reinforcement Learning From Scratch <a href="https://arxiv.org/pdf/2602.14578" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] AI Arms and Influence: Frontier Models Exhibit Sophisticated Reasoning in Simulated Nuclear Crises <a href="https://arxiv.org/pdf/2602.14740" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Rethinking Diffusion Models with Symmetries through Canonicalization with Applications to Molecular Graph Generation <a href="https://arxiv.org/pdf/2602.15022" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Fast Compute for ML Optimization <a href="https://arxiv.org/pdf/2602.14280" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Faster Molecular Dynamics with Neural Network Potentials via Distilled Multiple Time-Stepping and Non-Conservative Forces <a href="https://arxiv.org/pdf/2602.14975" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-18">2026-02-18<a href="#2026-02-18" class="hash-link" aria-label="Direct link to 2026-02-18" title="Direct link to 2026-02-18" translate="no">​</a></h2>
<p><strong>cs.DC total: 7</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260218] Tight Communication Bounds for Distributed Algorithms in the Quantum Routing Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [quantum routing model, quantum walks, electric networks, message complexity, lower bounds]</li>
<li class=""><strong>authors:</strong> Fabien Dufoulon, Frédéric Magniez, Gopal Pandurangan</li>
<li class=""><strong>institution:</strong> Lancaster University, Université Paris Cité, University of Houston</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15529" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15529</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces new distributed quantum algorithms for fundamental problems like leader election and MST, using quantum walks based on electric networks to reduce communication. It shows these algorithms achieve near-optimal message complexities, significantly improving over prior quantum work and demonstrating a quadratic communication advantage over classical distributed algorithms.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260218] On the Geometric Coherence of Global Aggregation in Federated GNN</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, graph neural networks, geometric coherence, global aggregation, cross-domain federated GNN, GGRS]</li>
<li class=""><strong>authors:</strong> Chethana Prasad Kabgere, Shylaja SS</li>
<li class=""><strong>institution:</strong> PES University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15510" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15510</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes GGRS, a server-side framework that regulates client updates based on geometric criteria to address destructive interference in federated GNN aggregation. It concludes that this geometry-aware approach is necessary to preserve global message-passing coherence in cross-domain federated graph learning, which is not captured by conventional metrics like loss or accuracy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260218] SCENE OTA-FD: Self-Centering Noncoherent Estimator for Over-the-Air Federated Distillation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [over-the-air federated distillation, noncoherent energy aggregation, constant-envelope signaling, self-centering estimator, pilot-free aggregation]</li>
<li class=""><strong>authors:</strong> Hao Chen, Zavareh Bozorgasl</li>
<li class=""><strong>institution:</strong> Boise State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15326" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15326</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SCENE, a pilot-free and phase-invariant method for aggregating soft labels in over-the-air federated distillation. It uses noncoherent energy transmission and a self-centering estimator to avoid channel state information overhead. The method is designed for short-coherence or hardware-constrained regimes and can outperform coherent designs when pilot overhead is significant.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260218] FlashMem: Supporting Modern DNN Workloads on Mobile with GPU Memory Hierarchy Optimizations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [memory streaming, weight preloading, 2.5D texture memory, multi-DNN workloads, on-device inference, mobile GPU]</li>
<li class=""><strong>authors:</strong> Zhihao Shu, Md Musfiqur Rahman Sanim, Hangyu Zheng, Kunxiong Zhu, Miao Yin, Gagan Agrawal, Wei Niu</li>
<li class=""><strong>institution:</strong> University of Georgia, University of Texas at Arlington</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15379" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15379</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FlashMem is a memory streaming framework for mobile GPUs that statically schedules and dynamically streams model weights on-demand, instead of fully preloading them. It leverages 2.5D texture memory to reduce data transformations. The framework significantly reduces memory usage and speeds up inference for large-scale and multi-DNN workloads compared to existing approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260218] Service Orchestration in the Computing Continuum: Structural Challenges and Vision</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [service orchestration], [computing continuum, edge computing, cloud computing, active inference, service placement, quality of experience]</li>
<li class=""><strong>authors:</strong> Boris Sedlak, Víctor Casamayor Pujol, Ildefons Magrans de Abril, Praveen Kumar Donta, Adel N. Toosi, Schahram Dustdar</li>
<li class=""><strong>institution:</strong> Universitat Pompeu Fabra, Stockholm University, University of Melbourne, ICREA, TU Wien</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15794" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15794</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper analyzes structural challenges for service orchestration in the heterogeneous and dynamic Computing Continuum, proposing autonomous orchestration as an ideal solution and illustrating Active Inference as a potential approach. It concludes that no existing solution fully achieves this vision and identifies key research challenges, most notably the need for standardized simulation environments to compare orchestration mechanisms.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260218] Distributed Semi-Speculative Parallel Anisotropic Mesh Adaptation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing, mesh adaptation], [distributed memory, speculative execution, anisotropic mesh adaptation, parallel runtime, cc-NUMA]</li>
<li class=""><strong>authors:</strong> Kevin Garner, Polykarpos Thomadakis, Nikos Chrisochoides</li>
<li class=""><strong>institution:</strong> Old Dominion University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15204" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15204</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a distributed memory method for anisotropic mesh adaptation that separates meshing functionality from performance aspects, using a shared memory mesh generator and a parallel runtime system. The method avoids collective communication by first adapting interface elements on a single node and then adapting interior elements in parallel while keeping interfaces frozen. It is shown to generate large meshes (up to ~1 billion elements) with quality and performance comparable to state-of-the-art HPC meshing software.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260218] Co-Design and Evaluation of a CPU-Free MPI GPU Communication Abstraction and Implementation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing], [MPI, GPU communication, CPU-free communication, stream-triggered communication, halo exchange, Cabana/Kokkos]</li>
<li class=""><strong>authors:</strong> Patrick G. Bridges, Derek Schafer, Jack Lange, James B. White III, Anthony Skjellum, Evan Suggs, Thomas Hines, Purushotham Bangalore, Matthew G. F. Dosanjh, Whit Schonbein</li>
<li class=""><strong>institution:</strong> University of New Mexico, Oak Ridge National Laboratory, Tennessee Tech University, University of Alabama, Sandia National Laboratories</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15356" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15356</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces an MPI-based GPU communication API designed to enable CPU-free, high-performance communication by leveraging HPE Slingshot 11 network capabilities. The API supports two-sided communication and integrates with the Cabana/Kokkos framework for halo exchange primitives. Evaluation on Frontier and Tuolumne supercomputers shows up to 50% latency reduction in GPU ping-pong exchanges and a 28% speedup when scaling to 8,192 GPUs.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 13</strong></p>
<ul>
<li class="">[arXiv260218] Recursive Concept Evolution for Compositional Reasoning in Large Language Models <a href="https://arxiv.org/pdf/2602.15725" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction <a href="https://arxiv.org/pdf/2602.15733" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications <a href="https://arxiv.org/pdf/2602.15640" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning <a href="https://arxiv.org/pdf/2602.15817" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Near-Optimal Sample Complexity for Online Constrained MDPs <a href="https://arxiv.org/pdf/2602.15076" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] CDRL: A Reinforcement Learning Framework Inspired by Cerebellar Circuits and Dendritic Computational Strategies <a href="https://arxiv.org/pdf/2602.15367" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL <a href="https://arxiv.org/pdf/2602.15564" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching <a href="https://arxiv.org/pdf/2602.15827" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Fairness over Equality: Correcting Social Incentives in Asymmetric Sequential Social Dilemmas <a href="https://arxiv.org/pdf/2602.15407" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] CLOT: Closed-Loop Global Motion Tracking for Whole-Body Humanoid Teleoperation <a href="https://arxiv.org/pdf/2602.15060" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] MyoInteract: A Framework for Fast Prototyping of Biomechanical HCI Tasks using Reinforcement Learning <a href="https://arxiv.org/pdf/2602.15245" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] GLM-5: from Vibe Coding to Agentic Engineering <a href="https://arxiv.org/pdf/2602.15763" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens <a href="https://arxiv.org/pdf/2602.15620" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 10</strong></p>
<ul>
<li class="">[arXiv260218] Sparrow: Text-Anchored Window Attention with Visual-Semantic Glimpsing for Speculative Decoding in Video LLMs <a href="https://arxiv.org/pdf/2602.15318" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety <a href="https://arxiv.org/pdf/2602.15799" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Multi-Objective Coverage via Constraint Active Search <a href="https://arxiv.org/pdf/2602.15595" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Transforming Computational Lithography with AC and AI -- Faster, More Accurate, and Energy-efficient <a href="https://arxiv.org/pdf/2602.15036" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Fractional-Order Federated Learning <a href="https://arxiv.org/pdf/2602.15380" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Safe-SDL<!-- -->:Establishing<!-- --> Safety Boundaries and Control Mechanisms for AI-Driven Self-Driving Laboratories <a href="https://arxiv.org/pdf/2602.15061" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Stabilizing Test-Time Adaptation of High-Dimensional Simulation Surrogates via D-Optimal Statistics <a href="https://arxiv.org/pdf/2602.15820" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Molecular Design beyond Training Data with Novel Extended Objective Functionals of Generative AI Models Driven by Quantum Annealing Computer <a href="https://arxiv.org/pdf/2602.15451" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] MyoInteract: A Framework for Fast Prototyping of Biomechanical HCI Tasks using Reinforcement Learning <a href="https://arxiv.org/pdf/2602.15245" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization <a href="https://arxiv.org/pdf/2602.15277" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2026-02-18T03:31:47.000Z" itemprop="dateModified">Feb 18, 2026</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20260209-20260215"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20260209-20260215</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2026-02-16" class="table-of-contents__link toc-highlight">2026-02-16</a></li><li><a href="#2026-02-17" class="table-of-contents__link toc-highlight">2026-02-17</a></li><li><a href="#2026-02-18" class="table-of-contents__link toc-highlight">2026-02-18</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>