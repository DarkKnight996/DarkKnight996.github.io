<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20260216-20260222" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20260216-20260222 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20260216-20260222"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20260216-20260222 | DarkKnight Note"><meta data-rh="true" name="description" content="2026-02-16"><meta data-rh="true" property="og:description" content="2026-02-16"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20260216-20260222"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260216-20260222" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260216-20260222" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20260216-20260222","item":"https://darkknight996.github.io/daily/20260216-20260222"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.6cdbb34f.js" defer="defer"></script>
<script src="/assets/js/main.c7401d40.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260105-20260111"><span title="20260105-20260111" class="linkLabel_WmDU">20260105-20260111</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260112-20260118"><span title="20260112-20260118" class="linkLabel_WmDU">20260112-20260118</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260119-20260125"><span title="20260119-20260125" class="linkLabel_WmDU">20260119-20260125</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260126-20260201"><span title="20260126-20260201" class="linkLabel_WmDU">20260126-20260201</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260202-20260208"><span title="20260202-20260208" class="linkLabel_WmDU">20260202-20260208</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260209-20260215"><span title="20260209-20260215" class="linkLabel_WmDU">20260209-20260215</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20260216-20260222"><span title="20260216-20260222" class="linkLabel_WmDU">20260216-20260222</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260223-20260301"><span title="20260223-20260301" class="linkLabel_WmDU">20260223-20260301</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20260216-20260222</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20260216-20260222</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-16">2026-02-16<a href="#2026-02-16" class="hash-link" aria-label="Direct link to 2026-02-16" title="Direct link to 2026-02-16" translate="no">​</a></h2>
<p><strong>cs.DC total: 5</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260216] Classification of Local Optimization Problems in Directed Cycles</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed algorithms], [LOCAL model, directed cycles, classification, approximation algorithms, meta-algorithm]</li>
<li class=""><strong>authors:</strong> Thomas Boudier, Fabian Kuhn, Augusto Modanese, Ronja Stimpert, Jukka Suomela</li>
<li class=""><strong>institution:</strong> GSSI, University of Freiburg, CISPA Helmholtz Center for Information Security, Aalto University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13046" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13046</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper provides a complete complexity classification for local optimization problems in directed cycles within the distributed LOCAL model. It shows that for any constant approximation ratio, the problem falls into one of four deterministic and randomized complexity classes. The authors also present an efficient meta-algorithm to determine the class and synthesize an optimal distributed algorithm.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260216] DRAMatic Speedup: Accelerating HE Operations on a Processing-in-Memory System</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [hardware acceleration], [residue number system, number-theoretic transform, processing-in-memory]</li>
<li class=""><strong>authors:</strong> Niklas Klinger, Jonas Sander, Peterson Yuhala, Pascal Felber, Thomas Eisenbarth</li>
<li class=""><strong>institution:</strong> University of Luebeck, University of Neuchâtel</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.12433" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.12433</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents DRAMatic, a system that implements foundational homomorphic encryption operations on UPMEM&#x27;s processing-in-memory hardware. It uses arithmetic optimizations like the residue number system and number-theoretic transform to accelerate these operations. The evaluation shows DRAMatic significantly closes the performance gap with a software library like Microsoft SEAL but is still limited by the hardware&#x27;s multiplication performance and data transfer overhead.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260216] Bloom Filter Look-Up Tables for Private and Secure Distributed Databases in Web3 (Revised Version)</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed databases], [Bloom Filter, BFLUT, OrbitDB, IPFS, IPNS, decentralized key management]</li>
<li class=""><strong>authors:</strong> Shlomi Dolev, Ehud Gudes, Daniel Shlomo</li>
<li class=""><strong>institution:</strong> Ben-Gurion University of the Negev</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13167" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13167</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a decentralized database scheme for secure key management in Web3, using the BFLUT algorithm to encode and distribute cryptographic keys without explicit storage. The system integrates OrbitDB, IPFS, and IPNS to ensure privacy and prevent key discovery even if network nodes are compromised. The authors conclude it provides a foundational, secure, and private solution for decentralized applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260216] OptiML: An End-to-End Framework for Program Synthesis and CUDA Kernel Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [Monte Carlo Tree Search, Mixture-of-Thoughts, program synthesis, CUDA optimization, search under verification, Nsight Compute]</li>
<li class=""><strong>authors:</strong> Arijit Bhattacharjee, Heng Ping, Son Vu Le, Paul Bogdan, Nesreen K. Ahmed, Ali Jannesari</li>
<li class=""><strong>institution:</strong> Iowa State University, University of Southern California, Cisco AI Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.12305" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.12305</a></li>
<li class=""><strong>Simple LLM Summary:</strong> OptiML is an end-to-end framework that uses a two-stage process to generate and optimize CUDA kernels. It first synthesizes code from natural language using a Mixture-of-Thoughts generator, then refines it via Monte Carlo Tree Search guided by hardware-aware rewards from profiler feedback. The framework consistently produces verified performance improvements over strong LLM baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260216] Distance-based certification for leader election in meshed graphs and local recognition of their subclasses</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [graph theory], [proof labeling scheme, leader election, meshed graphs, distance verification, local certification]</li>
<li class=""><strong>authors:</strong> Jérémie Chalopin, Victor Chepoi, Maria Kokkou</li>
<li class=""><strong>institution:</strong> Aix-Marseille Université, Université Côte d&#x27;Azur, University of Crete</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.12894" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.12894</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents a 2-local proof labeling scheme using constant-size labels {0,1,2} to solve leader election in anonymous meshed graphs by verifying distances modulo 3 to a designated root. It also provides 3-local schemes to recognize subclasses of meshed graphs using labels of size O(log D). The main conclusion is that leader election can be certified locally with small labels in this broad class of graphs, and their subclasses can be locally recognized by leveraging distance verification and existing characterizations.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 32</strong></p>
<ul>
<li class="">[arXiv260216] Synthetic Interaction Data for Scalable Personalization in Large Language Models <a href="https://arxiv.org/pdf/2602.12394" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs <a href="https://arxiv.org/pdf/2602.12705" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Constraint-Rectified Training for Efficient Chain-of-Thought <a href="https://arxiv.org/pdf/2602.12526" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Flow-Factory: A Unified Framework for Reinforcement Learning in Flow-Matching Models <a href="https://arxiv.org/pdf/2602.12529" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning <a href="https://arxiv.org/pdf/2602.12375" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] FLAC: Maximum Entropy RL via Kinetic Energy Regularized Bridge Matching <a href="https://arxiv.org/pdf/2602.12829" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Provably Convergent Actor-Critic in Risk-averse MARL <a href="https://arxiv.org/pdf/2602.12386" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Safe Reinforcement Learning via Recovery-based Shielding with Gaussian Process Dynamics Models <a href="https://arxiv.org/pdf/2602.12444" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Amortized Reasoning Tree Search: Decoupling Proposal and Decision in Large Language Models <a href="https://arxiv.org/pdf/2602.12846" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] On Robustness and Chain-of-Thought Consistency of RL-Finetuned VLMs <a href="https://arxiv.org/pdf/2602.12506" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Designing RNAs with Language Models <a href="https://arxiv.org/pdf/2602.12470" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via Confidence-Guided Variance Reduction <a href="https://arxiv.org/pdf/2602.12579" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Look Inward to Explore Outward: Learning Temperature Policy from LLM Internal States via Hierarchical RL <a href="https://arxiv.org/pdf/2602.13035" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] TCRL: Temporal-Coupled Adversarial Training for Robust Constrained Reinforcement Learning in Worst-Case Scenarios <a href="https://arxiv.org/pdf/2602.13040" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Composable Model-Free RL for Navigation with Input-Affine Systems <a href="https://arxiv.org/pdf/2602.12492" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Wireless TokenCom: RL-Based Tokenizer Agreement for Multi-User Wireless Token Communications <a href="https://arxiv.org/pdf/2602.12338" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Dual-Granularity Contrastive Reward via Generated Episodic Guidance for Efficient Embodied RL <a href="https://arxiv.org/pdf/2602.12636" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Abstractive Red-Teaming of Language Model Character <a href="https://arxiv.org/pdf/2602.12318" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] In-Context Autonomous Network Incident Response: An End-to-End Large Language Model Agent Approach <a href="https://arxiv.org/pdf/2602.13156" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Learning to Approximate Uniform Facility Location via Graph Neural Networks <a href="https://arxiv.org/pdf/2602.13155" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] ALOE: Action-Level Off-Policy Evaluation for Vision-Language-Action Model Post-Training <a href="https://arxiv.org/pdf/2602.12691" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Unifying Model-Free Efficiency and Model-Based Representations via Latent Dynamics <a href="https://arxiv.org/pdf/2602.12643" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Curriculum-DPO++: Direct Preference Optimization via Data and Model Curricula for Text-to-Image Generation <a href="https://arxiv.org/pdf/2602.13055" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] PMG: Parameterized Motion Generator for Human-like Locomotion Control <a href="https://arxiv.org/pdf/2602.12656" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] What does RL improve for Visual Reasoning? A Frankenstein-Style Analysis <a href="https://arxiv.org/pdf/2602.12395" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Energy-Aware Reinforcement Learning for Robotic Manipulation of Articulated Components in Infrastructure Operation and Maintenance <a href="https://arxiv.org/pdf/2602.12288" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] AstRL: Analog and Mixed-Signal Circuit Synthesis with Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2602.12402" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Bench-MFG: A Benchmark Suite for Learning in Stationary Mean Field Games <a href="https://arxiv.org/pdf/2602.12517" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Agent Skills for Large Language Models: Architecture, Acquisition, Security, and the Path Forward <a href="https://arxiv.org/pdf/2602.12430" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models <a href="https://arxiv.org/pdf/2602.12566" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Multi-Agent Model-Based Reinforcement Learning with Joint State-Action Learned Embeddings <a href="https://arxiv.org/pdf/2602.12520" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Intrinsic Credit Assignment for Long Horizon Interaction <a href="https://arxiv.org/pdf/2602.12342" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 7</strong></p>
<ul>
<li class="">[arXiv260216] Multi-Dimensional Visual Data Recovery: Scale-Aware Tensor Modeling and Accelerated Randomized Computation <a href="https://arxiv.org/pdf/2602.12982" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Tight Bounds for Logistic Regression with Large Stepsize Gradient Descent in Low Dimension <a href="https://arxiv.org/pdf/2602.12471" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] CoPE-VideoLM: Codec Primitives For Efficient Video Language Models <a href="https://arxiv.org/pdf/2602.13191" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] SLA2: Sparse-Linear Attention with Learnable Routing and QAT <a href="https://arxiv.org/pdf/2602.12675" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] Accelerating Feedback-based Algorithms for Quantum Optimization Using Gradient Descent <a href="https://arxiv.org/pdf/2602.12387" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] SWING: Unlocking Implicit Graph Representations for Graph Random Features <a href="https://arxiv.org/pdf/2602.12703" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260216] TriGen: NPU Architecture for End-to-End Acceleration of Large Language Models based on SW-HW Co-Design <a href="https://arxiv.org/pdf/2602.12962" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-17">2026-02-17<a href="#2026-02-17" class="hash-link" aria-label="Direct link to 2026-02-17" title="Direct link to 2026-02-17" translate="no">​</a></h2>
<p><strong>cs.DC total: 12</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260217] Parallel Sparse and Data-Sparse Factorization-based Linear Solvers</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [numerical linear algebra], [sparse direct solvers, low-rank compression, hierarchical matrix algebra, parallel factorization]</li>
<li class=""><strong>authors:</strong> Xiaoye Sherry Li, Yang Liu</li>
<li class=""><strong>institution:</strong> Lawrence Berkeley National Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.14289" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.14289</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper reviews recent advances in parallel sparse direct solvers, focusing on reducing communication costs and computational complexity through low-rank and hierarchical compression techniques. It concludes that these methods are crucial for building scalable, robust solver toolchains for large-scale problems on modern heterogeneous machines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Preventing Rank Collapse in Federated Low-Rank Adaptation with Client Heterogeneity</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [federated learning, low-rank adaptation, rank collapse, heterogeneous ranks, rank-partitioned aggregation]</li>
<li class=""><strong>authors:</strong> Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang</li>
<li class=""><strong>institution:</strong> University of Exeter</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13486" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13486</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes raFLoRA, a rank-partitioned aggregation method for federated low-rank adaptation (FedLoRA) to address rank collapse in heterogeneous client settings. It prevents performance degradation by aggregating local model updates based on their effective rank contributions. Experiments show that raFLoRA improves model performance and maintains communication efficiency compared to existing FedLoRA baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Ask the Expert: Collaborative Inference for Vision Transformers with Near-Edge Accelerators</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [collaborative inference, near-edge accelerator, vision transformer, routing mechanism, progressive specialist training]</li>
<li class=""><strong>authors:</strong> Hao Liu, Suhaib A. Fahmy</li>
<li class=""><strong>institution:</strong> King Abdullah University of Science and Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13334" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13334</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a collaborative inference framework that uses a lightweight Vision Transformer on an edge device and multiple expert ViTs on a near-edge accelerator, with a routing mechanism to select experts for low-confidence samples. The method reduces latency by up to 45% and energy consumption by up to 46% compared to baseline approaches, while improving accuracy through a progressive training strategy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Intent-driven Diffusion-based Path for Mobile Data Collector in IoT-enabled Dense WSNs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [diffusion-based planning, intent-driven networking, mobile data collection, generative diffusion models, path planning, rendezvous point selection]</li>
<li class=""><strong>authors:</strong> Uma Mahesh Boda, Mallikharjuna Rao Nuka</li>
<li class=""><strong>institution:</strong> Annamacharya University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13277" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13277</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ID2P2, an intent-driven diffusion-based path planning framework for mobile data collectors in dense wireless sensor networks. It uses a generative diffusion process to create adaptive data collection trajectories that incorporate high-level operational intents like latency minimization. Simulation results show ID2P2 outperforms baselines with significant improvements in tour completion time, data freshness, and energy efficiency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] ML-ECS: A Collaborative Multimodal Learning Framework for Edge-Cloud Synergies</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [cross-modal contrastive learning, adaptive multimodal tuning, modality-aware model aggregation, SLM-enhanced CCL, LoRA, edge-cloud synergy]</li>
<li class=""><strong>authors:</strong> Yuze Liu, Shibo Chu, Tiehua Zhang, Hao Zhou, Zhishu Shen, Jinze Wang, Jianzhong Qi, Feng Xia</li>
<li class=""><strong>institution:</strong> Tongji University, Swinburne University of Technology, The University of Melbourne, RMIT University, Wuhan University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.14107" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.14107</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ML-ECS, a collaborative multimodal learning framework for edge-cloud systems that addresses modality and model heterogeneity. Its core method integrates cross-modal contrastive learning, adaptive tuning, and modality-aware aggregation to enable efficient knowledge sharing. The framework improves performance on multimodal tasks and achieves high communication efficiency by transmitting only low-rank LoRA parameters.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] TEG: Exascale Cluster Governance via Non-Equilibrium Thermodynamics and Langevin Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [thermodynamic governance, langevin agents, holographic potential field, landau phase transition, token evaporation, dual-number damping, glassy states, high-order control barrier functions]</li>
<li class=""><strong>authors:</strong> Zhengyan Chu</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13789" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13789</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes TEG, a decentralized cluster governance architecture that models resource contention using non-equilibrium thermodynamics and Langevin dynamics, replacing a global scheduler with agents performing Brownian motion on a potential field. It argues that this paradigm of emergent order, rather than deterministic orchestration, is necessary for scalability to exascale AI workloads.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] MergePipe: A Budget-Aware Parameter Management System for Scalable LLM Merging</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [model merging, parameter management, I/O optimization, cost-aware planning, streaming execution, catalog-driven abstraction]</li>
<li class=""><strong>authors:</strong> Yuanyi Wang, Yanggan Gu, Zihao Wang, Kunxi Li, Yifan Yang, Zhaoyi Yan, Congkai Xie, Jianmin Wu, Hongxia Yang</li>
<li class=""><strong>institution:</strong> Hong Kong Polytechnic University, InfiX.ai, Zhejiang University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13273" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13273</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MergePipe, a system that treats LLM merging as a data management problem, using a catalog-driven abstraction, a cost-aware planner to enforce I/O budgets, and a streaming execution engine. It significantly reduces I/O and speeds up merging by optimizing expert parameter access, achieving up to an order of magnitude less I/O and 11x end-to-end speedup over existing pipelines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Efficient Multi-round LLM Inference over Disaggregated Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [prefill-decode disaggregation, multi-round inference, service level objective, workload scheduling, resource allocation, incremental prefill]</li>
<li class=""><strong>authors:</strong> Wenhao He, Youhe Jiang, Penghao Zhao, Quanqing Xu, Eiko Yoneki, Bin Cui, Fangcheng Fu</li>
<li class=""><strong>institution:</strong> Southeast University, University of Cambridge, Peking University, Ant Group, Shanghai Jiao Tong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.14516" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.14516</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces AMPD, a new disaggregated serving framework that adaptively coordinates and schedules prefill workloads for multi-round LLM inference to maximize SLO attainment. It includes a tailored planning algorithm for optimal resource allocation and parallel strategies. Empirical results show that AMPD significantly improves SLO attainment compared to state-of-the-art baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Floe: Federated Specialization for Real-Time LLM-SLM Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [federated learning, edge-cloud collaboration, LoRA, logit-level fusion, privacy-preserving]</li>
<li class=""><strong>authors:</strong> Chunlin Tian, Kahou Tam, Yebo Wu, Shuaihang Zhong, Li Li, Nicholas D. Lane, Chengzhong Xu</li>
<li class=""><strong>institution:</strong> University of Science and Technology of China, University of Oxford</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.14302" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.14302</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Floe is a hybrid federated learning framework that combines a cloud-based black-box LLM with lightweight SLMs on edge devices for real-time inference. It uses a heterogeneity-aware LoRA adaptation and logit-level fusion to coordinate models. The approach enhances privacy, personalization, and reduces inference latency on edge devices compared to baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] SIDSense: Database-Free TV White Space Sensing for Disaster-Resilient Connectivity</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [CNN-based spectrum classification, edge AI framework, GPU-aware scheduling, hybrid sensing-first authorization workflow, compliance-gated controller, TV White Space sensing]</li>
<li class=""><strong>authors:</strong> George M. Gichuru, Zoe Aiyanna M. Cayetano</li>
<li class=""><strong>institution:</strong> Amini</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.13542" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.13542</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents SIDSense, an edge AI framework that uses CNN-based spectrum classification and a hybrid workflow to enable database-free TV White Space operation for disaster-resilient connectivity. Field experiments in Barbados demonstrated sustained connectivity during simulated outages with high sensing accuracy and low latency, while maintaining 5G performance. The work aims to accelerate resilient connectivity deployments in climate-vulnerable regions by contributing components to open source.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Evaluation of Dynamic Vector Bin Packing for Virtual Machine Placement</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud computing resource management], [dynamic vector bin packing, virtual machine placement, online algorithms, MinUsageTime DVBP, non-clairvoyant, clairvoyant, learning-augmented]</li>
<li class=""><strong>authors:</strong> Zong Yu Lee, Xueyan Tang</li>
<li class=""><strong>institution:</strong> Nanyang Technological University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.14704" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.14704</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper formulates virtual machine placement as a MinUsageTime Dynamic Vector Bin Packing problem and evaluates various online algorithms in non-clairvoyant, clairvoyant, and learning-augmented settings. It develops new algorithms and enhancements, testing them empirically on real-world Microsoft Azure datasets. The study provides insights into effective algorithm structures and design elements for practical cloud resource management.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260217] Atomix: Timely, Transactional Tool Use for Reliable Agentic Workflows</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [transactional semantics, speculative execution, epoch tagging, frontier gating, compensation, bufferable effects]</li>
<li class=""><strong>authors:</strong> Bardia Mohammadi, Nearchos Potamitis, Lars Klein, Akhil Arora, Laurent Bindschaedler</li>
<li class=""><strong>institution:</strong> MPI-SWS, Aarhus University, EPFL</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.14849" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.14849</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Atomix, a runtime that provides progress-aware transactional semantics for LLM agent tool calls by tagging calls with epochs and using per-resource frontiers to gate commits. This approach isolates speculative branches and manages contention, allowing bufferable effects to be delayed and externalized effects to be compensated on abort. The method improves task success and strengthens isolation under failures, speculation, and contention in agentic workflows.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 54</strong></p>
<ul>
<li class="">[arXiv260217] Nanbeige4.1-3B: A Small General Model that Reasons, Aligns, and Acts <a href="https://arxiv.org/pdf/2602.13367" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Cast-R1: Learning Tool-Augmented Sequential Decision Policies for Time Series Forecasting <a href="https://arxiv.org/pdf/2602.13802" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Process-Supervised Multi-Agent Reinforcement Learning for Reliable Clinical Reasoning <a href="https://arxiv.org/pdf/2602.14160" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] AnomaMind: Agentic Time Series Anomaly Detection with Tool-Augmented Reasoning <a href="https://arxiv.org/pdf/2602.13807" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] An Overlay Multicast Routing Method Based on Network Situational Aware-ness and Hierarchical Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.13211" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study <a href="https://arxiv.org/pdf/2602.14322" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] On-Policy Supervised Fine-Tuning for Efficient Reasoning <a href="https://arxiv.org/pdf/2602.13407" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Scaling the Scaling Logic: Agentic Meta-Synthesis of Logic Reasoning <a href="https://arxiv.org/pdf/2602.13218" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Deep Dense Exploration for LLM Reinforcement Learning via Pivot-Driven Resampling <a href="https://arxiv.org/pdf/2602.14169" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] You Can Learn Tokenization End-to-End with Reinforcement Learning <a href="https://arxiv.org/pdf/2602.13940" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Train Less, Learn More: Adaptive Efficient Rollout Optimization for Group-Based Reinforcement Learning <a href="https://arxiv.org/pdf/2602.14338" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Large Language Model (LLM)-enabled Reinforcement Learning for Wireless Network Optimization <a href="https://arxiv.org/pdf/2602.13210" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Experiential Reinforcement Learning <a href="https://arxiv.org/pdf/2602.13949" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] GeoEyes: On-Demand Visual Focusing for Evidence-Grounded Understanding of Ultra-High-Resolution Remote Sensing Imagery <a href="https://arxiv.org/pdf/2602.14201" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] LACONIC: Length-Aware Constrained Reinforcement Learning for LLM <a href="https://arxiv.org/pdf/2602.14468" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] A Safety-Constrained Reinforcement Learning Framework for Reliable Wireless Autonomy <a href="https://arxiv.org/pdf/2602.13207" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Adaptive Value Decomposition: Coordinating a Varying Number of Agents in Urban Systems <a href="https://arxiv.org/pdf/2602.13309" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Zero-Shot Instruction Following in RL via Structured LTL Representations <a href="https://arxiv.org/pdf/2602.14344" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] QuRL: Efficient Reinforcement Learning with Quantized Rollout <a href="https://arxiv.org/pdf/2602.13953" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] General learned delegation by clones <a href="https://arxiv.org/pdf/2602.13262" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Text Before Vision: Staged Knowledge Injection Matters for Agentic RLVR in Ultra-High-Resolution Remote Sensing Understanding <a href="https://arxiv.org/pdf/2602.14225" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Socially-Weighted Alignment: A Game-Theoretic Framework for Multi-Agent LLM Systems <a href="https://arxiv.org/pdf/2602.14471" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Mean Flow Policy with Instantaneous Velocity Constraint for One-step Action Generation <a href="https://arxiv.org/pdf/2602.13810" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Lang2Act: Fine-Grained Visual Reasoning through Self-Emergent Linguistic Toolchains <a href="https://arxiv.org/pdf/2602.13235" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] WIMLE: Uncertainty-Aware World Models with IMLE for Sample-Efficient Continuous Control <a href="https://arxiv.org/pdf/2602.14351" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] WoVR: World Models as Reliable Simulators for Post-Training VLA Policies with RL <a href="https://arxiv.org/pdf/2602.13977" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] REDSearcher: A Scalable and Cost-Efficient Framework for Long-Horizon Search Agents <a href="https://arxiv.org/pdf/2602.14234" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Securing SIM-Assisted Wireless Networks via Quantum Reinforcement Learning <a href="https://arxiv.org/pdf/2602.13238" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Learning Transferability: A Two-Stage Reinforcement Learning Approach for Enhancing Quadruped Robots&#x27; Performance in U-Shaped Stair Climbing <a href="https://arxiv.org/pdf/2602.14473" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] AdaptManip: Learning Adaptive Whole-Body Object Lifting and Delivery with Online Recurrent State Estimation <a href="https://arxiv.org/pdf/2602.14363" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] GRAIL: Goal Recognition Alignment through Imitation Learning <a href="https://arxiv.org/pdf/2602.14252" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] TikArt: Aperture-Guided Observation for Fine-Grained Visual Reasoning via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.14482" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Why Code, Why Now: Learnability, Computability, and the Real Limits of Machine Learning <a href="https://arxiv.org/pdf/2602.13934" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Policy Gradient with Adaptive Entropy Annealing for Continual Fine-Tuning <a href="https://arxiv.org/pdf/2602.14078" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] AuTAgent: A Reinforcement Learning Framework for Tool-Augmented Audio Reasoning <a href="https://arxiv.org/pdf/2602.13685" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Building Autonomous GUI Navigation via Agentic-Q Estimation and Step-Wise Policy Optimization <a href="https://arxiv.org/pdf/2602.13653" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Formally Verifying and Explaining Sepsis Treatment Policies with COOL-MC <a href="https://arxiv.org/pdf/2602.14505" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Enabling Option Learning in Sparse Rewards with Hindsight Experience Replay <a href="https://arxiv.org/pdf/2602.13865" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] From Pixels to Policies: Reinforcing Spatial Reasoning in Language Models for Content-Aware Layout Design <a href="https://arxiv.org/pdf/2602.13912" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] KernelBlaster: Continual Cross-Task CUDA Optimization via Memory-Augmented In-Context Reinforcement Learning <a href="https://arxiv.org/pdf/2602.14293" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] OpAgent: Operator Agent for Web Navigation <a href="https://arxiv.org/pdf/2602.13559" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] TWISTED-RL: Hierarchical Skilled Agents for Knot-Tying without Human Demonstrations <a href="https://arxiv.org/pdf/2602.14526" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Fluid-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.14559" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] RNM-TD3: N<!-- -->:M<!-- --> Semi-structured Sparse Reinforcement Learning From Scratch <a href="https://arxiv.org/pdf/2602.14578" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Decoupled Continuous-Time Reinforcement Learning via Hamiltonian Flow <a href="https://arxiv.org/pdf/2602.14587" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] GREAT-EER: Graph Edge Attention Network for Emergency Evacuation Responses <a href="https://arxiv.org/pdf/2602.14676" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Evolutionary System Prompt Learning can Facilitate Reinforcement Learning for LLMs <a href="https://arxiv.org/pdf/2602.14697" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] ManeuverNet: A Soft Actor-Critic Framework for Precise Maneuvering of Double-Ackermann-Steering Robots with Optimized Reward Functions <a href="https://arxiv.org/pdf/2602.14726" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Interactionless Inverse Reinforcement Learning: A Data-Centric Framework for Durable Alignment <a href="https://arxiv.org/pdf/2602.14844" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Goldilocks RL: Tuning Task Difficulty to Escape Sparse Rewards for Reasoning <a href="https://arxiv.org/pdf/2602.14868" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] On the Learning Dynamics of RLVR at the Edge of Competence <a href="https://arxiv.org/pdf/2602.14872" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] BFS-PO: Best-First Search for Large Reasoning Models <a href="https://arxiv.org/pdf/2602.14917" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] MAC-AMP: A Closed-Loop Multi-Agent Collaboration System for Multi-Objective Antimicrobial Peptide Design <a href="https://arxiv.org/pdf/2602.14926" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Cold-Start Personalization via Training-Free Priors from Structured World Models <a href="https://arxiv.org/pdf/2602.15012" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 19</strong></p>
<ul>
<li class="">[arXiv260217] Geometry-Aware Physics-Informed PointNets for Modeling Flows Across Porous Structures <a href="https://arxiv.org/pdf/2602.14108" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Why is Normalization Preferred? A Worst-Case Complexity Theory for Stochastically Preconditioned SGD under Heavy-Tailed Noise <a href="https://arxiv.org/pdf/2602.13413" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Accelerated Discovery of Cryoprotectant Cocktails via Multi-Objective Bayesian Optimization <a href="https://arxiv.org/pdf/2602.13398" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] On-Policy Supervised Fine-Tuning for Efficient Reasoning <a href="https://arxiv.org/pdf/2602.13407" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] WiSparse: Boosting LLM Inference Efficiency with Weight-Aware Mixed Activation Sparsity <a href="https://arxiv.org/pdf/2602.14452" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] QuRL: Efficient Reinforcement Learning with Quantized Rollout <a href="https://arxiv.org/pdf/2602.13953" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] IDPruner: Harmonizing Importance and Diversity in Visual Token Pruning for MLLMs <a href="https://arxiv.org/pdf/2602.13315" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Discrete Double-Bracket Flows for Isotropic-Noise Invariant Eigendecomposition <a href="https://arxiv.org/pdf/2602.13759" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Responsible AI in Business <a href="https://arxiv.org/pdf/2602.13244" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Decentralized Federated Learning With Energy Harvesting Devices <a href="https://arxiv.org/pdf/2602.14051" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] SpargeAttention2: Trainable Sparse Attention via Hybrid Top-k+Top-p Masking and Distillation Fine-Tuning <a href="https://arxiv.org/pdf/2602.13515" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Fast Swap-Based Element Selection for Multiplication-Free Dimension Reduction <a href="https://arxiv.org/pdf/2602.13532" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Experimentation Accelerator: Interpretable Insights and Creative Recommendations for A/B Testing with Content-Aware ranking <a href="https://arxiv.org/pdf/2602.13852" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] AdaCorrection: Adaptive Offset Cache Correction for Accurate Diffusion Transformers <a href="https://arxiv.org/pdf/2602.13357" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] RNM-TD3: N<!-- -->:M<!-- --> Semi-structured Sparse Reinforcement Learning From Scratch <a href="https://arxiv.org/pdf/2602.14578" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] AI Arms and Influence: Frontier Models Exhibit Sophisticated Reasoning in Simulated Nuclear Crises <a href="https://arxiv.org/pdf/2602.14740" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Rethinking Diffusion Models with Symmetries through Canonicalization with Applications to Molecular Graph Generation <a href="https://arxiv.org/pdf/2602.15022" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Fast Compute for ML Optimization <a href="https://arxiv.org/pdf/2602.14280" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260217] Faster Molecular Dynamics with Neural Network Potentials via Distilled Multiple Time-Stepping and Non-Conservative Forces <a href="https://arxiv.org/pdf/2602.14975" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-18">2026-02-18<a href="#2026-02-18" class="hash-link" aria-label="Direct link to 2026-02-18" title="Direct link to 2026-02-18" translate="no">​</a></h2>
<p><strong>cs.DC total: 7</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260218] Tight Communication Bounds for Distributed Algorithms in the Quantum Routing Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [quantum routing model, quantum walks, electric networks, message complexity, lower bounds]</li>
<li class=""><strong>authors:</strong> Fabien Dufoulon, Frédéric Magniez, Gopal Pandurangan</li>
<li class=""><strong>institution:</strong> Lancaster University, Université Paris Cité, University of Houston</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15529" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15529</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces new distributed quantum algorithms for fundamental problems like leader election and MST, using quantum walks based on electric networks to reduce communication. It shows these algorithms achieve near-optimal message complexities, significantly improving over prior quantum work and demonstrating a quadratic communication advantage over classical distributed algorithms.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260218] On the Geometric Coherence of Global Aggregation in Federated GNN</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, graph neural networks, geometric coherence, global aggregation, cross-domain federated GNN, GGRS]</li>
<li class=""><strong>authors:</strong> Chethana Prasad Kabgere, Shylaja SS</li>
<li class=""><strong>institution:</strong> PES University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15510" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15510</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes GGRS, a server-side framework that regulates client updates based on geometric criteria to address destructive interference in federated GNN aggregation. It concludes that this geometry-aware approach is necessary to preserve global message-passing coherence in cross-domain federated graph learning, which is not captured by conventional metrics like loss or accuracy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260218] SCENE OTA-FD: Self-Centering Noncoherent Estimator for Over-the-Air Federated Distillation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [over-the-air federated distillation, noncoherent energy aggregation, constant-envelope signaling, self-centering estimator, pilot-free aggregation]</li>
<li class=""><strong>authors:</strong> Hao Chen, Zavareh Bozorgasl</li>
<li class=""><strong>institution:</strong> Boise State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15326" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15326</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SCENE, a pilot-free and phase-invariant method for aggregating soft labels in over-the-air federated distillation. It uses noncoherent energy transmission and a self-centering estimator to avoid channel state information overhead. The method is designed for short-coherence or hardware-constrained regimes and can outperform coherent designs when pilot overhead is significant.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260218] FlashMem: Supporting Modern DNN Workloads on Mobile with GPU Memory Hierarchy Optimizations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [memory streaming, weight preloading, 2.5D texture memory, multi-DNN workloads, on-device inference, mobile GPU]</li>
<li class=""><strong>authors:</strong> Zhihao Shu, Md Musfiqur Rahman Sanim, Hangyu Zheng, Kunxiong Zhu, Miao Yin, Gagan Agrawal, Wei Niu</li>
<li class=""><strong>institution:</strong> University of Georgia, University of Texas at Arlington</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15379" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15379</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FlashMem is a memory streaming framework for mobile GPUs that statically schedules and dynamically streams model weights on-demand, instead of fully preloading them. It leverages 2.5D texture memory to reduce data transformations. The framework significantly reduces memory usage and speeds up inference for large-scale and multi-DNN workloads compared to existing approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260218] Service Orchestration in the Computing Continuum: Structural Challenges and Vision</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [service orchestration], [computing continuum, edge computing, cloud computing, active inference, service placement, quality of experience]</li>
<li class=""><strong>authors:</strong> Boris Sedlak, Víctor Casamayor Pujol, Ildefons Magrans de Abril, Praveen Kumar Donta, Adel N. Toosi, Schahram Dustdar</li>
<li class=""><strong>institution:</strong> Universitat Pompeu Fabra, Stockholm University, University of Melbourne, ICREA, TU Wien</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15794" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15794</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper analyzes structural challenges for service orchestration in the heterogeneous and dynamic Computing Continuum, proposing autonomous orchestration as an ideal solution and illustrating Active Inference as a potential approach. It concludes that no existing solution fully achieves this vision and identifies key research challenges, most notably the need for standardized simulation environments to compare orchestration mechanisms.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260218] Distributed Semi-Speculative Parallel Anisotropic Mesh Adaptation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing, mesh adaptation], [distributed memory, speculative execution, anisotropic mesh adaptation, parallel runtime, cc-NUMA]</li>
<li class=""><strong>authors:</strong> Kevin Garner, Polykarpos Thomadakis, Nikos Chrisochoides</li>
<li class=""><strong>institution:</strong> Old Dominion University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15204" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15204</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a distributed memory method for anisotropic mesh adaptation that separates meshing functionality from performance aspects, using a shared memory mesh generator and a parallel runtime system. The method avoids collective communication by first adapting interface elements on a single node and then adapting interior elements in parallel while keeping interfaces frozen. It is shown to generate large meshes (up to ~1 billion elements) with quality and performance comparable to state-of-the-art HPC meshing software.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260218] Co-Design and Evaluation of a CPU-Free MPI GPU Communication Abstraction and Implementation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing], [MPI, GPU communication, CPU-free communication, stream-triggered communication, halo exchange, Cabana/Kokkos]</li>
<li class=""><strong>authors:</strong> Patrick G. Bridges, Derek Schafer, Jack Lange, James B. White III, Anthony Skjellum, Evan Suggs, Thomas Hines, Purushotham Bangalore, Matthew G. F. Dosanjh, Whit Schonbein</li>
<li class=""><strong>institution:</strong> University of New Mexico, Oak Ridge National Laboratory, Tennessee Tech University, University of Alabama, Sandia National Laboratories</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15356" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15356</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces an MPI-based GPU communication API designed to enable CPU-free, high-performance communication by leveraging HPE Slingshot 11 network capabilities. The API supports two-sided communication and integrates with the Cabana/Kokkos framework for halo exchange primitives. Evaluation on Frontier and Tuolumne supercomputers shows up to 50% latency reduction in GPU ping-pong exchanges and a 28% speedup when scaling to 8,192 GPUs.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 13</strong></p>
<ul>
<li class="">[arXiv260218] Recursive Concept Evolution for Compositional Reasoning in Large Language Models <a href="https://arxiv.org/pdf/2602.15725" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction <a href="https://arxiv.org/pdf/2602.15733" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications <a href="https://arxiv.org/pdf/2602.15640" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning <a href="https://arxiv.org/pdf/2602.15817" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Near-Optimal Sample Complexity for Online Constrained MDPs <a href="https://arxiv.org/pdf/2602.15076" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] CDRL: A Reinforcement Learning Framework Inspired by Cerebellar Circuits and Dendritic Computational Strategies <a href="https://arxiv.org/pdf/2602.15367" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL <a href="https://arxiv.org/pdf/2602.15564" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching <a href="https://arxiv.org/pdf/2602.15827" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Fairness over Equality: Correcting Social Incentives in Asymmetric Sequential Social Dilemmas <a href="https://arxiv.org/pdf/2602.15407" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] CLOT: Closed-Loop Global Motion Tracking for Whole-Body Humanoid Teleoperation <a href="https://arxiv.org/pdf/2602.15060" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] MyoInteract: A Framework for Fast Prototyping of Biomechanical HCI Tasks using Reinforcement Learning <a href="https://arxiv.org/pdf/2602.15245" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] GLM-5: from Vibe Coding to Agentic Engineering <a href="https://arxiv.org/pdf/2602.15763" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens <a href="https://arxiv.org/pdf/2602.15620" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 10</strong></p>
<ul>
<li class="">[arXiv260218] Sparrow: Text-Anchored Window Attention with Visual-Semantic Glimpsing for Speculative Decoding in Video LLMs <a href="https://arxiv.org/pdf/2602.15318" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety <a href="https://arxiv.org/pdf/2602.15799" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Multi-Objective Coverage via Constraint Active Search <a href="https://arxiv.org/pdf/2602.15595" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Transforming Computational Lithography with AC and AI -- Faster, More Accurate, and Energy-efficient <a href="https://arxiv.org/pdf/2602.15036" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Fractional-Order Federated Learning <a href="https://arxiv.org/pdf/2602.15380" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Safe-SDL<!-- -->:Establishing<!-- --> Safety Boundaries and Control Mechanisms for AI-Driven Self-Driving Laboratories <a href="https://arxiv.org/pdf/2602.15061" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Stabilizing Test-Time Adaptation of High-Dimensional Simulation Surrogates via D-Optimal Statistics <a href="https://arxiv.org/pdf/2602.15820" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Molecular Design beyond Training Data with Novel Extended Objective Functionals of Generative AI Models Driven by Quantum Annealing Computer <a href="https://arxiv.org/pdf/2602.15451" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] MyoInteract: A Framework for Fast Prototyping of Biomechanical HCI Tasks using Reinforcement Learning <a href="https://arxiv.org/pdf/2602.15245" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260218] Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization <a href="https://arxiv.org/pdf/2602.15277" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-19">2026-02-19<a href="#2026-02-19" class="hash-link" aria-label="Direct link to 2026-02-19" title="Direct link to 2026-02-19" translate="no">​</a></h2>
<p><strong>cs.DC total: 11</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260219] DistributedEstimator: Distributed Training of Quantum Neural Networks via Circuit Cutting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [circuit cutting, distributed training, quantum neural networks, estimator pipeline, classical reconstruction, subcircuit execution]</li>
<li class=""><strong>authors:</strong> Prabhjot Singh, Adel N. Toosi, Rajkumar Buyya</li>
<li class=""><strong>institution:</strong> The University of Melbourne</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.16233" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.16233</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a distributed training pipeline for Quantum Neural Networks that uses circuit cutting to decompose large quantum circuits into smaller, parallelizable subcircuits. The main conclusion is that while this method preserves model accuracy, it introduces significant system overhead dominated by classical reconstruction, which limits the achievable speedup from parallelism.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260219] SRFed: Mitigating Poisoning Attacks in Privacy-Preserving Federated Learning with Heterogeneous Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [functional encryption, decentralized efficient functional encryption (DEFE), layer-wise projection, clustering-based analysis, Byzantine-robust aggregation, Non-IID data]</li>
<li class=""><strong>authors:</strong> Yiwen Lu</li>
<li class=""><strong>institution:</strong> Nanjing University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.16480" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.16480</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes SRFed, a federated learning framework that uses a novel decentralized efficient functional encryption (DEFE) scheme to protect client privacy and a defensive aggregation mechanism based on layer-wise projection and clustering to filter out poisoning attacks, especially under Non-IID data. It concludes that SRFed outperforms existing methods in privacy protection, robustness against Byzantine attacks, and efficiency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260219] How Reliable is Your Service at the Extreme Edge? Analytical Modeling of Computational Reliability</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [analytical modeling, computational reliability, distributed inference, quality of service, maximum likelihood estimation, workload allocation, extreme edge computing]</li>
<li class=""><strong>authors:</strong> MHD Saria Allahham, Hossam S. Hassanein</li>
<li class=""><strong>institution:</strong> Queen&#x27;s University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.16362" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.16362</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents an analytical framework to quantify computational reliability in Extreme Edge Computing, deriving closed-form probability expressions for whether device capacity meets service demand under different information regimes. It extends the model to multi-device deployments and provides optimal workload allocation rules. The framework is validated through experiments with a YOLO-based object detection workload, showing close agreement between analytical predictions and empirical measurements.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260219] Load Balanced Parallel Node Generation for Meshless Numerical Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [parallel computing], [meshless methods, Poisson disc sampling, hypertrees, parallel node generation, advancing front]</li>
<li class=""><strong>authors:</strong> Jon Vehovar, Miha Rot, Matjaž Depolli, Gregor Kosec</li>
<li class=""><strong>institution:</strong> Jozef Stefan International Postgraduate School, Institut &quot;Jožef Stefan&quot;</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.16347" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.16347</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a parallel algorithm for generating nodes for meshless numerical methods using coupled spatial indexing and work distribution hypertrees. It modifies a Poisson disc sampling-based method to enable load-balanced parallel execution by prebuilding work units and managing thread collisions at the leaf level. The approach reduces mutex contention and improves performance compared to existing parallelization attempts.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260219] push0: Scalable and Fault-Tolerant Orchestration for Zero-Knowledge Proof Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain orchestration], [event-driven dispatcher-collector architecture, persistent priority queues, Kubernetes, fault-tolerant task reassignment, prover-agnostic workflow]</li>
<li class=""><strong>authors:</strong> Mohsen Ahmadvand, Rok Pajnič, Ching-Lun Chiu</li>
<li class=""><strong>institution:</strong> Zircuit</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.16338" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.16338</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents push0, a cloud-native orchestration system for zero-knowledge proof generation that uses an event-driven dispatcher-collector architecture over persistent queues to enforce ordering and enable parallelism. It demonstrates low orchestration overhead (5 ms median) and high scaling efficiency in production experiments, enabling reliable, real-time proof generation for blockchain applications like ZK-rollups and Ethereum&#x27;s zkEVM.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260219] Near-optimal population protocols on bounded-degree trees</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [population protocols, self-stabilising algorithms, tree orientation, 2-hop colouring, stochastic drift, leader election, exact majority]</li>
<li class=""><strong>authors:</strong> Joel Rybicki, Jakob Solnerzik, Robin Vacus</li>
<li class=""><strong>institution:</strong> Humboldt-Universität zu Berlin, Sorbonne Université, CNRS, LIP6</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.16222" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.16222</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces new constant-space population protocols for leader election and exact majority on bounded-degree trees, based on a fast self-stabilising 2-hop colouring protocol and a tree orientation algorithm. It concludes that, unlike in complete graphs, these sparse graphs do not exhibit significant space-time trade-offs, allowing for near-optimal time with minimal space.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260219] Scrutinizing Variables for Checkpoint Using Automatic Differentiation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [fault-tolerance], [checkpoint/restart, automatic differentiation, Enzyme, storage optimization]</li>
<li class=""><strong>authors:</strong> Xin Huang, Weiping Zhang, Shiman Meng, Wubiao Xu, Xiang Fu, Luanzheng Guo, Kento Sato</li>
<li class=""><strong>institution:</strong> Nanchang Hangkong University, Pacific Northwest National Laboratory, RIKEN</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.16010" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.16010</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method that uses automatic differentiation (specifically the Enzyme tool) to analyze variables in HPC applications, identifying and excluding data elements that do not affect the final output from checkpointing. The approach was validated on NAS Parallel Benchmarks, showing it can reduce checkpoint storage by up to 20%. The distribution of critical and uncritical elements was found to align with the underlying physical logic of the algorithms.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260219] FlowPrefill: Decoupling Preemption from Prefill Scheduling Granularity to Mitigate Head-of-Line Blocking in LLM Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [prefill scheduling, operator-level preemption, event-driven scheduling, head-of-line blocking mitigation, SLO-aware scheduling]</li>
<li class=""><strong>authors:</strong> Chia-chi Hsieh, Zan Zong, Xinyang Chen, Jianjiang Li, Jidong Zhai, Lijie Wen</li>
<li class=""><strong>institution:</strong> Tsinghua University, University of Science and Technology Beijing</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.16603" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.16603</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FlowPrefill, an LLM serving system that decouples preemption granularity from scheduling frequency to mitigate head-of-line blocking during the prefill phase. Its core innovations are operator-level preemption for fine-grained interruption and event-driven scheduling to minimize overhead. Evaluation shows it improves maximum goodput by up to 5.6x while meeting heterogeneous SLOs compared to state-of-the-art systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260219] LLM-Driven Intent-Based Privacy-Aware Orchestration Across the Cloud-Edge Continuum</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [intent-based orchestration, Kubernetes, SDN, GPT-4o, pipeline reconfiguration, serverless computing]</li>
<li class=""><strong>authors:</strong> Zijie Su, Muhammed Tawfiqul Islam, Mohammad Goudarzi, Adel N. Toosi</li>
<li class=""><strong>institution:</strong> The University of Melbourne, Monash University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.16100" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.16100</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an LLM-driven framework that uses GPT-4o to automatically translate natural-language privacy intents into enforcement-ready policies for Kubernetes and SDN controllers across the cloud-edge continuum. It also introduces a dynamic pipeline reconfiguration approach for LLM serving to adapt to changing workloads in heterogeneous GPU environments. Experimental results show high accuracy in policy generation and low overhead for service reconfiguration.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260219] Distributed Order Recording Techniques for Efficient Record-and-Replay of Multi-threaded Programs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [parallel computing, debugging], [Distributed Clock, Distributed Epoch, ReOMP, ReMPI, record-and-replay]</li>
<li class=""><strong>authors:</strong> Xiang Fu, Shiman Meng, Weiping Zhang, Luanzheng Guo, Kento Sato, Dong H. Ahn, Ignacio Laguna, Gregory L. Lee, Martin Schulz</li>
<li class=""><strong>institution:</strong> Nanchang Hangkong University, Pacific Northwest National Laboratory, RIKEN R-CCS, NVIDIA, Lawrence Livermore National Laboratory, Technical University of Munich</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15995" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15995</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes two novel techniques, Distributed Clock (DC) and Distributed Epoch (DE), to efficiently record and replay non-deterministic OpenMP programs by eliminating excessive thread synchronization. The evaluation shows these techniques, implemented in ReOMP, are 2-5x more efficient than traditional methods and can be integrated with MPI replay tools for hybrid applications. The approach enables scalable debugging and testing of complex MPI+OpenMP HPC applications with minimal overhead.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260219] ROIX-Comp: Optimizing X-ray Computed Tomography Imaging Strategy for Data Reduction and Reconstruction</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [data compression], [region-of-interest extraction, error-bounded quantization, lossless/lossy compression, object extraction]</li>
<li class=""><strong>authors:</strong> Amarjit Singh, Kento Sato, Kohei Yoshida, Kentaro Uesugi, Yasumasa Joti, Takaki Hatsui, Andrès Rubio Proaño</li>
<li class=""><strong>institution:</strong> RIKEN, The University of Electro-Communications, Japan Synchrotron Radiation Research Institute, Universidad Tecnológica Indoamérica</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.15917" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.15917</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces ROIX-Comp, a framework that compresses X-ray Computed Tomography data by identifying and extracting essential regions-of-interest and applying error-bounded quantization and advanced compressors. It significantly reduces data volume while preserving critical information, achieving a 12.34x improvement in compression ratio compared to standard methods.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 17</strong></p>
<ul>
<li class="">[arXiv260219] Balancing Faithfulness and Performance in Reasoning via Multi-Listener Soft Execution <a href="https://arxiv.org/pdf/2602.16154" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Multi-agent cooperation through in-context co-player inference <a href="https://arxiv.org/pdf/2602.16301" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Learning to Drive in New Cities Without Human Demonstrations <a href="https://arxiv.org/pdf/2602.15891" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] A Scalable Approach to Solving Simulation-Based Network Security Games <a href="https://arxiv.org/pdf/2602.16564" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] RIDER: 3D RNA Inverse Design with Reinforcement Learning-Guided Diffusion <a href="https://arxiv.org/pdf/2602.16548" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Vulnerability Analysis of Safe Reinforcement Learning via Inverse Constrained Reinforcement Learning <a href="https://arxiv.org/pdf/2602.16543" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.16435" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.16196" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] MARVL: Multi-Stage Guidance for Robotic Manipulation via Vision-Language Models <a href="https://arxiv.org/pdf/2602.15872" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents <a href="https://arxiv.org/pdf/2602.16165" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Decoupling Strategy and Execution in Task-Focused Dialogue via Goal-Oriented Preference Optimization <a href="https://arxiv.org/pdf/2602.15854" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Capacity-constrained demand response in smart grids using deep reinforcement learning <a href="https://arxiv.org/pdf/2602.16525" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Edge Learning via Federated Split Decision Transformers for Metaverse Resource Allocation <a href="https://arxiv.org/pdf/2602.16174" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments <a href="https://arxiv.org/pdf/2602.16179" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study <a href="https://arxiv.org/pdf/2602.16523" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets <a href="https://arxiv.org/pdf/2602.16062" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Almost Sure Convergence of Differential Temporal Difference Learning for Average Reward Markov Decision Processes <a href="https://arxiv.org/pdf/2602.16629" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 14</strong></p>
<ul>
<li class="">[arXiv260219] Distributed physics-informed neural networks via domain decomposition for fast flow reconstruction <a href="https://arxiv.org/pdf/2602.15883" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] CLAA: Cross-Layer Attention Aggregation for Accelerating LLM Prefill <a href="https://arxiv.org/pdf/2602.16054" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Graph neural network for colliding particles with an application to sea ice floe modeling <a href="https://arxiv.org/pdf/2602.16213" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] MoE-Spec: Expert Budgeting for Efficient Speculative Decoding <a href="https://arxiv.org/pdf/2602.16052" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Easy Data Unlearning Bench <a href="https://arxiv.org/pdf/2602.16400" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] MolCrystalFlow: Molecular Crystal Structure Prediction via Flow Matching <a href="https://arxiv.org/pdf/2602.16020" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] FEKAN: Feature-Enriched Kolmogorov-Arnold Networks <a href="https://arxiv.org/pdf/2602.16530" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA <a href="https://arxiv.org/pdf/2602.16442" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] HAWX: A Hardware-Aware FrameWork for Fast and Scalable ApproXimation of DNNs <a href="https://arxiv.org/pdf/2602.16336" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] B-DENSE: Branching For Dense Ensemble Network Learning <a href="https://arxiv.org/pdf/2602.15971" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Statistical-Geometric Degeneracy in UAV Search: A Physics-Aware Asymmetric Filtering Approach <a href="https://arxiv.org/pdf/2602.15893" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Optimizer choice matters for the emergence of Neural Collapse <a href="https://arxiv.org/pdf/2602.16642" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Steering Dynamical Regimes of Diffusion Models by Breaking Detailed Balance <a href="https://arxiv.org/pdf/2602.15914" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260219] Local adapt-then-combine algorithms for distributed nonsmooth optimization: Achieving provable communication acceleration <a href="https://arxiv.org/pdf/2602.16148" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-20">2026-02-20<a href="#2026-02-20" class="hash-link" aria-label="Direct link to 2026-02-20" title="Direct link to 2026-02-20" translate="no">​</a></h2>
<p><strong>cs.DC total: 12</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260220] Evaluating Malleable Job Scheduling in HPC Clusters using Real-World Workloads</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [HPC job scheduling], [malleable jobs, resource elasticity, ElastiSim, job scheduling strategies, workload simulation]</li>
<li class=""><strong>authors:</strong> Patrick Zojer, Jonas Posner, Taylan Özden</li>
<li class=""><strong>institution:</strong> University of Kassel, Technical University of Darmstadt</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17318" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17318</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper evaluates the benefits of malleable job scheduling in HPC clusters by simulating varying proportions of malleable jobs using real-world supercomputer workload traces and the ElastiSim software. It finds that malleable scheduling significantly improves key metrics like job turnaround time and node utilization, with substantial gains even at low adoption rates, demonstrating its potential to address inefficiencies in current HPC practices.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260220] Do GPUs Really Need New Tabular File Formats?</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [Parquet, columnar storage, GPU scan, file configuration, row group, page encoding, compression, bandwidth optimization]</li>
<li class=""><strong>authors:</strong> Jigao Luo, Qi Chen, Carsten Binnig</li>
<li class=""><strong>institution:</strong> TU Darmstadt, hessian.AI, DFKI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17335" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17335</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper systematically studies how Parquet file configurations, such as row group size and page encoding, affect GPU scan performance. It concludes that Parquet&#x27;s poor GPU performance is not inherent to the format but results from CPU-centric defaults, and by applying GPU-aware configurations, read bandwidth can be dramatically increased without needing a new file format.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260220] Read-Modify-Writable Snapshots from Read/Write operations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [concurrent algorithms], [linearizability, wait-freedom, lock-freedom, read/write operations, RMWable snapshots]</li>
<li class=""><strong>authors:</strong> Armando Castañeda, Braulio Ramses Hernández Martínez</li>
<li class=""><strong>institution:</strong> Universidad Nacional Autónoma de México (UNAM)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.16903" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.16903</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents two read/write RMWable snapshot algorithms for asynchronous concurrent shared-memory systems. The first algorithm works in the standard model with a finite, known number of processes, while the second operates in a model with unbounded concurrency. The main conclusion is that RMWable snapshots are possible using only simple read/write operations, without relying on more powerful primitives like compare&amp;swap.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260220] Heterogeneous Federated Fine-Tuning with Parallel One-Rank Adaptation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [federated learning, low-rank adaptation, heterogeneous clients, parallel one-rank adaptation, select-n-fold, federated fine-tuning]</li>
<li class=""><strong>authors:</strong> Zikai Zhang, Rui Hu, Jiahao Xu</li>
<li class=""><strong>institution:</strong> University of Nevada, Reno</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.16936" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.16936</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Fed-PLoRA, a federated fine-tuning framework that introduces Parallel One-Rank Adaptation (PLoRA) and a Select-N-Fold strategy to handle heterogeneous client resources by allowing different LoRA ranks. This approach reduces initialization and aggregation noise compared to standard methods. Experiments show that Fed-PLoRA outperforms existing methods in both accuracy and efficiency for LLM fine-tuning tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260220] Informative Trains: A Memory-Efficient Journey to a Self-Stabilizing Leader Election Algorithm in Anonymous Graphs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed algorithms], [self-stabilization, leader election, anonymous networks, information train, probabilistic algorithm, state model, synchronous scheduler]</li>
<li class=""><strong>authors:</strong> Lelia Blin, Sylvain Gay, Isabella Ziccardi</li>
<li class=""><strong>institution:</strong> Université Paris Cité, CNRS, IRIF, École Normale Supérieure</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17541" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17541</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents a probabilistic self-stabilizing leader election algorithm for arbitrary anonymous networks that uses only O(log log n) bits of memory per node. It introduces an &quot;information train&quot; mechanism to propagate information efficiently while maintaining low local memory. The algorithm converges almost surely to a unique leader and stabilizes within polynomial rounds, achieving space-optimal memory complexity for general graphs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260220] Visual Insights into Agentic Optimization of Pervasive Stream Processing Services</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [autoscaling, service level objectives (SLOs), multi-dimensional elasticity, regression analysis, edge computing, stream processing]</li>
<li class=""><strong>authors:</strong> Boris Sedlak, Víctor Casamayor Pujol, Schahram Dustdar</li>
<li class=""><strong>institution:</strong> Universitat Pompeu Fabra, TU Wien</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17282" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17282</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents a platform (MUDAP) and an agent (RASK) for context-aware, multi-dimensional autoscaling of stream processing services at the edge. The agent uses regression analysis to understand the impact of different service parameters on performance and dynamically optimizes service execution to meet fluctuating demands and resource constraints. This approach enables services to autonomously adjust their operation to sustain critical Service Level Objectives like latency in pervasive applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260220] Trivance: Latency-Optimal AllReduce by Shortcutting Multiport Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [AllReduce, torus networks, latency-optimal, congestion reduction, bidirectional ring, Bruck&#x27;s algorithm, Swing, collective communication]</li>
<li class=""><strong>authors:</strong> Anton Juerss, Vamsi Addanki, Stefan Schmid</li>
<li class=""><strong>institution:</strong> Weizenbaum Institute, TU Berlin, Purdue University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17254" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17254</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Trivance, a novel AllReduce algorithm that achieves latency-optimal performance in log3 n steps on bidirectional ring and torus networks while reducing congestion compared to prior methods. It exploits both transmission ports per step to triple communication distance and uses joint reductions to improve steps and congestion. Empirical evaluation shows Trivance outperforms state-of-the-art approaches by 5-30% across various message sizes and network topologies.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260220] TopoSZp: Lightweight Topology-Aware Error-controlled Compression for Scientific Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [scientific data compression], [error-bounded lossy compression, topology preservation, critical point detection, SZp compressor, local ordering preservation, saddle-point refinement]</li>
<li class=""><strong>authors:</strong> Tripti Agarwal, Sheng Di, Xin Liang, Zhaoyuan Su, Yuxiao Li, Ganesh Gopalakrishnan, Hanqi Guo, Franck Cappello</li>
<li class=""><strong>institution:</strong> University of Utah, Argonne National Laboratory, University of Kentucky, University of Virginia, The Ohio State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17552" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17552</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents TopoSZp, a lightweight, topology-aware lossy compressor built on SZp that integrates critical point detection and local ordering preservation within a strict error bound. It demonstrates that TopoSZp significantly better preserves topological features like minima and saddle points compared to standard compressors, while offering orders-of-magnitude faster compression and decompression than prior topology-aware methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260220] Privacy-Aware Split Inference with Speculative Decoding for Large Language Models over Wide-Area Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [split inference, speculative decoding, lookahead decoding, privacy-aware inference, wide-area networks, inversion attack, n-gram speculation, greedy argmax]</li>
<li class=""><strong>authors:</strong> Michael Cunningham</li>
<li class=""><strong>institution:</strong> Not explicitly provided; author name only (Michael Cunningham). Unable to infer institution from given content.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.16760" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.16760</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a privacy-aware LLM inference system that splits a transformer model between a local trusted device and an untrusted cloud GPU, using speculative (lookahead) decoding to mitigate the latency of wide-area networks. The system ensures raw tokens never leave the local device and demonstrates a tunable privacy-performance tradeoff, achieving practical throughput (e.g., 8.7-9.3 tok/s for Mistral 7B) over an ~80ms WAN link while maintaining output identical to standard greedy decoding.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260220] Exploring Novel Data Storage Approaches for Large-Scale Numerical Weather Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing storage], [DAOS, Ceph, Lustre, object storage, POSIX, I/O benchmarking, NVMe SSDs]</li>
<li class=""><strong>authors:</strong> Nicolau Manubens Gil</li>
<li class=""><strong>institution:</strong> University of Edinburgh, ECMWF</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17610" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17610</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper evaluates the performance of DAOS and Ceph object storage systems for large-scale Numerical Weather Prediction (NWP) and HPC applications by developing new software adapters and conducting extensive I/O benchmarks against Lustre file systems. The study finds that both object stores perform well, but DAOS demonstrates superior scalability and flexibility for large-scale I/O workloads, suggesting promising potential for broader adoption in HPC centers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260220] Catastrophic Forgetting Resilient One-Shot Incremental Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion training], [one-shot federated learning, incremental learning, catastrophic forgetting, vision-language model, diffusion model, selective sample retention]</li>
<li class=""><strong>authors:</strong> Obaidullah Zaland, Zulfiqar Ahmad Khan, Monowar Bhuyan</li>
<li class=""><strong>institution:</strong> Umeå University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17625" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17625</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes OSI-FL, a one-shot incremental federated learning framework that uses a vision-language model to generate client embeddings and a diffusion model to synthesize training data at the server, augmented with a selective sample retention strategy to mitigate catastrophic forgetting. The method addresses communication overhead and forgetting in incremental data scenarios. Experiments show it outperforms traditional and one-shot FL baselines on class- and domain-incremental tasks across multiple datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260220] Guarding the Middle: Protecting Intermediate Representations in Federated Split Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated split learning, differential privacy, microaggregation, data reconstruction attack, k-anonymity]</li>
<li class=""><strong>authors:</strong> Obaidullah Zaland, Sajib Mistry, Monowar Bhuyan</li>
<li class=""><strong>institution:</strong> Umeå University, Curtin University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.17614" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.17614</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes KD-UFSL, a method that combines k-anonymity via microaggregation and differential privacy to protect intermediate data (smashed data) in U-shaped federated split learning from reconstruction attacks. The experiments show that KD-UFSL significantly increases reconstruction error and reduces similarity between original and reconstructed data while preserving the utility of the global model. The method is suitable for balancing privacy and utility in large-scale, privacy-sensitive applications.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 21</strong></p>
<ul>
<li class="">[arXiv260220] LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation <a href="https://arxiv.org/pdf/2602.16953" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] References Improve LLM Alignment in Non-Verifiable Domains <a href="https://arxiv.org/pdf/2602.16802" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.17062" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Action-Graph Policies: Learning Action Co-dependencies in Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.17009" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] RLGT: A reinforcement learning framework for extremal graph theory <a href="https://arxiv.org/pdf/2602.17276" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] DeepVision-103K: A Visually Diverse, Broad-Coverage, and Verifiable Mathematical Dataset for Multimodal Reasoning <a href="https://arxiv.org/pdf/2602.16742" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Phase-Aware Mixture of Experts for Agentic Reinforcement Learning <a href="https://arxiv.org/pdf/2602.17038" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] LexiSafe: Offline Safe Reinforcement Learning with Lexicographic Safety-Reward Hierarchy <a href="https://arxiv.org/pdf/2602.17312" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] SimToolReal: An Object-Centric Policy for Zero-Shot Dexterous Tool Manipulation <a href="https://arxiv.org/pdf/2602.16863" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Training Large Reasoning Models Efficiently via Progressive Thought Encoding <a href="https://arxiv.org/pdf/2602.16839" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] A Unified Framework for Locality in Scalable MARL <a href="https://arxiv.org/pdf/2602.16966" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Discovering Multiagent Learning Algorithms with Large Language Models <a href="https://arxiv.org/pdf/2602.16928" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Adapting Actively on the Fly: Relevance-Guided Online Meta-Learning with Latent Concepts for Geospatial Discovery <a href="https://arxiv.org/pdf/2602.17605" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Spatio-temporal dual-stage hypergraph MARL for human-centric multimodal corridor traffic signal control <a href="https://arxiv.org/pdf/2602.17068" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] MASPO: Unifying Gradient Utilization, Probability Mass, and Signal Reliability for Robust and Sample-Efficient LLM Reasoning <a href="https://arxiv.org/pdf/2602.17550" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] VAM: Verbalized Action Masking for Controllable Exploration in RL Post-Training -- A Chess Case Study <a href="https://arxiv.org/pdf/2602.16833" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Continual uncertainty learning <a href="https://arxiv.org/pdf/2602.17174" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Stable Asynchrony: Variance-Controlled Off-Policy RL for LLMs <a href="https://arxiv.org/pdf/2602.17616" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] SMAC: Score-Matched Actor-Critics for Robust Offline-to-Online Transfer <a href="https://arxiv.org/pdf/2602.17632" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Dynamic Decision-Making under Model Misspecification: A Stochastic Stability Approach <a href="https://arxiv.org/pdf/2602.17086" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Deep Reinforcement Learning for Optimal Portfolio Allocation: A Comparative Study with Mean-Variance Optimization <a href="https://arxiv.org/pdf/2602.17098" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 14</strong></p>
<ul>
<li class="">[arXiv260220] Shortcut learning in geometric knot classification <a href="https://arxiv.org/pdf/2602.17350" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Linear Convergence in Games with Delayed Feedback via Extra Prediction <a href="https://arxiv.org/pdf/2602.17486" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Transforming Behavioral Neuroscience Discovery with In-Context Learning and AI-Enhanced Tensor Methods <a href="https://arxiv.org/pdf/2602.17027" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Greedy Multi-Path Block Verification for Faster Decoding in Speculative Sampling <a href="https://arxiv.org/pdf/2602.16961" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Early-Warning Signals of Grokking via Loss-Landscape Geometry <a href="https://arxiv.org/pdf/2602.16967" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] SubQuad: Near-Quadratic-Free Structure Inference with Distribution-Balanced Objectives in Adaptive Receptor framework <a href="https://arxiv.org/pdf/2602.17330" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] MMCAformer: Macro-Micro Cross-Attention Transformer for Traffic Speed Prediction with Microscopic Connected Vehicle Driving Behavior <a href="https://arxiv.org/pdf/2602.16730" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Predictive Batch Scheduling: Accelerating Language Model Training Through Loss-Aware Sample Prioritization <a href="https://arxiv.org/pdf/2602.17066" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] GPU-Accelerated Algorithms for Graph Vector Search: Taxonomy, Empirical Study, and Research Directions <a href="https://arxiv.org/pdf/2602.16719" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Powering Up Zeroth-Order Training via Subspace Gradient Orthogonalization <a href="https://arxiv.org/pdf/2602.17155" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] One-step Language Modeling via Continuous Denoising <a href="https://arxiv.org/pdf/2602.16813" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Dynamic Delayed Tree Expansion For Improved Multi-Path Speculative Decoding <a href="https://arxiv.org/pdf/2602.16994" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Continual uncertainty learning <a href="https://arxiv.org/pdf/2602.17174" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260220] Toward a Fully Autonomous, AI-Native Particle Accelerator <a href="https://arxiv.org/pdf/2602.17536" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2026-02-26T03:26:47.000Z" itemprop="dateModified">Feb 26, 2026</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20260209-20260215"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20260209-20260215</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/daily/20260223-20260301"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">20260223-20260301</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2026-02-16" class="table-of-contents__link toc-highlight">2026-02-16</a></li><li><a href="#2026-02-17" class="table-of-contents__link toc-highlight">2026-02-17</a></li><li><a href="#2026-02-18" class="table-of-contents__link toc-highlight">2026-02-18</a></li><li><a href="#2026-02-19" class="table-of-contents__link toc-highlight">2026-02-19</a></li><li><a href="#2026-02-20" class="table-of-contents__link toc-highlight">2026-02-20</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>