<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20260112-20260118" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20260112-20260118 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20260112-20260118"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20260112-20260118 | DarkKnight Note"><meta data-rh="true" name="description" content="2026-01-12"><meta data-rh="true" property="og:description" content="2026-01-12"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20260112-20260118"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260112-20260118" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260112-20260118" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20260112-20260118","item":"https://darkknight996.github.io/daily/20260112-20260118"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.a45d7c41.js" defer="defer"></script>
<script src="/assets/js/main.7763be90.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260105-20260111"><span title="20260105-20260111" class="linkLabel_WmDU">20260105-20260111</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20260112-20260118"><span title="20260112-20260118" class="linkLabel_WmDU">20260112-20260118</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20260112-20260118</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20260112-20260118</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-12">2026-01-12<a href="#2026-01-12" class="hash-link" aria-label="Direct link to 2026-01-12" title="Direct link to 2026-01-12" translate="no">​</a></h2>
<p><strong>cs.DC total: 5</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260112] LACIN: Linearly Arranged Complete Interconnection Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [interconnection networks], [complete graph, isoport, wiring, routing, Dragonfly, HyperX]</li>
<li class=""><strong>authors:</strong> Ramón Beivide, Cristóbal Camarero, Carmen Martínez, Enrique Vallejo, Mateo Valero</li>
<li class=""><strong>institution:</strong> Universidad de Cantabria, Barcelona Supercomputing Center</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.05668" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.05668</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces LACIN, a method for implementing Complete Interconnection Networks (CINs) by connecting switches using identically indexed ports (isoport). This approach simplifies network cabling and routing complexity. It facilitates the deployment of scalable networks from VLSI systems to large supercomputers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260112] MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [mixture-of-experts, memory wall, activation checkpointing, kernel co-design, token dispatch, memory-efficient training]</li>
<li class=""><strong>authors:</strong> Jiyuan Zhang, Yining Liu, Siqi Yan, Lisen Deng, Jennifer Cao, Shuqi Yang, Min Ni, Bi Xue, Shen Li</li>
<li class=""><strong>institution:</strong> Meta Platforms Inc, Thinking Machines Lab</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.05296" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.05296</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MoEBlaze, a memory-efficient training framework for Mixture-of-Experts models that co-designs an end-to-end token dispatch method and optimized kernels to eliminate intermediate activation buffers and reduce memory footprint. The system achieves significant performance gains and memory savings, demonstrating over 4x speedups and over 50% memory reduction compared to existing frameworks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260112] Self-Evolving Distributed Memory Architecture for Scalable AI Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [distributed memory architecture, dual memory system, memory-guided matrix processing, memory-aware peer selection, runtime-adaptive deployment]</li>
<li class=""><strong>authors:</strong> Zixuan Li, Chuanzhen Wang, Haotian Sun</li>
<li class=""><strong>institution:</strong> Tongji University, Pacific Coast University, Northern Research Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.05569" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.05569</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Self-Evolving Distributed Memory Architecture, a three-layer framework that unifies memory management across computation, communication, and deployment layers using techniques like dynamic partitioning and a dual memory system. The experiments show it outperforms baselines like Ray Distributed in memory utilization, operational speed, and communication latency. The main conclusion is that coordinated, adaptive memory management across architectural layers is crucial for scalable and efficient distributed AI systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260112] Multi-Modal Style Transfer-based Prompt Tuning for Efficient Federated Domain Generalization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [federated domain generalization, multi-modal style transfer, prompt tuning, dual-prompt module, domain-aware prompt generation]</li>
<li class=""><strong>authors:</strong> Yuliang Chen, Xi Lin, Jun Wu, Xiangrui Cai, Qiaolun Zhang, Xichun Fan, Jiapeng Xu, Xiu Su</li>
<li class=""><strong>institution:</strong> Shanghai Jiao Tong University, Nankai University, Polytechnic Institute of Milan, New York University Shanghai, Central South University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.05955" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.05955</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes FaST-PT, a federated domain generalization framework that uses a lightweight Multi-Modal Style Transfer method for local feature augmentation and a dual-prompt module with Domain-aware Prompt Generation for efficient unseen domain adaptation. The method demonstrates superior performance over state-of-the-art FDG methods on benchmark datasets like PACS and DomainNet, validating its effectiveness and efficiency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260112] Performance-Portable Optimization and Analysis of Multiple Right-Hand Sides in a Lattice QCD Solver</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing], [multiple right-hand sides, SIMD, data layout, auto-vectorization, GMRES, performance portability, SME]</li>
<li class=""><strong>authors:</strong> Shiting Long, Gustavo Ramirez-Hidalgo, Stepan Nassyr, Jose Jimenez-Merchan, Andreas Frommer, Dirk Pleiter</li>
<li class=""><strong>institution:</strong> KTH Royal Institute of Technology, Forschungszentrum Jülich GmbH, University of Wuppertal, University of Groningen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.05816" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.05816</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper extends a lattice QCD solver to support multiple right-hand sides and optimizes it with a flexible data layout interface for better SIMD utilization. The optimizations are evaluated on x86 and Arm clusters, demonstrating performance portability and revealing insights into architectural constraints and compiler behavior. An early assessment of the Arm SME instruction set is also provided.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 19</strong></p>
<ul>
<li class="">[arXiv260112] WildSci: Advancing Scientific Reasoning from In-the-Wild Literature <a href="https://arxiv.org/pdf/2601.05567" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] On the Limits of Self-Improving in LLMs and Why AGI, ASI and the Singularity Are Not Near Without Symbolic Model Synthesis <a href="https://arxiv.org/pdf/2601.05280" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning <a href="https://arxiv.org/pdf/2601.05836" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization <a href="https://arxiv.org/pdf/2601.05475" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits <a href="https://arxiv.org/pdf/2601.05257" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck <a href="https://arxiv.org/pdf/2601.05870" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] Do LLMs Need Inherent Reasoning Before Reinforcement Learning? A Study in Korean Self-Correction <a href="https://arxiv.org/pdf/2601.05459" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management <a href="https://arxiv.org/pdf/2601.05890" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization <a href="https://arxiv.org/pdf/2601.05432" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents <a href="https://arxiv.org/pdf/2601.05899" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR <a href="https://arxiv.org/pdf/2601.05607" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning <a href="https://arxiv.org/pdf/2601.05593" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] Sequential Bayesian Optimal Experimental Design in Infinite Dimensions via Policy Gradient Reinforcement Learning <a href="https://arxiv.org/pdf/2601.05868" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] Autonomous Discovery of the Ising Model&#x27;s Critical Parameters with Reinforcement Learning <a href="https://arxiv.org/pdf/2601.05577" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection <a href="https://arxiv.org/pdf/2601.05578" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering <a href="https://arxiv.org/pdf/2601.05465" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation <a href="https://arxiv.org/pdf/2601.05787" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] Dual-Phase LLM Reasoning: Self-Evolved Mathematical Frameworks <a href="https://arxiv.org/pdf/2601.05616" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis <a href="https://arxiv.org/pdf/2601.05808" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 9</strong></p>
<ul>
<li class="">[arXiv260112] FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching <a href="https://arxiv.org/pdf/2601.05684" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning <a href="https://arxiv.org/pdf/2601.05593" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2601.05407" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] mHC-lite: You Don&#x27;t Need 20 Sinkhorn-Knopp Iterations <a href="https://arxiv.org/pdf/2601.05732" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] DNATokenizer: A GPU-First Byte-to-Identifier Tokenizer for High-Throughput DNA Language Models <a href="https://arxiv.org/pdf/2601.05531" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] Influence of Parallelism in Vector-Multiplication Units on Correlation Power Analysis <a href="https://arxiv.org/pdf/2601.05828" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] Tracing Stereotypes in Pre-trained Transformers: From Biased Neurons to Fairer Models <a href="https://arxiv.org/pdf/2601.05663" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] A Survey of Agentic AI and Cybersecurity: Challenges, Opportunities and Use-case Prototypes <a href="https://arxiv.org/pdf/2601.05293" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260112] Can We Predict Before Executing Machine Learning Agents? <a href="https://arxiv.org/pdf/2601.05930" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-13">2026-01-13<a href="#2026-01-13" class="hash-link" aria-label="Direct link to 2026-01-13" title="Direct link to 2026-01-13" translate="no">​</a></h2>
<p><strong>cs.DC total: 18</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260113] Behavioral Analytics for Continuous Insider Threat Detection in Zero-Trust Architectures</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [AdaBoost, SMOTE, PCA, SVM, ANN, Bayesian Network, behavioral analytics, insider threat detection]</li>
<li class=""><strong>authors:</strong> Gaurav Sarraf</li>
<li class=""><strong>institution:</strong> Independent researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.06708" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.06708</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a framework using behavioral analytics and machine learning for continuous insider threat detection in zero-trust architectures. It employs data preprocessing (SMOTE, PCA) and benchmarks classifiers, finding that an AdaBoost model achieves the highest performance (98% accuracy). The results demonstrate the effectiveness of AdaBoost-based analytics for reinforcing security in zero-trust settings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] BlazeAIoT: A Modular Multi-Layer Platform for Real-Time Distributed Robotics Across Edge, Fog, and Cloud Infrastructures</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [Kubernetes, DDS, Kafka, Redis, ROS2, adaptive data distribution, hierarchical rate limiting, multi-layer configuration service]</li>
<li class=""><strong>authors:</strong> Cedric Melancon, Julien Gascon-Samson, Maarouf Saad, Kuljeet Kaur, Simon Savard</li>
<li class=""><strong>institution:</strong> École de technologie supérieure</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.06344" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.06344</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces BlazeAIoT, a modular platform that uses Kubernetes clusters and broker interoperability (e.g., DDS, Kafka) to unify distributed robotics across edge, fog, and cloud layers. It demonstrates that the platform can dynamically allocate services, maintain system health, and minimize latency, making it a scalable solution for real-time robotics and IoT applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] Resource-Aware Task Allocator Design: Insights and Recommendations for Distributed Satellite Constellations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed satellite systems], [Single-Level Tree Network (SLTN), resource-aware task allocator (RATA), blocking probability, solar-aware scheduling, energy consumption]</li>
<li class=""><strong>authors:</strong> Bharadwaj Veeravalli</li>
<li class=""><strong>institution:</strong> National University of Singapore</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.06706" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.06706</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper designs a Resource-Aware Task Allocator (RATA) for Distributed Satellite Systems using a Single-Level Tree Network architecture to manage real-time tasks. The empirical analysis shows that while system capacity increases with constellation size, blocking and delay grow non-linearly, and CPU availability, not energy, is the primary bottleneck causing task blocking.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] HiDVFS: A Hierarchical Multi-Agent DVFS Scheduler for OpenMP DAG Workloads</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [hierarchical multi-agent reinforcement learning, dynamic voltage and frequency scaling, OpenMP DAG scheduling, temperature-aware task allocation, makespan optimization]</li>
<li class=""><strong>authors:</strong> Mohammad Pivezhandi, Abusayeed Saifullah, Ali Jannesari</li>
<li class=""><strong>institution:</strong> Iowa State University, University of Texas at Dallas</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.06425" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.06425</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes HiDVFS, a hierarchical multi-agent DVFS scheduler that optimizes task allocation and frequency scaling for OpenMP DAG workloads using profiling data and temperature sensors to prioritize makespan while reducing energy. Experiments on an NVIDIA Jetson TX2 show HiDVFS achieves significant speedup and energy reduction compared to existing methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] AIConfigurator: Lightning-Fast Configuration Optimization for Multi-Framework LLM Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [performance modeling, configuration search, kernel-level database, GEMM, attention, communication, memory operations, distributed parallelism, tensor parallelism, pipeline parallelism, expert parallelism, CUDA graphs, KV-cache]</li>
<li class=""><strong>authors:</strong> Tianhao Xu, Yiming Liu, Xianglong Lu, Yijia Zhao, Xuting Zhou, Aichen Feng, Yiyi Chen, Yi Shen, Qin Zhou, Xumeng Chen, Ilya Sherstyuk, Haorui Li, Rishi Thakkar, Ben Hamm, Yuanzhe Li, Xue Huang, Wenpeng Wu, Anish Shanbhag, Harry Kim, Chuan Chen, Junjie Lai</li>
<li class=""><strong>institution:</strong> NVIDIA</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.06288" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.06288</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AIConfigurator is a unified performance-modeling system that rapidly optimizes LLM inference configurations by decomposing inference into analytical primitives and using a calibrated kernel-level database, without requiring GPU profiling. It identifies configurations that improve performance by up to 40-50% for various models and completes searches within 30 seconds on average.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] Privacy-Preserving Data Processing in Cloud : From Homomorphic Encryption to Federated Analytics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [homomorphic encryption, secure multi-party computation, differential privacy, federated analytics, federated learning, hybrid privacy frameworks]</li>
<li class=""><strong>authors:</strong> Gaurav Sarraf, Vibhor Pal</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.06710" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.06710</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper reviews privacy-preserving data processing methods for cloud computing, including cryptographic techniques like homomorphic encryption and statistical approaches like differential privacy, as well as distributed frameworks like federated learning. It concludes by analyzing the trade-offs between security, efficiency, and accuracy in these methods and highlights the potential of hybrid frameworks to offer better privacy protection. The review serves as a crucial resource for understanding secure and effective solutions in data processing.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] Rethinking Inter-Process Communication with Memory Operation Offloading</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [memory operation offloading, asynchronous pipelining, selective cache injection, hybrid coordination, shared-memory communication]</li>
<li class=""><strong>authors:</strong> Misun Park, Richi Dubey, Yifan Yuan, Nam Sung Kim, Ada Gavrilovska</li>
<li class=""><strong>institution:</strong> Georgia Institute of Technology, Meta, University of Illinois–Urbana-Champaign</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.06331" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.06331</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents ROCKET, a unified IPC runtime that integrates hardware- and software-based memory offloading into shared-memory communication to reduce CPU overhead from data copies. It introduces techniques like asynchronous pipelining and selective cache injection to coordinate offloading strategies. Evaluations show the system significantly reduces instruction counts, improves throughput, and lowers latency for modern data-intensive, multi-modal workloads.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] Learning-Augmented Performance Model for Tensor Product Factorization in High-Order FEM</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [performance modeling, sum-factorization, tensor n-mode product, XGBoost, dependency-chain analysis, loop-body splitting, Roofline model, ECM model]</li>
<li class=""><strong>authors:</strong> Xuanzhengbo Ren, Yuta Kawai, Tetsuya Hoshino, Hirofumi Tomita, Takahiro Katagiri, Daichi Mukunoki, Seiya Nishizawa</li>
<li class=""><strong>institution:</strong> Nagoya University, RIKEN R-CCS</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.06886" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.06886</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper develops a learning-augmented performance model for tensor product factorization kernels in high-order FEM. It combines an analytical dependency-chain formulation with XGBoost to estimate key parameters, focusing on instruction-level efficiency for loop-splitting configurations. The model significantly outperforms standard Roofline and ECM models in prediction accuracy on both Fujitsu A64FX and Intel Xeon processors.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] SkyNomad: On Using Multi-Region Spot Instances to Minimize AI Batch Job Cost</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [spot instances, multi-region scheduling, cost model, checkpoint-based recovery, deadline guarantee, migration]</li>
<li class=""><strong>authors:</strong> Zhifei Li, Tian Xia, Ziming Mao, Zihan Zhou, Ethan J. Jackson, Jamison Kerney, Zhanghao Wu, Pratik Mishra, Yi Xu, Yifan Qiao, Scott Shenker, Ion Stoica</li>
<li class=""><strong>institution:</strong> UC Berkeley, Shanghai Jiao Tong University, AMD, ICSI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.06520" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.06520</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SkyNomad is a multi-region scheduling system that minimizes the cost of AI batch jobs by exploiting spatial and temporal heterogeneity in spot instance availability and prices, while guaranteeing deadlines. It uses lightweight probing, spot lifetime prediction, and a unified cost model to guide migration decisions between spot and on-demand instances. The evaluation shows it achieves significant cost savings (1.25-3.96x) in real deployments and performs close to an optimal policy in simulation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] Employ SmartNICs&#x27; Data Path Accelerators for Ordered Key-Value Stores</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems], [SmartNIC, Data Path Accelerators (DPAs), learned index, lock-free, PCIe, DMA, stateless clients, range queries]</li>
<li class=""><strong>authors:</strong> Frederic Schimmelpfennig, Jan Sass, Reza Salkhordeh, Martin Kröning, Stefan Lankes, André Brinkmann</li>
<li class=""><strong>institution:</strong> Johannes Gutenberg University Mainz, RWTH Aachen University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.06231" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.06231</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a key-value store that uses the Data Path Accelerators (DPAs) on a BlueField-3 SmartNIC to process requests directly, bypassing the host OS and minimizing PCIe crossings. It employs a lock-free learned index on the SmartNIC for efficient point and range queries, achieving high throughput. The analysis shows this architecture matches or exceeds state-of-the-art performance while suggesting hardware refinements for further acceleration.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [split computing, intermediate output integration, LiDAR, 3D object detection, edge computing, point cloud]</li>
<li class=""><strong>authors:</strong> Taisuke Noguchi, Takayuki Nishio, Takuya Azumi</li>
<li class=""><strong>institution:</strong> Saitama University, Institute of Science Tokyo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.07119" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.07119</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes SC-MII, a split computing method for 3D object detection using multiple infrastructure LiDARs. Edge devices process initial DNN layers on local point clouds and send intermediate features to a server, which integrates them to complete inference. The approach significantly reduces edge device processing time and latency with minimal accuracy loss.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [distributed orchestration, resource allocation, task scheduling, three-service architecture]</li>
<li class=""><strong>authors:</strong> Lei Zhang, Mouxiang Chen, Ruisheng Cao, Jiawei Chen, Fan Zhou, Yiheng Xu, Jiaxi Yang, Liang Chen, Changwei Luo, Kai Zhang, Fan Yan, KaShun Shum, Jiajun Zhang, Zeyu Cui, Hu Feng, Junyang Lin, Binyuan Hui, Min Yang</li>
<li class=""><strong>institution:</strong> Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Alibaba Group</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.07526" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.07526</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces MegaFlow, a large-scale distributed orchestration system that abstracts agent training into three independent services (Model, Agent, and Environment) for flexible scaling and management. It successfully coordinates tens of thousands of concurrent agent tasks, addressing a critical infrastructure gap for training AI agents on complex tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] Divergence-Based Adaptive Aggregation for Byzantine Robust Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [divergence of degree, linear calibration, vetted root dataset, Byzantine attacks, client drift, federated averaging, non-convex models]</li>
<li class=""><strong>authors:</strong> Bingnan Xiao, Feng Zhu, Jingjing Zhang, Wei Ni, Xin Wang</li>
<li class=""><strong>institution:</strong> Fudan University, North Carolina State University, Edith Cowan University, University of New South Wales</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.06903" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.06903</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces two federated learning frameworks, DRAG and BR-DRAG, which use a divergence metric and linear calibration to align local model updates and mitigate client drift. BR-DRAG enhances this by using a trusted server dataset to defend against Byzantine attacks. The methods are proven to converge quickly under non-convex settings and are validated as effective against data heterogeneity and malicious attacks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] Peformance Isolation for Inference Processes in Edge GPU Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [MPS, MIG, Green Contexts, temporal isolation, GPU partitioning, edge computing]</li>
<li class=""><strong>authors:</strong> Juan José Martín, José Flich, Carles Hernández</li>
<li class=""><strong>institution:</strong> Universitat Politècnica de València</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.07600" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.07600</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper analyzes GPU isolation mechanisms (MPS, MIG, Green Contexts) to ensure predictable inference times for deep learning models in safety-critical edge systems. The experimental evaluation on NVIDIA A100 and Jetson Orin platforms shows that MIG provides high isolation, while Green Contexts offer a promising low-overhead alternative for fine-grained SM allocation on edge devices, though without memory isolation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] OpenTinker: Separating Concerns in Agentic Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [reinforcement learning, large language model agents, separation of concerns, composable components, managed execution runtime, centralized scheduler, LoRA, full-parameter RL, supervised fine-tuning]</li>
<li class=""><strong>authors:</strong> Siqi Zhu, Jiaxuan You</li>
<li class=""><strong>institution:</strong> University of Illinois Urbana-Champaign</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.07376" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.07376</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces OpenTinker, an infrastructure for RL of LLM agents that separates concerns into algorithm design, execution, and agent-environment interaction using lightweight, composable components. It features a centralized scheduler to manage diverse workloads like LoRA-based RL and inference over shared resources. The framework aims to lower the barrier for agentic RL by abstracting infrastructure, making it more reusable and accessible than monolithic pipelines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] Advanced computing for reproducibility of astronomy Big Data Science, with a showcase of AMIGA and the SKA Science prototype</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [astronomy big data infrastructure], [semantic data models, federated infrastructures, reproducibility, SKA Regional Centre Network (SRCNet)]</li>
<li class=""><strong>authors:</strong> Julián Garrido, Susana Sánchez, Edgar Ribeiro João, Roger Ianjamasimanana, Manuel Parra, Lourdes Verdes-Montenegro</li>
<li class=""><strong>institution:</strong> Instituto de Astrofísica de Andalucía, CSIC</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.07439" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.07439</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents the AMIGA group&#x27;s research on using semantic data models and federated analysis services to address computing and reproducibility challenges for the SKA Observatory&#x27;s Big Data. It concludes that for the SKAO to succeed, reproducibility requirements must be explicitly embedded into the fundamental architectural design of the SKA Regional Centre Network (SRCNet) to enable verifiable and sustainable research.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] Bringing Computation to the data: Interoperable serverless function execution for astrophysical data analysis in the SRCNet</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [scientific computing, data-intensive workflows], [serverless computing, Function-as-a-Service (FaaS), data-proximate computation, Gaussian convolution, SKA Regional Centre Network (SRCNet)]</li>
<li class=""><strong>authors:</strong> Manuel Parra-Royón, Julián Garrido-Sánchez, Susana Sánchez-Expósito, María Ángeles Mendoza, Rob Barnsley, Anthony Moraghan, Jesús Sánchez, Laura Darriba, Carlos Ruíz-Monje, Edgar Joao, Javier Moldón, Jesús Salgado, Lourdes Verdes-Montenegro</li>
<li class=""><strong>institution:</strong> Instituto de Astrofísica de Andalucía, Square Kilometre Array Observatory (SKAO), University of Sevilla, University of Manchester</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.07308" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.07308</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper explores the use of serverless Function-as-a-Service (FaaS) computing to enable interoperable, data-proximate astrophysical analysis within the SKA Regional Centre Network. It demonstrates the deployment of representative functions, such as Gaussian convolution, directly at data storage sites to reduce latency and transfers. The results indicate that serverless models provide a scalable and efficient approach for handling the massive data volumes expected from the Square Kilometre Array.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260113] Beyond Single-GPU: Scaling PDLP to Distributed Multi-GPU Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [PDHG, distributed multi-GPU, two-dimensional grid partitioning, NCCL, block-wise random shuffling, nonzero-aware data distribution, fused CUDA kernels]</li>
<li class=""><strong>authors:</strong> Hongpei Li, Yicheng Huang, Huikang Liu, Dongdong Ge, Yinyu Ye</li>
<li class=""><strong>institution:</strong> Cardinal Operations, Shanghai University of Finance and Economics, Shanghai Jiao Tong University, Stanford University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.07628" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.07628</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a distributed implementation of the Primal-Dual Hybrid Gradient (PDHG) algorithm for solving massive-scale linear programming problems. The method uses a two-dimensional grid partitioning of the constraint matrix and techniques like block-wise shuffling and fused CUDA kernels to scale across multiple GPUs with low communication overhead. The experiments show that this distributed framework overcomes single-GPU memory limits and achieves strong scalability and high performance while maintaining numerical accuracy.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 50</strong></p>
<ul>
<li class="">[arXiv260113] Reinforcement Learning-Guided Dynamic Multi-Graph Fusion for Evacuation Traffic Prediction <a href="https://arxiv.org/pdf/2601.06664" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Toward Safe and Responsible AI Agents: A Three-Pillar Model for Transparency, Accountability, and Trustworthiness <a href="https://arxiv.org/pdf/2601.06223" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] A Review of Online Diffusion Policy RL Algorithms for Scalable Robotic Control <a href="https://arxiv.org/pdf/2601.06133" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization <a href="https://arxiv.org/pdf/2601.06052" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] KASER: Knowledge-Aligned Student Error Simulator for Open-Ended Coding Tasks <a href="https://arxiv.org/pdf/2601.06633" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] TimeGNN-Augmented Hybrid-Action MARL for Fine-Grained Task Partitioning and Energy-Aware Offloading in MEC <a href="https://arxiv.org/pdf/2601.06191" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Thinking with Deltas: Incentivizing Reinforcement Learning via Differential Visual Reasoning Policy <a href="https://arxiv.org/pdf/2601.06801" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] HiMeS: Hippocampus-inspired Memory System for Personalized AI Assistants <a href="https://arxiv.org/pdf/2601.06152" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Plasticity vs. Rigidity: The Impact of Low-Rank Adapters on Reasoning on a Micro-Budget <a href="https://arxiv.org/pdf/2601.06677" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] GanitLLM: Difficulty-Aware Bengali Mathematical Reasoning through Curriculum-GRPO <a href="https://arxiv.org/pdf/2601.06767" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Object-Centric World Models Meet Monte Carlo Tree Search <a href="https://arxiv.org/pdf/2601.06604" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] COVR<!-- -->:Collaborative<!-- --> Optimization of VLMs and RL Agent for Visual-Based Control <a href="https://arxiv.org/pdf/2601.06122" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning <a href="https://arxiv.org/pdf/2601.06794" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] From RLHF to Direct Alignment: A Theoretical Unification of Preference Learning for Large Language Models <a href="https://arxiv.org/pdf/2601.06108" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning <a href="https://arxiv.org/pdf/2601.06795" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Future-as-Label: Scalable Supervision from Real-World Outcomes <a href="https://arxiv.org/pdf/2601.06336" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Personality-Aware Reinforcement Learning for Persuasive Dialogue with LLM-Driven Simulation <a href="https://arxiv.org/pdf/2601.06877" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Code Evolution for Control: Synthesizing Policies via LLM-Driven Evolutionary Search <a href="https://arxiv.org/pdf/2601.06845" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] The Impact of Post-training on Data Contamination <a href="https://arxiv.org/pdf/2601.06103" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] A Brain-like Synergistic Core in LLMs Drives Behaviour and Learning <a href="https://arxiv.org/pdf/2601.06851" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Characterising Toxicity in Generative Large Language Models <a href="https://arxiv.org/pdf/2601.06700" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] How well can off-the-shelf LLMs elucidate molecular structures from mass spectra using chain-of-thought reasoning? <a href="https://arxiv.org/pdf/2601.06289" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Deep Q-Network Based Resilient Drone Communication<!-- -->:Neutralizing<!-- --> First-Order Markov Jammers <a href="https://arxiv.org/pdf/2601.06095" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] ArenaRL: Scaling RL for Open-Ended Agents via Tournament-based Relative Ranking <a href="https://arxiv.org/pdf/2601.06487" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Distributional Clarity: The Hidden Driver of RL-Friendliness in Large Language Models <a href="https://arxiv.org/pdf/2601.06911" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests <a href="https://arxiv.org/pdf/2601.06953" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] MEDVISTAGYM: A Scalable Training Environment for Thinking with Medical Images via Tool-Integrated Reinforcement Learning <a href="https://arxiv.org/pdf/2601.07107" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework <a href="https://arxiv.org/pdf/2601.07122" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] ENTRA: Entropy-Based Redundancy Avoidance in Large Language Model Reasoning <a href="https://arxiv.org/pdf/2601.07123" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Generating readily synthesizable small molecule fluorophore scaffolds with reinforcement learning <a href="https://arxiv.org/pdf/2601.07145" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Rewarding Creativity: A Human-Aligned Generative Reward Model for Reinforcement Learning in Storytelling <a href="https://arxiv.org/pdf/2601.07149" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units <a href="https://arxiv.org/pdf/2601.07160" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Offline Meta-Reinforcement Learning with Flow-Based Task Inference and Adaptive Correction of Feature Overgeneralization <a href="https://arxiv.org/pdf/2601.07164" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration <a href="https://arxiv.org/pdf/2601.07224" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning <a href="https://arxiv.org/pdf/2601.07238" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] LRAS: Advanced Legal Reasoning with Agentic Search <a href="https://arxiv.org/pdf/2601.07296" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts <a href="https://arxiv.org/pdf/2601.07304" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM Training <a href="https://arxiv.org/pdf/2601.07320" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training <a href="https://arxiv.org/pdf/2601.07389" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Outcome-Grounded Advantage Reshaping for Fine-Grained Credit Assignment in Mathematical Reasoning <a href="https://arxiv.org/pdf/2601.07408" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2601.07463" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Graph Inference Towards ICD Coding <a href="https://arxiv.org/pdf/2601.07496" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions <a href="https://arxiv.org/pdf/2601.07516" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Stagewise Reinforcement Learning and the Geometry of the Regret Landscape <a href="https://arxiv.org/pdf/2601.07524" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] GRPO with State Mutations: Improving LLM-Based Hardware Test Plan Generation <a href="https://arxiv.org/pdf/2601.07593" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids <a href="https://arxiv.org/pdf/2601.07718" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning <a href="https://arxiv.org/pdf/2601.07782" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation <a href="https://arxiv.org/pdf/2601.07821" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Large Language Models for Physics Instrument Design <a href="https://arxiv.org/pdf/2601.07580" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Reinforcement Learning for Micro-Level Claims Reserving <a href="https://arxiv.org/pdf/2601.07637" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 18</strong></p>
<ul>
<li class="">[arXiv260113] TeleMem: Building Long-Term and Multimodal Memory for Agentic AI <a href="https://arxiv.org/pdf/2601.06037" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Pareto-Optimal Model Selection for Low-Cost, Single-Lead EMG Control in Embedded Systems <a href="https://arxiv.org/pdf/2601.06516" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Logic-Driven Semantic Communication for Resilient Multi-Agent Systems <a href="https://arxiv.org/pdf/2601.06733" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Attention in Geometry: Scalable Spatial Modeling via Adaptive Density Fields and FAISS-Accelerated Kernels <a href="https://arxiv.org/pdf/2601.06135" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Bridging the AI divide in sub-Saharan Africa: Challenges and opportunities for inclusivity <a href="https://arxiv.org/pdf/2601.06145" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Lower Bounds for the Algorithmic Complexity of Learned Indexes <a href="https://arxiv.org/pdf/2601.06629" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning <a href="https://arxiv.org/pdf/2601.06795" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Channel Knowledge Map Construction via Guided Flow Matching <a href="https://arxiv.org/pdf/2601.06156" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] MicLog: Towards Accurate and Efficient LLM-based Log Parsing via Progressive Meta In-Context Learning <a href="https://arxiv.org/pdf/2601.07005" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Jasper: ANNS Quantized for Speed, Built for Change on GPU <a href="https://arxiv.org/pdf/2601.07048" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units <a href="https://arxiv.org/pdf/2601.07160" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent <a href="https://arxiv.org/pdf/2601.07263" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Software-Hardware Co-optimization for Modular E2E AV Paradigm: A Unified Framework of Optimization Approaches, Simulation Environment and Evaluation Metrics <a href="https://arxiv.org/pdf/2601.07393" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] PLANET v2.0: A comprehensive Protein-Ligand Affinity Prediction Model Based on Mixture Density Network <a href="https://arxiv.org/pdf/2601.07415" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Pheromone-Focused Ant Colony Optimization algorithm for path planning <a href="https://arxiv.org/pdf/2601.07597" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Learning to accelerate Krasnosel&#x27;skii-Mann fixed-point iterations with guarantees <a href="https://arxiv.org/pdf/2601.07665" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] Match Made with Matrix Completion: Efficient Learning under Matching Interference <a href="https://arxiv.org/pdf/2601.06982" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260113] A Model of Artificial Jagged Intelligence <a href="https://arxiv.org/pdf/2601.07573" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-14">2026-01-14<a href="#2026-01-14" class="hash-link" aria-label="Direct link to 2026-01-14" title="Direct link to 2026-01-14" translate="no">​</a></h2>
<p><strong>cs.DC total: 9</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260114] Coordinated Cooling and Compute Management for AI Datacenters</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [GPU profiling, hierarchical control, DVFS, thermal modeling, joint cooling-compute optimization]</li>
<li class=""><strong>authors:</strong> Nardos Belay Abera, Yize Chen</li>
<li class=""><strong>institution:</strong> University of Alberta</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.08113" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.08113</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a hierarchical control framework that co-optimizes computing (via GPU parallelism and DVFS) and cooling management for AI datacenters, based on workload and thermal dynamics models. Using real Azure traces and GPU profiling, the method balances serving latency and thermal constraints, significantly improving datacenter energy efficiency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260114] Improving Zero-shot ADL Recognition with Large Language Models through Event-based Context and Confidence</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [event-based segmentation, zero-shot learning, confidence estimation, prompting strategies, smart home sensor data]</li>
<li class=""><strong>authors:</strong> Michele Fiori, Gabriele Civitarese, Marco Colussi, Claudio Bettini</li>
<li class=""><strong>institution:</strong> University of Milan</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.08241" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.08241</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a zero-shot method for recognizing Activities of Daily Living (ADLs) using Large Language Models with event-based segmentation instead of traditional time-based windows, and introduces a novel confidence estimation measure. The approach outperforms existing time-based LLM methods and even supervised data-driven methods on complex datasets, with the confidence measure effectively identifying correct predictions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260114] Where to Split? A Pareto-Front Analysis of DNN Partitioning for Edge Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [DNN partitioning, pipeline parallelism, Pareto front analysis, edge inference, latency-throughput trade-off]</li>
<li class=""><strong>authors:</strong> Adiba Masud, Nicholas Foley, Pragathi Durga Rajarajan, Palden Lama</li>
<li class=""><strong>institution:</strong> The University of Texas at San Antonio</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.08025" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.08025</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces ParetoPipe, a framework that reframes DNN partitioning for edge inference as a multi-objective optimization problem, using Pareto front analysis to identify optimal strategies balancing latency and throughput. The main conclusion is that real-world deployments require navigating a complex trade-off space, and the framework&#x27;s benchmarking on a heterogeneous testbed reveals these trade-offs under varying network conditions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260114] Multivariate Polynomial Codes for Efficient Matrix Chain Multiplication in Distributed Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [multivariate polynomial coding, coded distributed computing, matrix chain multiplication, straggler mitigation, storage-computation trade-off]</li>
<li class=""><strong>authors:</strong> Jesús Gómez-Vilardebò</li>
<li class=""><strong>institution:</strong> Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.08708" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.08708</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes two novel multivariate polynomial coding schemes to mitigate stragglers in distributed matrix chain multiplication. The method reduces storage overhead at workers compared to univariate polynomial codes, but at the cost of increased computational complexity. The main conclusion is that multivariate codes offer a practical trade-off between computation and storage efficiency for large-scale distributed linear algebra.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260114] MixServe: An Automatic Distributed Serving System for MoE Models with Hybrid Parallelism Based on Fused Communication Algorithm</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [mixture of experts, tensor parallelism, expert parallelism, hybrid parallelism, fused communication, all-reduce, all-to-all, automatic parallel strategy selection]</li>
<li class=""><strong>authors:</strong> Bowen Zhou, Jinrui Jia, Wenhao He, Yong Zhang, Fang Dong</li>
<li class=""><strong>institution:</strong> Southeast University, The Chinese University of Hong Kong</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.08800" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.08800</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces MixServe, an automatic distributed serving system for MoE models. Its core method is a novel TP-EP hybrid parallelism based on a fused AR-A2A communication algorithm that overlaps intra-node and inter-node communication. Experiments show that MixServe significantly improves inference performance, including latency and throughput, compared to existing approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260114] Hierarchical Precision and Recursion for Accelerating Symmetric Linear Solves on MXUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [mixed-precision, recursive algorithms, Cholesky decomposition, triangular solve (TRSM), symmetric rank-k update (SYRK), hierarchical recursion, matrix processing units (MXUs)]</li>
<li class=""><strong>authors:</strong> Vicki Carrica, Rabab Alomairy, Evelyne Ringoot, Alan Edelman</li>
<li class=""><strong>institution:</strong> Massachusetts Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.08082" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.08082</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a portable, mixed-precision solver for symmetric linear systems, using a nested recursive algorithm that assigns low-precision arithmetic to off-diagonal blocks and high precision to diagonal blocks for numerical stability. Implemented in Julia, it achieves significant speedups on NVIDIA and AMD GPUs, with up to a 5x overall acceleration for Cholesky decomposition while maintaining high accuracy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260114] Shifting the Sweet Spot: High-Performance Matrix-Free Method for High-Order Elasticity</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing, finite element methods], [matrix-free methods, sum-factorization, tensor factorization, Voigt symmetry, macro-kernel fusion, geometric multigrid, MFEM]</li>
<li class=""><strong>authors:</strong> Dali Chang, Chong Zhang, Kaiqi Zhang, Mingguan Yang, Huiyuan Li, Weiqiang Kong</li>
<li class=""><strong>institution:</strong> Dalian University of Technology, Institute of Software Chinese Academy of Sciences</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.08374" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.08374</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a highly optimized matrix-free operator for high-order finite element elasticity simulations, using techniques like tensor factorization and macro-kernel fusion to improve computational efficiency. The method successfully shifts the performance &quot;sweet spot&quot; to higher polynomial orders (p ≥ 6), achieving significant speedups over the baseline. It provides an efficient path for large-scale, high-order elasticity simulations on mainstream CPU hardware.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260114] Hierarchical Online-Scheduling for Energy-Efficient Split Inference with Progressive Transmission</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [split inference, Lyapunov optimization, hierarchical scheduling, progressive transmission, device-edge collaboration, energy efficiency]</li>
<li class=""><strong>authors:</strong> Zengzipeng Tang, Yuxuan Sun, Wei Chen, Jianwen Ding, Bo Ai, Yulin Shao</li>
<li class=""><strong>institution:</strong> Beijing Jiaotong University, The University of Hong Kong</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.08135" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.08135</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes ENACHI, a hierarchical online-scheduling framework that jointly optimizes task- and packet-level decisions using a two-tier Lyapunov-based approach and progressive transmission to maximize inference accuracy under energy and delay constraints. The method dynamically manages DNN partitioning, bandwidth allocation, and transmit power to adapt to channel conditions and per-task complexity. Experiments show it significantly improves accuracy and reduces energy consumption compared to benchmarks, demonstrating high scalability in multi-user scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260114] Matrix-PIC: Harnessing Matrix Outer-product for High-Performance Particle-in-Cell Simulations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing], [matrix outer-product, block-matrix formulation, hybrid MPU-VPU pipeline, incremental particle sorting, gapped packed-memory array]</li>
<li class=""><strong>authors:</strong> Yizhuo Rao, Xingjian Cui, Jiabin Xie, Shangzhi Pang, Guangnan Feng, Jinhui Wei, Zhiguang Chen, Yutong Lu</li>
<li class=""><strong>institution:</strong> Sun Yat-Sen University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.08277" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.08277</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents Matrix-PIC, a co-designed framework that accelerates Particle-in-Cell simulations by reformulating the current deposition step into block-matrix operations that leverage CPU-integrated Matrix Processing Units (MPUs). It combines MPU-based accumulation with VPU-based data preparation and an incremental sorter to maintain data locality. The method achieves significant speedups over baseline and GPU-optimized implementations, demonstrating the effectiveness of matrix-oriented co-design on modern CPU architectures.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 28</strong></p>
<ul>
<li class="">[arXiv260114] Structure Detection for Contextual Reinforcement Learning <a href="https://arxiv.org/pdf/2601.08120" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs <a href="https://arxiv.org/pdf/2601.08763" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Provably Safe Reinforcement Learning using Entropy Regularizer <a href="https://arxiv.org/pdf/2601.08646" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety <a href="https://arxiv.org/pdf/2601.08000" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback <a href="https://arxiv.org/pdf/2601.08734" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Incorporating Cognitive Biases into Reinforcement Learning for Financial Decision-Making <a href="https://arxiv.org/pdf/2601.08247" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Scalable Multiagent Reinforcement Learning with Collective Influence Estimation <a href="https://arxiv.org/pdf/2601.08210" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning <a href="https://arxiv.org/pdf/2601.08310" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Model-Agnostic Solutions for Deep Reinforcement Learning in Non-Ergodic Contexts <a href="https://arxiv.org/pdf/2601.08726" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination <a href="https://arxiv.org/pdf/2601.08237" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] AtomMem : Learnable Dynamic Agentic Memory with Atomic Memory Operation <a href="https://arxiv.org/pdf/2601.08323" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs <a href="https://arxiv.org/pdf/2601.08403" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] AUV Trajectory Learning for Underwater Acoustic Energy Transfer and Age Minimization <a href="https://arxiv.org/pdf/2601.08491" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition <a href="https://arxiv.org/pdf/2601.08327" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation <a href="https://arxiv.org/pdf/2601.08430" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order <a href="https://arxiv.org/pdf/2601.08107" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Reinforcement Learning Methods for Neighborhood Selection in Local Search <a href="https://arxiv.org/pdf/2601.07948" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning <a href="https://arxiv.org/pdf/2601.08679" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving? <a href="https://arxiv.org/pdf/2601.08434" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Your Group-Relative Advantage Is Biased <a href="https://arxiv.org/pdf/2601.08521" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] JudgeRLVR: Judge First, Generate Second for Efficient Reasoning <a href="https://arxiv.org/pdf/2601.08468" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Reverse Flow Matching: A Unified Framework for Online Reinforcement Learning with Diffusion and Flow Policies <a href="https://arxiv.org/pdf/2601.08136" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] From Classical to Quantum Reinforcement Learning and Its Applications in Quantum Control: A Beginner&#x27;s Tutorial <a href="https://arxiv.org/pdf/2601.08662" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Large Artificial Intelligence Model Guided Deep Reinforcement Learning for Resource Allocation in Non Terrestrial Networks <a href="https://arxiv.org/pdf/2601.08254" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms <a href="https://arxiv.org/pdf/2601.08166" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms <a href="https://arxiv.org/pdf/2601.08052" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge <a href="https://arxiv.org/pdf/2601.08808" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures <a href="https://arxiv.org/pdf/2601.08026" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 7</strong></p>
<ul>
<li class="">[arXiv260114] HIPPO: Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding <a href="https://arxiv.org/pdf/2601.08273" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards <a href="https://arxiv.org/pdf/2601.08778" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Internal Deployment Gaps in AI Regulation <a href="https://arxiv.org/pdf/2601.08005" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Reducing Compute Waste in LLMs through Kernel-Level DVFS <a href="https://arxiv.org/pdf/2601.08539" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] DataScribe: An AI-Native, Policy-Aligned Web Platform for Multi-Objective Materials Design and Discovery <a href="https://arxiv.org/pdf/2601.07966" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Autonomous Materials Exploration by Integrating Automated Phase Identification and AI-Assisted Human Reasoning <a href="https://arxiv.org/pdf/2601.08185" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260114] Dynamic Graph Structure Learning via Resistance Curvature Flow <a href="https://arxiv.org/pdf/2601.08149" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-15">2026-01-15<a href="#2026-01-15" class="hash-link" aria-label="Direct link to 2026-01-15" title="Direct link to 2026-01-15" translate="no">​</a></h2>
<p><strong>cs.DC total: 13</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260115] Transaction-Driven Dynamic Reconfiguration for Certificate-Based Payment Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems], [Byzantine Consistent Broadcast, dynamic reconfiguration, certificate-based payment, PDCC, leaderless PBFT]</li>
<li class=""><strong>authors:</strong> Lingkang Shangguan</li>
<li class=""><strong>institution:</strong> The University of Sydney</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09146" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09146</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes PDCC, a transaction-driven dynamic reconfiguration protocol for certificate-based payment systems. It builds on Byzantine Consistent Broadcast to avoid global transaction ordering, enabling smooth membership changes without impacting system performance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260115] Lean Clients, Full Accuracy: Hybrid Zeroth- and First-Order Split Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [split federated learning, zeroth-order optimization, first-order optimization, hybrid optimization, auxiliary networks, low effective rank]</li>
<li class=""><strong>authors:</strong> Zhoubin Kou, Zihan Chen, Jing Yang, Cong Shen</li>
<li class=""><strong>institution:</strong> University of Virginia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09076" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09076</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes HERON-SFL, a hybrid split federated learning framework that uses zeroth-order optimization on resource-constrained clients to reduce memory and computation costs, while keeping first-order optimization on the server. Theoretically, its convergence rate is independent of model dimensionality, and empirically it matches benchmark accuracy while significantly reducing client resource usage.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260115] A Machine Learning Approach Towards Runtime Optimisation of Matrix Multiplication</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [machine learning, autotuning, multi-threaded GEMM, BLAS, BLIS, MKL]</li>
<li class=""><strong>authors:</strong> Yufan Xia, Marco De La Pierre, Amanda S. Barnard, Giuseppe Maria Junior Barca</li>
<li class=""><strong>institution:</strong> Australian National University, Pawsey Supercomputing Research Centre</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09114" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09114</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a machine learning approach to optimize the runtime of matrix multiplication (GEMM) by automatically selecting the optimal number of threads for a given task. The method, part of an Architecture and Data-Structure Aware Linear Algebra (ADSALA) library, achieved a 25-40% speedup compared to traditional BLAS implementations on two HPC node architectures.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260115] Revisiting Disaggregated Large Language Model Serving for Performance and Energy Implications</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [disaggregated serving, KV cache transfer, dynamic voltage and frequency scaling (DVFS), performance-energy Pareto frontiers, colocated serving]</li>
<li class=""><strong>authors:</strong> Jiaxi Li, Yue Zhu, Eun Kyung Lee, Klara Nahrstedt</li>
<li class=""><strong>institution:</strong> UIUC, IBM Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.08833" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.08833</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper systematically benchmarks disaggregated LLM serving, where prefill and decode stages run on separate GPUs, by evaluating different KV cache transfer paths and optimization strategies like frequency scaling. It finds that performance benefits are not guaranteed and depend on request load and transfer mediums, and that disaggregation does not lead to energy savings due to its inherently higher energy consumption.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260115] Optimizing View Change for Byzantine Fault Tolerance in Parallel Consensus</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed consensus], [mixed integer programming, benders decomposition, view change optimization, parallel BFT, leader selection]</li>
<li class=""><strong>authors:</strong> Yifei Xie, Btissam Er-Rahmadi, Xiao Chen, Tiejun Ma, Jane Hillston</li>
<li class=""><strong>institution:</strong> University of Edinburgh, Huawei Technologies R&amp;D, University of Leicester</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09184" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09184</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a View Change Optimization (VCO) model using mixed integer programming and an improved Benders decomposition method to optimize leader selection and follower reassignment in parallel Byzantine Fault Tolerant consensus. The model aims to minimize latency during leader failures by considering communication delays and failure probabilities. Experiments on Microsoft Azure show that the VCO-driven approach outperforms existing methods, especially as network size increases.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260115] Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [natural language processing, large language model, kubernetes scheduler extender, semantic parsing, soft affinity, intent-driven scheduling, AWS Bedrock]</li>
<li class=""><strong>authors:</strong> Leszek Sliwko, Jolanta Mizeria-Pietraszko</li>
<li class=""><strong>institution:</strong> Standard Chartered Bank, Opole University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09282" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09282</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a semantic scheduling system that uses a Large Language Model (LLM) to interpret natural language hints for workload placement in a Kubernetes cluster. The prototype demonstrated high parsing accuracy and achieved superior or equivalent scheduling quality compared to standard configurations, particularly in complex scenarios. The results validate the viability of using LLMs for accessible, intent-driven cluster orchestration, though latency remains a challenge for production use.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260115] Probabilistic Computers for MIMO Detection: From Sparsification to 2D Parallel Tempering</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [p-bit, graph sparsification, parallel tempering, FPGA, MIMO detection, Ising Hamiltonian, two-dimensional parallel tempering]</li>
<li class=""><strong>authors:</strong> M Mahmudul Hasan Sajeeb, Corentin Delacour, Kevin Callahan-Coray, Sanjay Seshan, Tathagata Srimani, Kerem Y. Camsari</li>
<li class=""><strong>institution:</strong> University of California, Santa Barbara, Carnegie Mellon University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09037" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09037</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a probabilistic computer using p-bits with graph sparsification and on-chip parallel tempering to solve dense combinatorial optimization problems like MIMO detection. It demonstrates improved bit error rates and faster convergence with two-dimensional parallel tempering on an FPGA. The results show potential for scalable hardware architectures to meet next-generation wireless throughput demands.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260115] Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [GEPA framework, prompt optimization, genetic algorithm, OpenACC, parallel code generation]</li>
<li class=""><strong>authors:</strong> Samyak Jhaveri, Cristina V. Lopes</li>
<li class=""><strong>institution:</strong> University of California, Irvine</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.08884" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.08884</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a systematic prompt optimization approach using the GEPA (GEnetic-PAreto) framework to enhance the generation of OpenACC pragmas by smaller, cheaper LLMs. The method evolves prompts through a reflective feedback loop guided by expert-curated examples, significantly improving compilation success rates and functional GPU speedups. The results demonstrate that optimized prompting can effectively unlock the potential of small models for automated directive-based parallelization, offering a cost-effective alternative to larger models.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260115] DP-FEDSOFIM: Differentially Private Federated Stochastic Optimization using Regularized Fisher Information Matrix</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [differential privacy, federated learning, second-order optimization, Fisher Information Matrix, Sherman-Morrison formula, server-side preconditioning]</li>
<li class=""><strong>authors:</strong> Sidhant R. Nair, Tanmay Sen, Mrinmay Sen</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology Delhi, Indian Statistical Institute Kolkata, Indian Institute of Technology Hyderabad</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09166" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09166</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes DP-FedSOFIM, a differentially private federated learning method that uses a server-side second-order optimization framework with a regularized Fisher Information Matrix as a preconditioner. It achieves O(d) memory and computational complexity per client, making it scalable for high-dimensional models while preserving privacy. Empirical results on CIFAR-10 show it achieves superior test accuracy compared to first-order baselines across various privacy budgets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260115] LatencyPrism: Online Non-intrusive Latency Sculpting for SLO-Guaranteed LLM Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [latency sculpting, anomaly detection, root cause analysis, SLO guarantee, non-intrusive monitoring, distributed inference]</li>
<li class=""><strong>authors:</strong> Du Yin, Jiayi Ren, Xiayu Sun, Tianyao Zhou, Haizhu Zhou, Ruiyan Ma, Danyang Zhang</li>
<li class=""><strong>institution:</strong> Alibaba Cloud Computing, Xi&#x27;an Jiaotong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09258" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09258</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents LatencyPrism, a zero-intrusion system for online latency monitoring and anomaly detection in LLM inference pipelines. It breaks down inference latency, distinguishes workload-driven variations from anomalies with high accuracy (F1-score 0.98), and guarantees SLO adherence without requiring code changes or service restarts. The system has been successfully deployed at scale across thousands of XPUs, enabling real-time, low-overhead monitoring and proactive alerting.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260115] Network-Based Quantum Computing: an efficient design framework for many-small-node distributed fault-tolerant quantum computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [quantum computing], [distributed fault-tolerant quantum computing, network-based quantum computation, logical qubit, algorithmic qubit, Bell-state distillation]</li>
<li class=""><strong>authors:</strong> Soshun Naito, Yasunari Suzuki, Yuuki Tokunaga</li>
<li class=""><strong>institution:</strong> The University of Tokyo, NTT Inc., RIKEN</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09374" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09374</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Network-Based Quantum Computation (NBQC), a framework for distributed fault-tolerant quantum computing where computational data continuously moves through a network of many small nodes. It shows that NBQC achieves shorter execution times than circuit-based strategies and uses nodes more efficiently than measurement-based approaches, providing a foundation for scalable quantum architecture.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260115] AI-NativeBench: An Open-Source White-Box Agentic Benchmark Suite for AI-Native Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Model Context Protocol (MCP), Agent-to-Agent (A2A), distributed tracing, white-box benchmarking, agentic spans]</li>
<li class=""><strong>authors:</strong> Zirui Wang, Guangba Yu, Michael R.Lyu</li>
<li class=""><strong>institution:</strong> Sun Yat-sen University, The Chinese University of Hong Kong</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09393" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09393</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces AI-NativeBench, an open-source, white-box benchmark suite for evaluating AI-Native systems by using distributed tracing to analyze agentic spans. The benchmark reveals key engineering insights, such as a &quot;parameter paradox&quot; where smaller models can outperform larger ones in protocol adherence and that inference costs dominate system performance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260115] High-Performance Serverless Computing: A Systematic Literature Review on Serverless for HPC, AI, and Big Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [serverless computing, high-performance computing, cloud computing, systematic literature review, taxonomy]</li>
<li class=""><strong>authors:</strong> Valerio Besozzi, Matteo Della Bartola, Patrizio Dazzi, Marco Danelutto</li>
<li class=""><strong>institution:</strong> University of Pisa, ISTI – National Research Council</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09334" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09334</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper conducts a systematic literature review of 122 research articles to explore the use of serverless computing for high-performance, AI, and big data workloads. It proposes a taxonomy of research directions and use cases, concluding that serverless is a promising model for improving scalability and resource utilization in compute-intensive applications.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 16</strong></p>
<ul>
<li class="">[arXiv260115] GIFT: Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization <a href="https://arxiv.org/pdf/2601.09233" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] TranslateGemma Technical Report <a href="https://arxiv.org/pdf/2601.09012" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL <a href="https://arxiv.org/pdf/2601.09136" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models <a href="https://arxiv.org/pdf/2601.09260" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Reading or Reasoning? Format Decoupled Reinforcement Learning for Document OCR <a href="https://arxiv.org/pdf/2601.08834" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Reward Learning through Ranking Mean Squared Error <a href="https://arxiv.org/pdf/2601.09236" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Learning to Trust Experience: A Monitor-Trust-Regulator Framework for Learning under Unobservable Feedback Reliability <a href="https://arxiv.org/pdf/2601.09261" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache <a href="https://arxiv.org/pdf/2601.09083" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering <a href="https://arxiv.org/pdf/2601.09269" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Enhancing Spatial Reasoning in Large Language Models for Metal-Organic Frameworks Structure Prediction <a href="https://arxiv.org/pdf/2601.09285" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop Scheduling under Uncertainty: Handling Random Arrivals and Machine Failures <a href="https://arxiv.org/pdf/2601.09293" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving <a href="https://arxiv.org/pdf/2601.09353" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR <a href="https://arxiv.org/pdf/2601.09361" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Draw it like Euclid: Teaching transformer models to generate CAD profiles using ruler and compass construction steps <a href="https://arxiv.org/pdf/2601.09428" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing <a href="https://arxiv.org/pdf/2601.09609" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning <a href="https://arxiv.org/pdf/2601.09667" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 11</strong></p>
<ul>
<li class="">[arXiv260115] MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting <a href="https://arxiv.org/pdf/2601.09085" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Navigating Ideation Space: Decomposed Conceptual Representations for Positioning Scientific Ideas <a href="https://arxiv.org/pdf/2601.08901" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Hidden States as Early Signals: Step-level Trace Evaluation and Pruning for Efficient Test-Time Scaling <a href="https://arxiv.org/pdf/2601.09093" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Mi<!-- -->:dm<!-- --> 2.0 Korea-centric Bilingual Language Models <a href="https://arxiv.org/pdf/2601.09066" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Discrete Solution Operator Learning for Geometry-Dependent PDEs <a href="https://arxiv.org/pdf/2601.09143" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Human-AI Co-design for Clinical Prediction Models <a href="https://arxiv.org/pdf/2601.09072" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache <a href="https://arxiv.org/pdf/2601.09083" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Layer-Parallel Training for Transformers <a href="https://arxiv.org/pdf/2601.09026" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving <a href="https://arxiv.org/pdf/2601.09353" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Preliminary Tests of the Anticipatory Classifier System with Hindsight Experience Replay <a href="https://arxiv.org/pdf/2601.09400" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260115] Deep Operator Networks for Surrogate Modeling of Cyclic Adsorption Processes with Varying Initial Conditions <a href="https://arxiv.org/pdf/2601.09491" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-16">2026-01-16<a href="#2026-01-16" class="hash-link" aria-label="Direct link to 2026-01-16" title="Direct link to 2026-01-16" translate="no">​</a></h2>
<p><strong>cs.DC total: 10</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260116] SCRamble: Adaptive Decentralized Overlay Construction for Blockchain Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain networks], [decentralized protocol, overlay construction, peer-to-peer, scoring mechanism, network latency, block dissemination]</li>
<li class=""><strong>authors:</strong> Evangelos Kolyvas, Alexandros Antonov, Spyros Voulgaris</li>
<li class=""><strong>institution:</strong> Athens University of Economics and Business</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.10277" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.10277</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SCRamble, a decentralized protocol that reduces block dissemination time in blockchain networks. It uses a link selection strategy combining a scoring mechanism based on block arrival times and a heuristic considering network latency. The method improves transaction throughput and system security by accelerating block propagation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260116] Fuzzychain-edge: A novel Fuzzy logic-based adaptive Access control model for Blockchain in Edge Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [access control systems], [Zero-Knowledge Proofs, Fuzzy Logic, Blockchain, Smart Contracts, Edge Computing]</li>
<li class=""><strong>authors:</strong> Khushbakht Farooq, Muhammad Ibrahim, Irsa Manzoor, Mukhtaj Khan, Wei Song</li>
<li class=""><strong>institution:</strong> IEEE</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.10105" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.10105</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Fuzzychain-edge, a novel access control framework that integrates Zero-Knowledge Proofs, fuzzy logic, and blockchain-based smart contracts for IoT in edge computing. It concludes that this approach enhances security, privacy, and traceability, providing a robust solution for sensitive data environments like healthcare.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260116] Clustering-Based User Selection in Federated Learning: Metadata Exploitation for 3GPP Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [homogeneous Poisson point process, clustering, metadata-driven, non-IID, user selection]</li>
<li class=""><strong>authors:</strong> Ce Zheng, Shiyao Ma, Ke Zhang, Chen Sun, Wenqi Zhang</li>
<li class=""><strong>institution:</strong> Pengcheng Laboratory, Southwest University, Waseda University, SONY(China) Ltd</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.10013" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.10013</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a metadata-driven federated learning framework that uses a novel data partition model based on a homogeneous Poisson point process and a clustering-based user selection strategy to reduce data correlation. Experiments show the method improves model performance, stability, and convergence in non-IID scenarios, especially when few users are selected per round.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260116] Mitigating GIL Bottlenecks in Edge AI Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Blocking Ratio (beta), adaptive thread pool, GIL contention, runtime profiling, saturation cliff]</li>
<li class=""><strong>authors:</strong> Mridankan Mandal, Smit Sanjay Shende</li>
<li class=""><strong>institution:</strong> Indian Institute of Information Technology, Allahabad</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.10582" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.10582</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a library-based adaptive runtime system that uses a novel Blocking Ratio metric to distinguish I/O wait from GIL contention, enabling automatic thread pool scaling to avoid performance degradation in Python-based edge AI systems. It demonstrates that this approach achieves high efficiency, outperforming alternatives like multiprocessing and asyncio, and remains relevant even in environments without the GIL.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260116] Breaking the Storage-Bandwidth Tradeoff in Distributed Storage with Quantum Entanglement</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed storage], [quantum entanglement, distributed storage systems, storage-bandwidth tradeoff, quantum communication, regenerating codes]</li>
<li class=""><strong>authors:</strong> Lei Hu, Mohamed Nomeir, Alptug Aytekin, Sennur Ulukus</li>
<li class=""><strong>institution:</strong> University of Maryland</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.10676" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.10676</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates the use of quantum communication and entanglement among helper nodes in distributed storage systems to improve the fundamental tradeoff between storage and repair bandwidth. It shows that, unlike classical systems, quantum resources can significantly enhance this tradeoff, and remarkably, when d ≥ 2k-2, both storage and repair bandwidth can be minimized simultaneously, breaking the classical tradeoff.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260116] Distributed Linearly Separable Computation with Arbitrary Heterogeneous Data Assignment</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computation], [linearly separable computation, heterogeneous data assignment, communication cost, computable dimension, universal computing scheme, converse bound]</li>
<li class=""><strong>authors:</strong> Ziting Zhang, Kai Wan, Minquan Cheng, Shuo Shao, Giuseppe Caire</li>
<li class=""><strong>institution:</strong> Huazhong University of Science and Technology, Guangxi Normal University, University of Shanghai for Science and Technology, Technische Universität Berlin</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.10177" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.10177</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper studies distributed linearly separable computation with arbitrary heterogeneous data assignment, where workers may hold different numbers of datasets. It proposes a universal computing scheme and a universal converse bound to characterize the tradeoff between computable dimension and communication cost. The scheme and bound coincide in some parameter regimes and are extended to fractional communication costs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260116] Fundamental Limits of Coded Polynomial Aggregation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [coded polynomial aggregation, polynomial coded computing, straggler-aware, exact recovery, interpolation]</li>
<li class=""><strong>authors:</strong> Xi Zhong, Jörg Kliewer, Mingyue Ji</li>
<li class=""><strong>institution:</strong> University of Florida, New Jersey Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.10028" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.10028</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a straggler-aware coded polynomial aggregation (CPA) framework for distributed computing, which directly recovers a weighted sum of polynomial evaluations without decoding each term individually. It establishes necessary and sufficient conditions for exact recovery, showing that CPA requires fewer worker responses than individual decoding, and provides explicit constructions that achieve the derived fundamental limit.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260116] Federated Unlearning in Edge Networks: A Survey of Fundamentals, Challenges, Practical Applications and Future Directions</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, federated unlearning, machine unlearning, communication cost, resource allocation, security, privacy, edge networks]</li>
<li class=""><strong>authors:</strong> Jer Shyuan Ng, Wathsara Daluwatta, Shehan Edirimannage, Charitha Elvitigala, Asitha Kottahachchi Kankanamge Don, Ibrahim Khalil, Heng Zhang, Dusit Niyato</li>
<li class=""><strong>institution:</strong> Nanyang Technological University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09978" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09978</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This survey paper introduces Federated Unlearning (FUL), a method for removing a client&#x27;s data influence from a trained federated learning model to comply with data deletion regulations. It reviews FUL frameworks addressing challenges like communication cost and security, and discusses applications in distributed networks. The paper concludes by highlighting open challenges and positioning FUL as key for building trustworthy, regulation-compliant federated systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260116] QFed: Parameter-Compact Quantum-Classical Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [quantum federated learning, variational quantum circuits, quantum neural network, parameter reduction, hybrid quantum-classical training]</li>
<li class=""><strong>authors:</strong> Samar Abdelghani, Soumaya Cherkaoui</li>
<li class=""><strong>institution:</strong> Polytechnique Montreal</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.09809" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.09809</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces QFed, a quantum-classical federated learning framework that uses a quantum neural network to generate parameters for a classical model, drastically reducing the number of trainable parameters. The method achieves a 77.6% parameter reduction in a VGG-like model on the FashionMNIST dataset while maintaining comparable accuracy, demonstrating the potential of quantum computing to enhance the efficiency of federated learning on edge devices.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260116] Chebyshev Accelerated Subspsace Eigensolver for Pseudo-hermitian Hamiltonians</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [numerical linear algebra], [Chebyshev filter, oblique Rayleigh-Ritz, pseudo-hermitian solver, Bethe-Salpeter equation, quadratic convergence, parallel matrix multiplication]</li>
<li class=""><strong>authors:</strong> Edoardo Di Napoli, Clément Richefort, Xinzhe Wu</li>
<li class=""><strong>institution:</strong> Jülich Supercomputing Centre, Forschungszentrum Jülich</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.10557" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.10557</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper extends the Chebyshev Accelerated Subspace iteration Eigensolver (ChASE) to compute eigenpairs for pseudo-hermitian Hamiltonians arising from the Bethe-Salpeter equation in materials science. It introduces an oblique Rayleigh-Ritz projection for quadratic convergence and a parallel implementation of the Chebyshev filter with reduced communication. The new solver achieves performance and convergence comparable to the original Hermitian version.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 18</strong></p>
<ul>
<li class="">[arXiv260116] OUTLINEFORGE: Hierarchical Reinforcement Learning with Explicit States for Scientific Writing <a href="https://arxiv.org/pdf/2601.09858" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] Urban Socio-Semantic Segmentation with Vision-Language Reasoning <a href="https://arxiv.org/pdf/2601.10477" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning <a href="https://arxiv.org/pdf/2601.10187" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] Eluder dimension: localise it! <a href="https://arxiv.org/pdf/2601.09825" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning <a href="https://arxiv.org/pdf/2601.10306" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis <a href="https://arxiv.org/pdf/2601.10143" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] Reinforcement Learning to Discover a NorthEast Monsoon Index for Monthly Rainfall Prediction in Thailand <a href="https://arxiv.org/pdf/2601.10181" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] Combinatorial Optimization Augmented Machine Learning <a href="https://arxiv.org/pdf/2601.10583" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] PRL: Process Reward Learning Improves LLMs&#x27; Reasoning Ability and Broadens the Reasoning Boundary <a href="https://arxiv.org/pdf/2601.10201" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] DecisionLLM: Large Language Models for Long Sequence Decision Exploration <a href="https://arxiv.org/pdf/2601.10148" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] Reinforcement Learning with Multi-Step Lookahead Information Via Adaptive Batching <a href="https://arxiv.org/pdf/2601.10418" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching <a href="https://arxiv.org/pdf/2601.10712" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents <a href="https://arxiv.org/pdf/2601.09770" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] SuS: Strategy-aware Surprise for Intrinsic Exploration <a href="https://arxiv.org/pdf/2601.10349" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] StatLLaMA: A multi-stage training framework for building a domain-optimized statistical language model <a href="https://arxiv.org/pdf/2601.09718" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization <a href="https://arxiv.org/pdf/2601.10029" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts <a href="https://arxiv.org/pdf/2601.10079" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] CS-GBA: A Critical Sample-based Gradient-guided Backdoor Attack for Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2601.10407" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 12</strong></p>
<ul>
<li class="">[arXiv260116] Development of Ontological Knowledge Bases by Leveraging Large Language Models <a href="https://arxiv.org/pdf/2601.10436" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] State of AI: An Empirical 100 Trillion Token Study with OpenRouter <a href="https://arxiv.org/pdf/2601.10088" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] Single-Stage Huffman Encoder for ML Compression <a href="https://arxiv.org/pdf/2601.10673" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] FaTRQ: Tiered Residual Quantization for LLM Vector Search in Far-Memory-Aware ANNS Systems <a href="https://arxiv.org/pdf/2601.09985" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] OctoBench: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding <a href="https://arxiv.org/pdf/2601.10343" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series <a href="https://arxiv.org/pdf/2601.09949" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging <a href="https://arxiv.org/pdf/2601.10154" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] Accelerated Regularized Wasserstein Proximal Sampling Algorithms <a href="https://arxiv.org/pdf/2601.09848" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] RAG-3DSG: Enhancing 3D Scene Graphs with Re-Shot Guided Retrieval-Augmented Generation <a href="https://arxiv.org/pdf/2601.10168" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement <a href="https://arxiv.org/pdf/2601.10373" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment <a href="https://arxiv.org/pdf/2601.09865" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260116] What Understanding Means in AI-Laden Astronomy <a href="https://arxiv.org/pdf/2601.10038" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2026-01-16T02:52:40.000Z" itemprop="dateModified">Jan 16, 2026</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20260105-20260111"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20260105-20260111</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2026-01-12" class="table-of-contents__link toc-highlight">2026-01-12</a></li><li><a href="#2026-01-13" class="table-of-contents__link toc-highlight">2026-01-13</a></li><li><a href="#2026-01-14" class="table-of-contents__link toc-highlight">2026-01-14</a></li><li><a href="#2026-01-15" class="table-of-contents__link toc-highlight">2026-01-15</a></li><li><a href="#2026-01-16" class="table-of-contents__link toc-highlight">2026-01-16</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>