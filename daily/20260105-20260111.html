<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20260105-20260111" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20260105-20260111 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20260105-20260111"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20260105-20260111 | DarkKnight Note"><meta data-rh="true" name="description" content="2026-01-05"><meta data-rh="true" property="og:description" content="2026-01-05"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20260105-20260111"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260105-20260111" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260105-20260111" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20260105-20260111","item":"https://darkknight996.github.io/daily/20260105-20260111"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.b93aa66f.js" defer="defer"></script>
<script src="/assets/js/main.b9b584ee.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20260105-20260111"><span title="20260105-20260111" class="linkLabel_WmDU">20260105-20260111</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260112-20260118"><span title="20260112-20260118" class="linkLabel_WmDU">20260112-20260118</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260119-20260125"><span title="20260119-20260125" class="linkLabel_WmDU">20260119-20260125</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20260105-20260111</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20260105-20260111</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-05">2026-01-05<a href="#2026-01-05" class="hash-link" aria-label="Direct link to 2026-01-05" title="Direct link to 2026-01-05" translate="no">​</a></h2>
<p><strong>cs.DC total: 9</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260105] From Consensus to Chaos: A Vulnerability Assessment of the RAFT Algorithm</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed consensus], [RAFT, message replay attacks, message forgery, cryptography, authenticated message verification, freshness check]</li>
<li class=""><strong>authors:</strong> Tamer Afifi, Abdelfatah Hegazy, Ehab Abousaif</li>
<li class=""><strong>institution:</strong> Arab Academy for Science, Technology &amp; Maritime</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00273" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00273</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper conducts a security analysis of the RAFT distributed consensus algorithm, identifying vulnerabilities to replay and forgery attacks. It proposes a novel security enhancement framework using cryptography, authenticated message verification, and freshness checks to protect against these threats and build more resilient systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Federated Customization of Large Models: Approaches, Experiments, and Insights</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [federated learning, prefix-tuning, fine-tuning, prompt engineering, knowledge distillation, retrieval-augmented generation]</li>
<li class=""><strong>authors:</strong> Yuchuan Ye, Ming Ding, Youjia Chen, Peng Cheng, Dusit Niyato</li>
<li class=""><strong>institution:</strong> Fuzhou University, CSIRO Data61, La Trobe University, Nanyang Technological University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00526" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00526</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper explores federated customization of large models, reviewing techniques like fine-tuning and prefix-tuning within a federated learning framework. It experimentally validates federated prefix-tuning, showing it achieves performance close to centralized approaches with competitive efficiency and robustness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Cost-Performance Analysis of Cloud-Based Retail Point-of-Sale Systems: A Comparative Study of Google Cloud Platform and Microsoft Azure</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud computing], [benchmarking, cost-performance analysis, scalability, response latency, throughput, API endpoints]</li>
<li class=""><strong>authors:</strong> Ravi Teja Pagidoju</li>
<li class=""><strong>institution:</strong> Campbellsville University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00530" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00530</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a systematic, code-driven benchmarking methodology to compare the performance and cost of deploying retail Point-of-Sale workloads on Google Cloud Platform and Microsoft Azure using free-tier resources. The main conclusion is that GCP offers 23.0% faster response times, while Azure demonstrates 71.9% higher cost efficiency for steady-state operations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Secure, Verifiable, and Scalable Multi-Client Data Sharing via Consensus-Based Privacy-Preserving Data Distribution</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [secure multi-party computation], [affine masking, consensus locking, step checksums, data checksums, IND-CPA security]</li>
<li class=""><strong>authors:</strong> Prajwal Panth, Sahaj Raj Malla</li>
<li class=""><strong>institution:</strong> KIIT University, Kathmandu University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00418" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00418</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes the Consensus-Based Privacy-Preserving Data Distribution (CPPDD) framework, which uses per-client affine masking and sequential consensus locking for secure multi-client data aggregation with verifiable integrity. It demonstrates linear scalability up to 500 clients, achieves 100% malicious deviation detection, and significantly reduces computational overhead compared to MPC and HE baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Impact of Clustering on the Observability and Controllability of Complex Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [network theory], [structured systems theory, Monte-Carlo simulations, clustering, scale-free networks, graph theory]</li>
<li class=""><strong>authors:</strong> Mohammadreza Doostmohammadian, Hamid R. Rabiee</li>
<li class=""><strong>institution:</strong> Semnan University, Sharif University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00221" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00221</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper uses structured systems theory and Monte-Carlo simulations to study how clustering affects the observability and controllability of scale-free networks. It concludes that densely clustered networks require fewer driver and observer nodes for control and observation, offering practical insights for optimizing network design in resource-constrained applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Word Frequency Counting Based on Serverless MapReduce</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [serverless computing, mapreduce, function as a service (faas), word frequency counting, optimization]</li>
<li class=""><strong>authors:</strong> Hanzhe Li, Bingchen Lin, Mengyuan Xu</li>
<li class=""><strong>institution:</strong> Xi’an Jiaotong University, Chongqing University of Education, Qilu Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00380" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00380</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using a serverless MapReduce model on a Function-as-a-Service platform to optimize word frequency counting tasks. It focuses on determining the optimal number of map and reduce functions to minimize execution time and improve efficiency. The experiments show that increasing the number of functions improves performance, providing a method to find optimized configurations for such tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [time-warp emulation, CUDA API interception, discrete-event simulation, virtual time coordination]</li>
<li class=""><strong>authors:</strong> Amey Agrawal, Mayank Yadav, Sukrit Kumar, Anirudha Agrawal, Garv Ghai, Souradeep Bera, Elton Pinto, Sirish Gambhira, Mohammad Adain, Kasra Sohrab, Chus Antonanzas, Alexey Tumanov</li>
<li class=""><strong>institution:</strong> Georgia Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00397" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00397</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents Revati, a GPU-free time-warp emulator for LLM serving that directly executes real serving system code by intercepting CUDA calls and performing virtual time jumps instead of running actual GPU kernels. It introduces a coordination protocol to synchronize these time jumps across distributed processes. The system achieves less than 5% prediction error and runs 5-17x faster than real GPU execution on frameworks like vLLM and SGLang.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] FlexSpec: Frozen Drafts Meet Evolving Targets in Edge-Cloud Collaborative LLM Speculative Decoding</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [speculative decoding, edge-cloud collaboration, shared-backbone architecture, channel-aware adaptive speculation]</li>
<li class=""><strong>authors:</strong> Yuchen Li, Rui Kong, Zhonghao Lyu, Qiyang Li, Xinran Chen, Hengyi Cai, Lingyong Yan, Shuaiqiang Wang, Jiashu Zhao, Guangxu Zhu, Linghe Kong, Guihai Chen, Haoyi Xiong, Dawei Yin</li>
<li class=""><strong>institution:</strong> Baidu Inc., Shanghai Jiao Tong University, KTH Royal Institute of Technology, Wilfrid Laurier University, Shenzhen Research Institute of Big Data</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00644" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00644</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FlexSpec, a framework for edge-cloud collaborative inference that uses a static, shared-backbone draft model at the edge to work with evolving target models in the cloud, eliminating the need for frequent model synchronization. It also introduces a channel-aware mechanism to dynamically adjust the draft length based on network conditions. Experiments show that FlexSpec improves inference efficiency over conventional speculative decoding approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [multi-agent systems, language model agents, bio-inspired self-healing, distributed computing continuum, fault diagnosis, resource reconfiguration]</li>
<li class=""><strong>authors:</strong> Alaa Saleh, Praveen Kumar Donta, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Qiyang Zhang, Schahram Dustdar Susanna Pirttikangas, Lauri Lovén</li>
<li class=""><strong>institution:</strong> University of Oulu, Stockholm University, EURECOM, University of Helsinki, RISE Research Institutes of Sweden, Luleå University of Technology, Peking University, TU Wien</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00339" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00339</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces ReCiSt, a bio-inspired self-healing framework for resilient distributed computing systems. It uses language model-powered agents across four computational layers to autonomously isolate faults, diagnose causes, and reconfigure resources. The evaluation demonstrates the framework&#x27;s ability to perform self-healing within tens of seconds with low CPU overhead.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 15</strong></p>
<ul>
<li class="">[arXiv260105] Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings <a href="https://arxiv.org/pdf/2601.00186" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Online Finetuning Decision Transformers with Pure RL Gradients <a href="https://arxiv.org/pdf/2601.00167" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Can Optimal Transport Improve Federated Inverse Reinforcement Learning? <a href="https://arxiv.org/pdf/2601.00309" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty <a href="https://arxiv.org/pdf/2601.00737" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Reinforcement Learning with Function Approximation for Non-Markov Processes <a href="https://arxiv.org/pdf/2601.00151" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning <a href="https://arxiv.org/pdf/2601.00607" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing <a href="https://arxiv.org/pdf/2601.00245" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks <a href="https://arxiv.org/pdf/2601.00538" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments <a href="https://arxiv.org/pdf/2601.00116" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models <a href="https://arxiv.org/pdf/2601.00423" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning <a href="https://arxiv.org/pdf/2601.00677" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective <a href="https://arxiv.org/pdf/2601.00257" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Reinforcement learning with timed constraints for robotics motion planning <a href="https://arxiv.org/pdf/2601.00087" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL <a href="https://arxiv.org/pdf/2601.00728" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] ARISE: Adaptive Reinforcement Integrated with Swarm Exploration <a href="https://arxiv.org/pdf/2601.00693" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 1</strong></p>
<ul>
<li class="">[arXiv260105] Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations <a href="https://arxiv.org/pdf/2601.00282" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-06">2026-01-06<a href="#2026-01-06" class="hash-link" aria-label="Direct link to 2026-01-06" title="Direct link to 2026-01-06" translate="no">​</a></h2>
<p><strong>cs.DC total: 19</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260106] pMSz: A Distributed Parallel Algorithm for Correcting Extrema and Morse Smale Segmentations in Lossy Compression</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing], [distributed parallel algorithm, Morse-Smale segmentation, lossy compression, integral paths, steepest ascending directions, GPU]</li>
<li class=""><strong>authors:</strong> Yuxiao Li, Mingze Xia, Xin Liang, Bei Wang, Robert Underwood, Sheng Di, Hemant Sharma, Dishant Beniwal, Franck Cappello, Hanqi Guo</li>
<li class=""><strong>institution:</strong> The Ohio State University, Argonne National Laboratory, Oregon State University, University of Utah</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01787" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01787</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces pMSz, a distributed parallel algorithm that corrects topological distortions in lossy-compressed scientific data by preserving steepest ascending and descending directions instead of explicitly computing integral paths. This approach minimizes communication and achieves high parallel efficiency, scaling effectively to 128 GPUs on the Perlmutter supercomputer.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [Singleton Weight Sharing, Topological Synapse, KV-cache sparsification, witness complex, hybrid landmarking, Referential Injection]</li>
<li class=""><strong>authors:</strong> Jorge L. Ruiz Williams</li>
<li class=""><strong>institution:</strong> Warp Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01298" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01298</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Warp Cortex, an asynchronous architecture for multi-agent LLMs that decouples agent logic from memory to enable massive scaling. Its core methods include Singleton Weight Sharing and a Topological Synapse for KV-cache sparsification, reducing memory complexity. The authors demonstrate the system can support 100 concurrent agents on a single consumer GPU, with a theoretical capacity for over 1,000 agents.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] RelayGR: Scaling Long-Sequence Generative Recommendation via Cross-Stage Relay-Race Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [KV cache, cross-stage relay-race inference, sequence-aware trigger, affinity-aware router, memory-aware expander]</li>
<li class=""><strong>authors:</strong> Jiarui Wang, Huichao Chai, Yuanhang Zhang, Zongjin Zhou, Wei Guo, Xingkun Yang, Qiang Tang, Bo Pan, Jiawei Zhu, Ke Cheng, Yuting Yan, Shulan Wang, Yingjie Zhu, Zhengfan Yuan, Jiaqi Huang, Yuhan Zhang, Xiaosong Sun, Zhinan Zhang, Hong Zhu, Yongsheng Zhang, Tiantian Dong, Zhong Xiao, Deliang Liu, Chengzhou Lu, Yuan Sun, Zhiyuan Chen, Xinming Han, Zaizhu Liu, Yaoyuan Wang, Ziyang Zhang, Yong Liu, Jinxin Xu, Yajing Sun, Zhoujun Yu, Wenting Zhou, Qidong Zhang, Zhengyong Zhang, Zhonghai Gu, Yibo Jin, Yongxiang Feng, Pengfei Zuo</li>
<li class=""><strong>institution:</strong> Huawei Technologies Co., Ltd.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01712" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01712</a></li>
<li class=""><strong>Simple LLM Summary:</strong> RelayGR is a production system that scales long-sequence generative recommendation by pre-inferring and caching user-behavior prefixes in HBM across pipeline stages, enabling reuse during ranking. It uses a sequence-aware trigger, affinity-aware router, and memory-aware expander to manage cache footprint and locality. The system allows for longer sequences and significantly improves throughput while meeting strict latency SLOs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] A Multi-Port Concurrent Communication Model for handling Compute Intensive Tasks on Distributed Satellite System Constellations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed satellite systems], [divisible load theory, multi-port concurrent communication, admission control, inter-satellite links, load allocation]</li>
<li class=""><strong>authors:</strong> Bharadwaj Veeravalli</li>
<li class=""><strong>institution:</strong> National University of Singapore</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01031" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01031</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper develops a Multi-Port Concurrent Communication Divisible Load Theory (MPCC-DLT) framework for scheduling compute-intensive tasks across distributed satellite constellations. It provides closed-form solutions for optimal load distribution and analyzes the trade-offs between computation and communication overhead. The main conclusion is that while highly distributable tasks benefit significantly, communication-heavy tasks show diminishing returns, and the extended framework with admission control enables practical, deadline-aware operation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] DiT-HC: Enabling Efficient Training of Visual Generation Model DiT on HPC-oriented CPU Cluster</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion training], [communication-free tensor parallelism, AutoMem, HCOps, custom MPI backend, vector and matrix acceleration units]</li>
<li class=""><strong>authors:</strong> Jinxiao Zhang, Yunpu Xu, Xiyong Wu, Runmin Dong, Shenggan Cheng, Yi Zhao, Mengxuan Chen, Qinrui Zheng, Jianting Liu, Haohuan Fu</li>
<li class=""><strong>institution:</strong> Tsinghua University, Sun Yat-sen University, National University of Singapore, National Supercomputing Center in Shenzhen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01500" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01500</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DiT-HC introduces a system for training the DiT generative model on HPC CPU clusters using techniques like communication-free tensor parallelism, optimized kernels, and a custom MPI backend. It achieves significant speedups and high weak scaling efficiency, demonstrating the feasibility of large-scale generative model training on CPU-based supercomputers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Performance and Security Aware Distributed Service Placement in Fog Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [deep reinforcement learning, long short-term memory networks, prioritized experience replay, off-policy correction, multi-objective optimization, security score hierarchy]</li>
<li class=""><strong>authors:</strong> Mohammad Goudarzi, Arash Shaghaghi, Zhiyu Wang, Rajkumar Buyya</li>
<li class=""><strong>institution:</strong> Monash University, The University of New South Wales</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01125" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01125</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Security and Performance-Aware Distributed Deep Reinforcement Learning (SPA-DDRL) framework for service placement in Fog computing, which jointly optimizes latency and security using a distributed broker-learner architecture. The method integrates LSTM networks, Prioritized Experience Replay, and off-policy correction. Experiments show it improves service response time by 16.3% and converges 33% faster than baseline approaches while maintaining security compliance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Communication-Efficient Federated AUC Maximization with Cyclic Client Participation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, AUC maximization, cyclic client participation, minimax optimization, Polyak-Łojasiewicz condition, communication complexity]</li>
<li class=""><strong>authors:</strong> Umesh Vangapally, Wenhan Wu, Chen Chen, Zhishuai Guo</li>
<li class=""><strong>institution:</strong> Northern Illinois University, University of North Carolina at Charlotte, University of Central Florida</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01649" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01649</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes communication-efficient algorithms for federated AUC maximization under cyclic client participation, addressing the challenge of partial client availability in real-world federated learning. It analyzes two settings: one with a squared surrogate loss and one with general pairwise losses, establishing improved communication and iteration complexities, especially under the Polyak-Łojasiewicz condition. Experiments on tasks like image classification and fraud detection demonstrate the methods&#x27; superior efficiency and effectiveness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] FFCz: Fast Fourier Correction for Spectrum-Preserving Lossy Compression of Scientific Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [scientific data compression], [fast Fourier correction, error-bounded lossy compression, GPU parallelism, SZ3, ZFP, SPERR]</li>
<li class=""><strong>authors:</strong> Congrong Ren, Robert Underwood, Sheng Di, Emrecan Kutay, Zarija Lukic, Aylin Yener, Franck Cappello, Hanqi Guo</li>
<li class=""><strong>institution:</strong> The Ohio State University, Argonne National Laboratory, Lawrence Berkeley National Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01596" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01596</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces FFCz, a fast Fourier correction algorithm that modifies the error from existing lossy compressors to preserve both spatial and frequency-domain accuracy in scientific data. It achieves this by iteratively projecting the spatial error vector to satisfy user-defined bounds in both domains, accelerated by GPU parallelism. The method is validated on datasets from cosmology, combustion, and X-ray diffraction, effectively maintaining critical spectral features.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Making MoE based LLM inference resilient with Tarragon</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [mixture-of-experts, KV cache checkpointing, shadow experts, reconfigurable datapath, asynchronous recovery]</li>
<li class=""><strong>authors:</strong> Songyu Zhang, Aaron Tam, Myungjin Lee, Shixiong Qi, K. K. Ramakrishnan</li>
<li class=""><strong>institution:</strong> University of California, Riverside, Cisco Research, University of Kentucky</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01310" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01310</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents Tarragon, a resilient inference framework for Mixture-of-Experts LLMs. It confines failures to individual workers by using a reconfigurable datapath and self-healing mechanisms like incremental KV cache checkpointing and shadow experts. The evaluation shows it reduces failure-induced stalls by over 160x compared to prior systems while maintaining performance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] OrchestrRL: Dynamic Compute and Network Orchestration for Disaggregated RL</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [disaggregated RL, adaptive compute scheduler, reconfigurable hybrid optical-electrical fabric, RFabric, parallelism switching, RLSim]</li>
<li class=""><strong>authors:</strong> Xin Tan, Yicheng Feng, Yu Zhou, Yimin Jiang, Yibo Zhu, Hong Xu</li>
<li class=""><strong>institution:</strong> The Chinese University of Hong Kong, StepFun</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01209" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01209</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces OrchestrRL, a framework that dynamically orchestrates compute and network resources for disaggregated reinforcement learning. It co-designs an adaptive compute scheduler and a reconfigurable network fabric (RFabric) to address bottlenecks in generation and dynamic traffic patterns. The evaluation shows OrchestrRL improves throughput by up to 1.40x and RFabric offers better performance-cost efficiency than static networks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Cutting Quantum Circuits Beyond Qubits</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [quantum computing], [circuit cutting, qudit decomposition, Gell-Mann matrices, distributed quantum computing, memory reduction]</li>
<li class=""><strong>authors:</strong> Manav Seksaria, Anil Prabhakar</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology Madras</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02064" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02064</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper extends quantum circuit cutting to mixed-dimensional qudit registers by decomposing non-local interactions using tensor products of generalized Gell-Mann matrices. This enables simulation of high-dimensional circuits on disconnected hardware fragments, achieving exact state reconstruction and reducing memory usage significantly, as demonstrated in an 8-particle system.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, personalized federated learning, cosine sparsification, parameter packing, dual-weighted aggregation, sparse updates, Non-IID data]</li>
<li class=""><strong>authors:</strong> Qiantao Yang, Liquan Chen, Mingfu Xue, Songze Li</li>
<li class=""><strong>institution:</strong> Southeast University, Purple Mountain Laboratories, East China Normal University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01840" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01840</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FedCSPACK, a personalized federated learning method that uses cosine sparsification for parameter packing and a dual-weighted aggregation mechanism to reduce communication costs and mitigate data heterogeneity. It concludes that this approach effectively improves communication and computational efficiency while maintaining high model accuracy across heterogeneous datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Vouchsafe: A Zero-Infrastructure Capability Graph Model for Offline Identity and Trust</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [identity and trust systems], [Ed25519, SHA-256, JSON Web Tokens, Zero-Infrastructure Capability Graph, offline verification]</li>
<li class=""><strong>authors:</strong> Jay Kuri</li>
<li class=""><strong>institution:</strong> Ionzero Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02254" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02254</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Vouchsafe, a system that implements a Zero-Infrastructure Capability Graph model for offline identity and trust. It uses self-contained, signed statements with standard cryptographic primitives like Ed25519 and JWTs, enabling trust verification without any online infrastructure. The main conclusion is that a practical, offline-verifiable trust substrate can be built today using only locally available cryptographic data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Deciding Serializability in Network Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [formal verification], [Petri net reachability, semilinear-set compression, Presburger-formula manipulation, network-system abstraction]</li>
<li class=""><strong>authors:</strong> Guy Amir, Mark Barbone, Nicolas Amat, Jules Jacobs</li>
<li class=""><strong>institution:</strong> Cornell University, ONERA, Jane Street Capital</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02251" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02251</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents the SER modeling language and an automated decision procedure for verifying serializability in concurrent programs. The method compiles programs to a network-system abstraction and reduces the verification problem to a Petri net reachability query, using optimizations like slicing and semilinear-set compression. The authors conclude that their framework can successfully handle models of real-world systems like stateful firewalls and BGP routers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Benchmarking Quantum Data Center Architectures: A Performance and Scalability Perspective</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [quantum computing systems], [quantum data center, distributed quantum computing, entanglement generation, Bell State Measurement, teleportation, QFly, BCube, Clos, Fat-Tree]</li>
<li class=""><strong>authors:</strong> Shahrooz Pouryousef, Eneet Kaur, Hassan Shapourian, Don Towsley, Ramana Kompella, Reza Nejabati</li>
<li class=""><strong>institution:</strong> Cisco Research, University of Massachusetts Amherst</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01353" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01353</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper benchmarks four quantum data center architectures (QFly, BCube, Clos, Fat-Tree) by analyzing their performance under quantum-specific constraints like entanglement generation delays and resource contention. The study concludes that distributed quantum performance is shaped by a complex interaction of topology, scheduling policies, and physical-layer parameters.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] SuperSFL: Resource-Heterogeneous Federated Split Learning with Weight-Sharing Super-Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [federated split learning, weight-sharing super-network, three-phase gradient fusion, resource-aware subnetwork, gradient fusion]</li>
<li class=""><strong>authors:</strong> Abdullah Al Asif, Sixing Yu, Juan Pablo Munoz, Arya Mazaheri, Ali Jannesari</li>
<li class=""><strong>institution:</strong> Iowa State University, Intel Corporation, Technical University of Darmstadt</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02092" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02092</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes SuperSFL, a federated split learning framework that uses a weight-sharing super-network to generate client-specific subnetworks for heterogeneous edge devices and employs a Three-Phase Gradient Fusion mechanism for optimization. It demonstrates faster convergence, lower communication cost, and improved energy efficiency compared to baseline methods, making it a practical solution for heterogeneous edge environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Placement Semantics for Distributed Deep Learning: A Systematic Framework for Analyzing Parallelism Strategies</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [placement semantics, data parallelism, tensor parallelism, pipeline parallelism, ZeRO, FSDP, memory consumption, communication volume]</li>
<li class=""><strong>authors:</strong> Deep Pankajbhai Mehta</li>
<li class=""><strong>institution:</strong> Adobe Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02311" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02311</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a systematic framework called &quot;placement semantics&quot; to analyze distributed deep learning parallelism strategies by specifying how training states are placed across devices. From this specification alone, it can derive key performance metrics like memory use and communication cost, unifying strategies like ZeRO and pipeline parallelism. The main conclusion is that this framework provides a theoretical foundation to predict and compare strategy behavior without implementation details, matching published empirical results.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Bringing computation to the data: A MOEA-driven approach for optimising data processing in the context of the SKA and SRCNet</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [Multi-Objective Evolutionary Algorithms (MOEAs), Function-as-a-Service (FaaS), in-situ processing, distributed computing, data-intensive workflows]</li>
<li class=""><strong>authors:</strong> Manuel Parra-Royón, Álvaro Rodríguez-Gallardo, Susana Sánchez-Expósito, Laura Darriba-Pol, Jesús Sánchez-Castañeda, M. Ángeles Mendoza, Julián Garrido, Javier Moldón, Lourdes Verdes-Montenegro</li>
<li class=""><strong>institution:</strong> Instituto de Astrofísica de Andalucía, IAA-CSIC</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01980" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01980</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a framework that integrates Function-as-a-Service (FaaS) with a decision-making entity based on Multi-Objective Evolutionary Algorithms (MOEAs) to optimize data processing workflows for the SKA telescope. The approach moves computation closer to the data to overcome network bottlenecks, using MOEAs to find execution plans that balance time and energy costs. The conclusion is that this provides a baseline for efficient, cost-aware computation-to-data strategies within the SKA Regional Centres Network.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] BigSUMO: A Scalable Framework for Big Data Traffic Analytics and Parallel Simulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [parallel simulation, SUMO, loop detector data, probe trajectory data, descriptive analytics, prescriptive analytics, interruption detection]</li>
<li class=""><strong>authors:</strong> Rahul Sengupta, Nooshin Yousefzadeh, Manav Sanghvi, Yash Ranjan, Anand Rangarajan, Sanjay Ranka, Yashaswi Karnati, Jeremy Dilmore, Tushar Patel, Ryan Casburn</li>
<li class=""><strong>institution:</strong> University of Florida, NVIDIA Corp., FDOT</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02286" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02286</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents BigSUMO, a scalable open-source framework that ingests traffic data like loop detector and probe trajectories to perform descriptive analytics and interruption detection, then uses the SUMO microsimulator for parallel prescriptive simulations of &quot;what-if&quot; scenarios. The main conclusion is that this end-to-end, modular system provides a cost-effective and deployable tool for traffic management and optimization in smart cities.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 22</strong></p>
<ul>
<li class="">[arXiv260106] SmartFlow Reinforcement Learning and Agentic AI for Bike-Sharing Optimisation <a href="https://arxiv.org/pdf/2601.00868" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Horizon Reduction as Information Loss in Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2601.00831" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS <a href="https://arxiv.org/pdf/2601.01288" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines <a href="https://arxiv.org/pdf/2601.01785" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives <a href="https://arxiv.org/pdf/2601.01665" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement <a href="https://arxiv.org/pdf/2601.01562" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Dichotomous Diffusion Policy Optimization <a href="https://arxiv.org/pdf/2601.00898" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller <a href="https://arxiv.org/pdf/2601.01577" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving <a href="https://arxiv.org/pdf/2601.01800" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor <a href="https://arxiv.org/pdf/2601.01802" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Moments Matter<!-- -->:Stabilizing<!-- --> Policy Optimization using Return Distributions <a href="https://arxiv.org/pdf/2601.01803" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning <a href="https://arxiv.org/pdf/2601.01904" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Distorted Distributional Policy Evaluation for Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2601.01917" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] GDRO: Group-level Reward Post-training Suitable for Diffusion Models <a href="https://arxiv.org/pdf/2601.02036" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management <a href="https://arxiv.org/pdf/2601.02061" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] MDAgent2: Large Language Model for Code Generation and Knowledge Q&amp;A in Molecular Dynamics <a href="https://arxiv.org/pdf/2601.02075" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting <a href="https://arxiv.org/pdf/2601.02151" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] ACDZero: Graph-Embedding-Based Tree Search for Mastering Automated Cyber Defense <a href="https://arxiv.org/pdf/2601.02196" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents <a href="https://arxiv.org/pdf/2601.02201" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation <a href="https://arxiv.org/pdf/2601.02204" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation <a href="https://arxiv.org/pdf/2601.02256" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Reinforcement Learning for Option Hedging: Static Implied-Volatility Fit versus Shortfall-Aware Performance <a href="https://arxiv.org/pdf/2601.01709" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 17</strong></p>
<ul>
<li class="">[arXiv260106] RovoDev Code Reviewer: A Large-Scale Online Evaluation of LLM-based Code Review Automation at Atlassian <a href="https://arxiv.org/pdf/2601.01129" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] UltraEval-Audio: A Unified Framework for Comprehensive Evaluation of Audio Foundation Models <a href="https://arxiv.org/pdf/2601.01373" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Digital Twin-Driven Communication-Efficient Federated Anomaly Detection for Industrial IoT <a href="https://arxiv.org/pdf/2601.01701" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Accelerating Decentralized Optimization via Overlapping Local Steps <a href="https://arxiv.org/pdf/2601.01493" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Accelerated Full Waveform Inversion by Deep Compressed Learning <a href="https://arxiv.org/pdf/2601.01268" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation <a href="https://arxiv.org/pdf/2601.01513" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Efficient Cover Construction for Ball Mapper via Accelerated Range Queries <a href="https://arxiv.org/pdf/2601.01405" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Generating Diverse TSP Tours via a Combination of Graph Pointer Network and Dispersion <a href="https://arxiv.org/pdf/2601.01132" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Promptable Foundation Models for SAR Remote Sensing: Adapting the Segment Anything Model for Snow Avalanche Segmentation <a href="https://arxiv.org/pdf/2601.01213" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification <a href="https://arxiv.org/pdf/2601.01807" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Yukthi Opus: A Multi-Chain Hybrid Metaheuristic for Large-Scale NP-Hard Optimization <a href="https://arxiv.org/pdf/2601.01832" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations <a href="https://arxiv.org/pdf/2601.02071" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction <a href="https://arxiv.org/pdf/2601.02213" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission <a href="https://arxiv.org/pdf/2601.02253" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Physically-Constrained Autoencoder-Assisted Bayesian Optimization for Refinement of High-Dimensional Defect-Sensitive Single Crystalline Structure <a href="https://arxiv.org/pdf/2601.00855" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Learning Relationship between Quantum Walks and Underdamped Langevin Dynamics <a href="https://arxiv.org/pdf/2601.01589" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Predicting Early and Complete Drug Release from Long-Acting Injectables Using Explainable Machine Learning <a href="https://arxiv.org/pdf/2601.02265" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-07">2026-01-07<a href="#2026-01-07" class="hash-link" aria-label="Direct link to 2026-01-07" title="Direct link to 2026-01-07" translate="no">​</a></h2>
<p><strong>cs.DC total: 7</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260107] Proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024)</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wim Vanderbauwhede, Lauritz Thamsen, José Cano</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02898" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02898</a></li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260107] Exploring Blockchain Interoperability: Frameworks, Use Cases, and Future Challenges</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain interoperability], [blockchain, interoperability, cross-chain communication, layer-0, layer-1, layer-2, smart contracts, consensus algorithms]</li>
<li class=""><strong>authors:</strong> Stanly Wilson, Kwabena Adu-Duodu, Yinhao Li, Ellis Solaiman, Omer Rana, Rajiv Ranjan</li>
<li class=""><strong>institution:</strong> Newcastle University, Cardiff University, St Vincent Pallotti College of Engineering &amp; Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02949" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02949</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper explores frameworks and solutions for blockchain interoperability, discussing platforms that enable heterogeneous blockchains to connect and share information. It concludes that as applications become more complex, interoperable solutions are a necessity, but several challenges remain to be solved in this domain.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260107] Optimal Oblivious Load-Balancing for Sparse Traffic in Large-Scale Satellite Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [network routing], [oblivious load-balancing, torus network, linear programming, Valiant Load Balancing, worst-case load]</li>
<li class=""><strong>authors:</strong> Rudrapatna Vallabh Ramakanth, Eytan Modiano</li>
<li class=""><strong>institution:</strong> Massachusetts Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02537" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02537</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper formulates the problem of oblivious load-balancing for sparse traffic in a torus network as a linear program and constructs an optimal routing scheme. It shows that the Valiant Load Balancing scheme is suboptimal for sparse traffic and establishes a lower bound for any oblivious scheme, along with a performance gap compared to non-oblivious routing.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260107] Software-Defined Agentic Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [software-defined networking, dynamic communication, multi-agent pipelines, runtime state, batching, streaming, pipelining]</li>
<li class=""><strong>authors:</strong> Saurabh Agarwal, Marco Laju, Jayanth Srinivasa, Myungjin Lee, Aditya Akella</li>
<li class=""><strong>institution:</strong> University of Texas-Austin, Cisco-Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.03197" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.03197</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a new software-defined networking (SDN)-inspired framework for serving multi-agent LLM pipelines. It aims to make agent communication programmable and adaptive to runtime system state, enabling more efficient and responsive serving. The authors conclude that this architecture addresses the limitations of static serving strategies and paves the way for intent-driven agentic systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260107] First Provably Optimal Asynchronous SGD for Homogeneous and Heterogeneous Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [asynchronous SGD, staleness, heterogeneous workers, federated learning, gradient table, task allocation]</li>
<li class=""><strong>authors:</strong> Artavazd Maranjyan</li>
<li class=""><strong>institution:</strong> King Abdullah University of Science and Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02523" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02523</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This dissertation introduces new asynchronous SGD algorithms, Ringmaster ASGD and Ringleader ASGD, which use techniques like selective update discarding and structured gradient tables to handle staleness and heterogeneous data. It demonstrates that these methods can achieve optimal time complexity, matching synchronous guarantees, and proposes ATA for adaptive task allocation to improve resource efficiency. The work establishes asynchronous optimization as a theoretically sound and efficient foundation for distributed learning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260107] APoW: Auditable Proof-of-Work Against Block Withholding Attacks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain security], [proof-of-work, nonce space auditing, block withholding attack detection, hashcash, decentralized mining pools]</li>
<li class=""><strong>authors:</strong> Sergio Demian Lerner</li>
<li class=""><strong>institution:</strong> Fairgate Labs, Rootstock Labs</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02496" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02496</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces APoW, an auditable proof-of-work scheme that enables miners to probabilistically attest to having searched specific nonce space regions, allowing retroactive auditing of claimed work. This method facilitates the detection of block withholding attacks in mining pools without trusted hardware, thereby supporting the design of verifiable, decentralized pools. The construction maintains core PoW properties while adding an auditability layer, which can be deployed either via consensus changes or as a pool-level mechanism.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260107] Chronicals: A High-Performance Framework for LLM Fine-Tuning with 3.51x Speedup over Unsloth</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [fused triton kernels, cut cross-entropy, lora+, sequence packing, flashattention, online softmax]</li>
<li class=""><strong>authors:</strong> Arjun S. Nair</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02609" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02609</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Chronicals is a high-performance framework for LLM fine-tuning that integrates four key optimizations: fused Triton kernels, a memory-efficient Cut Cross-Entropy loss, LoRA+ with differential learning rates, and sequence packing. It achieves a 3.51x speedup over the Unsloth framework for full fine-tuning by dramatically reducing memory footprint and computational waste. The paper also critically notes that a competing benchmark showed zero gradient norms, indicating the model was not actually training.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 22</strong></p>
<ul>
<li class="">[arXiv260107] IBISAgent: Reinforcing Pixel-Level Visual Reasoning in MLLMs for Universal Biomedical Object Referring and Segmentation <a href="https://arxiv.org/pdf/2601.03054" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] WebGym: Scaling Training Environments for Visual Web Agents with Realistic Tasks <a href="https://arxiv.org/pdf/2601.02439" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Dementia-R1: Reinforced Pretraining and Reasoning from Unstructured Clinical Notes for Real-World Dementia Prognosis <a href="https://arxiv.org/pdf/2601.03018" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] One Sample to Rule Them All: Extreme Data Efficiency in RL Scaling <a href="https://arxiv.org/pdf/2601.03111" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] In-Context Reinforcement Learning through Bayesian Fusion of Context and Value Prior <a href="https://arxiv.org/pdf/2601.03015" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] SWaRL: Safeguard Code Watermarking via Reinforcement Learning <a href="https://arxiv.org/pdf/2601.02602" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Unified Thinker: A General Reasoning Modular Core for Image Generation <a href="https://arxiv.org/pdf/2601.03127" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Correct, Concise and Complete: Multi-stage Training For Adaptive Reasoning <a href="https://arxiv.org/pdf/2601.02972" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] UltraLogic: Enhancing LLM Reasoning through Large-Scale Data Synthesis and Bipolar Float Reward <a href="https://arxiv.org/pdf/2601.03205" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] MiMo-V2-Flash Technical Report <a href="https://arxiv.org/pdf/2601.02780" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] The World is Not Mono: Enabling Spatial Understanding in Large Audio-Language Models <a href="https://arxiv.org/pdf/2601.02954" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] LLM-Enhanced Reinforcement Learning for Time Series Anomaly Detection <a href="https://arxiv.org/pdf/2601.02511" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] SimRPD: Optimizing Recruitment Proactive Dialogue Agents through Simulator-Based Data Evaluation and Selection <a href="https://arxiv.org/pdf/2601.02871" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Textual Explanations and Their Evaluations for Reinforcement Learning Policy <a href="https://arxiv.org/pdf/2601.02514" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Sample-Efficient Neurosymbolic Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2601.02850" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] AI-Native Integrated Sensing and Communications for Self-Organizing Wireless Networks: Architectures, Learning Paradigms, and System-Level Design <a href="https://arxiv.org/pdf/2601.02398" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Effective Online 3D Bin Packing with Lookahead Parcels Using Monte Carlo Tree Search <a href="https://arxiv.org/pdf/2601.02649" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Closing the Reality Gap: Zero-Shot Sim-to-Real Deployment for Dexterous Force-Based Grasping and Manipulation <a href="https://arxiv.org/pdf/2601.02778" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Inferring Causal Graph Temporal Logic Formulas to Expedite Reinforcement Learning in Temporally Extended Tasks <a href="https://arxiv.org/pdf/2601.02666" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Time-Scaling Is What Agents Need Now <a href="https://arxiv.org/pdf/2601.02714" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] ChemBART: A Pre-trained BART Model Assisting Organic Chemistry Analysis <a href="https://arxiv.org/pdf/2601.02915" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Q-Regularized Generative Auto-Bidding: From Suboptimal Trajectories to Optimal Policies <a href="https://arxiv.org/pdf/2601.02754" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 7</strong></p>
<ul>
<li class="">[arXiv260107] Threat Detection in Social Media Networks Using Machine Learning Based Network Analysis <a href="https://arxiv.org/pdf/2601.02581" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] A large-scale nanocrystal database with aligned synthesis and properties enabling generative inverse design <a href="https://arxiv.org/pdf/2601.02424" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] PersonaLedger: Generating Realistic Financial Transactions with Persona Conditioned LLMs and Rule Grounded Feedback <a href="https://arxiv.org/pdf/2601.03149" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] RadioDiff-Flux: Efficient Radio Map Construction via Generative Denoise Diffusion Model Trajectory Midpoint Reuse <a href="https://arxiv.org/pdf/2601.02790" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Dynamic Hyperparameter Importance for Efficient Multi-Objective Optimization <a href="https://arxiv.org/pdf/2601.03166" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Sample-Efficient Neurosymbolic Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2601.02850" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] The Vibe-Check Protocol: Quantifying Cognitive Offloading in AI Programming <a href="https://arxiv.org/pdf/2601.02410" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-08">2026-01-08<a href="#2026-01-08" class="hash-link" aria-label="Direct link to 2026-01-08" title="Direct link to 2026-01-08" translate="no">​</a></h2>
<p><strong>cs.DC total: 6</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260108] Majorum: Ebb-and-Flow Consensus with Dynamic Quorums</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed consensus], [ebb-and-flow, dynamic availability, quorum-based protocol, TOB-SVD, finality, Byzantine fault tolerance]</li>
<li class=""><strong>authors:</strong> Francesco D&#x27;Amato, Roberto Saltini, Thanh-Hai Tran, Yann Vonlanthen, Luca Zanolini</li>
<li class=""><strong>institution:</strong> Ethereum Foundation</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.03862" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.03862</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents Majorum, a consensus protocol that combines a dynamically available quorum-based protocol (TOB-SVD) with a finality layer to achieve both liveness and strong safety. Under optimistic conditions, it achieves finality in as few as three slots with only one voting phase per slot, significantly improving optimistic finality time compared to existing systems like Ethereum.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260108] Failure-Resilient and Carbon-Efficient Deployment of Microservices over the Cloud-Edge Continuum</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud-edge computing], [microservices, deployment automation, failure resilience, carbon efficiency, workload rebalancing, service migration]</li>
<li class=""><strong>authors:</strong> Francisco Ponce, Simone Gazza, Andrea D&#x27;Iapico, Roberto Amadini, Antonio Brogi, Stefano Forti, Saverio Giallorenzo, Pierluigi Plebani, Davide Usai, Monica Vitali, Gianluigi Zavattaro, Jacopo Soldani</li>
<li class=""><strong>institution:</strong> University of Pisa, University of Bologna, Politecnico di Milano</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04123" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04123</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces the FREEDA toolchain, which automates the deployment of microservices across the Cloud-Edge Continuum by continuously adapting to changing conditions like resource availability and carbon intensity. It demonstrates that FREEDA can autonomously reconfigure deployments through service migration and workload rebalancing to achieve an optimal balance among failure resilience, performance, and reduced carbon emissions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260108] Hummingbird: SLO-Oriented GPU Preemption at Microsecond-scale</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [GPU preemption, temporal sharing, spatial sharing, SLO attainment, microsecond-scale scheduling]</li>
<li class=""><strong>authors:</strong> Tiancheng Hu, Chenxi Wang, Ting Cao, Jin Qin, Lei Chen, Xinyu Xiao, Junhao Hu, Hongliang Tian, Shoumeng Yan, Huimin Cui, Quan Chen, Tao Xie</li>
<li class=""><strong>institution:</strong> Peking University, University of Chinese Academy of Sciences, Tsinghua University, Huazhong University of Science and Technology, Ant Group, Shanghai Jiao Tong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04071" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04071</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents Hummingbird, a GPU scheduling system that enables microsecond-scale preemption on closed-source GPUs to harvest idle time slices. It significantly improves the SLO attainment of high-priority tasks while boosting the throughput of low-priority tasks, thereby enhancing GPU utilization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260108] A Scheduling Framework for Efficient MoE Inference on Edge GPU-NDP Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [tensor parallelism, load-balancing-aware scheduling, dataset-free pre-fetching, near-data processing (NDP), Mixture-of-Experts (MoE)]</li>
<li class=""><strong>authors:</strong> Qi Wu, Chao Fang, Jiayuan Chen, Ye Lin, Yueqi Zhang, Yichuan Bai, Yuan Du, Li Du</li>
<li class=""><strong>institution:</strong> Nanjing University, China Mobile Research Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.03992" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.03992</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a scheduling framework to accelerate Mixture-of-Experts (MoE) model inference on edge GPU systems with near-data processing (NDP) units. The core method employs tensor parallelism for experts, a load-balancing scheduler, and a dataset-free pre-fetching strategy to overcome memory and utilization challenges. The framework achieves up to 2.56x speedup in end-to-end latency compared to state-of-the-art approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260108] Revisiting Speculative Leaderless Protocols for Low-Latency BFT Replication</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems, fault tolerance], [leaderless BFT, speculative protocols, optimistic fast path, PBFT fallback, network delay estimation, clock synchronization]</li>
<li class=""><strong>authors:</strong> Daniel Qian, Xiyu Hao, Jinkun Geng, Yuncheng Yao, Aurojit Panda, Jinyang Li, Anirudh Sivaraman</li>
<li class=""><strong>institution:</strong> New York University, Stony Brook University, New York University Shanghai</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.03390" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.03390</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents Aspen, a leaderless Byzantine Fault Tolerant (BFT) protocol that uses a best-effort sequencing layer with synchronized clocks and network delay estimates to achieve low-latency consensus (2Δ+ε) even under contention. It requires extra replicas (n=3f+2p+1) to tolerate network delays and falls back to a PBFT-style protocol when optimistic conditions fail. Experiments show Aspen commits requests in under 75 ms, offering a 1.2–3.3× speedup over prior protocols while handling 19,000 requests per second.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260108] Local Gradient Regulation Stabilizes Federated Learning under Client Heterogeneity</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, client heterogeneity, gradient regulation, Exploratory–Convergent Gradient Re-aggregation (ECGR), swarm intelligence]</li>
<li class=""><strong>authors:</strong> Ping Luo, Jiahuan Wang, Ziqing Wen, Tao Sun, Dongsheng Li</li>
<li class=""><strong>institution:</strong> National University of Defense Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.03584" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.03584</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a client-side method called Exploratory–Convergent Gradient Re-aggregation (ECGR) to stabilize federated learning by regulating local gradient dynamics under heterogeneous data distributions. It concludes that this regulation of local gradients effectively suppresses destabilizing drift and consistently improves the stability and convergence of federated learning across various state-of-the-art methods.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 27</strong></p>
<ul>
<li class="">[arXiv260108] Aligning Findings with Diagnosis: A Self-Consistent Reinforcement Learning Framework for Trustworthy Radiology Reporting <a href="https://arxiv.org/pdf/2601.03321" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models <a href="https://arxiv.org/pdf/2601.03555" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] O-Researcher: An Open Ended Deep Research Model via Multi-Agent Distillation and Agentic RL <a href="https://arxiv.org/pdf/2601.03743" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] NeoAMT: Neologism-Aware Agentic Machine Translation with Reinforcement Learning <a href="https://arxiv.org/pdf/2601.03790" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models <a href="https://arxiv.org/pdf/2601.03969" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training <a href="https://arxiv.org/pdf/2601.04126" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Agentic Rubrics as Contextual Verifiers for SWE Agents <a href="https://arxiv.org/pdf/2601.04171" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Shielded RecRL: Explanation Generation for Recommender Systems without Ranking Degradation <a href="https://arxiv.org/pdf/2601.03608" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] R<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>L: Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification <a href="https://arxiv.org/pdf/2601.03715" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] From Brute Force to Semantic Insight: Performance-Guided Data Transformation Design with LLMs <a href="https://arxiv.org/pdf/2601.03808" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] AMIR-GRPO: Inducing Implicit Preference Signals into GRPO <a href="https://arxiv.org/pdf/2601.03661" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] ETR: Outcome-Guided Elastic Trust Regions for Policy Optimization <a href="https://arxiv.org/pdf/2601.03723" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Sensor to Pixels: Decentralized Swarm Gathering via Image-Based Reinforcement Learning <a href="https://arxiv.org/pdf/2601.03413" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition <a href="https://arxiv.org/pdf/2601.03822" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Sandwich Reasoning: An Answer-Reasoning-Answer Approach for Low-Latency Query Correction <a href="https://arxiv.org/pdf/2601.03672" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Exploration Through Introspection: A Self-Aware Reward Model <a href="https://arxiv.org/pdf/2601.03389" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Cells on Autopilot: Adaptive Cell (Re)Selection via Reinforcement Learning <a href="https://arxiv.org/pdf/2601.04083" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] TreeAdv: Tree-Structured Advantage Redistribution for Group-Based RL <a href="https://arxiv.org/pdf/2601.03703" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Mastering the Game of Go with Self-play Experience Replay <a href="https://arxiv.org/pdf/2601.03306" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Ratio-Variance Regularized Policy Optimization for Efficient LLM Fine-tuning <a href="https://arxiv.org/pdf/2601.03320" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] PC2P: Multi-Agent Path Finding via Personalized-Enhanced Communication and Crowd Perception <a href="https://arxiv.org/pdf/2601.03301" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] IndexTTS 2.5 Technical Report <a href="https://arxiv.org/pdf/2601.03888" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Adaptive-Boundary-Clipping GRPO: Ensuring Bounded Ratios for Stable and Generalizable Training <a href="https://arxiv.org/pdf/2601.03895" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification <a href="https://arxiv.org/pdf/2601.03948" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Interleaved Tool-Call Reasoning for Protein Function Understanding <a href="https://arxiv.org/pdf/2601.03604" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] VeRPO: Verifiable Dense Reward Policy Optimization for Code Generation <a href="https://arxiv.org/pdf/2601.03525" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] EDCO: Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning <a href="https://arxiv.org/pdf/2601.03725" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 9</strong></p>
<ul>
<li class="">[arXiv260108] Bare-Metal Tensor Virtualization: Overcoming the Memory Wall in Edge-AI Inference on ARM64 <a href="https://arxiv.org/pdf/2601.03324" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Weather-Aware Transformer for Real-Time Route Optimization in Drone-as-a-Service Operations <a href="https://arxiv.org/pdf/2601.03376" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Unsupervised Modular Adaptive Region Growing and RegionMix Classification for Wind Turbine Segmentation <a href="https://arxiv.org/pdf/2601.04065" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] ETR: Outcome-Guided Elastic Trust Regions for Policy Optimization <a href="https://arxiv.org/pdf/2601.03723" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] MetagenBERT: a Transformer-based Architecture using Foundational genomic Large Language Models for novel Metagenome Representation <a href="https://arxiv.org/pdf/2601.03295" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Provable Acceleration of Distributed Optimization with Local Updates <a href="https://arxiv.org/pdf/2601.03442" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] Learning from Limited Labels: Transductive Graph Label Propagation for Indian Music Analysis <a href="https://arxiv.org/pdf/2601.03626" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] CageDroneRF: A Large-Scale RF Benchmark and Toolkit for Drone Perception <a href="https://arxiv.org/pdf/2601.03302" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260108] A Reinforcement Learning-Based Model for Mapping and Goal-Directed Navigation Using Multiscale Place Fields <a href="https://arxiv.org/pdf/2601.03520" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-09">2026-01-09<a href="#2026-01-09" class="hash-link" aria-label="Direct link to 2026-01-09" title="Direct link to 2026-01-09" translate="no">​</a></h2>
<p><strong>cs.DC total: 12</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260109] Quantifying Autoscaler Vulnerabilities: An Empirical Study of Resource Misallocation Induced by Cloud Infrastructure Faults</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud computing], [autoscaling, fault injection, simulation, resource management, SLO]</li>
<li class=""><strong>authors:</strong> Gijun Park</li>
<li class=""><strong>institution:</strong> Okestro AI Research Center</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04659" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04659</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper uses controlled simulation experiments to measure how different cloud infrastructure faults affect vertical and horizontal autoscaling decisions. It finds that storage-related faults cause the highest cost overhead, while routing anomalies lead to systematic under-provisioning, and horizontal scaling is more sensitive to transient faults near scaling thresholds.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260109] Cognitive Infrastructure: A Unified DCIM Framework for AI Data Centers</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [knowledge graphs, digital twin, thermal modeling, unified device connectivity protocol, semantic reasoning, predictive analytics]</li>
<li class=""><strong>authors:</strong> Krishna Chaitanya Sunkara</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04750" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04750</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes DCIM 3.0, a unified framework for AI data center management that integrates semantic reasoning, predictive analytics, and autonomous orchestration using knowledge graphs and digital twins. The main conclusion is that this framework addresses critical challenges in automation, sustainability, and thermal management for next-generation GPU computing infrastructure.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260109] Proof of Commitment: A Human-Centric Resource for Permissionless Consensus</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [consensus protocols], [Proof of Commitment, Sybil resistance, Human Challenge Oracle, weighted-backbone analysis, partial synchrony]</li>
<li class=""><strong>authors:</strong> Homayoun Maleki, Nekane Sainz, Jon Legarda</li>
<li class=""><strong>institution:</strong> University of Deusto</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04813" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04813</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Proof of Commitment (PoCmt), a consensus primitive that uses real-time human engagement as a non-parallelizable resource to regulate leader election and provide Sybil resistance. It establishes that PoCmt enforces a linear Sybil cost, unlike Proof of Work or Proof of Stake, and achieves safety, liveness, and fairness under partial synchrony.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260109] Sharded Elimination and Combining for Highly-Efficient Concurrent Stacks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [concurrent data structures], [sharding, elimination, software combining, fetch&amp;increment, linearizability]</li>
<li class=""><strong>authors:</strong> Ajay Singh, Nikos Metaxakis, Panagiota Fatourou</li>
<li class=""><strong>institution:</strong> FORTH ICS, University of Waterloo, University of Crete</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04523" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04523</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents a new concurrent stack implementation that blends a novel elimination mechanism with a new software combining approach, using sharding and fetch&amp;increment to reduce contention. This design enhances parallelism and lowers access contention on the shared stack. Experiments show it outperforms existing concurrent stacks by up to 2x, especially in high-contention scenarios with many threads.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260109] Hybrid Cloud Architectures for Research Computing: Applications and Use Cases</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud computing], [hybrid cloud, federated computing, multi-cloud orchestration, workload scheduling, OpenPBS, SLURM, OpenStack, Kubernetes, Nextflow, Snakemake, CWL]</li>
<li class=""><strong>authors:</strong> Xaver Stiensmeier, Alexander Kanitz, Jan Krüger, Santiago Insua, Adrián Rošinec, Viktória Spišáková, Lukáš Hejtmánek, David Yuan, Gavin Farrell, Jonathan Tedds, Juha Törnroos, Harald Wagener, Alex Sczyrba, Nils Hoffmann, Matej Antol</li>
<li class=""><strong>institution:</strong> ELIXIR</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04349" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04349</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper explores hybrid cloud architectures as a solution for integrating fragmented research computing environments, using platforms like OpenStack and Kubernetes and workflow tools like Nextflow. It concludes by proposing a governance and technical roadmap, developed through the ELIXIR Compute Platform, to accelerate the sustainable adoption of hybrid clouds in scientific research.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260109] MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-queue pipelining, asynchronous gradient sharing, global neighbor sampling with caching, adaptive periodic synchronization, adaptive queue-sizing]</li>
<li class=""><strong>authors:</strong> Irfan Ullah, Young-Koo Lee</li>
<li class=""><strong>institution:</strong> Kyung Hee University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04707" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04707</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes MQ-GNN, a multi-queue pipelined framework that improves GNN training efficiency by overlapping mini-batch generation, data transfer, and computation stages. Its key innovations include an asynchronous gradient sharing mechanism with adaptive synchronization and global neighbor sampling with caching. Experiments show MQ-GNN achieves up to 4.6x faster training and 30% better GPU utilization while maintaining model accuracy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260109] Timeliness-Oriented Scheduling and Resource Allocation in Multi-Region Collaborative Perception</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Age of Information (AoI), Lyapunov optimization, scheduling algorithm, collaborative perception, resource allocation]</li>
<li class=""><strong>authors:</strong> Mengmeng Zhu, Yuxuan Sun, Yukuan Jia, Wei Chen, Bo Ai, Sheng Zhou</li>
<li class=""><strong>institution:</strong> Beijing Jiaotong University, Tsinghua University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04542" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04542</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Timeliness-Aware Multi-region Prioritized (TAMP) scheduling algorithm, a Lyapunov-based optimization policy, to manage communication and computational resources in multi-region collaborative perception by balancing information timeliness (via Age of Information) and communication volume. The algorithm is validated on real-world datasets, demonstrating significant improvements in perception accuracy over baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260109] Mechanism Design for Federated Learning with Non-Monotonic Network Effects</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [mechanism design, federated learning, network effects, social welfare maximization, incentive mechanism, model trading and sharing]</li>
<li class=""><strong>authors:</strong> Xiang Li, Bing Luo, Jianwei Huang, Yuan Luo</li>
<li class=""><strong>institution:</strong> The Chinese University of Hong Kong, Shenzhen; Duke Kunshan University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04648" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04648</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a Model Trading and Sharing (MoTS) framework and a Social Welfare maximization with Application-aware and Network effects (SWAN) mechanism for federated learning. It addresses non-monotonic network effects and application-specific model requirements by allowing clients to obtain models through participation or purchase. Experimental results show the SWAN mechanism significantly improves social welfare and reduces incentive costs compared to existing approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260109] ParaCodex: A Profiling-Guided Autonomous Coding Agent for Reliable Parallel Code Generation and Translation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [OpenMP GPU offload, autonomous coding agent, profiling-guided refinement, hotspot analysis, data planning, correctness gating]</li>
<li class=""><strong>authors:</strong> Erel Kaplan, Tomer Bitan, Lian Ghrayeb, Le Chen, Tom Yotam, Niranjan Hasabnis, Gal Oren</li>
<li class=""><strong>institution:</strong> Technion – Israel Institute of Technology, Argonne National Laboratory, Code Metal, Stanford University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04327" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04327</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ParaCodex is an autonomous LLM agent that transforms serial or CUDA code into optimized OpenMP GPU offload kernels using a staged workflow of hotspot analysis, data planning, and iterative refinement guided by compiler tests and profiling. It successfully translated 31 kernels, achieving significant speedups over reference implementations and outperforming a zero-shot baseline, demonstrating reliable parallel code generation through an artifact-driven, tool-verified approach.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260109] Parallel Quadratic Selected Inversion in Quantum Transport Simulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing], [selected inversion, recursive Green&#x27;s function, block-tridiagonal matrices, distributed algorithms, GPU acceleration]</li>
<li class=""><strong>authors:</strong> Vincent Maillou, Matthias Bollhofer, Olaf Schenk, Alexandros Nikolaos Ziogas, Mathieu Luisier</li>
<li class=""><strong>institution:</strong> ETH Zurich, TU Braunschweig, Università della Svizzera italiana</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04904" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04904</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces distributed parallel methods, building on the recursive Green&#x27;s function technique, for selected inversion and selected solution of quadratic matrix equations in quantum transport simulations. These methods handle block-tridiagonal matrices with arrowhead patterns, enabling the simulation of multi-terminal transistors. The proposed solver, when scaled to 16 GPUs, demonstrates a 5.2x speedup over a baseline sparse direct solver, highlighting its potential to accelerate large-scale nano-device simulations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260109] Nalar: An agent serving framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [agent-serving framework, workflow specification, managed state layer, two-level control architecture, futures, dependency metadata]</li>
<li class=""><strong>authors:</strong> Marco Laju, Donghyun Son, Saurabh Agarwal, Nitin Kedia, Myungjin Lee, Jayanth Srinivasa, Aditya Akella</li>
<li class=""><strong>institution:</strong> UT-Austin, Cisco-Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.05109" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.05109</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Nalar is a new framework designed to efficiently serve LLM-driven agentic applications by separating workflow specification from execution. It uses auto-generated stubs to turn invocations into futures with metadata and employs a managed state layer and a two-level control architecture for adaptive resource management. The paper concludes that Nalar significantly reduces latency, improves speed, and scales effectively compared to existing baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260109] Asynchronous Secure Federated Learning with Byzantine aggregators</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [federated averaging, secure aggregation, differential privacy, Byzantine aggregators, asynchronous communication, Gaussian noise, model masking, client verification, replicated servers]</li>
<li class=""><strong>authors:</strong> Antonella Del Pozzo, Achille Desreumaux, Mathieu Gestin, Alexandre Rapetti, Sara Tucci-Piergiovanni</li>
<li class=""><strong>institution:</strong> CEA List (based on author affiliations from arXiv)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.04930" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.04930</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a secure federated learning method that combines replicated aggregators, secure aggregation, and differential privacy to protect client data in asynchronous settings with malicious servers. It ensures training liveness and uniform client participation without relying on consensus. The approach maintains performance comparable to state-of-the-art while improving reliability and privacy in Byzantine environments.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 35</strong></p>
<ul>
<li class="">[arXiv260109] Not All Steps are Informative: On the Linearity of LLMs&#x27; RLVR Training <a href="https://arxiv.org/pdf/2601.04537" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Multiagent Reinforcement Learning with Neighbor Action Estimation <a href="https://arxiv.org/pdf/2601.04511" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] SCALER<!-- -->:Synthetic<!-- --> Scalable Adaptive Learning Environment for Reasoning <a href="https://arxiv.org/pdf/2601.04809" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead <a href="https://arxiv.org/pdf/2601.04686" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Enhanced-FQL(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">λ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span>), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay <a href="https://arxiv.org/pdf/2601.04392" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Learning Dynamics in RL Post-Training for Language Models <a href="https://arxiv.org/pdf/2601.04670" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Transformer-based Multi-agent Reinforcement Learning for Separation Assurance in Structured and Unstructured Airspaces <a href="https://arxiv.org/pdf/2601.04401" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] ResMAS: Resilience Optimization in LLM-based Multi-agent Systems <a href="https://arxiv.org/pdf/2601.04694" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] A Method for Constructing a Digital Transformation Driving Mechanism Based on Semantic Understanding of Large Models <a href="https://arxiv.org/pdf/2601.04696" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation <a href="https://arxiv.org/pdf/2601.04521" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Cross-Language Speaker Attribute Prediction Using MIL and RL <a href="https://arxiv.org/pdf/2601.04257" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Optimizing Path Planning using Deep Reinforcement Learning for UGVs in Precision Agriculture <a href="https://arxiv.org/pdf/2601.04668" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Making Tunable Parameters State-Dependent in Weather and Climate Models with Reinforcement Learning <a href="https://arxiv.org/pdf/2601.04268" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] ThinkDrive: Chain-of-Thought Guided Progressive Reinforcement Learning Fine-Tuning for Autonomous Driving <a href="https://arxiv.org/pdf/2601.04714" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] A Future Capabilities Agent for Tactical Air Traffic Control <a href="https://arxiv.org/pdf/2601.04285" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Improving and Accelerating Offline RL in Large Discrete Action Spaces with Structured Policy Initialization <a href="https://arxiv.org/pdf/2601.04441" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Rate or Fate? RLV<span class="katex-error" title="ParseError: KaTeX parse error: Expected group after &#x27;^&#x27; at position 1: ^̲" style="color:#cc0000">^</span>R: Reinforcement Learning with Verifiable Noisy Rewards <a href="https://arxiv.org/pdf/2601.04411" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] AT<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>PO: Agentic Turn-based Policy Optimization via Tree Search <a href="https://arxiv.org/pdf/2601.04767" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Online Action-Stacking Improves Reinforcement Learning Performance for Air Traffic Control <a href="https://arxiv.org/pdf/2601.04287" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Reasoning Over Space: Enabling Geographic Reasoning for LLM-Based Generative Next POI Recommendation <a href="https://arxiv.org/pdf/2601.04562" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] AgentOCR: Reimagining Agent History via Optical Self-Compression <a href="https://arxiv.org/pdf/2601.04786" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] TourPlanner: A Competitive Consensus Framework with Constraint-Gated Reinforcement Learning for Travel Planning <a href="https://arxiv.org/pdf/2601.04698" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Flexible Manufacturing Systems Intralogistics: Dynamic Optimization of AGVs and Tool Sharing Using Coloured-Timed Petri Nets and Actor-Critic RL with Actions Masking <a href="https://arxiv.org/pdf/2601.04887" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Thinking-Based Non-Thinking: Solving the Reward Hacking Problem in Training Hybrid Reasoning Models via Reinforcement Learning <a href="https://arxiv.org/pdf/2601.04805" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Survival Dynamics of Neural and Programmatic Policies in Evolutionary Reinforcement Learning <a href="https://arxiv.org/pdf/2601.04365" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following <a href="https://arxiv.org/pdf/2601.04954" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Text as a Universal Interface for Transferable Personalization <a href="https://arxiv.org/pdf/2601.04963" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] ConMax: Confidence-Maximizing Compression for Efficient Chain-of-Thought Reasoning <a href="https://arxiv.org/pdf/2601.04973" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] AlgBench: To What Extent Do Large Reasoning Models Understand Algorithms? <a href="https://arxiv.org/pdf/2601.04996" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] On the Hidden Objective Biases of Group-based Reinforcement Learning <a href="https://arxiv.org/pdf/2601.05002" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Hán Dān Xué Bù (Mimicry) or Qīng Chū Yú Lán (Mastery)? A Cognitive Perspective on Reasoning Distillation in Large Language Models <a href="https://arxiv.org/pdf/2601.05019" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Reinforced Efficient Reasoning via Semantically Diverse Exploration <a href="https://arxiv.org/pdf/2601.05053" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Safe Continual Reinforcement Learning Methods for Nonstationary Environments. Towards a Survey of the State of the Art <a href="https://arxiv.org/pdf/2601.05152" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI <a href="https://arxiv.org/pdf/2601.05205" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization <a href="https://arxiv.org/pdf/2601.05242" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 15</strong></p>
<ul>
<li class="">[arXiv260109] Learning Dynamics in RL Post-Training for Language Models <a href="https://arxiv.org/pdf/2601.04670" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Prior-Informed Zeroth-Order Optimization with Adaptive Direction Alignment for Memory-Efficient LLM Fine-Tuning <a href="https://arxiv.org/pdf/2601.04710" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models <a href="https://arxiv.org/pdf/2601.04719" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] GEnSHIN: Graphical Enhanced Spatio-temporal Hierarchical Inference Network for Traffic Flow Prediction <a href="https://arxiv.org/pdf/2601.04550" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] XGrammar 2: Dynamic and Efficient Structured Generation Engine for Agentic LLMs <a href="https://arxiv.org/pdf/2601.04426" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Sci-Reasoning: A Dataset Decoding AI Innovation Patterns <a href="https://arxiv.org/pdf/2601.04577" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] CRUNet-MR-Univ: A Foundation Model for Diverse Cardiac MRI Reconstruction <a href="https://arxiv.org/pdf/2601.04428" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Higher-Order Knowledge Representations for Agentic Scientific Reasoning <a href="https://arxiv.org/pdf/2601.04878" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] TeleTables: A Benchmark for Large Language Models in Telecom Table Interpretation <a href="https://arxiv.org/pdf/2601.04202" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] MPM-LLM4DSE: Reaching the Pareto Frontier in HLS with Multimodal Learning and LLM-Driven Exploration <a href="https://arxiv.org/pdf/2601.04801" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Integrating Multi-Agent Simulation, Behavioral Forensics, and Trust-Aware Machine Learning for Adaptive Insider Threat Detection <a href="https://arxiv.org/pdf/2601.04243" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Conversational AI for Rapid Scientific Prototyping: A Case Study on ESA&#x27;s ELOPE Competition <a href="https://arxiv.org/pdf/2601.04920" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Arabic Prompts with English Tools: A Benchmark <a href="https://arxiv.org/pdf/2601.05101" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] SimuAgent: An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning <a href="https://arxiv.org/pdf/2601.05187" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260109] Crystal Generation using the Fully Differentiable Pipeline and Latent Space Optimization <a href="https://arxiv.org/pdf/2601.04606" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2026-01-21T04:44:32.000Z" itemprop="dateModified">Jan 21, 2026</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20251229-20260104"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251229-20260104</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/daily/20260112-20260118"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">20260112-20260118</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2026-01-05" class="table-of-contents__link toc-highlight">2026-01-05</a></li><li><a href="#2026-01-06" class="table-of-contents__link toc-highlight">2026-01-06</a></li><li><a href="#2026-01-07" class="table-of-contents__link toc-highlight">2026-01-07</a></li><li><a href="#2026-01-08" class="table-of-contents__link toc-highlight">2026-01-08</a></li><li><a href="#2026-01-09" class="table-of-contents__link toc-highlight">2026-01-09</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>