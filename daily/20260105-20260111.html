<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20260105-20260111" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20260105-20260111 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20260105-20260111"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20260105-20260111 | DarkKnight Note"><meta data-rh="true" name="description" content="2026-01-05"><meta data-rh="true" property="og:description" content="2026-01-05"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20260105-20260111"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260105-20260111" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260105-20260111" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20260105-20260111","item":"https://darkknight996.github.io/daily/20260105-20260111"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.4a30eeda.js" defer="defer"></script>
<script src="/assets/js/main.4de0392a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20260105-20260111"><span title="20260105-20260111" class="linkLabel_WmDU">20260105-20260111</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20260105-20260111</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20260105-20260111</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-05">2026-01-05<a href="#2026-01-05" class="hash-link" aria-label="Direct link to 2026-01-05" title="Direct link to 2026-01-05" translate="no">​</a></h2>
<p><strong>cs.DC total: 9</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260105] From Consensus to Chaos: A Vulnerability Assessment of the RAFT Algorithm</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed consensus], [RAFT, message replay attacks, message forgery, cryptography, authenticated message verification, freshness check]</li>
<li class=""><strong>authors:</strong> Tamer Afifi, Abdelfatah Hegazy, Ehab Abousaif</li>
<li class=""><strong>institution:</strong> Arab Academy for Science, Technology &amp; Maritime</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00273" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00273</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper conducts a security analysis of the RAFT distributed consensus algorithm, identifying vulnerabilities to replay and forgery attacks. It proposes a novel security enhancement framework using cryptography, authenticated message verification, and freshness checks to protect against these threats and build more resilient systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Federated Customization of Large Models: Approaches, Experiments, and Insights</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [federated learning, prefix-tuning, fine-tuning, prompt engineering, knowledge distillation, retrieval-augmented generation]</li>
<li class=""><strong>authors:</strong> Yuchuan Ye, Ming Ding, Youjia Chen, Peng Cheng, Dusit Niyato</li>
<li class=""><strong>institution:</strong> Fuzhou University, CSIRO Data61, La Trobe University, Nanyang Technological University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00526" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00526</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper explores federated customization of large models, reviewing techniques like fine-tuning and prefix-tuning within a federated learning framework. It experimentally validates federated prefix-tuning, showing it achieves performance close to centralized approaches with competitive efficiency and robustness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Cost-Performance Analysis of Cloud-Based Retail Point-of-Sale Systems: A Comparative Study of Google Cloud Platform and Microsoft Azure</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud computing], [benchmarking, cost-performance analysis, scalability, response latency, throughput, API endpoints]</li>
<li class=""><strong>authors:</strong> Ravi Teja Pagidoju</li>
<li class=""><strong>institution:</strong> Campbellsville University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00530" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00530</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a systematic, code-driven benchmarking methodology to compare the performance and cost of deploying retail Point-of-Sale workloads on Google Cloud Platform and Microsoft Azure using free-tier resources. The main conclusion is that GCP offers 23.0% faster response times, while Azure demonstrates 71.9% higher cost efficiency for steady-state operations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Secure, Verifiable, and Scalable Multi-Client Data Sharing via Consensus-Based Privacy-Preserving Data Distribution</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [secure multi-party computation], [affine masking, consensus locking, step checksums, data checksums, IND-CPA security]</li>
<li class=""><strong>authors:</strong> Prajwal Panth, Sahaj Raj Malla</li>
<li class=""><strong>institution:</strong> KIIT University, Kathmandu University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00418" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00418</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes the Consensus-Based Privacy-Preserving Data Distribution (CPPDD) framework, which uses per-client affine masking and sequential consensus locking for secure multi-client data aggregation with verifiable integrity. It demonstrates linear scalability up to 500 clients, achieves 100% malicious deviation detection, and significantly reduces computational overhead compared to MPC and HE baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Impact of Clustering on the Observability and Controllability of Complex Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [network theory], [structured systems theory, Monte-Carlo simulations, clustering, scale-free networks, graph theory]</li>
<li class=""><strong>authors:</strong> Mohammadreza Doostmohammadian, Hamid R. Rabiee</li>
<li class=""><strong>institution:</strong> Semnan University, Sharif University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00221" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00221</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper uses structured systems theory and Monte-Carlo simulations to study how clustering affects the observability and controllability of scale-free networks. It concludes that densely clustered networks require fewer driver and observer nodes for control and observation, offering practical insights for optimizing network design in resource-constrained applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Word Frequency Counting Based on Serverless MapReduce</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [serverless computing, mapreduce, function as a service (faas), word frequency counting, optimization]</li>
<li class=""><strong>authors:</strong> Hanzhe Li, Bingchen Lin, Mengyuan Xu</li>
<li class=""><strong>institution:</strong> Xi’an Jiaotong University, Chongqing University of Education, Qilu Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00380" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00380</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using a serverless MapReduce model on a Function-as-a-Service platform to optimize word frequency counting tasks. It focuses on determining the optimal number of map and reduce functions to minimize execution time and improve efficiency. The experiments show that increasing the number of functions improves performance, providing a method to find optimized configurations for such tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [time-warp emulation, CUDA API interception, discrete-event simulation, virtual time coordination]</li>
<li class=""><strong>authors:</strong> Amey Agrawal, Mayank Yadav, Sukrit Kumar, Anirudha Agrawal, Garv Ghai, Souradeep Bera, Elton Pinto, Sirish Gambhira, Mohammad Adain, Kasra Sohrab, Chus Antonanzas, Alexey Tumanov</li>
<li class=""><strong>institution:</strong> Georgia Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00397" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00397</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents Revati, a GPU-free time-warp emulator for LLM serving that directly executes real serving system code by intercepting CUDA calls and performing virtual time jumps instead of running actual GPU kernels. It introduces a coordination protocol to synchronize these time jumps across distributed processes. The system achieves less than 5% prediction error and runs 5-17x faster than real GPU execution on frameworks like vLLM and SGLang.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] FlexSpec: Frozen Drafts Meet Evolving Targets in Edge-Cloud Collaborative LLM Speculative Decoding</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [speculative decoding, edge-cloud collaboration, shared-backbone architecture, channel-aware adaptive speculation]</li>
<li class=""><strong>authors:</strong> Yuchen Li, Rui Kong, Zhonghao Lyu, Qiyang Li, Xinran Chen, Hengyi Cai, Lingyong Yan, Shuaiqiang Wang, Jiashu Zhao, Guangxu Zhu, Linghe Kong, Guihai Chen, Haoyi Xiong, Dawei Yin</li>
<li class=""><strong>institution:</strong> Baidu Inc., Shanghai Jiao Tong University, KTH Royal Institute of Technology, Wilfrid Laurier University, Shenzhen Research Institute of Big Data</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00644" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00644</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FlexSpec, a framework for edge-cloud collaborative inference that uses a static, shared-backbone draft model at the edge to work with evolving target models in the cloud, eliminating the need for frequent model synchronization. It also introduces a channel-aware mechanism to dynamically adjust the draft length based on network conditions. Experiments show that FlexSpec improves inference efficiency over conventional speculative decoding approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [multi-agent systems, language model agents, bio-inspired self-healing, distributed computing continuum, fault diagnosis, resource reconfiguration]</li>
<li class=""><strong>authors:</strong> Alaa Saleh, Praveen Kumar Donta, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Qiyang Zhang, Schahram Dustdar Susanna Pirttikangas, Lauri Lovén</li>
<li class=""><strong>institution:</strong> University of Oulu, Stockholm University, EURECOM, University of Helsinki, RISE Research Institutes of Sweden, Luleå University of Technology, Peking University, TU Wien</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00339" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00339</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces ReCiSt, a bio-inspired self-healing framework for resilient distributed computing systems. It uses language model-powered agents across four computational layers to autonomously isolate faults, diagnose causes, and reconfigure resources. The evaluation demonstrates the framework&#x27;s ability to perform self-healing within tens of seconds with low CPU overhead.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 15</strong></p>
<ul>
<li class="">[arXiv260105] Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings <a href="https://arxiv.org/pdf/2601.00186" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Online Finetuning Decision Transformers with Pure RL Gradients <a href="https://arxiv.org/pdf/2601.00167" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Can Optimal Transport Improve Federated Inverse Reinforcement Learning? <a href="https://arxiv.org/pdf/2601.00309" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty <a href="https://arxiv.org/pdf/2601.00737" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Reinforcement Learning with Function Approximation for Non-Markov Processes <a href="https://arxiv.org/pdf/2601.00151" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning <a href="https://arxiv.org/pdf/2601.00607" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing <a href="https://arxiv.org/pdf/2601.00245" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks <a href="https://arxiv.org/pdf/2601.00538" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments <a href="https://arxiv.org/pdf/2601.00116" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models <a href="https://arxiv.org/pdf/2601.00423" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning <a href="https://arxiv.org/pdf/2601.00677" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective <a href="https://arxiv.org/pdf/2601.00257" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Reinforcement learning with timed constraints for robotics motion planning <a href="https://arxiv.org/pdf/2601.00087" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL <a href="https://arxiv.org/pdf/2601.00728" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260105] ARISE: Adaptive Reinforcement Integrated with Swarm Exploration <a href="https://arxiv.org/pdf/2601.00693" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 1</strong></p>
<ul>
<li class="">[arXiv260105] Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations <a href="https://arxiv.org/pdf/2601.00282" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-06">2026-01-06<a href="#2026-01-06" class="hash-link" aria-label="Direct link to 2026-01-06" title="Direct link to 2026-01-06" translate="no">​</a></h2>
<p><strong>cs.DC total: 19</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260106] pMSz: A Distributed Parallel Algorithm for Correcting Extrema and Morse Smale Segmentations in Lossy Compression</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing], [distributed parallel algorithm, Morse-Smale segmentation, lossy compression, integral paths, steepest ascending directions, GPU]</li>
<li class=""><strong>authors:</strong> Yuxiao Li, Mingze Xia, Xin Liang, Bei Wang, Robert Underwood, Sheng Di, Hemant Sharma, Dishant Beniwal, Franck Cappello, Hanqi Guo</li>
<li class=""><strong>institution:</strong> The Ohio State University, Argonne National Laboratory, Oregon State University, University of Utah</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01787" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01787</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces pMSz, a distributed parallel algorithm that corrects topological distortions in lossy-compressed scientific data by preserving steepest ascending and descending directions instead of explicitly computing integral paths. This approach minimizes communication and achieves high parallel efficiency, scaling effectively to 128 GPUs on the Perlmutter supercomputer.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [Singleton Weight Sharing, Topological Synapse, KV-cache sparsification, witness complex, hybrid landmarking, Referential Injection]</li>
<li class=""><strong>authors:</strong> Jorge L. Ruiz Williams</li>
<li class=""><strong>institution:</strong> Warp Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01298" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01298</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Warp Cortex, an asynchronous architecture for multi-agent LLMs that decouples agent logic from memory to enable massive scaling. Its core methods include Singleton Weight Sharing and a Topological Synapse for KV-cache sparsification, reducing memory complexity. The authors demonstrate the system can support 100 concurrent agents on a single consumer GPU, with a theoretical capacity for over 1,000 agents.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] RelayGR: Scaling Long-Sequence Generative Recommendation via Cross-Stage Relay-Race Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [KV cache, cross-stage relay-race inference, sequence-aware trigger, affinity-aware router, memory-aware expander]</li>
<li class=""><strong>authors:</strong> Jiarui Wang, Huichao Chai, Yuanhang Zhang, Zongjin Zhou, Wei Guo, Xingkun Yang, Qiang Tang, Bo Pan, Jiawei Zhu, Ke Cheng, Yuting Yan, Shulan Wang, Yingjie Zhu, Zhengfan Yuan, Jiaqi Huang, Yuhan Zhang, Xiaosong Sun, Zhinan Zhang, Hong Zhu, Yongsheng Zhang, Tiantian Dong, Zhong Xiao, Deliang Liu, Chengzhou Lu, Yuan Sun, Zhiyuan Chen, Xinming Han, Zaizhu Liu, Yaoyuan Wang, Ziyang Zhang, Yong Liu, Jinxin Xu, Yajing Sun, Zhoujun Yu, Wenting Zhou, Qidong Zhang, Zhengyong Zhang, Zhonghai Gu, Yibo Jin, Yongxiang Feng, Pengfei Zuo</li>
<li class=""><strong>institution:</strong> Huawei Technologies Co., Ltd.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01712" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01712</a></li>
<li class=""><strong>Simple LLM Summary:</strong> RelayGR is a production system that scales long-sequence generative recommendation by pre-inferring and caching user-behavior prefixes in HBM across pipeline stages, enabling reuse during ranking. It uses a sequence-aware trigger, affinity-aware router, and memory-aware expander to manage cache footprint and locality. The system allows for longer sequences and significantly improves throughput while meeting strict latency SLOs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] A Multi-Port Concurrent Communication Model for handling Compute Intensive Tasks on Distributed Satellite System Constellations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed satellite systems], [divisible load theory, multi-port concurrent communication, admission control, inter-satellite links, load allocation]</li>
<li class=""><strong>authors:</strong> Bharadwaj Veeravalli</li>
<li class=""><strong>institution:</strong> National University of Singapore</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01031" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01031</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper develops a Multi-Port Concurrent Communication Divisible Load Theory (MPCC-DLT) framework for scheduling compute-intensive tasks across distributed satellite constellations. It provides closed-form solutions for optimal load distribution and analyzes the trade-offs between computation and communication overhead. The main conclusion is that while highly distributable tasks benefit significantly, communication-heavy tasks show diminishing returns, and the extended framework with admission control enables practical, deadline-aware operation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] DiT-HC: Enabling Efficient Training of Visual Generation Model DiT on HPC-oriented CPU Cluster</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion training], [communication-free tensor parallelism, AutoMem, HCOps, custom MPI backend, vector and matrix acceleration units]</li>
<li class=""><strong>authors:</strong> Jinxiao Zhang, Yunpu Xu, Xiyong Wu, Runmin Dong, Shenggan Cheng, Yi Zhao, Mengxuan Chen, Qinrui Zheng, Jianting Liu, Haohuan Fu</li>
<li class=""><strong>institution:</strong> Tsinghua University, Sun Yat-sen University, National University of Singapore, National Supercomputing Center in Shenzhen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01500" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01500</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DiT-HC introduces a system for training the DiT generative model on HPC CPU clusters using techniques like communication-free tensor parallelism, optimized kernels, and a custom MPI backend. It achieves significant speedups and high weak scaling efficiency, demonstrating the feasibility of large-scale generative model training on CPU-based supercomputers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Performance and Security Aware Distributed Service Placement in Fog Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [deep reinforcement learning, long short-term memory networks, prioritized experience replay, off-policy correction, multi-objective optimization, security score hierarchy]</li>
<li class=""><strong>authors:</strong> Mohammad Goudarzi, Arash Shaghaghi, Zhiyu Wang, Rajkumar Buyya</li>
<li class=""><strong>institution:</strong> Monash University, The University of New South Wales</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01125" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01125</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Security and Performance-Aware Distributed Deep Reinforcement Learning (SPA-DDRL) framework for service placement in Fog computing, which jointly optimizes latency and security using a distributed broker-learner architecture. The method integrates LSTM networks, Prioritized Experience Replay, and off-policy correction. Experiments show it improves service response time by 16.3% and converges 33% faster than baseline approaches while maintaining security compliance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Communication-Efficient Federated AUC Maximization with Cyclic Client Participation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, AUC maximization, cyclic client participation, minimax optimization, Polyak-Łojasiewicz condition, communication complexity]</li>
<li class=""><strong>authors:</strong> Umesh Vangapally, Wenhan Wu, Chen Chen, Zhishuai Guo</li>
<li class=""><strong>institution:</strong> Northern Illinois University, University of North Carolina at Charlotte, University of Central Florida</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01649" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01649</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes communication-efficient algorithms for federated AUC maximization under cyclic client participation, addressing the challenge of partial client availability in real-world federated learning. It analyzes two settings: one with a squared surrogate loss and one with general pairwise losses, establishing improved communication and iteration complexities, especially under the Polyak-Łojasiewicz condition. Experiments on tasks like image classification and fraud detection demonstrate the methods&#x27; superior efficiency and effectiveness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] FFCz: Fast Fourier Correction for Spectrum-Preserving Lossy Compression of Scientific Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [scientific data compression], [fast Fourier correction, error-bounded lossy compression, GPU parallelism, SZ3, ZFP, SPERR]</li>
<li class=""><strong>authors:</strong> Congrong Ren, Robert Underwood, Sheng Di, Emrecan Kutay, Zarija Lukic, Aylin Yener, Franck Cappello, Hanqi Guo</li>
<li class=""><strong>institution:</strong> The Ohio State University, Argonne National Laboratory, Lawrence Berkeley National Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01596" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01596</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces FFCz, a fast Fourier correction algorithm that modifies the error from existing lossy compressors to preserve both spatial and frequency-domain accuracy in scientific data. It achieves this by iteratively projecting the spatial error vector to satisfy user-defined bounds in both domains, accelerated by GPU parallelism. The method is validated on datasets from cosmology, combustion, and X-ray diffraction, effectively maintaining critical spectral features.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Making MoE based LLM inference resilient with Tarragon</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [mixture-of-experts, KV cache checkpointing, shadow experts, reconfigurable datapath, asynchronous recovery]</li>
<li class=""><strong>authors:</strong> Songyu Zhang, Aaron Tam, Myungjin Lee, Shixiong Qi, K. K. Ramakrishnan</li>
<li class=""><strong>institution:</strong> University of California, Riverside, Cisco Research, University of Kentucky</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01310" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01310</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents Tarragon, a resilient inference framework for Mixture-of-Experts LLMs. It confines failures to individual workers by using a reconfigurable datapath and self-healing mechanisms like incremental KV cache checkpointing and shadow experts. The evaluation shows it reduces failure-induced stalls by over 160x compared to prior systems while maintaining performance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] OrchestrRL: Dynamic Compute and Network Orchestration for Disaggregated RL</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [disaggregated RL, adaptive compute scheduler, reconfigurable hybrid optical-electrical fabric, RFabric, parallelism switching, RLSim]</li>
<li class=""><strong>authors:</strong> Xin Tan, Yicheng Feng, Yu Zhou, Yimin Jiang, Yibo Zhu, Hong Xu</li>
<li class=""><strong>institution:</strong> The Chinese University of Hong Kong, StepFun</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01209" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01209</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces OrchestrRL, a framework that dynamically orchestrates compute and network resources for disaggregated reinforcement learning. It co-designs an adaptive compute scheduler and a reconfigurable network fabric (RFabric) to address bottlenecks in generation and dynamic traffic patterns. The evaluation shows OrchestrRL improves throughput by up to 1.40x and RFabric offers better performance-cost efficiency than static networks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Cutting Quantum Circuits Beyond Qubits</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [quantum computing], [circuit cutting, qudit decomposition, Gell-Mann matrices, distributed quantum computing, memory reduction]</li>
<li class=""><strong>authors:</strong> Manav Seksaria, Anil Prabhakar</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology Madras</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02064" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02064</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper extends quantum circuit cutting to mixed-dimensional qudit registers by decomposing non-local interactions using tensor products of generalized Gell-Mann matrices. This enables simulation of high-dimensional circuits on disconnected hardware fragments, achieving exact state reconstruction and reducing memory usage significantly, as demonstrated in an 8-particle system.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, personalized federated learning, cosine sparsification, parameter packing, dual-weighted aggregation, sparse updates, Non-IID data]</li>
<li class=""><strong>authors:</strong> Qiantao Yang, Liquan Chen, Mingfu Xue, Songze Li</li>
<li class=""><strong>institution:</strong> Southeast University, Purple Mountain Laboratories, East China Normal University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01840" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01840</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FedCSPACK, a personalized federated learning method that uses cosine sparsification for parameter packing and a dual-weighted aggregation mechanism to reduce communication costs and mitigate data heterogeneity. It concludes that this approach effectively improves communication and computational efficiency while maintaining high model accuracy across heterogeneous datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Vouchsafe: A Zero-Infrastructure Capability Graph Model for Offline Identity and Trust</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [identity and trust systems], [Ed25519, SHA-256, JSON Web Tokens, Zero-Infrastructure Capability Graph, offline verification]</li>
<li class=""><strong>authors:</strong> Jay Kuri</li>
<li class=""><strong>institution:</strong> Ionzero Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02254" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02254</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Vouchsafe, a system that implements a Zero-Infrastructure Capability Graph model for offline identity and trust. It uses self-contained, signed statements with standard cryptographic primitives like Ed25519 and JWTs, enabling trust verification without any online infrastructure. The main conclusion is that a practical, offline-verifiable trust substrate can be built today using only locally available cryptographic data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Deciding Serializability in Network Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [formal verification], [Petri net reachability, semilinear-set compression, Presburger-formula manipulation, network-system abstraction]</li>
<li class=""><strong>authors:</strong> Guy Amir, Mark Barbone, Nicolas Amat, Jules Jacobs</li>
<li class=""><strong>institution:</strong> Cornell University, ONERA, Jane Street Capital</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02251" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02251</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents the SER modeling language and an automated decision procedure for verifying serializability in concurrent programs. The method compiles programs to a network-system abstraction and reduces the verification problem to a Petri net reachability query, using optimizations like slicing and semilinear-set compression. The authors conclude that their framework can successfully handle models of real-world systems like stateful firewalls and BGP routers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Benchmarking Quantum Data Center Architectures: A Performance and Scalability Perspective</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [quantum computing systems], [quantum data center, distributed quantum computing, entanglement generation, Bell State Measurement, teleportation, QFly, BCube, Clos, Fat-Tree]</li>
<li class=""><strong>authors:</strong> Shahrooz Pouryousef, Eneet Kaur, Hassan Shapourian, Don Towsley, Ramana Kompella, Reza Nejabati</li>
<li class=""><strong>institution:</strong> Cisco Research, University of Massachusetts Amherst</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01353" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01353</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper benchmarks four quantum data center architectures (QFly, BCube, Clos, Fat-Tree) by analyzing their performance under quantum-specific constraints like entanglement generation delays and resource contention. The study concludes that distributed quantum performance is shaped by a complex interaction of topology, scheduling policies, and physical-layer parameters.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] SuperSFL: Resource-Heterogeneous Federated Split Learning with Weight-Sharing Super-Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [federated split learning, weight-sharing super-network, three-phase gradient fusion, resource-aware subnetwork, gradient fusion]</li>
<li class=""><strong>authors:</strong> Abdullah Al Asif, Sixing Yu, Juan Pablo Munoz, Arya Mazaheri, Ali Jannesari</li>
<li class=""><strong>institution:</strong> Iowa State University, Intel Corporation, Technical University of Darmstadt</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02092" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02092</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes SuperSFL, a federated split learning framework that uses a weight-sharing super-network to generate client-specific subnetworks for heterogeneous edge devices and employs a Three-Phase Gradient Fusion mechanism for optimization. It demonstrates faster convergence, lower communication cost, and improved energy efficiency compared to baseline methods, making it a practical solution for heterogeneous edge environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Placement Semantics for Distributed Deep Learning: A Systematic Framework for Analyzing Parallelism Strategies</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [placement semantics, data parallelism, tensor parallelism, pipeline parallelism, ZeRO, FSDP, memory consumption, communication volume]</li>
<li class=""><strong>authors:</strong> Deep Pankajbhai Mehta</li>
<li class=""><strong>institution:</strong> Adobe Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02311" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02311</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a systematic framework called &quot;placement semantics&quot; to analyze distributed deep learning parallelism strategies by specifying how training states are placed across devices. From this specification alone, it can derive key performance metrics like memory use and communication cost, unifying strategies like ZeRO and pipeline parallelism. The main conclusion is that this framework provides a theoretical foundation to predict and compare strategy behavior without implementation details, matching published empirical results.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] Bringing computation to the data: A MOEA-driven approach for optimising data processing in the context of the SKA and SRCNet</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [Multi-Objective Evolutionary Algorithms (MOEAs), Function-as-a-Service (FaaS), in-situ processing, distributed computing, data-intensive workflows]</li>
<li class=""><strong>authors:</strong> Manuel Parra-Royón, Álvaro Rodríguez-Gallardo, Susana Sánchez-Expósito, Laura Darriba-Pol, Jesús Sánchez-Castañeda, M. Ángeles Mendoza, Julián Garrido, Javier Moldón, Lourdes Verdes-Montenegro</li>
<li class=""><strong>institution:</strong> Instituto de Astrofísica de Andalucía, IAA-CSIC</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.01980" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.01980</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a framework that integrates Function-as-a-Service (FaaS) with a decision-making entity based on Multi-Objective Evolutionary Algorithms (MOEAs) to optimize data processing workflows for the SKA telescope. The approach moves computation closer to the data to overcome network bottlenecks, using MOEAs to find execution plans that balance time and energy costs. The conclusion is that this provides a baseline for efficient, cost-aware computation-to-data strategies within the SKA Regional Centres Network.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260106] BigSUMO: A Scalable Framework for Big Data Traffic Analytics and Parallel Simulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [parallel simulation, SUMO, loop detector data, probe trajectory data, descriptive analytics, prescriptive analytics, interruption detection]</li>
<li class=""><strong>authors:</strong> Rahul Sengupta, Nooshin Yousefzadeh, Manav Sanghvi, Yash Ranjan, Anand Rangarajan, Sanjay Ranka, Yashaswi Karnati, Jeremy Dilmore, Tushar Patel, Ryan Casburn</li>
<li class=""><strong>institution:</strong> University of Florida, NVIDIA Corp., FDOT</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02286" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02286</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents BigSUMO, a scalable open-source framework that ingests traffic data like loop detector and probe trajectories to perform descriptive analytics and interruption detection, then uses the SUMO microsimulator for parallel prescriptive simulations of &quot;what-if&quot; scenarios. The main conclusion is that this end-to-end, modular system provides a cost-effective and deployable tool for traffic management and optimization in smart cities.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 22</strong></p>
<ul>
<li class="">[arXiv260106] SmartFlow Reinforcement Learning and Agentic AI for Bike-Sharing Optimisation <a href="https://arxiv.org/pdf/2601.00868" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Horizon Reduction as Information Loss in Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2601.00831" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS <a href="https://arxiv.org/pdf/2601.01288" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines <a href="https://arxiv.org/pdf/2601.01785" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives <a href="https://arxiv.org/pdf/2601.01665" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement <a href="https://arxiv.org/pdf/2601.01562" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Dichotomous Diffusion Policy Optimization <a href="https://arxiv.org/pdf/2601.00898" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller <a href="https://arxiv.org/pdf/2601.01577" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving <a href="https://arxiv.org/pdf/2601.01800" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor <a href="https://arxiv.org/pdf/2601.01802" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Moments Matter<!-- -->:Stabilizing<!-- --> Policy Optimization using Return Distributions <a href="https://arxiv.org/pdf/2601.01803" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning <a href="https://arxiv.org/pdf/2601.01904" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Distorted Distributional Policy Evaluation for Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2601.01917" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] GDRO: Group-level Reward Post-training Suitable for Diffusion Models <a href="https://arxiv.org/pdf/2601.02036" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management <a href="https://arxiv.org/pdf/2601.02061" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] MDAgent2: Large Language Model for Code Generation and Knowledge Q&amp;A in Molecular Dynamics <a href="https://arxiv.org/pdf/2601.02075" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting <a href="https://arxiv.org/pdf/2601.02151" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] ACDZero: Graph-Embedding-Based Tree Search for Mastering Automated Cyber Defense <a href="https://arxiv.org/pdf/2601.02196" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents <a href="https://arxiv.org/pdf/2601.02201" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation <a href="https://arxiv.org/pdf/2601.02204" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation <a href="https://arxiv.org/pdf/2601.02256" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Reinforcement Learning for Option Hedging: Static Implied-Volatility Fit versus Shortfall-Aware Performance <a href="https://arxiv.org/pdf/2601.01709" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 17</strong></p>
<ul>
<li class="">[arXiv260106] RovoDev Code Reviewer: A Large-Scale Online Evaluation of LLM-based Code Review Automation at Atlassian <a href="https://arxiv.org/pdf/2601.01129" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] UltraEval-Audio: A Unified Framework for Comprehensive Evaluation of Audio Foundation Models <a href="https://arxiv.org/pdf/2601.01373" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Digital Twin-Driven Communication-Efficient Federated Anomaly Detection for Industrial IoT <a href="https://arxiv.org/pdf/2601.01701" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Accelerating Decentralized Optimization via Overlapping Local Steps <a href="https://arxiv.org/pdf/2601.01493" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Accelerated Full Waveform Inversion by Deep Compressed Learning <a href="https://arxiv.org/pdf/2601.01268" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation <a href="https://arxiv.org/pdf/2601.01513" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Efficient Cover Construction for Ball Mapper via Accelerated Range Queries <a href="https://arxiv.org/pdf/2601.01405" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Generating Diverse TSP Tours via a Combination of Graph Pointer Network and Dispersion <a href="https://arxiv.org/pdf/2601.01132" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Promptable Foundation Models for SAR Remote Sensing: Adapting the Segment Anything Model for Snow Avalanche Segmentation <a href="https://arxiv.org/pdf/2601.01213" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification <a href="https://arxiv.org/pdf/2601.01807" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Yukthi Opus: A Multi-Chain Hybrid Metaheuristic for Large-Scale NP-Hard Optimization <a href="https://arxiv.org/pdf/2601.01832" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations <a href="https://arxiv.org/pdf/2601.02071" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction <a href="https://arxiv.org/pdf/2601.02213" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission <a href="https://arxiv.org/pdf/2601.02253" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Physically-Constrained Autoencoder-Assisted Bayesian Optimization for Refinement of High-Dimensional Defect-Sensitive Single Crystalline Structure <a href="https://arxiv.org/pdf/2601.00855" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Learning Relationship between Quantum Walks and Underdamped Langevin Dynamics <a href="https://arxiv.org/pdf/2601.01589" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260106] Predicting Early and Complete Drug Release from Long-Acting Injectables Using Explainable Machine Learning <a href="https://arxiv.org/pdf/2601.02265" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-07">2026-01-07<a href="#2026-01-07" class="hash-link" aria-label="Direct link to 2026-01-07" title="Direct link to 2026-01-07" translate="no">​</a></h2>
<p><strong>cs.DC total: 7</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260107] Proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024)</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wim Vanderbauwhede, Lauritz Thamsen, José Cano</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02898" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02898</a></li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260107] Exploring Blockchain Interoperability: Frameworks, Use Cases, and Future Challenges</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain interoperability], [blockchain, interoperability, cross-chain communication, layer-0, layer-1, layer-2, smart contracts, consensus algorithms]</li>
<li class=""><strong>authors:</strong> Stanly Wilson, Kwabena Adu-Duodu, Yinhao Li, Ellis Solaiman, Omer Rana, Rajiv Ranjan</li>
<li class=""><strong>institution:</strong> Newcastle University, Cardiff University, St Vincent Pallotti College of Engineering &amp; Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02949" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02949</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper explores frameworks and solutions for blockchain interoperability, discussing platforms that enable heterogeneous blockchains to connect and share information. It concludes that as applications become more complex, interoperable solutions are a necessity, but several challenges remain to be solved in this domain.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260107] Optimal Oblivious Load-Balancing for Sparse Traffic in Large-Scale Satellite Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [network routing], [oblivious load-balancing, torus network, linear programming, Valiant Load Balancing, worst-case load]</li>
<li class=""><strong>authors:</strong> Rudrapatna Vallabh Ramakanth, Eytan Modiano</li>
<li class=""><strong>institution:</strong> Massachusetts Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02537" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02537</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper formulates the problem of oblivious load-balancing for sparse traffic in a torus network as a linear program and constructs an optimal routing scheme. It shows that the Valiant Load Balancing scheme is suboptimal for sparse traffic and establishes a lower bound for any oblivious scheme, along with a performance gap compared to non-oblivious routing.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260107] Software-Defined Agentic Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [software-defined networking, dynamic communication, multi-agent pipelines, runtime state, batching, streaming, pipelining]</li>
<li class=""><strong>authors:</strong> Saurabh Agarwal, Marco Laju, Jayanth Srinivasa, Myungjin Lee, Aditya Akella</li>
<li class=""><strong>institution:</strong> University of Texas-Austin, Cisco-Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.03197" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.03197</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a new software-defined networking (SDN)-inspired framework for serving multi-agent LLM pipelines. It aims to make agent communication programmable and adaptive to runtime system state, enabling more efficient and responsive serving. The authors conclude that this architecture addresses the limitations of static serving strategies and paves the way for intent-driven agentic systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260107] First Provably Optimal Asynchronous SGD for Homogeneous and Heterogeneous Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [asynchronous SGD, staleness, heterogeneous workers, federated learning, gradient table, task allocation]</li>
<li class=""><strong>authors:</strong> Artavazd Maranjyan</li>
<li class=""><strong>institution:</strong> King Abdullah University of Science and Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02523" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02523</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This dissertation introduces new asynchronous SGD algorithms, Ringmaster ASGD and Ringleader ASGD, which use techniques like selective update discarding and structured gradient tables to handle staleness and heterogeneous data. It demonstrates that these methods can achieve optimal time complexity, matching synchronous guarantees, and proposes ATA for adaptive task allocation to improve resource efficiency. The work establishes asynchronous optimization as a theoretically sound and efficient foundation for distributed learning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260107] APoW: Auditable Proof-of-Work Against Block Withholding Attacks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain security], [proof-of-work, nonce space auditing, block withholding attack detection, hashcash, decentralized mining pools]</li>
<li class=""><strong>authors:</strong> Sergio Demian Lerner</li>
<li class=""><strong>institution:</strong> Fairgate Labs, Rootstock Labs</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02496" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02496</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces APoW, an auditable proof-of-work scheme that enables miners to probabilistically attest to having searched specific nonce space regions, allowing retroactive auditing of claimed work. This method facilitates the detection of block withholding attacks in mining pools without trusted hardware, thereby supporting the design of verifiable, decentralized pools. The construction maintains core PoW properties while adding an auditability layer, which can be deployed either via consensus changes or as a pool-level mechanism.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260107] Chronicals: A High-Performance Framework for LLM Fine-Tuning with 3.51x Speedup over Unsloth</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [fused triton kernels, cut cross-entropy, lora+, sequence packing, flashattention, online softmax]</li>
<li class=""><strong>authors:</strong> Arjun S. Nair</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.02609" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.02609</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Chronicals is a high-performance framework for LLM fine-tuning that integrates four key optimizations: fused Triton kernels, a memory-efficient Cut Cross-Entropy loss, LoRA+ with differential learning rates, and sequence packing. It achieves a 3.51x speedup over the Unsloth framework for full fine-tuning by dramatically reducing memory footprint and computational waste. The paper also critically notes that a competing benchmark showed zero gradient norms, indicating the model was not actually training.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 22</strong></p>
<ul>
<li class="">[arXiv260107] IBISAgent: Reinforcing Pixel-Level Visual Reasoning in MLLMs for Universal Biomedical Object Referring and Segmentation <a href="https://arxiv.org/pdf/2601.03054" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] WebGym: Scaling Training Environments for Visual Web Agents with Realistic Tasks <a href="https://arxiv.org/pdf/2601.02439" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Dementia-R1: Reinforced Pretraining and Reasoning from Unstructured Clinical Notes for Real-World Dementia Prognosis <a href="https://arxiv.org/pdf/2601.03018" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] One Sample to Rule Them All: Extreme Data Efficiency in RL Scaling <a href="https://arxiv.org/pdf/2601.03111" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] In-Context Reinforcement Learning through Bayesian Fusion of Context and Value Prior <a href="https://arxiv.org/pdf/2601.03015" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] SWaRL: Safeguard Code Watermarking via Reinforcement Learning <a href="https://arxiv.org/pdf/2601.02602" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Unified Thinker: A General Reasoning Modular Core for Image Generation <a href="https://arxiv.org/pdf/2601.03127" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Correct, Concise and Complete: Multi-stage Training For Adaptive Reasoning <a href="https://arxiv.org/pdf/2601.02972" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] UltraLogic: Enhancing LLM Reasoning through Large-Scale Data Synthesis and Bipolar Float Reward <a href="https://arxiv.org/pdf/2601.03205" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] MiMo-V2-Flash Technical Report <a href="https://arxiv.org/pdf/2601.02780" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] The World is Not Mono: Enabling Spatial Understanding in Large Audio-Language Models <a href="https://arxiv.org/pdf/2601.02954" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] LLM-Enhanced Reinforcement Learning for Time Series Anomaly Detection <a href="https://arxiv.org/pdf/2601.02511" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] SimRPD: Optimizing Recruitment Proactive Dialogue Agents through Simulator-Based Data Evaluation and Selection <a href="https://arxiv.org/pdf/2601.02871" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Textual Explanations and Their Evaluations for Reinforcement Learning Policy <a href="https://arxiv.org/pdf/2601.02514" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Sample-Efficient Neurosymbolic Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2601.02850" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] AI-Native Integrated Sensing and Communications for Self-Organizing Wireless Networks: Architectures, Learning Paradigms, and System-Level Design <a href="https://arxiv.org/pdf/2601.02398" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Effective Online 3D Bin Packing with Lookahead Parcels Using Monte Carlo Tree Search <a href="https://arxiv.org/pdf/2601.02649" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Closing the Reality Gap: Zero-Shot Sim-to-Real Deployment for Dexterous Force-Based Grasping and Manipulation <a href="https://arxiv.org/pdf/2601.02778" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Inferring Causal Graph Temporal Logic Formulas to Expedite Reinforcement Learning in Temporally Extended Tasks <a href="https://arxiv.org/pdf/2601.02666" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Time-Scaling Is What Agents Need Now <a href="https://arxiv.org/pdf/2601.02714" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] ChemBART: A Pre-trained BART Model Assisting Organic Chemistry Analysis <a href="https://arxiv.org/pdf/2601.02915" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Q-Regularized Generative Auto-Bidding: From Suboptimal Trajectories to Optimal Policies <a href="https://arxiv.org/pdf/2601.02754" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 7</strong></p>
<ul>
<li class="">[arXiv260107] Threat Detection in Social Media Networks Using Machine Learning Based Network Analysis <a href="https://arxiv.org/pdf/2601.02581" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] A large-scale nanocrystal database with aligned synthesis and properties enabling generative inverse design <a href="https://arxiv.org/pdf/2601.02424" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] PersonaLedger: Generating Realistic Financial Transactions with Persona Conditioned LLMs and Rule Grounded Feedback <a href="https://arxiv.org/pdf/2601.03149" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] RadioDiff-Flux: Efficient Radio Map Construction via Generative Denoise Diffusion Model Trajectory Midpoint Reuse <a href="https://arxiv.org/pdf/2601.02790" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Dynamic Hyperparameter Importance for Efficient Multi-Objective Optimization <a href="https://arxiv.org/pdf/2601.03166" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] Sample-Efficient Neurosymbolic Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2601.02850" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260107] The Vibe-Check Protocol: Quantifying Cognitive Offloading in AI Programming <a href="https://arxiv.org/pdf/2601.02410" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2026-01-07T02:51:06.000Z" itemprop="dateModified">Jan 7, 2026</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20251229-20260104"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251229-20260104</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2026-01-05" class="table-of-contents__link toc-highlight">2026-01-05</a></li><li><a href="#2026-01-06" class="table-of-contents__link toc-highlight">2026-01-06</a></li><li><a href="#2026-01-07" class="table-of-contents__link toc-highlight">2026-01-07</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>