<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20251027-20251102" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251027-20251102 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20251027-20251102"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251027-20251102 | DarkKnight Note"><meta data-rh="true" name="description" content="2025-10-27"><meta data-rh="true" property="og:description" content="2025-10-27"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20251027-20251102"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20251027-20251102" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20251027-20251102" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20251027-20251102","item":"https://darkknight996.github.io/daily/20251027-20251102"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.f3ae01c9.js" defer="defer"></script>
<script src="/assets/js/main.4a92b8d6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251027-20251102</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251027-20251102</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-10-27">2025-10-27<a href="#2025-10-27" class="hash-link" aria-label="Direct link to 2025-10-27" title="Direct link to 2025-10-27" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv2510] Learning to Schedule: A Supervised Learning Framework for Network-Aware
Scheduling of Data-Intensive Workloads</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [scheduling], [network-aware scheduling, supervised learning, data-intensive workloads, Kubernetes, job completion time prediction]</li>
<li class=""><strong>authors:</strong> Sankalpa Timilsina, Susmit Shannigrahi</li>
<li class=""><strong>institution:</strong> Tennessee Technological University</li>
<li class=""><strong>link:</strong> <a href="http://arxiv.org/pdf/2510.21419v1" target="_blank" rel="noopener noreferrer" class="">http://arxiv.org/pdf/2510.21419v1</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a network-aware job scheduler using supervised learning to predict job completion times based on real-time cluster telemetry. The system employs a prediction-and-ranking mechanism that evaluates nodes and selects optimal placements for data-intensive workloads. Evaluation on a geo-distributed Kubernetes cluster showed 34-54% higher accuracy in node selection compared to the default Kubernetes scheduler.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv2510] From SLA to vendor-neutral metrics: An intelligent knowledge-based
approach for multi-cloud SLA-based broker</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [cloud computing, multi-cloud, SLA management, vendor-neutral metrics, intelligent knowledge-based system, auto-scaling]</li>
<li class=""><strong>authors:</strong> Víctor Rampérez, Javier Soriano, David Lizcano, Shadi Aljawarneh, Juan A. Lara</li>
<li class=""><strong>institution:</strong> Universidad Politécnica de Madrid (UPM), Madrid Open University (UDIMA)</li>
<li class=""><strong>link:</strong> <a href="http://arxiv.org/pdf/2510.21173v1" target="_blank" rel="noopener noreferrer" class="">http://arxiv.org/pdf/2510.21173v1</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an intelligent knowledge-based system that automatically translates high-level SLAs into vendor-neutral metrics for multi-cloud environments. The approach enables cross-provider metric measurement and provides consumer feedback through an intelligent tutoring system. Validation with IaaS and PaaS use cases demonstrates the system allows transparent multi-cloud exploitation across various application domains.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv2510] xMem: A CPU-Based Approach for Accurate Estimation of GPU Memory in Deep
Learning Training Workloads</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [GPU memory estimation, dynamic analysis, resource management, scheduling]</li>
<li class=""><strong>authors:</strong> Jiabo Shi, Dimitrios Pezaros, Yehia Elkhatib</li>
<li class=""><strong>institution:</strong> University of Glasgow</li>
<li class=""><strong>link:</strong> <a href="http://arxiv.org/pdf/2510.21048v1" target="_blank" rel="noopener noreferrer" class="">http://arxiv.org/pdf/2510.21048v1</a></li>
<li class=""><strong>Simple LLM Summary:</strong> xMem proposes a CPU-based dynamic analysis framework to accurately estimate peak GPU memory requirements for deep learning training workloads without consuming GPU resources. The method achieves 91% reduction in median relative error and 75% reduction in OOM probability compared to existing solutions. This enables better GPU sharing and scheduling in cluster environments while significantly improving memory conservation potential.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv2510] Lincoln AI Computing Survey (LAICS) and Trends</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [Other models training, Other models inference], [AI accelerators, performance analysis, power consumption, market segmentation, computing architectures]</li>
<li class=""><strong>authors:</strong> Albert Reuther, Peter Michaleas, Michael Jones, Vijay Gadepally, Jeremy Kepner</li>
<li class=""><strong>institution:</strong> MIT Lincoln Laboratory</li>
<li class=""><strong>link:</strong> <a href="http://arxiv.org/pdf/2510.20931v1" target="_blank" rel="noopener noreferrer" class="">http://arxiv.org/pdf/2510.20931v1</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper updates the Lincoln AI Computing Survey by collecting performance and power consumption data of commercial AI accelerators, plotting them on scatter graphs, and analyzing market trends. It introduces a new categorization of computing architectures and examines how GenAI models have shifted computational demands toward matrix-vector operations and high memory bandwidth. The survey highlights ongoing innovations in AI hardware across various deployment scales from embedded systems to data centers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv2510] ParaRNN: Unlocking Parallel Training of Nonlinear RNNs for Large
Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [LLM training], [parallel training, nonlinear RNNs, sequence modeling, Newton&#x27;s iterations, parallel reductions]</li>
<li class=""><strong>authors:</strong> Federico Danieli, Pau Rodriguez, Miguel Sarabia, Xavier Suau, Luca Zappella</li>
<li class=""><strong>institution:</strong> Apple</li>
<li class=""><strong>link:</strong> <a href="http://arxiv.org/pdf/2510.21450v1" target="_blank" rel="noopener noreferrer" class="">http://arxiv.org/pdf/2510.21450v1</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ParaRNN enables parallel training of nonlinear RNNs by formulating recurrence relationships as a system of equations and solving them using Newton&#x27;s iterations with parallel reductions. This approach achieves up to 665x speedup over sequential methods and allows training 7B parameter RNNs with performance comparable to Transformers and Mamba2. The framework is released as open-source to facilitate scalable nonlinear RNN research.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv2510] REVE: A Foundation Model for EEG -- Adapting to Any Setup with
Large-Scale Pretraining on 25,000 Subjects</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [Other models training], [EEG foundation model, 4D positional encoding, masked autoencoding, brain-computer interfaces, clinical neuroscience]</li>
<li class=""><strong>authors:</strong> Yassine El Ouahidi, Jonathan Lys, Philipp Thölke, Nicolas Farrugia, Bastien Pasdeloup, Vincent Gripon, Karim Jerbi, Giulia Lioi</li>
<li class=""><strong>institution:</strong> IMT Atlantique, Université de Montréal, Mila, UNIQUE</li>
<li class=""><strong>link:</strong> <a href="http://arxiv.org/pdf/2510.21585v1" target="_blank" rel="noopener noreferrer" class="">http://arxiv.org/pdf/2510.21585v1</a></li>
<li class=""><strong>Simple LLM Summary:</strong> REVE introduces a novel 4D positional encoding scheme and uses masked autoencoding pretraining on 60,000 hours of EEG data from 25,000 subjects. The model achieves state-of-the-art performance across 10 EEG tasks including motor imagery and seizure detection. It demonstrates strong generalization with minimal fine-tuning and enables standardized EEG research through released code and weights.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-10-28">2025-10-28<a href="#2025-10-28" class="hash-link" aria-label="Direct link to 2025-10-28" title="Direct link to 2025-10-28" translate="no">​</a></h2>
<p><strong>cs.DC total: 13</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251028] Simopt-Power: Leveraging Simulation Metadata for Low-Power Design Synthesis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [FPGA power optimization], [simulation metadata, Shannon Decomposition, activity profiling, truth table duplication, netlist transformation]</li>
<li class=""><strong>authors:</strong> Eashan Wadhwa, Shanker Shreejith</li>
<li class=""><strong>institution:</strong> Trinity College Dublin</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.21745" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.21745</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents Simopt-Power, a framework that uses simulation metadata to identify high-toggle paths in FPGA designs and applies Shannon Decomposition to insert duplicate logic and relocate critical nets. The method achieves approximately 9% reduction in switching-induced power while adding only modest resource overhead. Results demonstrate that coupling simulation insights with targeted optimizations provides an effective approach for dynamic power reduction in FPGA design flows.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] Separation of Unconscious Robots with Obstructed Visibility</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed robotics], [opaque robots, semicircle separation, look-compute-move cycle, semi-synchronous scheduler]</li>
<li class=""><strong>authors:</strong> Prajyot Pyati, Navjot Kaur, Saswata Jana, Adri Bhattacharya, Partha Sarathi Mandal</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.22434" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.22434</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a collision-free algorithm for unconscious robots with obstructed visibility that separates robots into concentric semicircles. The algorithm operates under a semi-synchronous scheduler and achieves separation in O(n) epochs. The robots coordinate without knowing the total number of robots but agree on one coordinate axis.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] When Agents are Powerful: Black Hole Search in Time-Varying Graphs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed algorithms], [global communication, 1-hop visibility, deterministic algorithms, mobile agents]</li>
<li class=""><strong>authors:</strong> Tanvir Kaur, Ashish Saxena</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology Ropar</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.22309" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.22309</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper enhances Black Hole Search in dynamic graphs by equipping agents with global communication and 1-hop visibility capabilities. These improvements allow for more efficient solutions compared to previous face-to-face communication approaches. The enhanced agent capabilities reduce the number of agents required to successfully identify the black hole while ensuring at least one agent survives.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] A Feature Engineering Approach for Business Impact-Oriented Failure Detection in Distributed Instant Payment Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [feature engineering, anomaly detection, ISO 20022 message processing, processing time analysis, explainable AI]</li>
<li class=""><strong>authors:</strong> Lorenzo Porcelli</li>
<li class=""><strong>institution:</strong> Bank of Italy, University of Salerno</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.21710" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.21710</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a feature engineering approach that computes processing times between consecutive ISO 20022 message exchanges to create system state representations for anomaly detection. The method enables early failure detection and incident classification in distributed instant payment systems. Experimental evaluation on TARGET Instant Payment Settlement demonstrates effectiveness in detecting diverse anomaly patterns while providing interpretable explanations for business impact assessment.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] Heaven &amp; Hell II: Scale Laws and Robustness in One-Step Heaven-Hell Consensus</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [network consensus], [Heaven-Hell dynamics, conservation-law perspective, tie-breaking policies, pointwise bounds, asynchronous updates, Coq proofs]</li>
<li class=""><strong>authors:</strong> Nnamdi Daniel Aghanya, Romain Leemans</li>
<li class=""><strong>institution:</strong> Cranfield University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.21950" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.21950</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper develops scale laws and operational refinements for Heaven-Hell consensus dynamics, using a conservation-law perspective to derive tighter bounds and robustness guarantees. The research establishes conditions for robust convergence under various scenarios including tie-breaking policies, asynchronous updates, and multiple hubs. All proofs are mechanized in Coq and experiments validate the tightness of the bounds across diverse network types.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] Rethinking Inference Placement for Deep Learning across Edge and Cloud Platforms: A Multi-Objective Optimization Perspective and Future Directions</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [model offloading, model compression, model distillation, transmission compression, internal classifiers]</li>
<li class=""><strong>authors:</strong> Zongshun Zhang, Ibrahim Matta</li>
<li class=""><strong>institution:</strong> Boston University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.22909" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.22909</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper surveys methods for optimizing deep learning inference placement across edge and cloud platforms using techniques like model partitioning, compression, and architecture adaptations. It analyzes how these approaches balance multiple objectives including latency, privacy, and monetary cost. The research concludes that effective inference placement requires multi-objective optimization across the computational continuum from devices to cloud.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] CodeAD: Synthesize Code of Rules for Log-based Anomaly Detection with LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [hierarchical clustering, anchor-grounded sampling, agentic workflow, rule synthesis, contrastive log windows]</li>
<li class=""><strong>authors:</strong> Junjie Huang, Minghua He, Jinyang Liu, Yintong Huo, Domenico Bianculli, Michael R. Lyu</li>
<li class=""><strong>institution:</strong> The Chinese University of Hong Kong, Peking University, Singapore Management University, University of Luxembourg</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.22986" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.22986</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CodeAD automatically synthesizes lightweight Python rule functions for log-based anomaly detection using LLMs through hierarchical clustering and iterative agentic workflows. The framework achieves 3.6% higher F1 score than state-of-the-art methods while processing data 4x faster at minimal cost, providing an interpretable and efficient solution for real-time log analysis.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] Power to the Clients: Federated Learning in a Dictatorship Setting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [federated learning, byzantine clients, dictator clients, model convergence, attack strategies]</li>
<li class=""><strong>authors:</strong> Mohammadsajad Alipour, Mohammad Mohammadi Amiri</li>
<li class=""><strong>institution:</strong> Rensselaer Polytechnic Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.22149" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.22149</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces dictator clients, a class of malicious participants in federated learning that can erase other clients&#x27; contributions while preserving their own. The authors propose attack strategies and analyze their effects on model convergence in various scenarios including collaboration and betrayal between multiple dictator clients. Their theoretical analysis and empirical evaluations demonstrate how these clients can significantly compromise the global model&#x27;s integrity.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] Sentinel: Dynamic Knowledge Distillation for Personalized Federated Intrusion Detection in Heterogeneous IoT Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [personalized federated learning, knowledge distillation, dual-model architecture, class-balanced loss, gradient aggregation]</li>
<li class=""><strong>authors:</strong> Gurpreet Singh, Keshav Sood, P. Rajalakshmi, Yong Xiang</li>
<li class=""><strong>institution:</strong> Deakin University, Indian Institute of Technology Hyderabad</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23019" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23019</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Sentinel, a personalized federated intrusion detection system that uses a dual-model architecture with teacher-student knowledge distillation to handle data heterogeneity in IoT networks. It incorporates bidirectional distillation, feature alignment, and balanced loss functions to improve performance. Experiments show Sentinel outperforms existing methods while maintaining communication efficiency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] AirFed: Federated Graph-Enhanced Multi-Agent Reinforcement Learning for Multi-UAV Cooperative Mobile Edge Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, graph attention networks, multi-agent reinforcement learning, trajectory planning, task offloading, resource allocation, gradient quantization]</li>
<li class=""><strong>authors:</strong> Zhiyu Wang, Suman Raj, Rajkumar Buyya</li>
<li class=""><strong>institution:</strong> The University of Melbourne, Indian Institute of Science</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23053" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23053</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes AirFed, a federated graph-enhanced multi-agent reinforcement learning framework that uses dual-layer Graph Attention Networks and a dual-Actor single-Critic architecture for UAV coordination in mobile edge computing. The system achieves significant improvements including 42.9% cost reduction, over 99% deadline satisfaction, and 54.5% lower communication overhead compared to state-of-the-art methods, demonstrating strong scalability for large-scale UAV deployments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream Processing Pipelines</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [Hypergraph of Thoughts, multi-agent reasoning, resilient execution strategies, advanced query analysis]</li>
<li class=""><strong>authors:</strong> Abolfazl Younesi, Zahra Najafabadi Samani, Thomas Fahringer</li>
<li class=""><strong>institution:</strong> University of Innsbruck</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23408" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23408</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AutoStreamPipe uses Large Language Models with Hypergraph of Thoughts to automatically generate data stream processing pipelines from high-level user intents. The framework bridges the semantic gap between user requirements and platform-specific implementations through structured multi-agent reasoning. Experimental results show it significantly reduces development time by 6.3× and error rates by 5.19× compared to traditional LLM code-generation methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] Bayes-Split-Edge: Bayesian Optimization for Constrained Collaborative Inference in Wireless Edge Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Bayesian optimization, split learning, collaborative inference, wireless edge computing, constrained optimization, neural network splitting]</li>
<li class=""><strong>authors:</strong> Fatemeh Zahra Safaeipour, Jacob Chakareski, Morteza Hashemi</li>
<li class=""><strong>institution:</strong> University of Kansas, New Jersey Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23503" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23503</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Bayes-Split-Edge, a Bayesian optimization framework that jointly optimizes transmission power and neural network split points for collaborative inference in wireless edge systems. The method uses a novel hybrid acquisition function to balance inference utility with energy and delay constraints. Results show it achieves 2.4× evaluation cost reduction compared to standard Bayesian optimization while matching exhaustive search performance under tight constraints.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] The First Star-by-star <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span></span></span></span>-body/Hydrodynamics Simulation of Our Galaxy Coupling with a Surrogate Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [N-body simulation, smoothed-particle hydrodynamics, surrogate model, deep learning, Fugaku supercomputer]</li>
<li class=""><strong>authors:</strong> Keiya Hirashima, Michiko S. Fujii, Takayuki R. Saitoh, Naoto Harada, Kentaro Nomura, Kohji Yoshikawa, Yutaka Hirai, Tetsuro Asano, Kana Moriwaki, Masaki Iwasawa, Takashi Okamoto, Junichiro Makino</li>
<li class=""><strong>institution:</strong> RIKEN, University of Tokyo, Kobe University, Preferred Networks, University of Tsukuba, Tohoku University of Community Service and Science, Universitat de Barcelona, National Institute of Technology, Hokkaido University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23330" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23330</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a novel integration scheme combining N-body/hydrodynamics simulations with machine learning surrogate models to bypass computational bottlenecks caused by supernova explosions. The method achieved 300 billion particles using 148,900 nodes, breaking the billion-particle barrier and enabling the first star-by-star galaxy simulation. This represents a major advancement in computational astrophysics by resolving individual stars in Milky Way simulations.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 52</strong></p>
<ul>
<li class="">[arXiv251028] Transitive RL: Value Learning via Divide and Conquer <a href="http://arxiv.org/abs/2510.22512" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Predictive Coding Enhances Meta-RL To Achieve Interpretable Bayes-Optimal Belief Representation Under Partial Observability <a href="http://arxiv.org/abs/2510.22039" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Hazard-Responsive Digital Twin for Climate-Driven Urban Resilience and Equity <a href="http://arxiv.org/abs/2510.22941" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM <a href="http://arxiv.org/abs/2510.22740" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning <a href="http://arxiv.org/abs/2510.22282" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Beyond Reasoning Gains: Mitigating General Capabilities Forgetting in Large Reasoning Models <a href="http://arxiv.org/abs/2510.21978" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review <a href="http://arxiv.org/abs/2510.21758" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Advantage Shaping as Surrogate Reward Maximization: Unifying Pass@K Policy Gradients <a href="http://arxiv.org/abs/2510.23049" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] PACR: Progressively Ascending Confidence Reward for LLM Reasoning <a href="http://arxiv.org/abs/2510.22255" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Is Temporal Difference Learning the Gold Standard for Stitching in RL? <a href="http://arxiv.org/abs/2510.21995" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated Reinforcement Learning <a href="http://arxiv.org/abs/2510.23038" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] FlowCritic: Bridging Value Estimation with Flow Matching in Reinforcement Learning <a href="http://arxiv.org/abs/2510.22686" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Offline Preference Optimization via Maximum Marginal Likelihood Estimation <a href="http://arxiv.org/abs/2510.22881" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group Sequence Policy Optimization <a href="http://arxiv.org/abs/2510.22477" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Dopamine-driven synaptic credit assignment in neural networks <a href="http://arxiv.org/abs/2510.22178" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Activating Visual Context and Commonsense Reasoning through Masked Prediction in VLMs <a href="http://arxiv.org/abs/2510.21807" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Towards Stable and Effective Reinforcement Learning for Mixture-of-Experts <a href="http://arxiv.org/abs/2510.23027" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] UCB-type Algorithm for Budget-Constrained Expert Learning <a href="http://arxiv.org/abs/2510.22654" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Online Optimization for Offline Safe Reinforcement Learning <a href="http://arxiv.org/abs/2510.22027" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] GAPO: Group Adaptive Policy Optimization for Real-World Code Edit <a href="http://arxiv.org/abs/2510.21830" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Guardian: Decoupling Exploration from Safety in Reinforcement Learning <a href="http://arxiv.org/abs/2510.22859" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] STAR-RIS-assisted Collaborative Beamforming for Low-altitude Wireless Networks <a href="http://arxiv.org/abs/2510.22108" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing <a href="http://arxiv.org/abs/2510.22570" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Solving Continuous Mean Field Games: Deep Reinforcement Learning for Non-Stationary Dynamics <a href="http://arxiv.org/abs/2510.22158" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles <a href="http://arxiv.org/abs/2510.22370" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions <a href="http://arxiv.org/abs/2510.22798" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Softmax is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">1/2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">1/2</span></span></span></span>-Lipschitz: A tight bound across all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">ℓ</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">\ell_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord">ℓ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span> norms <a href="http://arxiv.org/abs/2510.23012" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions <a href="http://arxiv.org/abs/2510.22568" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Agentic Reinforcement Learning for Real-World Code Repair <a href="http://arxiv.org/abs/2510.22075" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Computational Hardness of Reinforcement Learning with Partial <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>q</mi><mi>π</mi></msup></mrow><annotation encoding="application/x-tex">q^π</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8588em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span></span></span></span></span></span></span></span></span></span></span>-Realizability <a href="http://arxiv.org/abs/2510.21888" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Toward Agents That Reason About Their Computation <a href="http://arxiv.org/abs/2510.22833" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable Reasoning <a href="http://arxiv.org/abs/2510.22543" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Do You Trust the Process?: Modeling Institutional Trust for Community Adoption of Reinforcement Learning Policies <a href="http://arxiv.org/abs/2510.22017" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning <a href="http://arxiv.org/abs/2510.22832" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping <a href="http://arxiv.org/abs/2510.22319" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] SynCast: Synergizing Contradictions in Precipitation Nowcasting via Diffusion Sequential Preference Optimization <a href="http://arxiv.org/abs/2510.21847" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Multi-Agent Conditional Diffusion Model with Mean Field Communication as Wireless Resource Allocation Planner <a href="http://arxiv.org/abs/2510.22969" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Think before Recommendation: Autonomous Reasoning-enhanced Recommender <a href="http://arxiv.org/abs/2510.23077" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Adapting Interleaved Encoders with PPO for Language-Guided Reinforcement Learning in BabyAI <a href="http://arxiv.org/abs/2510.23148" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Guiding Skill Discovery with Foundation Models <a href="http://arxiv.org/abs/2510.23167" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] TARC: Time-Adaptive Robotic Control <a href="http://arxiv.org/abs/2510.23176" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach <a href="http://arxiv.org/abs/2510.23216" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach <a href="http://arxiv.org/abs/2510.23304" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N Sampling via max@k Optimisation <a href="http://arxiv.org/abs/2510.23393" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Causal Deep Q Network <a href="http://arxiv.org/abs/2510.23424" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] An Information-Theoretic Analysis of Out-of-Distribution Generalization in Meta-Learning with Applications to Meta-RL <a href="http://arxiv.org/abs/2510.23448" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Learning to Reason Efficiently with Discounted Reinforcement Learning <a href="http://arxiv.org/abs/2510.23486" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Sequential Multi-Agent Dynamic Algorithm Configuration <a href="http://arxiv.org/abs/2510.23535" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Multi-Agent Evolve: LLM Self-Improve through Co-evolution <a href="http://arxiv.org/abs/2510.23595" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Right Place, Right Time: Market Simulation-based RL for Execution Optimisation <a href="http://arxiv.org/abs/2510.22206" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Reinforcement learning-guided optimization of critical current in high-temperature superconductors <a href="http://arxiv.org/abs/2510.22424" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] PASS-Enhanced MEC: Joint Optimization of Task Offloading and Uplink PASS Beamforming <a href="http://arxiv.org/abs/2510.22948" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerat&quot; total: 23</strong></p>
<ul>
<li class="">[arXiv251028] A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data <a href="http://arxiv.org/abs/2510.21735" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Impact and Implications of Generative AI for Enterprise Architects in Agile Environments: A Systematic Literature Review <a href="http://arxiv.org/abs/2510.22003" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Step2Motion: Locomotion Reconstruction from Pressure Sensing Insoles <a href="http://arxiv.org/abs/2510.22712" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Accelerating Materials Design via LLM-Guided Evolutionary Search <a href="http://arxiv.org/abs/2510.22503" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] PACR: Progressively Ascending Confidence Reward for LLM Reasoning <a href="http://arxiv.org/abs/2510.22255" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] AI-Enhanced Operator Assistance for UNICOS Applications <a href="http://arxiv.org/abs/2510.21717" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Dopamine-driven synaptic credit assignment in neural networks <a href="http://arxiv.org/abs/2510.22178" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] OpenEM: Large-scale multi-structural 3D datasets for electromagnetic methods <a href="http://arxiv.org/abs/2510.21859" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Encoder-Decoder Diffusion Language Models for Efficient Training and Inference <a href="http://arxiv.org/abs/2510.22852" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] QuArch: A Benchmark for Evaluating LLM Reasoning in Computer Architecture <a href="http://arxiv.org/abs/2510.22087" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Residual-guided AI-CFD hybrid method enables stable and scalable simulations: from 2D benchmarks to 3D applications <a href="http://arxiv.org/abs/2510.21804" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Graph-Coarsening Approach for the Capacitated Vehicle Routing Problem with Time Windows <a href="http://arxiv.org/abs/2510.22329" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Approximate Gradient Coding for Distributed Learning with Heterogeneous Stragglers <a href="http://arxiv.org/abs/2510.22539" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge <a href="http://arxiv.org/abs/2510.21879" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs <a href="http://arxiv.org/abs/2510.23127" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Guiding Skill Discovery with Foundation Models <a href="http://arxiv.org/abs/2510.23167" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Accelerating Eigenvalue Dataset Generation via Chebyshev Subspace Filter <a href="http://arxiv.org/abs/2510.23215" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Accelerating IC Thermal Simulation Data Generation via Block Krylov and Operator Action <a href="http://arxiv.org/abs/2510.23221" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Progressive Growing of Patch Size: Curriculum Learning for Accelerated and Improved Medical Image Segmentation <a href="http://arxiv.org/abs/2510.23241" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] PAHQ: Accelerating Automated Circuit Discovery through Mixed-Precision Inference Optimization <a href="http://arxiv.org/abs/2510.23264" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Towards a Generalizable AI for Materials Discovery: Validation through Immersion Coolant Screening <a href="http://arxiv.org/abs/2510.23371" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] HPC-Driven Modeling with ML-Based Surrogates for Magnon-Photon Dynamics in Hybrid Quantum Systems <a href="http://arxiv.org/abs/2510.22221" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Reinforcement learning-guided optimization of critical current in high-temperature superconductors <a href="http://arxiv.org/abs/2510.22424" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-10-29">2025-10-29<a href="#2025-10-29" class="hash-link" aria-label="Direct link to 2025-10-29" title="Direct link to 2025-10-29" translate="no">​</a></h2>
<p><strong>cs.DC total: 14</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251029] Odyssey: An End-to-End System for Pareto-Optimal Serverless Query Processing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [serverless data analytics], [query planner, cost model, execution engine, state space pruning, Pareto-optimal plans]</li>
<li class=""><strong>authors:</strong> Shyam Jesalpura, Shengda Zhu, Amir Shaikhha, Antonio Barbalace, Boris Grot</li>
<li class=""><strong>institution:</strong> The University of Edinburgh</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24307" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24307</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Odyssey introduces an end-to-end serverless data analytics system that automatically generates and evaluates query plans using state space pruning and a novel search algorithm to find Pareto-optimal plans balancing cost and performance. The system consistently outperforms AWS Athena on cost and/or latency while accurately predicting both monetary cost and latency for serverless query processing.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] CoMPSeT: A Framework for Comparing Multiparty Session Types</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [formal methods], [multiparty session types, choreographic languages, operational semantics]</li>
<li class=""><strong>authors:</strong> Telmo Ribeiro, José Proença, Mário Florido</li>
<li class=""><strong>institution:</strong> University of Porto</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24205" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24205</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces CoMPSeT, a framework for comparing different variations of Multiparty Session Types through representative examples and semantic animation. The tool allows researchers and educators to combine different MPST features and analyze their behavior. CoMPSeT is implemented as an open-source JavaScript tool that runs directly in web browsers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] ARIMA_PLUS: Large-scale, Accurate, Automatic and Interpretable In-Database Time Series Forecasting and Anomaly Detection in Google BigQuery</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [ARIMA_PLUS, time series forecasting, anomaly detection, BigQuery, SQL interface, modular decomposition]</li>
<li class=""><strong>authors:</strong> Xi Cheng, Weijie Shen, Haoming Chen, Chaoyi Shen, Jean Ortega, Jiashang Liu, Steve Thomas, Honglin Zheng, Haoyun Wu, Yuxiang Li, Casey Lichtendahl, Jenny Ortiz, Gang Liu, Haiyang Qi, Omid Fatemieh, Chris Fry, Jing Jing Long</li>
<li class=""><strong>institution:</strong> Google</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24452" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24452</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ARIMA_PLUS is a novel framework that combines interpretable time series modeling with scalable cloud infrastructure for forecasting and anomaly detection. It demonstrates superior accuracy over both statistical and neural network methods across 42 benchmark datasets. The system integrates directly into Google BigQuery, enabling automatic scaling to handle millions of time series efficiently through a simple SQL interface.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] Differential Privacy: Gradient Leakage Attacks in Federated Learning Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Differential Privacy, DP-SGD, PDP-SGD, Gradient Leakage Attacks, Federated Learning]</li>
<li class=""><strong>authors:</strong> Miguel Fernandez-de-Retana, Unai Zulaika, Rubén Sánchez-Corcuera, Aitor Almeida</li>
<li class=""><strong>institution:</strong> Basque Center for Applied Mathematics, University of Deusto</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23931" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23931</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper evaluates Differential Privacy mechanisms (DP-SGD and PDP-SGD) as defenses against gradient leakage attacks in federated learning. The results show DP-SGD effectively mitigates reconstruction attacks with moderate utility trade-off, while PDP-SGD maintains strong model performance but fails as a practical defense. The findings emphasize the need for empirical evaluation of privacy mechanisms beyond theoretical guarantees in distributed learning scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] Fault-Tolerant Multiparty Session Types with Global Escape Loops</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems], [multiparty session types, fault-tolerance, global escape loops, non-blocking messages, rotating coordinator algorithm]</li>
<li class=""><strong>authors:</strong> Lukas Bartl, Julian Linne, Kirstin Peters</li>
<li class=""><strong>institution:</strong> Universität Augsburg</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24203" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24203</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper extends fault-tolerant multiparty session types by introducing a novel global escape loop construct that allows processes to terminate distributed algorithms without global coordination. The approach uses non-blocking exit-messages to enable efficient fault-tolerant termination when solutions are found. The method is demonstrated through analysis of a variant of the rotating coordinator algorithm by Chandra and Toueg.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] The SAP Cloud Infrastructure Dataset: A Reality Check of Scheduling and Placement of VMs in Cloud Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud computing], [virtual machine scheduling, resource allocation, workload management, performance metrics]</li>
<li class=""><strong>authors:</strong> Arno Uhlig, Iris Braun, Matthias Wählisch</li>
<li class=""><strong>institution:</strong> TU Dresden, SAP SE</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23911" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23911</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper analyzes VM scheduling and placement in SAP&#x27;s cloud infrastructure using fine-grained telemetry data from 1,800 hypervisors and 48,000 VMs. The study identifies significant resource inefficiencies including CPU contention exceeding 40% and over 80% of VMs using less than 70% of allocated resources. Based on these findings, the authors derive requirements for improved scheduling algorithms and make their dataset publicly available for future research.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [personalized federated learning, FedAvg, client drift, out-of-distribution generalization, FLIU, adaptive personalization factor]</li>
<li class=""><strong>authors:</strong> Mortesa Hussaini, Jan Theiß, Anthony Stein</li>
<li class=""><strong>institution:</strong> University of Hohenheim</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24503" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24503</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes FLIU, a modified FedAvg approach with adaptive personalization factors, and evaluates both local performance and out-of-distribution generalization in personalized federated learning. The study finds that while PFL methods excel at local performance, they inadequately address generalization capabilities compared to traditional FL approaches. The research demonstrates the importance of balancing both local optimization and generalization in heterogeneous data environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] SPEAR++: Scaling Gradient Inversion via Sparsely-Used Dictionary Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [gradient inversion attacks, sparsely-used dictionary learning, federated learning, ReLU activations, linear layers, FedAvg, differential privacy]</li>
<li class=""><strong>authors:</strong> Alexander Bakarsky, Dimitar I. Dimitrov, Maximilian Baader, Martin Vechev</li>
<li class=""><strong>institution:</strong> ETH Zurich, INSAIT Sofia University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24200" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24200</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SPEAR++, a gradient inversion attack that uses sparsely-used dictionary learning to scale previous theoretical attacks on federated learning systems. The method makes gradient inversion tractable for linear layers with ReLU activations while maintaining robustness to DP noise and FedAvg aggregation. The authors demonstrate their attack can handle batch sizes 10x larger than previous approaches while preserving all desirable properties of the original SPEAR attack.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] Towards Exascale Computing for Astrophysical Simulation Leveraging the Leonardo EuroHPC System</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [astrophysical simulation], [GPU scaling, performance analysis, profiling tools, HPC optimization]</li>
<li class=""><strong>authors:</strong> Nitin Shukla, Alessandro Romeo, Caterina Caravita, Michael Redenti, Radim Vavrik, Lubomir Riha, Andrea Mignone, Marco Rossazza, Stefano Truzzi, Luca Tornatore, Antonio Ragagnin, Tiago Castro, Geray S. Karademir, Klaus Dolag, Pranab J. Deka, Fabio Bacchini, Rostislav-Paul Wilhelm, Daniele Gregori, Elisabetta Boella</li>
<li class=""><strong>institution:</strong> CINECA, IT4Innovations, University of Turin, INAF, Ludwig-Maximilians-Universität München, KU Leuven, E4 Computer Engineering</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24175" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24175</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents optimization strategies for three astrophysical simulation codes (gPLUTO, OpenGadget3, iPIC3D) on the Leonardo EuroHPC system using profiling tools to analyze performance. The research demonstrates that all three codes achieve efficient scaling, reaching 80% scalability up to 1,024 GPUs, enabling large-scale astrophysical simulations for the exascale computing era.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] A GPU-based Compressible Combustion Solver for Applications Exhibiting Disparate Space and Time Scales</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [computational fluid dynamics], [GPU optimization, AMReX framework, bulk-sparse integration, adaptive mesh refinement, column-major storage, roofline analysis]</li>
<li class=""><strong>authors:</strong> Anthony Carreon, Jagmohan Singh, Shivank Sharma, Shuzhi Zhang, Venkat Raman</li>
<li class=""><strong>institution:</strong> University of Michigan</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23993" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23993</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents a GPU-optimized compressible combustion solver built on the AMReX framework that addresses memory access patterns, workload variability, and multi-GPU load distribution. The solver achieves 2-5× performance improvements over initial GPU implementations with near-ideal weak scaling across 1-96 NVIDIA H100 GPUs. Roofline analysis confirms efficient utilization of GPU memory bandwidth and computational resources for both convection and chemistry routines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] PanDelos-plus: A parallel algorithm for computing sequence homology in pangenomic analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [bioinformatics], [parallel computing, k-mer profiles, data decomposition, thread pool, lightweight data structures]</li>
<li class=""><strong>authors:</strong> Simone Colli, Emiliano Maresi, Vincenzo Bonnici</li>
<li class=""><strong>institution:</strong> University of Parma</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23679" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23679</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PanDelos-plus is a parallel algorithm that improves upon PanDelos by parallelizing computationally intensive phases using data decomposition and thread pool strategies while employing lightweight data structures. Benchmarks show it achieves up to 14x faster execution and 96% memory reduction while maintaining accuracy. These improvements enable large-scale bacterial pangenome analysis to be performed on standard multicore workstations for routine research use.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] Distributed Stochastic Momentum Tracking with Local Updates: Achieving Optimal Communication and Iteration Complexities</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Local Momentum Tracking, momentum tracking, Loopless Chebyshev Acceleration, local updates, distributed optimization]</li>
<li class=""><strong>authors:</strong> Kun Huang, Shi Pu</li>
<li class=""><strong>institution:</strong> The Chinese University of Hong Kong, Shenzhen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24155" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24155</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Local Momentum Tracking (LMT), a distributed stochastic gradient method that combines local updates with momentum tracking and Loopless Chebyshev Acceleration to reduce communication overhead. LMT achieves linear speedup with respect to both local updates and number of agents, and attains optimal communication and iteration complexities under different local update regimes. This represents the first method to simultaneously achieve these properties for distributed optimization over networks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] Exascale In-situ visualization for Astronomy &amp; Cosmology</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing], [in-situ visualization, distributed database, streaming data, N-body simulation]</li>
<li class=""><strong>authors:</strong> Nicola Tuccari, Eva Sciacca, Yolanda Becerra, Enric Sosa Cintero, Emiliano Tramontana</li>
<li class=""><strong>institution:</strong> INAF Astrophysical Observatory of Catania, Università di Catania, Barcelona Supercomputing Center</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24545" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24545</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents an in-situ visualization approach using Hecuba, a distributed database framework that streams astronomy and cosmology simulation data directly into visualization pipelines. By integrating Hecuba with the ChaNGa cosmological simulator, the authors enable real-time visualization of N-body simulations using tools like ParaView and VisIVO. The main conclusion is that this approach overcomes traditional I/O bottlenecks in exascale computing by bypassing disk storage and enabling concurrent simulation and visualization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] In-Situ High Performance Visualization for Astronomy &amp; Cosmology</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing], [in-situ visualization, distributed database, Hecuba framework, ParaView, VisIVO]</li>
<li class=""><strong>authors:</strong> Nicola Tuccari, Eva Sciacca, Yolanda Becerra, Enric Sosa Cintero, Robert Wissing, Sijing Shen, Emiliano Tramontana</li>
<li class=""><strong>institution:</strong> INAF Astrophysical Observatory of Catania, Università di Catania, Barcelona Supercomputing Center, University of Oslo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24547" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24547</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents an in-situ visualization approach using the Hecuba distributed database framework to process cosmological simulation data concurrently with computation. The method integrates with the Changa cosmological simulator and visualization tools ParaView and VisIVO to bypass storage bottlenecks. The main conclusion is that this approach enables effective visualization of petascale datasets that would otherwise require data filtering or resolution reduction.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 18</strong></p>
<ul>
<li class="">[arXiv251029] PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling <a href="https://arxiv.org/pdf/2510.24235" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings <a href="https://arxiv.org/pdf/2510.24432" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model <a href="https://arxiv.org/pdf/2510.24285" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward <a href="https://arxiv.org/pdf/2510.24020" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Causal-Aware Generative Adversarial Networks with Reinforcement Learning <a href="https://arxiv.org/pdf/2510.24046" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks <a href="https://arxiv.org/pdf/2510.24461" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Sample-efficient and Scalable Exploration in Continuous-Time RL <a href="https://arxiv.org/pdf/2510.24482" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data <a href="https://arxiv.org/pdf/2510.24151" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins <a href="https://arxiv.org/pdf/2510.23882" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA <a href="https://arxiv.org/pdf/2510.23868" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation <a href="https://arxiv.org/pdf/2510.24431" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Latent Chain-of-Thought for Visual Reasoning <a href="https://arxiv.org/pdf/2510.23925" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Debiasing Reward Models by Representation Learning with Guarantees <a href="https://arxiv.org/pdf/2510.23751" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Survey and Tutorial of Reinforcement Learning Methods in Process Systems Engineering <a href="https://arxiv.org/pdf/2510.24272" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Dual-Mind World Models: A General Framework for Learning in Dynamic Wireless Networks <a href="https://arxiv.org/pdf/2510.24546" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning <a href="https://arxiv.org/pdf/2510.24650" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Learning to Drive Safely with Hybrid Options <a href="https://arxiv.org/pdf/2510.24674" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Greedy Sampling Is Provably Efficient for RLHF <a href="https://arxiv.org/pdf/2510.24700" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 12</strong></p>
<ul>
<li class="">[arXiv251029] Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings <a href="https://arxiv.org/pdf/2510.24432" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal Regression Trees <a href="https://arxiv.org/pdf/2510.23901" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Causal-Aware Generative Adversarial Networks with Reinforcement Learning <a href="https://arxiv.org/pdf/2510.24046" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Design and Optimization of Cloud Native Homomorphic Encryption Workflows for Privacy-Preserving ML Inference <a href="https://arxiv.org/pdf/2510.24498" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] SymMaP: Improving Computational Efficiency in Linear Solvers through Symbolic Preconditioning <a href="https://arxiv.org/pdf/2510.24170" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Fixed Point Neural Acceleration and Inverse Surrogate Model for Battery Parameter Identification <a href="https://arxiv.org/pdf/2510.24135" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point Arithmetic <a href="https://arxiv.org/pdf/2510.24061" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields <a href="https://arxiv.org/pdf/2510.23621" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Scalable GPU-Based Integrity Verification for Large Machine Learning Models <a href="https://arxiv.org/pdf/2510.23938" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach <a href="https://arxiv.org/pdf/2510.24085" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Taming the Tail: NoI Topology Synthesis for Mixed DL Workloads on Chiplet-Based Accelerators <a href="https://arxiv.org/pdf/2510.24113" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Trajectory Design for UAV-Based Low-Altitude Wireless Networks in Unknown Environments: A Digital Twin-Assisted TD3 Approach <a href="https://arxiv.org/pdf/2510.24255" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-10-30">2025-10-30<a href="#2025-10-30" class="hash-link" aria-label="Direct link to 2025-10-30" title="Direct link to 2025-10-30" translate="no">​</a></h2>
<p><strong>cs.DC total: 12</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251030] Scheduling Data-Intensive Workloads in Large-Scale Distributed Systems: Trends and Challenges</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [gang scheduling, workflow scheduling, bag-of-tasks scheduling, data locality, fault tolerance, energy efficiency]</li>
<li class=""><strong>authors:</strong> Georgios L. Stavrinides, Helen D. Karatza</li>
<li class=""><strong>institution:</strong> Aristotle University of Thessaloniki</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25362" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25362</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This chapter provides a classification of data-intensive workloads and surveys scheduling approaches for large-scale distributed systems. It presents novel scheduling strategies that address challenges like parallelism, data locality, and quality of service requirements. The paper concludes by identifying open challenges and future research directions in scheduling data-intensive applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251030] Multi-Resolution Model Fusion for Accelerating the Convolutional Neural Network Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Multi-Resolution Model Fusion, reduced-resolution training, model convergence, fine-tuning]</li>
<li class=""><strong>authors:</strong> Kewei Wang, Claire Songhyun Lee, Sunwoo Lee, Vishu Gupta, Jan Balewski, Alex Sim, Peter Nugent, Ankit Agrawal, Alok Choudhary, Kesheng Wu, Wei-keng Liao</li>
<li class=""><strong>institution:</strong> Northwestern University, Lawrence Berkeley National Laboratory, Inha University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25170" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25170</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a Multi-Resolution Model Fusion method that accelerates CNN training by first training models on reduced-resolution data and then fine-tuning with original resolution data. This approach speeds up convergence while maintaining model accuracy. Experiments show training time improvements of up to 47% and 44% on scientific applications without affecting accuracy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251030] Machine Learning and CPU (Central Processing Unit) Scheduling Co-Optimization over a Network of Computing Centers</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [distributed machine learning, CPU scheduling, consensus algorithm, quantization, Lyapunov stability, eigen-spectrum analysis]</li>
<li class=""><strong>authors:</strong> Mohammadreza Doostmohammadian, Zulfiya R. Gabidullina, Hamid R. Rabiee</li>
<li class=""><strong>institution:</strong> Sharif University of Technology, Kazan Federal University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25176" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25176</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a co-optimization algorithm that simultaneously trains machine learning models on distributed computing nodes while optimally allocating CPU resources across a network. The method ensures all-time feasibility and handles time-varying networks with quantization constraints. Results show the approach reduces the cost optimality gap by over 50% compared to existing CPU scheduling solutions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251030] The Singularity Theory of Concurrent Programs: A Topological Characterization and Detection of Deadlocks and Livelocks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [concurrency verification], [algebraic topology, homotopy groups, homology groups, topological invariants, branched topological space]</li>
<li class=""><strong>authors:</strong> Di Zhang</li>
<li class=""><strong>institution:</strong> Xi&#x27;an Jiaotong-Liverpool University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25112" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25112</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a topological framework called Singularity Theory that models concurrent program execution spaces as branched topological spaces. It uses algebraic topology tools like homotopy and homology groups to characterize deadlocks as attractors and livelocks as non-contractible loops. The method enables systematic detection of concurrency errors without exhaustive state-space exploration, overcoming limitations of traditional model checking.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251030] Effect of Full Common Randomness Replication in Symmetric PIR on Graph-Based Replicated Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [information theory], [symmetric private information retrieval, graph-based replication, common randomness, capacity bounds]</li>
<li class=""><strong>authors:</strong> Shreya Meel, Sennur Ulukus</li>
<li class=""><strong>institution:</strong> University of Maryland</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25736" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25736</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper develops an algorithm to convert PIR schemes into SPIR schemes for graph-based replicated systems where databases are distributed across servers according to graph edges. The authors show that using full common randomness replication across all servers improves SPIR capacity compared to graph-replicated common randomness, specifically achieving a capacity of 1/2 for path graphs with three vertices.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251030] A Privacy-Preserving Ecosystem for Developing Machine Learning Algorithms Using Patient Data: Insights from the TUM.ai Makeathon</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, clinical knowledge graph, simulated data, protected execution environment, multi-omics data]</li>
<li class=""><strong>authors:</strong> Simon Süwer, Mai Khanh Mai, Christoph Klein, Nicola Götzenberger, Denis Dalić, Andreas Maier, Jan Baumbach</li>
<li class=""><strong>institution:</strong> University of Hamburg, Ludwig-Maximilians-Universität München, University of Southern Denmark</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25277" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25277</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a privacy-preserving AI development approach using simulated clinical knowledge graphs and federated learning through FeatureCloud framework. This method allows model development on synthetic data structures followed by secure training within hospital environments without exposing sensitive patient data. The approach was successfully validated in a makeathon challenge where students developed diagnostic models while maintaining data privacy compliance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251030] Timing Games in Responsive Consensus Protocols</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain consensus], [timing games, prisoner&#x27;s dilemma, dynamic block rewards, voting mechanism, optimistic responsiveness]</li>
<li class=""><strong>authors:</strong> Kaya Alpturer, Kushal Babel, Aditya Saraf</li>
<li class=""><strong>institution:</strong> Princeton University, Category Labs, Cornell University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25144" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25144</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces dynamic block rewards that decrease with round time and a voting mechanism to measure delays, addressing timing games in responsive consensus protocols. It shows that by carefully setting protocol parameters, validators can coordinate to reach cooperative equilibria where responsiveness promotes faster block proposals. The analysis demonstrates this approach effectively mitigates timing game issues while having only minor effects on latency disparities between validators.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251030] Radar DataTree: A FAIR and Cloud-Native Framework for Scalable Weather Radar Archives</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [weather data infrastructure], [xarray DataTree, Zarr, FM-301/CfRadial 2.1, Icechunk, ACID-compliant storage]</li>
<li class=""><strong>authors:</strong> Alfonso Ladino-Rincon, Stephen W. Nesbitt</li>
<li class=""><strong>institution:</strong> University of Illinois Urbana-Champaign</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24943" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24943</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Radar DataTree introduces a cloud-native framework that transforms fragmented weather radar archives into FAIR-compliant datasets using hierarchical organization with xarray DataTree and Zarr storage. The system enables efficient parallel computation across thousands of radar scans with minimal preprocessing. Case studies demonstrate significant performance gains in meteorological workflows while providing a reproducible foundation for radar data stewardship and high-performance geoscience.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251030] Can Like Attract Like? A Study of Homonymous Gathering in Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed algorithms], [deterministic algorithm, mobile agents, synchronous rounds, termination detection]</li>
<li class=""><strong>authors:</strong> Stéphane Devismes, Yoann Dieudonné, Arnaud Labourel</li>
<li class=""><strong>institution:</strong> Université de Picardie Jules Verne, Aix Marseille University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25451" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25451</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper studies the gathering problem for mobile agents in networks where agents may share identical labels. The authors provide a complete characterization of gatherable teams and design a deterministic algorithm that gathers all such teams in polynomial time with minimal common knowledge. They also show their approach achieves near-optimal dependency on common knowledge and provides the first deterministic poly-time algorithm for gathering teams with distinct labels without requiring common knowledge.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251030] MoEntwine: Unleashing the Potential of Wafer-scale Chips for Large-scale Expert Parallel Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [expert parallelism, wafer-scale chips, mesh topology, entwined ring mapping, non-invasive balancer, communication optimization]</li>
<li class=""><strong>authors:</strong> Xinru Tang, Jingxiang Hou, Dingcheng Jiang, Taiquan Wei, Jiaxin Liu, Jinyi Deng, Huizheng Wang, Qize Yang, Haoran Shang, Chao Li, Yang Hu, Shouyi Yin</li>
<li class=""><strong>institution:</strong> Tsinghua University, Shanghai Jiao Tong University, Shanghai Artificial Intelligence Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25258" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25258</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes MoEntwine, a system that optimizes mixture-of-experts model inference on wafer-scale chips through two key techniques: ER-Mapping for balanced communication pressure and NI-Balancer for hiding expert migration overhead. The methods achieve significant communication reduction (up to 62%) and performance improvements in both computation (54%) and communication (22%). Compared to state-of-the-art GPU clusters, the wafer-scale platform delivers 39% higher per-device MoE performance due to better scalability for expert parallelism.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251030] CFL-SparseMed: Communication-Efficient Federated Learning for Medical Imaging with Top-k Sparse Updates</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Top-K Sparsification, Federated Learning, Non-IID Data, Medical Imaging, Communication Efficiency]</li>
<li class=""><strong>authors:</strong> Gousia Habib, Aniket Bhardwaj, Ritvik Sharma, Shoeib Amin Banday, Ishfaq Ahmad Malik</li>
<li class=""><strong>institution:</strong> University of Helsinki, Shoolini University, King Khalid University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24776" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24776</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes CFL-SparseMed, a federated learning approach that uses Top-k gradient sparsification to reduce communication overhead in medical imaging applications. The method effectively handles non-IID data heterogeneity while maintaining model accuracy, improving FL efficiency and preserving privacy for better diagnostic outcomes.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251030] Holon Streaming: Global Aggregations with Windowed CRDTs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [stream processing], [Windowed CRDTs, decentralized coordination, global aggregations, exactly-once processing]</li>
<li class=""><strong>authors:</strong> Jonas Spenger, Kolya Krafeld, Ruben van Gemeren, Philipp Haller, Paris Carbone</li>
<li class=""><strong>institution:</strong> KTH Royal Institute of Technology, RISE Research Institutes of Sweden</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25757" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25757</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents Holon Streaming, a stream processing system that uses Windowed Conflict-Free Replicated Data Types (CRDTs) to enable scalable global aggregations through decentralized coordination. The system achieves 5x lower latency and 2x higher throughput compared to existing approaches, with particularly significant improvements during failure scenarios. The research demonstrates that decentralized coordination with deterministic programming models can effectively overcome scalability bottlenecks in stream processing systems.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 19</strong></p>
<ul>
<li class="">[arXiv251030] KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA <a href="https://arxiv.org/pdf/2510.25101" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Reasoning-Aware GRPO using Process Mining <a href="https://arxiv.org/pdf/2510.25065" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Enhancing Hierarchical Reinforcement Learning through Change Point Detection in Time Series <a href="https://arxiv.org/pdf/2510.24988" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision <a href="https://arxiv.org/pdf/2510.25205" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Off-policy Reinforcement Learning with Model-based Exploration Augmentation <a href="https://arxiv.org/pdf/2510.25529" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models <a href="https://arxiv.org/pdf/2510.25206" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Learning to Attack: Uncovering Privacy Risks in Sequential Data Releases <a href="https://arxiv.org/pdf/2510.24807" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Zero Reinforcement Learning Towards General Domains <a href="https://arxiv.org/pdf/2510.25528" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] One-shot Humanoid Whole-body Motion Learning <a href="https://arxiv.org/pdf/2510.25241" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Dense and Diverse Goal Coverage in Multi Goal Reinforcement Learning <a href="https://arxiv.org/pdf/2510.25311" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data <a href="https://arxiv.org/pdf/2510.25223" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] LRT-Diffusion: Calibrated Risk-Aware Guidance for Diffusion Policies <a href="https://arxiv.org/pdf/2510.24983" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL <a href="https://arxiv.org/pdf/2510.25510" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2510.25679" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning <a href="https://arxiv.org/pdf/2510.25320" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents <a href="https://arxiv.org/pdf/2510.25668" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork <a href="https://arxiv.org/pdf/2510.25340" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Learning to Plan &amp; Schedule with Reinforcement-Learned Bimanual Robot Skills <a href="https://arxiv.org/pdf/2510.25634" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Scheduling Your LLM Reinforcement Learning with Reasoning Trees <a href="https://arxiv.org/pdf/2510.24832" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 14</strong></p>
<ul>
<li class="">[arXiv251030] INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats <a href="https://arxiv.org/pdf/2510.25602" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] TV-Rec: Time-Variant Convolutional Filter for Sequential Recommendation <a href="https://arxiv.org/pdf/2510.25259" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] BSFA: Leveraging the Subspace Dichotomy to Accelerate Neural Network Training <a href="https://arxiv.org/pdf/2510.25244" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Enhancing Hierarchical Reinforcement Learning through Change Point Detection in Time Series <a href="https://arxiv.org/pdf/2510.24988" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] RegionE: Adaptive Region-Aware Generation for Efficient Image Editing <a href="https://arxiv.org/pdf/2510.25590" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip Attack Resilience in Transformer Models <a href="https://arxiv.org/pdf/2510.24985" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] ESCA: Enabling Seamless Codec Avatar Execution through Algorithm and Hardware Co-Optimization for Virtual Reality <a href="https://arxiv.org/pdf/2510.24787" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] CDFlow: Building Invertible Layers with Circulant and Diagonal Matrices <a href="https://arxiv.org/pdf/2510.25323" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Resource-Efficient and Robust Inference of Deep and Bayesian Neural Networks on Embedded and Analog Computing Platforms <a href="https://arxiv.org/pdf/2510.24951" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] RLMEval: Evaluating Research-Level Neural Theorem Proving <a href="https://arxiv.org/pdf/2510.25427" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Learning to Plan &amp; Schedule with Reinforcement-Learned Bimanual Robot Skills <a href="https://arxiv.org/pdf/2510.25634" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Idea2Plan: Exploring AI-Powered Research Planning <a href="https://arxiv.org/pdf/2510.24891" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] Hawk: Leveraging Spatial Context for Faster Autoregressive Text-to-Image Generation <a href="https://arxiv.org/pdf/2510.25739" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251030] MLPrE -- A tool for preprocessing and exploratory data analysis prior to machine learning model construction <a href="https://arxiv.org/pdf/2510.25755" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-10-31">2025-10-31<a href="#2025-10-31" class="hash-link" aria-label="Direct link to 2025-10-31" title="Direct link to 2025-10-31" translate="no">​</a></h2>
<p><strong>cs.DC total: 8</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251031] Foundations of Fiat-Denominated Loans Collateralized by Cryptocurrencies</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain finance], [limited-custodial protocols, trusted arbitration, game-theoretical analysis, subgame perfect equilibrium]</li>
<li class=""><strong>authors:</strong> Pavel Hubáček, Jan Václavek, Michelle Yeo</li>
<li class=""><strong>institution:</strong> Czech Academy of Sciences, Charles University, Firefish, National University of Singapore</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25878" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25878</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper develops secure limited-custodial protocols for fiat-denominated loans collateralized by cryptocurrencies using trusted arbitration. The authors provide a game-theoretical analysis showing these protocols achieve subgame perfect equilibrium. The work establishes foundations for cryptocurrency-backed lending while highlighting future research directions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251031] ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [adaptive expert prefetching, cache-aware routing, hybrid cross-layer prediction, runtime statistics optimization]</li>
<li class=""><strong>authors:</strong> Zixu Shen, Kexin Chu, Yifan Zhang, Dawei Xiang, Runxin Wu, Wei Zhang</li>
<li class=""><strong>institution:</strong> University of Connecticut</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26730" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26730</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ExpertFlow introduces an adaptive runtime system that combines expert prefetching and cache-aware routing to optimize MoE inference. It continuously adjusts prediction horizons using runtime statistics and fuses pregating information with computational states to anticipate expert needs. The system reduces model stall time to less than 0.1% of baseline, demonstrating efficient MoE inference under memory constraints.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251031] Detecting Anomalies in Machine Learning Infrastructure via Hardware Telemetry</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [hardware telemetry, unsupervised learning, anomaly detection, hardware-centric approach]</li>
<li class=""><strong>authors:</strong> Ziji Chen, Steven Chien, Peng Qian, Noa Zilberman</li>
<li class=""><strong>institution:</strong> University of Oxford</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26008" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26008</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a hardware-centric approach called Reveal that uses hardware telemetry and unsupervised learning to detect anomalies in ML infrastructure without requiring workload knowledge. The system analyzes low-level hardware signals accessible to cloud operators to identify performance issues. This method successfully identified network and configuration problems, accelerating the DeepSeek model by 5.97% while maintaining operator privacy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251031] Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [over-the-air federated learning, stochastic gradient descent, successive convex approximation, power-control design, bias-variance trade-off]</li>
<li class=""><strong>authors:</strong> Muhammad Faraz Ul Abrar, Nicolò Michelusi</li>
<li class=""><strong>institution:</strong> Arizona State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26722" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26722</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a novel over-the-air federated learning approach that allows structured model bias to reduce variance in heterogeneous wireless environments. The method develops a joint power-control design optimized via successive convex approximation using only statistical channel state information. Experiments show this approach accelerates convergence and improves generalization compared to existing baselines by optimizing the bias-variance trade-off.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251031] An All-Reduce Compatible Top-K Compressor for Communication-Efficient Distributed Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [gradient sparsification, all-reduce, error feedback, top-k compression, communication compression]</li>
<li class=""><strong>authors:</strong> Chuyan Chen, Chenyang Ma, Zhangxin Li, Yutong He, Yanjie Dong, Kun Yuan</li>
<li class=""><strong>institution:</strong> Peking University, Shenzhen MSU-BIT University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26709" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26709</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ARC-Top-K, an All-Reduce compatible Top-K compressor that aligns sparsity patterns across nodes using gradient sketches to enable efficient communication. This method preserves contraction properties while avoiding costly All-Gather operations. Empirical results show it matches Top-K accuracy while reducing training time by up to 60.7%, combining Rand-K&#x27;s robustness with Top-K&#x27;s performance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251031] Wireless Sensor Networks as Parallel and Distributed Hardware Platform for Artificial Neural Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [wireless sensor networks, parallel distributed processing, artificial neural networks, real-time computation, large-scale problems]</li>
<li class=""><strong>authors:</strong> Gursel Serpen</li>
<li class=""><strong>institution:</strong> The University of Toledo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26492" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26492</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using wireless sensor networks as a massively parallel and distributed hardware platform to implement artificial neural network algorithms. The approach enables real-time computation of large-scale complex problems by leveraging hundreds of thousands of processing nodes with onboard processing and wireless communication capabilities. This implementation could revolutionize computing by making it possible to solve very large-scale scientific and engineering problems in real time through massive parallelism and distributed computing.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251031] ReSpec: Towards Optimizing Speculative Decoding in Reinforcement Learning Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [speculative decoding, reinforcement learning, knowledge distillation, dynamic configuration tuning, reward-weighted updates]</li>
<li class=""><strong>authors:</strong> Qiaoling Chen, Zijun Liu, Peng Sun, Shenggui Li, Guoteng Wang, Ziming Liu, Yonggang Wen, Siyuan Feng, Tianwei Zhang</li>
<li class=""><strong>institution:</strong> Nanyang Technological University, Shanghai Qiji Zhifeng Co., Ltd., Tsinghua University, National University of Singapore, Shanghai Innovation Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26475" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26475</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ReSpec optimizes speculative decoding for RL-based LLM training by dynamically tuning configurations, updating drafters via knowledge distillation, and weighting updates with rollout rewards. The system achieves up to 4.5× speedup while maintaining reward convergence and training stability, providing an efficient solution for RL adaptation of large language models.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251031] Environmental Impact of CI/CD Pipelines</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud computing sustainability], [Cloud Carbon Footprint framework, workflow analysis, computational resource optimization]</li>
<li class=""><strong>authors:</strong> Nuno Saavedra, Alexandra Mendes, João F. Ferreira</li>
<li class=""><strong>institution:</strong> INESC-ID, University of Lisbon, INESC TEC, University of Porto</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26413" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26413</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This study analyzes the environmental impact of GitHub Actions CI/CD pipelines using the Cloud Carbon Footprint framework on a dataset of over 2.2 million workflow runs. The research reveals substantial carbon and water footprints, estimating 456.9 MTCO2e and 5,738.2 kiloliters respectively in the most likely scenario. The paper recommends mitigation strategies including regional deployment optimization, stricter scheduling policies, and repository size reduction to reduce environmental impact.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 32</strong></p>
<ul>
<li class="">[arXiv251031] GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks <a href="https://arxiv.org/pdf/2510.26098" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Conformal Prediction Beyond the Horizon: Distribution-Free Inference for Policy Evaluation <a href="https://arxiv.org/pdf/2510.26026" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Do Not Step Into the Same River Twice: Learning to Reason from Trial and Error <a href="https://arxiv.org/pdf/2510.26109" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle <a href="https://arxiv.org/pdf/2510.26347" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] MedVLSynther: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs <a href="https://arxiv.org/pdf/2510.25867" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Adaptive Context Length Optimization with Low-Frequency Truncation for Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2510.26389" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Estimating cognitive biases with attention-aware inverse planning <a href="https://arxiv.org/pdf/2510.25951" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Human-in-the-loop Online Rejection Sampling for Robotic Manipulation <a href="https://arxiv.org/pdf/2510.26406" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Approximating Human Preferences Using a Multi-Judge Learned System <a href="https://arxiv.org/pdf/2510.25884" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Learning to Manage Investment Portfolios beyond Simple Utility Functions <a href="https://arxiv.org/pdf/2510.26165" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Data-Efficient RLVR via Off-Policy Influence Guidance <a href="https://arxiv.org/pdf/2510.26491" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start <a href="https://arxiv.org/pdf/2510.25801" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Kimi Linear: An Expressive, Efficient Attention Architecture <a href="https://arxiv.org/pdf/2510.26692" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math <a href="https://arxiv.org/pdf/2510.26143" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning <a href="https://arxiv.org/pdf/2510.25992" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Action-Driven Processes for Continuous-Time Control <a href="https://arxiv.org/pdf/2510.26672" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Graph-Enhanced Policy Optimization in LLM Agent Training <a href="https://arxiv.org/pdf/2510.26270" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mtext mathvariant="monospace">RL</mtext></msub></mrow><annotation encoding="application/x-tex">π_\texttt{RL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2778em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord texttt mtight">RL</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: Online RL Fine-tuning for Flow-based Vision-Language-Action Models <a href="https://arxiv.org/pdf/2510.25889" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning <a href="https://arxiv.org/pdf/2510.26167" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] A Game-Theoretic Spatio-Temporal Reinforcement Learning Framework for Collaborative Public Resource Allocation <a href="https://arxiv.org/pdf/2510.26184" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] A General Incentives-Based Framework for Fairness in Multi-agent Resource Allocation <a href="https://arxiv.org/pdf/2510.26740" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Think Outside the Policy: In-Context Steered Policy Optimization <a href="https://arxiv.org/pdf/2510.26519" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Multi-Agent Reinforcement Learning for Market Making: Competition without Collusion <a href="https://arxiv.org/pdf/2510.25929" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Non-myopic Matching and Rebalancing in Large-Scale On-Demand Ride-Pooling Systems Using Simulation-Informed Reinforcement Learning <a href="https://arxiv.org/pdf/2510.25796" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Defeating the Training-Inference Mismatch via FP16 <a href="https://arxiv.org/pdf/2510.26788" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] PORTool: Tool-Use LLM Training with Rewarded Tree <a href="https://arxiv.org/pdf/2510.26020" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] EgoExo-Con: Exploring View-Invariant Video Temporal Understanding <a href="https://arxiv.org/pdf/2510.26113" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle Routing <a href="https://arxiv.org/pdf/2510.26089" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] InputDSA: Demixing then Comparing Recurrent and Externally Driven Dynamics <a href="https://arxiv.org/pdf/2510.25943" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] InfoFlow: Reinforcing Search Agent Via Reward Density Optimization <a href="https://arxiv.org/pdf/2510.26575" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] The Era of Agentic Organization: Learning to Organize with Language Models <a href="https://arxiv.org/pdf/2510.26658" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Offline Clustering of Preference Learning with Active-data Augmentation <a href="https://arxiv.org/pdf/2510.26301" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 9</strong></p>
<ul>
<li class="">[arXiv251031] Risks and Opportunities in Human-Machine Teaming in Operationalizing Machine Learning Target Variables <a href="https://arxiv.org/pdf/2510.25974" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] PRESTO: Preimage-Informed Instruction Optimization for Prompting Black-Box LLMs <a href="https://arxiv.org/pdf/2510.25808" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Data-Efficient RLVR via Off-Policy Influence Guidance <a href="https://arxiv.org/pdf/2510.26491" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache <a href="https://arxiv.org/pdf/2510.25979" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] The FM Agent <a href="https://arxiv.org/pdf/2510.26144" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] FlowQ-Net: A Generative Framework for Automated Quantum Circuit Design <a href="https://arxiv.org/pdf/2510.26688" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation <a href="https://arxiv.org/pdf/2510.25904" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] Polybasic Speculative Decoding Through a Theoretical Perspective <a href="https://arxiv.org/pdf/2510.26527" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251031] The Kinetics of Reasoning: How Chain-of-Thought Shapes Learning in Transformers? <a href="https://arxiv.org/pdf/2510.25791" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-11-01">2025-11-01<a href="#2025-11-01" class="hash-link" aria-label="Direct link to 2025-11-01" title="Direct link to 2025-11-01" translate="no">​</a></h2>
<p><strong>cs.DC total: 8</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251101] Detecting Anomalies in Machine Learning Infrastructure via Hardware Telemetry</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [hardware telemetry, unsupervised learning, anomaly detection, performance optimization]</li>
<li class=""><strong>authors:</strong> Ziji Chen, Steven Chien, Peng Qian, Noa Zilberman</li>
<li class=""><strong>institution:</strong> University of Oxford</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26008" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26008</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes System-X/Reveal, a hardware-centric framework that uses low-level hardware telemetry and unsupervised learning to detect anomalies in ML infrastructure. This approach enables performance optimization without requiring workload knowledge from virtualized cloud environments. The system successfully identified configuration issues and accelerated the DeepSeek model by 5.97%.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251101] Foundations of Fiat-Denominated Loans Collateralized by Cryptocurrencies</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [decentralized finance], [trusted arbitration, game-theoretical analysis, subgame perfect equilibrium, limited-custodial protocols]</li>
<li class=""><strong>authors:</strong> Pavel Hubáček, Jan Václavek, Michelle Yeo</li>
<li class=""><strong>institution:</strong> Czech Academy of Sciences, Charles University, National University of Singapore, Firefish</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25878" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25878</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes secure protocols for fiat-denominated loans collateralized by cryptocurrencies using trusted arbitration and limited-custodial approaches. The authors provide game-theoretical analysis showing these protocols achieve subgame perfect equilibrium. The work establishes foundations for cryptocurrency-backed lending systems while highlighting future research directions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251101] Wireless Sensor Networks as Parallel and Distributed Hardware Platform for Artificial Neural Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [wireless sensor networks, parallel distributed processing, artificial neural networks, real-time computation, large-scale problems]</li>
<li class=""><strong>authors:</strong> Gursel Serpen</li>
<li class=""><strong>institution:</strong> The University of Toledo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26492" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26492</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using wireless sensor networks as a massively parallel and distributed hardware platform to implement artificial neural network algorithms. The method leverages networks of processing nodes with onboard computation and wireless communication capabilities to enable real-time solutions for large-scale complex problems. The authors conclude this approach could revolutionize computing by making affordable, practical neural network solutions possible for very large-scale scientific and engineering applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251101] ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [adaptive expert prefetching, cache-aware routing, hybrid cross-layer prediction, runtime statistics, memory coordination]</li>
<li class=""><strong>authors:</strong> Zixu Shen, Kexin Chu, Yifan Zhang, Dawei Xiang, Runxin Wu, Wei Zhang</li>
<li class=""><strong>institution:</strong> University of Connecticut</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26730" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26730</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ExpertFlow introduces an adaptive runtime system for MoE inference that combines expert prefetching and cache-aware routing using runtime statistics and hybrid prediction. It dynamically adjusts prediction horizons and fuses pregating information with computational states to anticipate expert needs. The system reduces model stall time to less than 0.1% of baseline, demonstrating efficient MoE inference under memory constraints.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251101] Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [over-the-air federated learning, stochastic gradient descent, successive convex approximation, power-control design, bias-variance trade-off]</li>
<li class=""><strong>authors:</strong> Muhammad Faraz Ul Abrar, Nicolò Michelusi</li>
<li class=""><strong>institution:</strong> Arizona State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26722" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26722</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper develops a novel over-the-air federated learning approach that allows structured model bias to reduce variance under heterogeneous wireless conditions. The method uses successive convex approximation for joint power-control optimization requiring only statistical channel state information. Experiments show this approach accelerates convergence and improves generalization compared to prior baselines by optimizing the bias-variance trade-off.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251101] An All-Reduce Compatible Top-K Compressor for Communication-Efficient Distributed Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [gradient sparsification, All-Reduce, Top-K compression, error feedback, communication compression]</li>
<li class=""><strong>authors:</strong> Chuyan Chen, Chenyang Ma, Zhangxin Li, Yutong He, Yanjie Dong, Kun Yuan</li>
<li class=""><strong>institution:</strong> Peking University, Shenzhen MSU-BIT University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26709" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26709</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ARC-Top-K, an All-Reduce compatible Top-K compressor that aligns sparsity patterns across nodes using gradient sketches to enable efficient distributed training. This method preserves globally significant gradient information while avoiding costly All-Gather operations. Empirical results show it matches Top-K accuracy while reducing training time by up to 60.7%, combining Rand-K&#x27;s robustness with Top-K&#x27;s performance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251101] Environmental Impact of CI/CD Pipelines</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud computing sustainability], [carbon footprint analysis, water footprint analysis, GitHub Actions workflow analysis, Cloud Carbon Footprint framework]</li>
<li class=""><strong>authors:</strong> Nuno Saavedra, Alexandra Mendes, João F. Ferreira</li>
<li class=""><strong>institution:</strong> INESC-ID, University of Lisbon, INESC TEC, University of Porto</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26413" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26413</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This study analyzes the environmental impact of GitHub Actions CI/CD pipelines using the Cloud Carbon Footprint framework on a dataset of over 2.2 million workflow runs. The research reveals substantial carbon and water footprints, estimating 456.9 MTCO2e carbon emissions and 5,738.2 kiloliters water consumption in the most likely scenario. The paper recommends mitigation strategies including regional deployment optimization, stricter deactivation policies, and repository size reduction.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251101] ReSpec: Towards Optimizing Speculative Decoding in Reinforcement Learning Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [speculative decoding, reinforcement learning, knowledge distillation, EAGLE-3, policy optimization]</li>
<li class=""><strong>authors:</strong> Qiaoling Chen, Zijun Liu, Peng Sun, Shenggui Li, Guoteng Wang, Ziming Liu, Yonggang Wen, Siyuan Feng, Tianwei Zhang</li>
<li class=""><strong>institution:</strong> Nanyang Technological University, Shanghai Qiji Zhifeng Co., Ltd., Tsinghua University, National University of Singapore, Shanghai Innovation Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26475" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26475</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces ReSpec, a system that optimizes speculative decoding for reinforcement learning-based LLM training by dynamically tuning configurations, updating drafters via knowledge distillation, and weighting updates with rollout rewards. The method achieves up to 4.5× speedup while maintaining reward convergence and training stability, providing an efficient solution for RL-based LLM adaptation.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 32</strong></p>
<ul>
<li class="">[arXiv251101] EgoExo-Con: Exploring View-Invariant Video Temporal Understanding <a href="https://arxiv.org/pdf/2510.26113" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Graph-Enhanced Policy Optimization in LLM Agent Training <a href="https://arxiv.org/pdf/2510.26270" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle Routing <a href="https://arxiv.org/pdf/2510.26089" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] InfoFlow: Reinforcing Search Agent Via Reward Density Optimization <a href="https://arxiv.org/pdf/2510.26575" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] A General Incentives-Based Framework for Fairness in Multi-agent Resource Allocation <a href="https://arxiv.org/pdf/2510.26740" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Data-Efficient RLVR via Off-Policy Influence Guidance <a href="https://arxiv.org/pdf/2510.26491" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Kimi Linear: An Expressive, Efficient Attention Architecture <a href="https://arxiv.org/pdf/2510.26692" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Offline Clustering of Preference Learning with Active-data Augmentation <a href="https://arxiv.org/pdf/2510.26301" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks <a href="https://arxiv.org/pdf/2510.26098" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] MedVLSynther: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs <a href="https://arxiv.org/pdf/2510.25867" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Do Not Step Into the Same River Twice: Learning to Reason from Trial and Error <a href="https://arxiv.org/pdf/2510.26109" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Defeating the Training-Inference Mismatch via FP16 <a href="https://arxiv.org/pdf/2510.26788" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle <a href="https://arxiv.org/pdf/2510.26347" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] InputDSA: Demixing then Comparing Recurrent and Externally Driven Dynamics <a href="https://arxiv.org/pdf/2510.25943" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Adaptive Context Length Optimization with Low-Frequency Truncation for Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2510.26389" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Approximating Human Preferences Using a Multi-Judge Learned System <a href="https://arxiv.org/pdf/2510.25884" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] The Era of Agentic Organization: Learning to Organize with Language Models <a href="https://arxiv.org/pdf/2510.26658" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math <a href="https://arxiv.org/pdf/2510.26143" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Human-in-the-loop Online Rejection Sampling for Robotic Manipulation <a href="https://arxiv.org/pdf/2510.26406" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Conformal Prediction Beyond the Horizon: Distribution-Free Inference for Policy Evaluation <a href="https://arxiv.org/pdf/2510.26026" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start <a href="https://arxiv.org/pdf/2510.25801" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Learning to Manage Investment Portfolios beyond Simple Utility Functions <a href="https://arxiv.org/pdf/2510.26165" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning <a href="https://arxiv.org/pdf/2510.26167" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] A Game-Theoretic Spatio-Temporal Reinforcement Learning Framework for Collaborative Public Resource Allocation <a href="https://arxiv.org/pdf/2510.26184" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning <a href="https://arxiv.org/pdf/2510.25992" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Action-Driven Processes for Continuous-Time Control <a href="https://arxiv.org/pdf/2510.26672" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Estimating cognitive biases with attention-aware inverse planning <a href="https://arxiv.org/pdf/2510.25951" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mtext mathvariant="monospace">RL</mtext></msub></mrow><annotation encoding="application/x-tex">π_\texttt{RL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2778em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord texttt mtight">RL</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: Online RL Fine-tuning for Flow-based Vision-Language-Action Models <a href="https://arxiv.org/pdf/2510.25889" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Non-myopic Matching and Rebalancing in Large-Scale On-Demand Ride-Pooling Systems Using Simulation-Informed Reinforcement Learning <a href="https://arxiv.org/pdf/2510.25796" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Think Outside the Policy: In-Context Steered Policy Optimization <a href="https://arxiv.org/pdf/2510.26519" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Multi-Agent Reinforcement Learning for Market Making: Competition without Collusion <a href="https://arxiv.org/pdf/2510.25929" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] PORTool: Tool-Use LLM Training with Rewarded Tree <a href="https://arxiv.org/pdf/2510.26020" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 9</strong></p>
<ul>
<li class="">[arXiv251101] Data-Efficient RLVR via Off-Policy Influence Guidance <a href="https://arxiv.org/pdf/2510.26491" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] PRESTO: Preimage-Informed Instruction Optimization for Prompting Black-Box LLMs <a href="https://arxiv.org/pdf/2510.25808" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] The FM Agent <a href="https://arxiv.org/pdf/2510.26144" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Risks and Opportunities in Human-Machine Teaming in Operationalizing Machine Learning Target Variables <a href="https://arxiv.org/pdf/2510.25974" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache <a href="https://arxiv.org/pdf/2510.25979" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] FlowQ-Net: A Generative Framework for Automated Quantum Circuit Design <a href="https://arxiv.org/pdf/2510.26688" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] The Kinetics of Reasoning: How Chain-of-Thought Shapes Learning in Transformers? <a href="https://arxiv.org/pdf/2510.25791" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation <a href="https://arxiv.org/pdf/2510.25904" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251101] Polybasic Speculative Decoding Through a Theoretical Perspective <a href="https://arxiv.org/pdf/2510.26527" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-11-01T02:25:43.000Z" itemprop="dateModified">Nov 1, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/category/daily"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Daily</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-10-27" class="table-of-contents__link toc-highlight">2025-10-27</a></li><li><a href="#2025-10-28" class="table-of-contents__link toc-highlight">2025-10-28</a></li><li><a href="#2025-10-29" class="table-of-contents__link toc-highlight">2025-10-29</a></li><li><a href="#2025-10-30" class="table-of-contents__link toc-highlight">2025-10-30</a></li><li><a href="#2025-10-31" class="table-of-contents__link toc-highlight">2025-10-31</a></li><li><a href="#2025-11-01" class="table-of-contents__link toc-highlight">2025-11-01</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>