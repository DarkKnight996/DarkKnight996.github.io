<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20251027-20251102" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251027-20251102 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20251027-20251102"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251027-20251102 | DarkKnight Note"><meta data-rh="true" name="description" content="2025-10-27"><meta data-rh="true" property="og:description" content="2025-10-27"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20251027-20251102"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20251027-20251102" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20251027-20251102" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20251027-20251102","item":"https://darkknight996.github.io/daily/20251027-20251102"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.944b48de.js" defer="defer"></script>
<script src="/assets/js/main.d8bc8af4.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20250901-20250907"><span title="20250901-20250907" class="linkLabel_WmDU">20250901-20250907</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20250908-20250914"><span title="20250908-20250914" class="linkLabel_WmDU">20250908-20250914</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20250915-20250921"><span title="20250915-20250921" class="linkLabel_WmDU">20250915-20250921</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20250922-20250928"><span title="20250922-20250928" class="linkLabel_WmDU">20250922-20250928</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20250929-20251005"><span title="20250929-20251005" class="linkLabel_WmDU">20250929-20251005</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251006-20251012"><span title="20251006-20251012" class="linkLabel_WmDU">20251006-20251012</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251013-20251019"><span title="20251013-20251019" class="linkLabel_WmDU">20251013-20251019</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251020-20251026"><span title="20251020-20251026" class="linkLabel_WmDU">20251020-20251026</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251027-20251102</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251027-20251102</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-10-27">2025-10-27<a href="#2025-10-27" class="hash-link" aria-label="Direct link to 2025-10-27" title="Direct link to 2025-10-27" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv2510] Learning to Schedule: A Supervised Learning Framework for Network-Aware
Scheduling of Data-Intensive Workloads</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [scheduling], [network-aware scheduling, supervised learning, data-intensive workloads, Kubernetes, job completion time prediction]</li>
<li class=""><strong>authors:</strong> Sankalpa Timilsina, Susmit Shannigrahi</li>
<li class=""><strong>institution:</strong> Tennessee Technological University</li>
<li class=""><strong>link:</strong> <a href="http://arxiv.org/pdf/2510.21419v1" target="_blank" rel="noopener noreferrer" class="">http://arxiv.org/pdf/2510.21419v1</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a network-aware job scheduler using supervised learning to predict job completion times based on real-time cluster telemetry. The system employs a prediction-and-ranking mechanism that evaluates nodes and selects optimal placements for data-intensive workloads. Evaluation on a geo-distributed Kubernetes cluster showed 34-54% higher accuracy in node selection compared to the default Kubernetes scheduler.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv2510] From SLA to vendor-neutral metrics: An intelligent knowledge-based
approach for multi-cloud SLA-based broker</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [cloud computing, multi-cloud, SLA management, vendor-neutral metrics, intelligent knowledge-based system, auto-scaling]</li>
<li class=""><strong>authors:</strong> Víctor Rampérez, Javier Soriano, David Lizcano, Shadi Aljawarneh, Juan A. Lara</li>
<li class=""><strong>institution:</strong> Universidad Politécnica de Madrid (UPM), Madrid Open University (UDIMA)</li>
<li class=""><strong>link:</strong> <a href="http://arxiv.org/pdf/2510.21173v1" target="_blank" rel="noopener noreferrer" class="">http://arxiv.org/pdf/2510.21173v1</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an intelligent knowledge-based system that automatically translates high-level SLAs into vendor-neutral metrics for multi-cloud environments. The approach enables cross-provider metric measurement and provides consumer feedback through an intelligent tutoring system. Validation with IaaS and PaaS use cases demonstrates the system allows transparent multi-cloud exploitation across various application domains.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv2510] xMem: A CPU-Based Approach for Accurate Estimation of GPU Memory in Deep
Learning Training Workloads</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [GPU memory estimation, dynamic analysis, resource management, scheduling]</li>
<li class=""><strong>authors:</strong> Jiabo Shi, Dimitrios Pezaros, Yehia Elkhatib</li>
<li class=""><strong>institution:</strong> University of Glasgow</li>
<li class=""><strong>link:</strong> <a href="http://arxiv.org/pdf/2510.21048v1" target="_blank" rel="noopener noreferrer" class="">http://arxiv.org/pdf/2510.21048v1</a></li>
<li class=""><strong>Simple LLM Summary:</strong> xMem proposes a CPU-based dynamic analysis framework to accurately estimate peak GPU memory requirements for deep learning training workloads without consuming GPU resources. The method achieves 91% reduction in median relative error and 75% reduction in OOM probability compared to existing solutions. This enables better GPU sharing and scheduling in cluster environments while significantly improving memory conservation potential.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv2510] Lincoln AI Computing Survey (LAICS) and Trends</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [Other models training, Other models inference], [AI accelerators, performance analysis, power consumption, market segmentation, computing architectures]</li>
<li class=""><strong>authors:</strong> Albert Reuther, Peter Michaleas, Michael Jones, Vijay Gadepally, Jeremy Kepner</li>
<li class=""><strong>institution:</strong> MIT Lincoln Laboratory</li>
<li class=""><strong>link:</strong> <a href="http://arxiv.org/pdf/2510.20931v1" target="_blank" rel="noopener noreferrer" class="">http://arxiv.org/pdf/2510.20931v1</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper updates the Lincoln AI Computing Survey by collecting performance and power consumption data of commercial AI accelerators, plotting them on scatter graphs, and analyzing market trends. It introduces a new categorization of computing architectures and examines how GenAI models have shifted computational demands toward matrix-vector operations and high memory bandwidth. The survey highlights ongoing innovations in AI hardware across various deployment scales from embedded systems to data centers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv2510] ParaRNN: Unlocking Parallel Training of Nonlinear RNNs for Large
Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [LLM training], [parallel training, nonlinear RNNs, sequence modeling, Newton&#x27;s iterations, parallel reductions]</li>
<li class=""><strong>authors:</strong> Federico Danieli, Pau Rodriguez, Miguel Sarabia, Xavier Suau, Luca Zappella</li>
<li class=""><strong>institution:</strong> Apple</li>
<li class=""><strong>link:</strong> <a href="http://arxiv.org/pdf/2510.21450v1" target="_blank" rel="noopener noreferrer" class="">http://arxiv.org/pdf/2510.21450v1</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ParaRNN enables parallel training of nonlinear RNNs by formulating recurrence relationships as a system of equations and solving them using Newton&#x27;s iterations with parallel reductions. This approach achieves up to 665x speedup over sequential methods and allows training 7B parameter RNNs with performance comparable to Transformers and Mamba2. The framework is released as open-source to facilitate scalable nonlinear RNN research.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv2510] REVE: A Foundation Model for EEG -- Adapting to Any Setup with
Large-Scale Pretraining on 25,000 Subjects</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [Other models training], [EEG foundation model, 4D positional encoding, masked autoencoding, brain-computer interfaces, clinical neuroscience]</li>
<li class=""><strong>authors:</strong> Yassine El Ouahidi, Jonathan Lys, Philipp Thölke, Nicolas Farrugia, Bastien Pasdeloup, Vincent Gripon, Karim Jerbi, Giulia Lioi</li>
<li class=""><strong>institution:</strong> IMT Atlantique, Université de Montréal, Mila, UNIQUE</li>
<li class=""><strong>link:</strong> <a href="http://arxiv.org/pdf/2510.21585v1" target="_blank" rel="noopener noreferrer" class="">http://arxiv.org/pdf/2510.21585v1</a></li>
<li class=""><strong>Simple LLM Summary:</strong> REVE introduces a novel 4D positional encoding scheme and uses masked autoencoding pretraining on 60,000 hours of EEG data from 25,000 subjects. The model achieves state-of-the-art performance across 10 EEG tasks including motor imagery and seizure detection. It demonstrates strong generalization with minimal fine-tuning and enables standardized EEG research through released code and weights.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-10-28">2025-10-28<a href="#2025-10-28" class="hash-link" aria-label="Direct link to 2025-10-28" title="Direct link to 2025-10-28" translate="no">​</a></h2>
<p><strong>cs.DC total: 13</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251028] Simopt-Power: Leveraging Simulation Metadata for Low-Power Design Synthesis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [FPGA power optimization], [simulation metadata, Shannon Decomposition, activity profiling, truth table duplication, netlist transformation]</li>
<li class=""><strong>authors:</strong> Eashan Wadhwa, Shanker Shreejith</li>
<li class=""><strong>institution:</strong> Trinity College Dublin</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.21745" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.21745</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents Simopt-Power, a framework that uses simulation metadata to identify high-toggle paths in FPGA designs and applies Shannon Decomposition to insert duplicate logic and relocate critical nets. The method achieves approximately 9% reduction in switching-induced power while adding only modest resource overhead. Results demonstrate that coupling simulation insights with targeted optimizations provides an effective approach for dynamic power reduction in FPGA design flows.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] Separation of Unconscious Robots with Obstructed Visibility</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed robotics], [opaque robots, semicircle separation, look-compute-move cycle, semi-synchronous scheduler]</li>
<li class=""><strong>authors:</strong> Prajyot Pyati, Navjot Kaur, Saswata Jana, Adri Bhattacharya, Partha Sarathi Mandal</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.22434" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.22434</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a collision-free algorithm for unconscious robots with obstructed visibility that separates robots into concentric semicircles. The algorithm operates under a semi-synchronous scheduler and achieves separation in O(n) epochs. The robots coordinate without knowing the total number of robots but agree on one coordinate axis.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] When Agents are Powerful: Black Hole Search in Time-Varying Graphs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed algorithms], [global communication, 1-hop visibility, deterministic algorithms, mobile agents]</li>
<li class=""><strong>authors:</strong> Tanvir Kaur, Ashish Saxena</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology Ropar</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.22309" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.22309</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper enhances Black Hole Search in dynamic graphs by equipping agents with global communication and 1-hop visibility capabilities. These improvements allow for more efficient solutions compared to previous face-to-face communication approaches. The enhanced agent capabilities reduce the number of agents required to successfully identify the black hole while ensuring at least one agent survives.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] A Feature Engineering Approach for Business Impact-Oriented Failure Detection in Distributed Instant Payment Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [feature engineering, anomaly detection, ISO 20022 message processing, processing time analysis, explainable AI]</li>
<li class=""><strong>authors:</strong> Lorenzo Porcelli</li>
<li class=""><strong>institution:</strong> Bank of Italy, University of Salerno</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.21710" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.21710</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a feature engineering approach that computes processing times between consecutive ISO 20022 message exchanges to create system state representations for anomaly detection. The method enables early failure detection and incident classification in distributed instant payment systems. Experimental evaluation on TARGET Instant Payment Settlement demonstrates effectiveness in detecting diverse anomaly patterns while providing interpretable explanations for business impact assessment.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] Heaven &amp; Hell II: Scale Laws and Robustness in One-Step Heaven-Hell Consensus</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [network consensus], [Heaven-Hell dynamics, conservation-law perspective, tie-breaking policies, pointwise bounds, asynchronous updates, Coq proofs]</li>
<li class=""><strong>authors:</strong> Nnamdi Daniel Aghanya, Romain Leemans</li>
<li class=""><strong>institution:</strong> Cranfield University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.21950" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.21950</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper develops scale laws and operational refinements for Heaven-Hell consensus dynamics, using a conservation-law perspective to derive tighter bounds and robustness guarantees. The research establishes conditions for robust convergence under various scenarios including tie-breaking policies, asynchronous updates, and multiple hubs. All proofs are mechanized in Coq and experiments validate the tightness of the bounds across diverse network types.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] Rethinking Inference Placement for Deep Learning across Edge and Cloud Platforms: A Multi-Objective Optimization Perspective and Future Directions</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [model offloading, model compression, model distillation, transmission compression, internal classifiers]</li>
<li class=""><strong>authors:</strong> Zongshun Zhang, Ibrahim Matta</li>
<li class=""><strong>institution:</strong> Boston University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.22909" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.22909</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper surveys methods for optimizing deep learning inference placement across edge and cloud platforms using techniques like model partitioning, compression, and architecture adaptations. It analyzes how these approaches balance multiple objectives including latency, privacy, and monetary cost. The research concludes that effective inference placement requires multi-objective optimization across the computational continuum from devices to cloud.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] CodeAD: Synthesize Code of Rules for Log-based Anomaly Detection with LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [hierarchical clustering, anchor-grounded sampling, agentic workflow, rule synthesis, contrastive log windows]</li>
<li class=""><strong>authors:</strong> Junjie Huang, Minghua He, Jinyang Liu, Yintong Huo, Domenico Bianculli, Michael R. Lyu</li>
<li class=""><strong>institution:</strong> The Chinese University of Hong Kong, Peking University, Singapore Management University, University of Luxembourg</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.22986" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.22986</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CodeAD automatically synthesizes lightweight Python rule functions for log-based anomaly detection using LLMs through hierarchical clustering and iterative agentic workflows. The framework achieves 3.6% higher F1 score than state-of-the-art methods while processing data 4x faster at minimal cost, providing an interpretable and efficient solution for real-time log analysis.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] Power to the Clients: Federated Learning in a Dictatorship Setting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [federated learning, byzantine clients, dictator clients, model convergence, attack strategies]</li>
<li class=""><strong>authors:</strong> Mohammadsajad Alipour, Mohammad Mohammadi Amiri</li>
<li class=""><strong>institution:</strong> Rensselaer Polytechnic Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.22149" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.22149</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces dictator clients, a class of malicious participants in federated learning that can erase other clients&#x27; contributions while preserving their own. The authors propose attack strategies and analyze their effects on model convergence in various scenarios including collaboration and betrayal between multiple dictator clients. Their theoretical analysis and empirical evaluations demonstrate how these clients can significantly compromise the global model&#x27;s integrity.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] Sentinel: Dynamic Knowledge Distillation for Personalized Federated Intrusion Detection in Heterogeneous IoT Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [personalized federated learning, knowledge distillation, dual-model architecture, class-balanced loss, gradient aggregation]</li>
<li class=""><strong>authors:</strong> Gurpreet Singh, Keshav Sood, P. Rajalakshmi, Yong Xiang</li>
<li class=""><strong>institution:</strong> Deakin University, Indian Institute of Technology Hyderabad</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23019" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23019</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Sentinel, a personalized federated intrusion detection system that uses a dual-model architecture with teacher-student knowledge distillation to handle data heterogeneity in IoT networks. It incorporates bidirectional distillation, feature alignment, and balanced loss functions to improve performance. Experiments show Sentinel outperforms existing methods while maintaining communication efficiency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] AirFed: Federated Graph-Enhanced Multi-Agent Reinforcement Learning for Multi-UAV Cooperative Mobile Edge Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, graph attention networks, multi-agent reinforcement learning, trajectory planning, task offloading, resource allocation, gradient quantization]</li>
<li class=""><strong>authors:</strong> Zhiyu Wang, Suman Raj, Rajkumar Buyya</li>
<li class=""><strong>institution:</strong> The University of Melbourne, Indian Institute of Science</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23053" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23053</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes AirFed, a federated graph-enhanced multi-agent reinforcement learning framework that uses dual-layer Graph Attention Networks and a dual-Actor single-Critic architecture for UAV coordination in mobile edge computing. The system achieves significant improvements including 42.9% cost reduction, over 99% deadline satisfaction, and 54.5% lower communication overhead compared to state-of-the-art methods, demonstrating strong scalability for large-scale UAV deployments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream Processing Pipelines</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [Hypergraph of Thoughts, multi-agent reasoning, resilient execution strategies, advanced query analysis]</li>
<li class=""><strong>authors:</strong> Abolfazl Younesi, Zahra Najafabadi Samani, Thomas Fahringer</li>
<li class=""><strong>institution:</strong> University of Innsbruck</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23408" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23408</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AutoStreamPipe uses Large Language Models with Hypergraph of Thoughts to automatically generate data stream processing pipelines from high-level user intents. The framework bridges the semantic gap between user requirements and platform-specific implementations through structured multi-agent reasoning. Experimental results show it significantly reduces development time by 6.3× and error rates by 5.19× compared to traditional LLM code-generation methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] Bayes-Split-Edge: Bayesian Optimization for Constrained Collaborative Inference in Wireless Edge Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Bayesian optimization, split learning, collaborative inference, wireless edge computing, constrained optimization, neural network splitting]</li>
<li class=""><strong>authors:</strong> Fatemeh Zahra Safaeipour, Jacob Chakareski, Morteza Hashemi</li>
<li class=""><strong>institution:</strong> University of Kansas, New Jersey Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23503" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23503</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Bayes-Split-Edge, a Bayesian optimization framework that jointly optimizes transmission power and neural network split points for collaborative inference in wireless edge systems. The method uses a novel hybrid acquisition function to balance inference utility with energy and delay constraints. Results show it achieves 2.4× evaluation cost reduction compared to standard Bayesian optimization while matching exhaustive search performance under tight constraints.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251028] The First Star-by-star $N$-body/Hydrodynamics Simulation of Our Galaxy Coupling with a Surrogate Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [N-body simulation, smoothed-particle hydrodynamics, surrogate model, deep learning, Fugaku supercomputer]</li>
<li class=""><strong>authors:</strong> Keiya Hirashima, Michiko S. Fujii, Takayuki R. Saitoh, Naoto Harada, Kentaro Nomura, Kohji Yoshikawa, Yutaka Hirai, Tetsuro Asano, Kana Moriwaki, Masaki Iwasawa, Takashi Okamoto, Junichiro Makino</li>
<li class=""><strong>institution:</strong> RIKEN, University of Tokyo, Kobe University, Preferred Networks, University of Tsukuba, Tohoku University of Community Service and Science, Universitat de Barcelona, National Institute of Technology, Hokkaido University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23330" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23330</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a novel integration scheme combining N-body/hydrodynamics simulations with machine learning surrogate models to bypass computational bottlenecks caused by supernova explosions. The method achieved 300 billion particles using 148,900 nodes, breaking the billion-particle barrier and enabling the first star-by-star galaxy simulation. This represents a major advancement in computational astrophysics by resolving individual stars in Milky Way simulations.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 52</strong></p>
<ul>
<li class="">[arXiv251028] Transitive RL: Value Learning via Divide and Conquer <a href="http://arxiv.org/abs/2510.22512" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Predictive Coding Enhances Meta-RL To Achieve Interpretable Bayes-Optimal Belief Representation Under Partial Observability <a href="http://arxiv.org/abs/2510.22039" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Hazard-Responsive Digital Twin for Climate-Driven Urban Resilience and Equity <a href="http://arxiv.org/abs/2510.22941" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM <a href="http://arxiv.org/abs/2510.22740" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning <a href="http://arxiv.org/abs/2510.22282" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Beyond Reasoning Gains: Mitigating General Capabilities Forgetting in Large Reasoning Models <a href="http://arxiv.org/abs/2510.21978" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review <a href="http://arxiv.org/abs/2510.21758" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Advantage Shaping as Surrogate Reward Maximization: Unifying Pass@K Policy Gradients <a href="http://arxiv.org/abs/2510.23049" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] PACR: Progressively Ascending Confidence Reward for LLM Reasoning <a href="http://arxiv.org/abs/2510.22255" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Is Temporal Difference Learning the Gold Standard for Stitching in RL? <a href="http://arxiv.org/abs/2510.21995" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated Reinforcement Learning <a href="http://arxiv.org/abs/2510.23038" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] FlowCritic: Bridging Value Estimation with Flow Matching in Reinforcement Learning <a href="http://arxiv.org/abs/2510.22686" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Offline Preference Optimization via Maximum Marginal Likelihood Estimation <a href="http://arxiv.org/abs/2510.22881" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group Sequence Policy Optimization <a href="http://arxiv.org/abs/2510.22477" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Dopamine-driven synaptic credit assignment in neural networks <a href="http://arxiv.org/abs/2510.22178" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Activating Visual Context and Commonsense Reasoning through Masked Prediction in VLMs <a href="http://arxiv.org/abs/2510.21807" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Towards Stable and Effective Reinforcement Learning for Mixture-of-Experts <a href="http://arxiv.org/abs/2510.23027" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] UCB-type Algorithm for Budget-Constrained Expert Learning <a href="http://arxiv.org/abs/2510.22654" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Online Optimization for Offline Safe Reinforcement Learning <a href="http://arxiv.org/abs/2510.22027" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] GAPO: Group Adaptive Policy Optimization for Real-World Code Edit <a href="http://arxiv.org/abs/2510.21830" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Guardian: Decoupling Exploration from Safety in Reinforcement Learning <a href="http://arxiv.org/abs/2510.22859" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] STAR-RIS-assisted Collaborative Beamforming for Low-altitude Wireless Networks <a href="http://arxiv.org/abs/2510.22108" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing <a href="http://arxiv.org/abs/2510.22570" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Solving Continuous Mean Field Games: Deep Reinforcement Learning for Non-Stationary Dynamics <a href="http://arxiv.org/abs/2510.22158" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles <a href="http://arxiv.org/abs/2510.22370" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions <a href="http://arxiv.org/abs/2510.22798" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Softmax is $1/2$-Lipschitz: A tight bound across all $\ell_p$ norms <a href="http://arxiv.org/abs/2510.23012" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions <a href="http://arxiv.org/abs/2510.22568" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Agentic Reinforcement Learning for Real-World Code Repair <a href="http://arxiv.org/abs/2510.22075" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Computational Hardness of Reinforcement Learning with Partial $q^π$-Realizability <a href="http://arxiv.org/abs/2510.21888" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Toward Agents That Reason About Their Computation <a href="http://arxiv.org/abs/2510.22833" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable Reasoning <a href="http://arxiv.org/abs/2510.22543" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Do You Trust the Process?: Modeling Institutional Trust for Community Adoption of Reinforcement Learning Policies <a href="http://arxiv.org/abs/2510.22017" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning <a href="http://arxiv.org/abs/2510.22832" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping <a href="http://arxiv.org/abs/2510.22319" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] SynCast: Synergizing Contradictions in Precipitation Nowcasting via Diffusion Sequential Preference Optimization <a href="http://arxiv.org/abs/2510.21847" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Multi-Agent Conditional Diffusion Model with Mean Field Communication as Wireless Resource Allocation Planner <a href="http://arxiv.org/abs/2510.22969" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Think before Recommendation: Autonomous Reasoning-enhanced Recommender <a href="http://arxiv.org/abs/2510.23077" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Adapting Interleaved Encoders with PPO for Language-Guided Reinforcement Learning in BabyAI <a href="http://arxiv.org/abs/2510.23148" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Guiding Skill Discovery with Foundation Models <a href="http://arxiv.org/abs/2510.23167" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] TARC: Time-Adaptive Robotic Control <a href="http://arxiv.org/abs/2510.23176" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach <a href="http://arxiv.org/abs/2510.23216" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach <a href="http://arxiv.org/abs/2510.23304" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N Sampling via max@k Optimisation <a href="http://arxiv.org/abs/2510.23393" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Causal Deep Q Network <a href="http://arxiv.org/abs/2510.23424" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] An Information-Theoretic Analysis of Out-of-Distribution Generalization in Meta-Learning with Applications to Meta-RL <a href="http://arxiv.org/abs/2510.23448" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Learning to Reason Efficiently with Discounted Reinforcement Learning <a href="http://arxiv.org/abs/2510.23486" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Sequential Multi-Agent Dynamic Algorithm Configuration <a href="http://arxiv.org/abs/2510.23535" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Multi-Agent Evolve: LLM Self-Improve through Co-evolution <a href="http://arxiv.org/abs/2510.23595" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Right Place, Right Time: Market Simulation-based RL for Execution Optimisation <a href="http://arxiv.org/abs/2510.22206" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Reinforcement learning-guided optimization of critical current in high-temperature superconductors <a href="http://arxiv.org/abs/2510.22424" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] PASS-Enhanced MEC: Joint Optimization of Task Offloading and Uplink PASS Beamforming <a href="http://arxiv.org/abs/2510.22948" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerat&quot; total: 23</strong></p>
<ul>
<li class="">[arXiv251028] A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data <a href="http://arxiv.org/abs/2510.21735" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Impact and Implications of Generative AI for Enterprise Architects in Agile Environments: A Systematic Literature Review <a href="http://arxiv.org/abs/2510.22003" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Step2Motion: Locomotion Reconstruction from Pressure Sensing Insoles <a href="http://arxiv.org/abs/2510.22712" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Accelerating Materials Design via LLM-Guided Evolutionary Search <a href="http://arxiv.org/abs/2510.22503" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] PACR: Progressively Ascending Confidence Reward for LLM Reasoning <a href="http://arxiv.org/abs/2510.22255" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] AI-Enhanced Operator Assistance for UNICOS Applications <a href="http://arxiv.org/abs/2510.21717" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Dopamine-driven synaptic credit assignment in neural networks <a href="http://arxiv.org/abs/2510.22178" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] OpenEM: Large-scale multi-structural 3D datasets for electromagnetic methods <a href="http://arxiv.org/abs/2510.21859" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Encoder-Decoder Diffusion Language Models for Efficient Training and Inference <a href="http://arxiv.org/abs/2510.22852" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] QuArch: A Benchmark for Evaluating LLM Reasoning in Computer Architecture <a href="http://arxiv.org/abs/2510.22087" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Residual-guided AI-CFD hybrid method enables stable and scalable simulations: from 2D benchmarks to 3D applications <a href="http://arxiv.org/abs/2510.21804" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Graph-Coarsening Approach for the Capacitated Vehicle Routing Problem with Time Windows <a href="http://arxiv.org/abs/2510.22329" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Approximate Gradient Coding for Distributed Learning with Heterogeneous Stragglers <a href="http://arxiv.org/abs/2510.22539" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge <a href="http://arxiv.org/abs/2510.21879" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs <a href="http://arxiv.org/abs/2510.23127" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Guiding Skill Discovery with Foundation Models <a href="http://arxiv.org/abs/2510.23167" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Accelerating Eigenvalue Dataset Generation via Chebyshev Subspace Filter <a href="http://arxiv.org/abs/2510.23215" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Accelerating IC Thermal Simulation Data Generation via Block Krylov and Operator Action <a href="http://arxiv.org/abs/2510.23221" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Progressive Growing of Patch Size: Curriculum Learning for Accelerated and Improved Medical Image Segmentation <a href="http://arxiv.org/abs/2510.23241" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] PAHQ: Accelerating Automated Circuit Discovery through Mixed-Precision Inference Optimization <a href="http://arxiv.org/abs/2510.23264" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Towards a Generalizable AI for Materials Discovery: Validation through Immersion Coolant Screening <a href="http://arxiv.org/abs/2510.23371" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] HPC-Driven Modeling with ML-Based Surrogates for Magnon-Photon Dynamics in Hybrid Quantum Systems <a href="http://arxiv.org/abs/2510.22221" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251028] Reinforcement learning-guided optimization of critical current in high-temperature superconductors <a href="http://arxiv.org/abs/2510.22424" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-10-29">2025-10-29<a href="#2025-10-29" class="hash-link" aria-label="Direct link to 2025-10-29" title="Direct link to 2025-10-29" translate="no">​</a></h2>
<p><strong>cs.DC total: 14</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251029] Fault-Tolerant Multiparty Session Types with Global Escape Loops</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems], [multiparty session types, fault-tolerance, global escape loops, non-blocking messages, rotating coordinator algorithm]</li>
<li class=""><strong>authors:</strong> Lukas Bartl, Julian Linne, Kirstin Peters</li>
<li class=""><strong>institution:</strong> Universität Augsburg</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24203" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24203</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper extends fault-tolerant multiparty session types with a novel global escape loop construct that allows processes to terminate distributed algorithms without global coordination. The approach uses non-blocking exit-messages to enable efficient fault-tolerant behavior in distributed systems. The method is demonstrated by analyzing a variant of the Chandra-Toueg rotating coordinator algorithm.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] CoMPSeT: A Framework for Comparing Multiparty Session Types</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [formal methods], [multiparty session types, choreographic languages, operational semantics]</li>
<li class=""><strong>authors:</strong> Telmo Ribeiro, José Proença, Mário Florido</li>
<li class=""><strong>institution:</strong> University of Porto</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24205" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24205</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces CoMPSeT, a framework for comparing different variations of Multiparty Session Types through feature combination and semantic animation. The tool provides mechanisms to analyze and contrast MPST implementations using concrete examples. CoMPSeT is implemented as an open-source web tool to help researchers understand MPST features and assist teachers in explaining global choreographies.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] Odyssey: An End-to-End System for Pareto-Optimal Serverless Query Processing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [serverless data analytics], [query planning, cost model, execution engine, state space pruning, Pareto-optimal plans]</li>
<li class=""><strong>authors:</strong> Shyam Jesalpura, Shengda Zhu, Amir Shaikhha, Antonio Barbalace, Boris Grot</li>
<li class=""><strong>institution:</strong> The University of Edinburgh</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24307" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24307</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Odyssey introduces an end-to-end serverless data analytics system that automatically generates and evaluates query plans using state space pruning and a novel search algorithm to find Pareto-optimal plans balancing cost and performance. The system consistently outperforms AWS Athena on both cost and latency metrics while accurately predicting monetary cost and query execution time.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [personalized federated learning, FedAvg, FLIU, client drift, out-of-distribution generalization, heterogeneous data]</li>
<li class=""><strong>authors:</strong> Mortesa Hussaini, Jan Theiß, Anthony Stein</li>
<li class=""><strong>institution:</strong> University of Hohenheim</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24503" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24503</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes FLIU, a modified FedAvg approach with adaptive personalization factors, and evaluates both local performance and out-of-distribution generalization in personalized federated learning. The study finds that while personalized methods improve local performance, they inadequately address generalization capabilities compared to traditional federated learning. The research demonstrates the importance of balancing both local optimization and generalization in heterogeneous data environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] Differential Privacy: Gradient Leakage Attacks in Federated Learning Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Differential Privacy, DP-SGD, PDP-SGD, Gradient Leakage Attacks, Federated Learning]</li>
<li class=""><strong>authors:</strong> Miguel Fernandez-de-Retana, Unai Zulaika, Rubén Sánchez-Corcuera, Aitor Almeida</li>
<li class=""><strong>institution:</strong> Basque Center for Applied Mathematics, University of Deusto</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23931" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23931</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper evaluates differential privacy mechanisms (DP-SGD and PDP-SGD) as defenses against gradient leakage attacks in federated learning. The results show DP-SGD effectively mitigates reconstruction attacks with moderate utility trade-offs, while PDP-SGD maintains strong model performance but fails as a practical defense. These findings emphasize the need for empirical evaluation of privacy mechanisms beyond theoretical guarantees in distributed learning scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] SPEAR++: Scaling Gradient Inversion via Sparsely-Used Dictionary Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [gradient inversion attacks, sparsely-used dictionary learning, federated learning, ReLU activations, linear layers, FedAvg aggregation, DP noise robustness]</li>
<li class=""><strong>authors:</strong> Alexander Bakarsky, Dimitar I. Dimitrov, Maximilian Baader, Martin Vechev</li>
<li class=""><strong>institution:</strong> ETH Zurich, INSAIT, Sofia University &quot;St. Kliment Ohridski&quot;</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24200" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24200</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SPEAR++ improves upon the SPEAR gradient inversion attack by applying sparsely-used dictionary learning techniques to make the attack tractable for larger batch sizes. The new method maintains robustness to differential privacy noise and FedAvg aggregation while scaling to 10x larger batch sizes compared to the original SPEAR attack. This demonstrates practical vulnerability in federated learning systems even with privacy protections in place.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] Towards Exascale Computing for Astrophysical Simulation Leveraging the Leonardo EuroHPC System</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [astrophysical simulation], [GPU scaling, performance analysis, profiling tools, HPC optimization]</li>
<li class=""><strong>authors:</strong> Nitin Shukla, Alessandro Romeo, Caterina Caravita, Michael Redenti, Radim Vavrik, Lubomir Riha, Andrea Mignone, Marco Rossazza, Stefano Truzzi, Luca Tornatore, Antonio Ragagnin, Tiago Castro, Geray S. Karademir, Klaus Dolag, Pranab J. Deka, Fabio Bacchini, Rostislav-Paul Wilhelm, Daniele Gregori, Elisabetta Boella</li>
<li class=""><strong>institution:</strong> CINECA, IT4Innovations, University of Turin, INAF, Ludwig-Maximilians-Universität München, KU Leuven, E4 Computer Engineering</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24175" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24175</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents performance optimization strategies for three astrophysical simulation codes (gPLUTO, OpenGadget3, iPIC3D) on the Leonardo EuroHPC system using profiling tools. The research demonstrates that all three codes achieve efficient scaling, reaching 80% scalability up to 1,024 GPUs, showing promising results for exascale computing in astrophysical simulations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] ARIMA_PLUS: Large-scale, Accurate, Automatic and Interpretable In-Database Time Series Forecasting and Anomaly Detection in Google BigQuery</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [ARIMA_PLUS, time series forecasting, anomaly detection, BigQuery, SQL interface, modular structure, holiday effects, seasonality, trend]</li>
<li class=""><strong>authors:</strong> Xi Cheng, Weijie Shen, Haoming Chen, Chaoyi Shen, Jean Ortega, Jiashang Liu, Steve Thomas, Honglin Zheng, Haoyun Wu, Yuxiang Li, Casey Lichtendahl, Jenny Ortiz, Gang Liu, Haiyang Qi, Omid Fatemieh, Chris Fry, Jing Jing Long</li>
<li class=""><strong>institution:</strong> Google</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24452" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24452</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ARIMA_PLUS is a novel framework that combines accurate time series models with scalable cloud infrastructure for forecasting and anomaly detection. It demonstrates superior accuracy over both statistical and neural network methods on benchmark datasets and achieves high throughput of over 18,000 time series per second when integrated into Google BigQuery. The system provides interpretable results through its modular structure handling holiday effects, seasonality, trend, and anomalies.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] The SAP Cloud Infrastructure Dataset: A Reality Check of Scheduling and Placement of VMs in Cloud Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud computing], [virtual machine scheduling, resource allocation, performance monitoring, workload management]</li>
<li class=""><strong>authors:</strong> Arno Uhlig, Iris Braun, Matthias Wählisch</li>
<li class=""><strong>institution:</strong> TU Dresden, SAP SE</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23911" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23911</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper analyzes VM scheduling and placement in SAP&#x27;s cloud infrastructure using fine-grained telemetry data from 1,800 hypervisors and 48,000 VMs. The study identifies significant resource inefficiencies including CPU contention exceeding 40% and over 80% of VMs using less than 70% of allocated resources. Based on these findings, the authors derive requirements for improved scheduling algorithms and make their dataset publicly available for future research.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] A GPU-based Compressible Combustion Solver for Applications Exhibiting Disparate Space and Time Scales</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [computational fluid dynamics], [GPU optimization, AMReX framework, adaptive mesh refinement, bulk-sparse integration, column-major storage, roofline analysis]</li>
<li class=""><strong>authors:</strong> Anthony Carreon, Jagmohan Singh, Shivank Sharma, Shuzhi Zhang, Venkat Raman</li>
<li class=""><strong>institution:</strong> University of Michigan</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23993" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23993</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a GPU-optimized compressible combustion solver built on the AMReX framework that addresses performance bottlenecks through column-major storage, bulk-sparse chemical kinetics integration, and multi-GPU load balancing. The solver demonstrates 2-5× performance improvements over initial GPU implementations with near-ideal weak scaling across 1-96 NVIDIA H100 GPUs. Roofline analysis confirms substantial improvements in arithmetic intensity for both convection and chemistry routines, enabling efficient utilization of GPU resources for high-speed reacting flow simulations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] PanDelos-plus: A parallel algorithm for computing sequence homology in pangenomic analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [bioinformatics], [k-mer profiles, parallel computing, data decomposition, thread pool, lightweight data structures]</li>
<li class=""><strong>authors:</strong> Simone Colli, Emiliano Maresi, Vincenzo Bonnici</li>
<li class=""><strong>institution:</strong> University of Parma</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.23679" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.23679</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PanDelos-plus is a parallel algorithm that improves upon PanDelos by parallelizing computationally intensive phases using data decomposition and thread pools while employing lightweight data structures. Benchmarks show it achieves up to 14x faster execution and 96% reduced memory usage while maintaining accuracy. These improvements make large-scale bacterial pangenome analysis accessible for routine research on standard multicore workstations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] Distributed Stochastic Momentum Tracking with Local Updates: Achieving Optimal Communication and Iteration Complexities</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Local Momentum Tracking, momentum tracking, Loopless Chebyshev Acceleration, distributed optimization, communication complexity, iteration complexity]</li>
<li class=""><strong>authors:</strong> Kun Huang, Shi Pu</li>
<li class=""><strong>institution:</strong> The Chinese University of Hong Kong, Shenzhen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24155" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24155</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Local Momentum Tracking (LMT), a distributed stochastic gradient method that combines local updates with momentum tracking and Loopless Chebyshev Acceleration to reduce communication overhead. LMT achieves linear speedup with respect to both local updates and number of agents, and attains optimal communication and iteration complexities depending on the number of local updates performed. This makes it the first method to simultaneously achieve these optimal complexity properties for distributed optimization over networks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] Exascale In-situ visualization for Astronomy &amp; Cosmology</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing], [in-situ visualization, distributed database, streaming data, Hecuba framework, ChaNGa simulator]</li>
<li class=""><strong>authors:</strong> Nicola Tuccari, Eva Sciacca, Yolanda Becerra, Enric Sosa Cintero, Emiliano Tramontana</li>
<li class=""><strong>institution:</strong> INAF Astrophysical Observatory of Catania, Università di Catania, Barcelona Supercomputing Center</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24545" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24545</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents an in-situ visualization approach using the Hecuba distributed database framework to stream astronomy and cosmology simulation data directly into visualization pipelines. By integrating Hecuba with the ChaNGa cosmological simulator, the method enables real-time visualization of N-body simulations using tools like ParaView and VisIVO. The approach successfully addresses the bottleneck of writing massive datasets to disk in exascale computing environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251029] In-Situ High Performance Visualization for Astronomy &amp; Cosmology</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing visualization], [in-situ visualization, Hecuba framework, distributed database, ParaView, VisIVO, Changa simulator]</li>
<li class=""><strong>authors:</strong> Nicola Tuccari, Eva Sciacca, Yolanda Becerra, Enric Sosa Cintero, Robert Wissing, Sijing Shen, Emiliano Tramontana</li>
<li class=""><strong>institution:</strong> INAF Astrophysical Observatory of Catania, Università di Catania, Barcelona Supercomputing Center, University of Oslo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.24547" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.24547</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents an in-situ visualization approach using the Hecuba framework to process astronomy and cosmology simulation data concurrently with simulations, bypassing storage bottlenecks. The method integrates with the Changa cosmological simulator and visualization tools ParaView and VisIVO. The main conclusion is that this approach effectively handles petascale datasets by eliminating the need to store full simulation results while enabling real-time visualization.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 18</strong></p>
<ul>
<li class="">[arXiv251029] ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model <a href="http://arxiv.org/abs/2510.24285" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Causal-Aware Generative Adversarial Networks with Reinforcement Learning <a href="http://arxiv.org/abs/2510.24046" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Latent Chain-of-Thought for Visual Reasoning <a href="http://arxiv.org/abs/2510.23925" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Survey and Tutorial of Reinforcement Learning Methods in Process Systems Engineering <a href="http://arxiv.org/abs/2510.24272" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Sample-efficient and Scalable Exploration in Continuous-Time RL <a href="http://arxiv.org/abs/2510.24482" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins <a href="http://arxiv.org/abs/2510.23882" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks <a href="http://arxiv.org/abs/2510.24461" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling <a href="http://arxiv.org/abs/2510.24235" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward <a href="http://arxiv.org/abs/2510.24020" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data <a href="http://arxiv.org/abs/2510.24151" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings <a href="http://arxiv.org/abs/2510.24432" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA <a href="http://arxiv.org/abs/2510.23868" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation <a href="http://arxiv.org/abs/2510.24431" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Debiasing Reward Models by Representation Learning with Guarantees <a href="http://arxiv.org/abs/2510.23751" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Dual-Mind World Models: A General Framework for Learning in Dynamic Wireless Networks <a href="http://arxiv.org/abs/2510.24546" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning <a href="http://arxiv.org/abs/2510.24650" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Learning to Drive Safely with Hybrid Options <a href="http://arxiv.org/abs/2510.24674" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Greedy Sampling Is Provably Efficient for RLHF <a href="http://arxiv.org/abs/2510.24700" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 12</strong></p>
<ul>
<li class="">[arXiv251029] Fixed Point Neural Acceleration and Inverse Surrogate Model for Battery Parameter Identification <a href="http://arxiv.org/abs/2510.24135" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Design and Optimization of Cloud Native Homomorphic Encryption Workflows for Privacy-Preserving ML Inference <a href="http://arxiv.org/abs/2510.24498" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach <a href="http://arxiv.org/abs/2510.24085" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Causal-Aware Generative Adversarial Networks with Reinforcement Learning <a href="http://arxiv.org/abs/2510.24046" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point Arithmetic <a href="http://arxiv.org/abs/2510.24061" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal Regression Trees <a href="http://arxiv.org/abs/2510.23901" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings <a href="http://arxiv.org/abs/2510.24432" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Scalable GPU-Based Integrity Verification for Large Machine Learning Models <a href="http://arxiv.org/abs/2510.23938" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Taming the Tail: NoI Topology Synthesis for Mixed DL Workloads on Chiplet-Based Accelerators <a href="http://arxiv.org/abs/2510.24113" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields <a href="http://arxiv.org/abs/2510.23621" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] SymMaP: Improving Computational Efficiency in Linear Solvers through Symbolic Preconditioning <a href="http://arxiv.org/abs/2510.24170" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251029] Trajectory Design for UAV-Based Low-Altitude Wireless Networks in Unknown Environments: A Digital Twin-Assisted TD3 Approach <a href="http://arxiv.org/abs/2510.24255" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-10-29T06:08:50.000Z" itemprop="dateModified">Oct 29, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20251020-20251026"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251020-20251026</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-10-27" class="table-of-contents__link toc-highlight">2025-10-27</a></li><li><a href="#2025-10-28" class="table-of-contents__link toc-highlight">2025-10-28</a></li><li><a href="#2025-10-29" class="table-of-contents__link toc-highlight">2025-10-29</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>