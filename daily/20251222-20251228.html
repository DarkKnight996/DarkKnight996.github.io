<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20251222-20251228" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251222-20251228 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20251222-20251228"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251222-20251228 | DarkKnight Note"><meta data-rh="true" name="description" content="2025-12-22"><meta data-rh="true" property="og:description" content="2025-12-22"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20251222-20251228"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20251222-20251228" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20251222-20251228" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20251222-20251228","item":"https://darkknight996.github.io/daily/20251222-20251228"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.dde2e284.js" defer="defer"></script>
<script src="/assets/js/main.fc99a02c.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251222-20251228</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251222-20251228</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-22">2025-12-22<a href="#2025-12-22" class="hash-link" aria-label="Direct link to 2025-12-22" title="Direct link to 2025-12-22" translate="no">​</a></h2>
<p><strong>cs.DC total: 13</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251222] Sedna: Sharding transactions in multiple concurrent proposer blockchains</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain consensus], [verifiable rateless coding, transaction sharding, multi-proposer consensus, until-decode privacy]</li>
<li class=""><strong>authors:</strong> Alejandro Ranchal-Pedrosa, Benjamin Marsh, Lefteris Kokoris-Kogias, Alberto Sonnino</li>
<li class=""><strong>institution:</strong> Sei Labs, Mysten Labs, University of Portsmouth, University College London</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17045" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17045</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Sedna is a user-facing protocol that uses verifiable, rateless coding to shard transactions across multiple concurrent proposers in a blockchain, replacing naive replication. It guarantees liveness and until-decode privacy, reducing MEV exposure and approaching the information-theoretic lower bound for bandwidth overhead, yielding a 2–3x efficiency improvement. The protocol requires no consensus modifications, enabling incremental deployment.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Practical Framework for Privacy-Preserving and Byzantine-robust Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [dimensionality reduction, Byzantine-robust aggregation, privacy-preserving federated learning, secure multi-party computation, adaptive tuning]</li>
<li class=""><strong>authors:</strong> Baolei Zhang, Minghong Fang, Zhuqing Liu, Biao Yi, Peizhao Zhou, Yuan Wang, Tong Li, Zheli Liu</li>
<li class=""><strong>institution:</strong> Nankai University, University of Louisville, University of North Texas</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17254" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17254</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ABBR, a practical framework for federated learning that integrates privacy-preserving and Byzantine-robust defenses. It uses dimensionality reduction to speed up secure computations for model filtering and an adaptive tuning strategy to mitigate the impact of undetected malicious models. The framework demonstrates significantly faster performance with minimal overhead while maintaining strong resilience against attacks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Dion2: A Simple Method to Shrink Matrix in Muon</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [Muon optimizer, orthonormalization, matrix shrinking, sampling, Newton-Schulz iterations, FSDP]</li>
<li class=""><strong>authors:</strong> Kwangjun Ahn, Noah Amsel, John Langford</li>
<li class=""><strong>institution:</strong> Microsoft Research, AI Frontiers, NYU</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16928" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16928</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Dion2, a simple method to improve the scalability of the Muon optimizer by reducing the computational cost of its orthonormalization step. It works by sampling a fraction of rows or columns at each iteration for orthonormalization, making the update sparse. The method maintains update quality close to full Muon while significantly reducing time per step, as demonstrated in large-scale model training.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Democratizing Scalable Cloud Applications: Transactional Stateful Functions on Streaming Dataflows</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems, cloud computing], [streaming dataflow, stateful functions, serializable transactions, fault-tolerance, serverless, Apache Flink, Stateflow, Styx]</li>
<li class=""><strong>authors:</strong> Kyriakos Psarakis</li>
<li class=""><strong>institution:</strong> Unknown (Institution not provided in the given text)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17429" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17429</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This thesis proposes using the streaming dataflow execution model to simplify building scalable cloud applications. It introduces Stateflow, a high-level programming model, and Styx, a distributed engine that provides deterministic, serializable transactions with strong fault tolerance. The work concludes that this approach democratizes development by improving programmability and performance over existing systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Scalable Distributed Vector Search via Accuracy Preserving Index Construction</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [SPIRE, hierarchical vector index, partition granularity, accuracy-preserving recursive construction, approximate nearest neighbor search, distributed index]</li>
<li class=""><strong>authors:</strong> Yuming Xu, Qianxi Zhang, Qi Chen, Baotong Lu, Menghao Li, Philip Adams, Mingqin Li, Zengzhong Li, Jing Liu, Cheng Li, Fan Yang</li>
<li class=""><strong>institution:</strong> University of Science and Technology of China, Microsoft Research, Shopify, Microsoft AI and Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17264" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17264</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SPIRE, a scalable distributed vector index system designed for Approximate Nearest Neighbor Search (ANNS). Its core method involves identifying a balanced partition granularity to avoid read-cost explosion and using an accuracy-preserving recursive construction to build a multi-level index. The main conclusion is that SPIRE achieves high scalability and up to 9.64x higher throughput than state-of-the-art systems in experiments with billions of vectors.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] The HEAL Data Platform</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [data platform], [Gen3 platform, federated system, cloud-based, FAIR principles, mesh architecture, persistent identifiers, metadata services, APIs]</li>
<li class=""><strong>authors:</strong> Brienna M. Larrick, L. Philip Schumm, Mingfei Shao, Craig Barnes, Anthony Juehne, Hara Prasad Juvvla, Michael B. Kranz, Michael Lukowski, Clint Malson, Jessica N. Mazerik, Christopher G. Meyer, Jawad Qureshi, Erin Spaniol, Andrea Tentner, Alexander VanTol, Peter Vassilatos, Sara Volk de Garcia, Robert L. Grossman</li>
<li class=""><strong>institution:</strong> University of Chicago</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17506" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17506</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents the HEAL Data Platform, a cloud-based federated system built on the open-source Gen3 platform to serve as a single point of search, discovery, and analysis for data from the NIH HEAL Initiative. It interoperates with multiple data repositories using framework services for authentication, metadata, and persistent identifiers. The platform maximizes data value by ensuring data are Findable, Accessible, Interoperable, and Reusable (FAIR), facilitating secondary analysis.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Taming the Memory Footprint Crisis: System Design for Production Diffusion LLM Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [Logit-Aware Activation Budgeting, Phase-Multiplexed Scheduler, Head-Centric Sparse Attention, parallel decoding, memory footprint optimization]</li>
<li class=""><strong>authors:</strong> Jiakun Fan, Yanglin Zhang, Xiangchen Li, Dimitrios S. Nikolopoulos</li>
<li class=""><strong>institution:</strong> Virginia Tech</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17077" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17077</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces dLLM-Serve, a serving system that addresses the memory footprint crisis in Diffusion LLMs by co-optimizing memory, scheduling, and generation quality. It proposes techniques like Logit-Aware Activation Budgeting and a Phase-Multiplexed Scheduler to manage resource oscillation and improve efficiency. The system significantly improves throughput and reduces latency across different hardware, establishing a blueprint for scalable dLLM inference.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Fixed-Priority and EDF Schedules for ROS2 Graphs on Uniprocessor</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [real-time systems], [fixed-priority scheduling, EDF, DAG task models, events executor, LIFO queue]</li>
<li class=""><strong>authors:</strong> Oren Bell, Harun Teper, Mario Günzel, Chris Gill, Jian-Jia Chen</li>
<li class=""><strong>institution:</strong> Washington University in St Louis, TU Dortmund University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16926" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16926</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a novel scheduling approach for ROS2 applications by using an events executor to implement fixed-job-level-priority schedulers for arbitrary Directed Acyclic Graph (DAG) tasks on uniprocessor systems. The method abstracts ROS2 applications as forests of trees and maps them to traditional real-time DAG models, requiring a special LIFO-ordered events queue. The authors conclude that their implementation generates schedules equivalent to a conventional fixed-priority DAG scheduler, helping to bridge the gap between real-time systems theory and ROS2 scheduling.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] LLM-HPC++: Evaluating LLM-Generated Modern C++ and MPI+OpenMP Codes for Scalable Mandelbrot Set Computation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [C++, MPI, OpenMP, parallel programming, code generation, scalability, ChatGPT, Claude, LLaMA]</li>
<li class=""><strong>authors:</strong> Patrick Diehl, Noujoud Nader, Deepti Gupta</li>
<li class=""><strong>institution:</strong> Los Alamos National Laboratory, Louisiana State University, Texas A&amp;M University-Central Texas</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17023" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17023</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper systematically evaluates large language models (LLMs) like ChatGPT, Claude, and LLaMA on generating correct and scalable parallel C++ code using MPI and OpenMP for Mandelbrot set computation. The method involves compiling and executing the generated programs to assess correctness, robustness, and performance. The main conclusion is that ChatGPT-4 and ChatGPT-5 achieve strong syntactic precision and scalable performance in this HPC code generation task.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Adaptive Graph Pruning with Sudden-Events Evaluation for Traffic Prediction using Online Semi-Decentralized ST-GNNs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [adaptive graph pruning, Spatio-Temporal Graph Neural Networks (ST-GNNs), Federated Learning (FL), Gossip Learning, Sudden Event Prediction Accuracy (SEPA), online semi-decentralized training]</li>
<li class=""><strong>authors:</strong> Ivan Kralj, Lodovico Giaretta, Gordan Ježić, Ivana Podnar Žarko, Šarūnas Girdzijauskas</li>
<li class=""><strong>institution:</strong> University of Zagreb, RISE Research Institutes of Sweden, KTH Royal Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17352" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17352</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an adaptive graph pruning algorithm for Spatio-Temporal Graph Neural Networks (ST-GNNs) to reduce communication overhead in online semi-decentralized traffic prediction systems. It also introduces a novel event-focused metric called SEPA to better evaluate responsiveness to sudden traffic changes. The experiments demonstrate that the method significantly lowers communication costs without compromising prediction accuracy or responsiveness to critical traffic events.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Torrent: A Distributed DMA for Efficient and Flexible Point-to-Multipoint Data Movement</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [distributed dma, chainwrite, network-on-chip, point-to-multipoint, scheduling algorithms]</li>
<li class=""><strong>authors:</strong> Yunhao Deng, Fanchen Kong, Xiaoling Yi, Ryan Antonio, Marian Verhelst</li>
<li class=""><strong>institution:</strong> KU Leuven</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17589" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17589</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Torrent, a distributed DMA architecture that performs efficient point-to-multipoint data transfers by forming logical data chains (Chainwrite) over a standard Network-on-Chip without modifying its hardware or protocol. It uses scheduling algorithms to optimize chain order and demonstrates significant performance improvements, achieving up to 7.88x speedup over unicast with minimal area and power overhead.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Enabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [GPU-internal scheduling, resource sharing, collaborative multi-GPU video decoding, logically decoupled execution, inter-stage blocking elimination]</li>
<li class=""><strong>authors:</strong> Lingxiao Zhao, Haoran Zhou, Yuezhi Che, Dazhao Cheng</li>
<li class=""><strong>institution:</strong> Wuhan University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17574" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17574</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FlashCodec and UnifiedServe, a framework that optimizes multi-stage MLLM inference by accelerating video decoding and enabling resource sharing between vision and LLM stages. This approach reduces latency and increases throughput by eliminating inter-stage blocking and improving GPU utilization. The system achieves significantly higher throughput and can serve more requests compared to existing state-of-the-art systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Asymptotic behaviour of galactic small-scale dynamos at modest magnetic Prandtl number</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [astrophysics], [Pencil Code, Astaroth, GPU acceleration, magnetohydrodynamics (MHD), supernova-driven dynamo, magnetic Prandtl number]</li>
<li class=""><strong>authors:</strong> Frederick A. Gent, Mordecai-Mark Mac Low, Maarit J. Korpi-Lagg, Touko Puro, Matthias Reinhardt</li>
<li class=""><strong>institution:</strong> Nordita, KTH Royal Institute of Technology and Stockholm University, Aalto University, Newcastle University, American Museum of Natural History</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17885" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17885</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper uses high-resolution GPU-accelerated simulations with the Pencil Code and Astaroth to model a supernova-driven galactic dynamo. The main finding is that the strength of the turbulent magnetic field from the small-scale dynamo reaches an asymptotic limit at a modest magnetic Prandtl number of only a few hundred, which is far below physical interstellar values. This asymptotic behavior allows the model&#x27;s characteristics to be incorporated into larger-scale galactic simulations.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 22</strong></p>
<ul>
<li class="">[arXiv251222] GB-DQN: Gradient Boosted DQN Models for Non-stationary Reinforcement Learning <a href="https://arxiv.org/pdf/2512.17034" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] CheXPO-v2: Preference Optimization for Chest X-ray VLMs with Knowledge Graph Consistency <a href="https://arxiv.org/pdf/2512.17213" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] MMRAG-RFT: Two-stage Reinforcement Fine-tuning for Explainable Multi-modal Retrieval-augmented Generation <a href="https://arxiv.org/pdf/2512.17194" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making <a href="https://arxiv.org/pdf/2512.17091" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Conservative Bias in Multi-Teacher Learning: Why Agents Prefer Low-Reward Advisors <a href="https://arxiv.org/pdf/2512.17180" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2512.17444" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Value Under Ignorance in Universal Artificial Intelligence <a href="https://arxiv.org/pdf/2512.17086" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Reinforcement Learning for Self-Improving Agent with Skill Library <a href="https://arxiv.org/pdf/2512.17102" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Understanding Generalization in Role-Playing Models via Information Theory <a href="https://arxiv.org/pdf/2512.17270" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] A Theoretical Analysis of State Similarity Between Markov Decision Processes <a href="https://arxiv.org/pdf/2512.17265" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows <a href="https://arxiv.org/pdf/2512.16969" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Large Language Models as Pokémon Battle Agents: Strategic Play and Content Generation <a href="https://arxiv.org/pdf/2512.17308" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Turn-PPO: Turn-Level Advantage Estimation with PPO for Improved Multi-Turn RL in Agentic LLMs <a href="https://arxiv.org/pdf/2512.17008" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] UniRel-R1: RL-tuned LLM Reasoning for Knowledge Graph Relational Question Answering <a href="https://arxiv.org/pdf/2512.17043" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Learning Safe Autonomous Driving Policies Using Predictive Safety Representations <a href="https://arxiv.org/pdf/2512.17586" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] SCOPE: Sequential Causal Optimization of Process Interventions <a href="https://arxiv.org/pdf/2512.17629" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Trust-Region Adaptive Policy Optimization <a href="https://arxiv.org/pdf/2512.17636" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] About Time: Model-free Reinforcement Learning with Timed Reward Machines <a href="https://arxiv.org/pdf/2512.17637" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Planning as Descent: Goal-Conditioned Latent Trajectory Synthesis in Learned Energy Landscapes <a href="https://arxiv.org/pdf/2512.17846" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning <a href="https://arxiv.org/pdf/2512.17853" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Distributionally Robust Imitation Learning: Layered Control Architecture for Certifiable Autonomy <a href="https://arxiv.org/pdf/2512.17899" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] HydroGym: A Reinforcement Learning Platform for Fluid Dynamics <a href="https://arxiv.org/pdf/2512.17534" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 8</strong></p>
<ul>
<li class="">[arXiv251222] AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators <a href="https://arxiv.org/pdf/2512.17267" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] LibriVAD: A Scalable Open Dataset with Deep Learning Benchmarks for Voice Activity Detection <a href="https://arxiv.org/pdf/2512.17281" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Fair Voting Methods as a Catalyst for Democratic Resilience: A Trilogy on Legitimacy, Impact and AI Safeguarding <a href="https://arxiv.org/pdf/2512.17461" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making <a href="https://arxiv.org/pdf/2512.17091" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] SDUM: A Scalable Deep Unrolled Model for Universal MRI Reconstruction <a href="https://arxiv.org/pdf/2512.17137" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] MINPO: Memory-Informed Neural Pseudo-Operator to Resolve Nonlocal Spatiotemporal Dynamics <a href="https://arxiv.org/pdf/2512.17273" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] M2RU: Memristive Minion Recurrent Unit for Continual Learning at the Edge <a href="https://arxiv.org/pdf/2512.17299" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251222] Generative Multi-Objective Bayesian Optimization with Scalable Batch Evaluations for Sample-Efficient De Novo Molecular Design <a href="https://arxiv.org/pdf/2512.17659" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-22T02:53:26.000Z" itemprop="dateModified">Dec 22, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20251215-20251221"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251215-20251221</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-12-22" class="table-of-contents__link toc-highlight">2025-12-22</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>