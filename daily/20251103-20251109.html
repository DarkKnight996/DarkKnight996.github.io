<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20251103-20251109" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251103-20251109 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20251103-20251109"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251103-20251109 | DarkKnight Note"><meta data-rh="true" name="description" content="2025-11-03"><meta data-rh="true" property="og:description" content="2025-11-03"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20251103-20251109"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20251103-20251109" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20251103-20251109" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20251103-20251109","item":"https://darkknight996.github.io/daily/20251103-20251109"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.6a1ccf3e.js" defer="defer"></script>
<script src="/assets/js/main.9a4ff55c.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251103-20251109</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251103-20251109</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-11-03">2025-11-03<a href="#2025-11-03" class="hash-link" aria-label="Direct link to 2025-11-03" title="Direct link to 2025-11-03" translate="no">​</a></h2>
<p><strong>cs.DC total: 8</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251103] ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [adaptive expert prefetching, cache-aware routing, hybrid cross-layer prediction, runtime statistics, memory coordination]</li>
<li class=""><strong>authors:</strong> Zixu Shen, Kexin Chu, Yifan Zhang, Dawei Xiang, Runxin Wu, Wei Zhang</li>
<li class=""><strong>institution:</strong> University of Connecticut</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26730" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26730</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ExpertFlow introduces an adaptive runtime system that combines expert prefetching and cache-aware routing to optimize MoE inference. It dynamically adjusts prediction horizons using runtime statistics and hybrid prediction schemes to reduce parameter transfer latency. The system reduces model stall time to less than 0.1% of baseline while operating under strict memory constraints.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251103] Wireless Sensor Networks as Parallel and Distributed Hardware Platform for Artificial Neural Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [wireless sensor networks, parallel distributed processing, artificial neural networks, real-time computation, large-scale problems]</li>
<li class=""><strong>authors:</strong> Gursel Serpen</li>
<li class=""><strong>institution:</strong> The University of Toledo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26492" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26492</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using wireless sensor networks as a massively parallel and distributed hardware platform to implement artificial neural network algorithms. The approach enables real-time computation of large-scale problems by leveraging hundreds of thousands of processing nodes with onboard processing and wireless communication capabilities. This implementation could revolutionize computing by making it possible to solve very large-scale scientific and engineering problems in real time.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251103] Detecting Anomalies in Machine Learning Infrastructure via Hardware Telemetry</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [hardware telemetry, unsupervised learning, anomaly detection, hardware-centric approach]</li>
<li class=""><strong>authors:</strong> Ziji Chen, Steven Chien, Peng Qian, Noa Zilberman</li>
<li class=""><strong>institution:</strong> University of Oxford</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26008" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26008</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a hardware-centric anomaly detection system that uses low-level hardware telemetry and unsupervised learning to identify performance issues in ML infrastructure. This approach requires no workload knowledge and relies solely on hardware signals accessible to cloud operators. The method successfully detected network and configuration issues, accelerating the DeepSeek model by 5.97% in experiments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251103] Foundations of Fiat-Denominated Loans Collateralized by Cryptocurrencies</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [decentralized finance protocols], [trusted arbitration, game-theoretical analysis, subgame perfect equilibrium, limited-custodial protocols]</li>
<li class=""><strong>authors:</strong> Pavel Hubáček, Jan Václavek, Michelle Yeo</li>
<li class=""><strong>institution:</strong> Institute of Mathematics, Czech Academy of Sciences, Charles University, Firefish, National University of Singapore</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.25878" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.25878</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes limited-custodial protocols for fiat-denominated loans collateralized by cryptocurrencies that rely on trusted arbitration. The authors provide a game-theoretical analysis showing these protocols achieve secure lending mechanisms. The work establishes foundations for cryptocurrency-backed lending while highlighting future research directions in decentralized finance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251103] ReSpec: Towards Optimizing Speculative Decoding in Reinforcement Learning Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [speculative decoding, reinforcement learning, knowledge distillation, dynamic configuration tuning, reward-weighted updates]</li>
<li class=""><strong>authors:</strong> Qiaoling Chen, Zijun Liu, Peng Sun, Shenggui Li, Guoteng Wang, Ziming Liu, Yonggang Wen, Siyuan Feng, Tianwei Zhang</li>
<li class=""><strong>institution:</strong> Nanyang Technological University, Shanghai Qiji Zhifeng Co., Ltd., Tsinghua University, National University of Singapore, Shanghai Innovation Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26475" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26475</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ReSpec optimizes speculative decoding for reinforcement learning systems by dynamically tuning configurations, evolving drafters via knowledge distillation, and weighting updates with rollout rewards. The system achieves up to 4.5× speedup while maintaining reward convergence and training stability, providing an efficient solution for RL-based LLM adaptation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251103] Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [over-the-air federated learning, stochastic gradient descent, successive convex approximation, power-control design, bias-variance trade-off]</li>
<li class=""><strong>authors:</strong> Muhammad Faraz Ul Abrar, Nicolò Michelusi</li>
<li class=""><strong>institution:</strong> Arizona State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26722" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26722</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a novel over-the-air federated learning approach that allows structured model bias to reduce update variance under heterogeneous wireless conditions. The method uses a successive convex approximation algorithm for joint power-control optimization requiring only statistical channel state information. Experiments show this approach accelerates convergence and improves generalization compared to prior OTA-FL baselines by optimizing the bias-variance trade-off.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251103] An All-Reduce Compatible Top-K Compressor for Communication-Efficient Distributed Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [gradient sparsification, all-reduce compatible compression, error feedback, top-k selection]</li>
<li class=""><strong>authors:</strong> Chuyan Chen, Chenyang Ma, Zhangxin Li, Yutong He, Yanjie Dong, Kun Yuan</li>
<li class=""><strong>institution:</strong> Peking University, Shenzhen MSU-BIT University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26709" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26709</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ARC-Top-K, an All-Reduce compatible gradient compressor that aligns sparsity patterns across nodes using gradient sketches to enable efficient communication. This method preserves globally significant gradient information while being provably contractive and compatible with momentum error feedback. Empirical results show it matches Top-K accuracy while reducing training time by up to 60.7%, combining Rand-K&#x27;s robustness with Top-K&#x27;s performance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251103] Environmental Impact of CI/CD Pipelines</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud computing sustainability], [carbon footprint analysis, water footprint analysis, GitHub Actions, Cloud Carbon Footprint framework, computational resource optimization]</li>
<li class=""><strong>authors:</strong> Nuno Saavedra, Alexandra Mendes, João F. Ferreira</li>
<li class=""><strong>institution:</strong> INESC-ID, University of Lisbon, INESC TEC, University of Porto</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2510.26413" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2510.26413</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper analyzes the environmental impact of GitHub Actions CI/CD pipelines using the Cloud Carbon Footprint framework on a dataset of over 2.2 million workflow runs. The study reveals substantial carbon and water footprints, estimating 456.9 MTCO2e and 5,738.2 kiloliters respectively in the most likely scenario. The authors recommend mitigation strategies including deploying runners in environmentally favorable regions and reducing wasted computational resources.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 32</strong></p>
<ul>
<li class="">[arXiv251103] A Game-Theoretic Spatio-Temporal Reinforcement Learning Framework for Collaborative Public Resource Allocation <a href="https://arxiv.org/pdf/2510.26184" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Think Outside the Policy: In-Context Steered Policy Optimization <a href="https://arxiv.org/pdf/2510.26519" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] InputDSA: Demixing then Comparing Recurrent and Externally Driven Dynamics <a href="https://arxiv.org/pdf/2510.25943" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Approximating Human Preferences Using a Multi-Judge Learned System <a href="https://arxiv.org/pdf/2510.25884" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] PORTool: Tool-Use LLM Training with Rewarded Tree <a href="https://arxiv.org/pdf/2510.26020" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Estimating cognitive biases with attention-aware inverse planning <a href="https://arxiv.org/pdf/2510.25951" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] MedVLSynther: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs <a href="https://arxiv.org/pdf/2510.25867" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Conformal Prediction Beyond the Horizon: Distribution-Free Inference for Policy Evaluation <a href="https://arxiv.org/pdf/2510.26026" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mtext mathvariant="monospace">RL</mtext></msub></mrow><annotation encoding="application/x-tex">π_\texttt{RL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2778em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord texttt mtight">RL</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: Online RL Fine-tuning for Flow-based Vision-Language-Action Models <a href="https://arxiv.org/pdf/2510.25889" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] EgoExo-Con: Exploring View-Invariant Video Temporal Understanding <a href="https://arxiv.org/pdf/2510.26113" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle Routing <a href="https://arxiv.org/pdf/2510.26089" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] InfoFlow: Reinforcing Search Agent Via Reward Density Optimization <a href="https://arxiv.org/pdf/2510.26575" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Offline Clustering of Preference Learning with Active-data Augmentation <a href="https://arxiv.org/pdf/2510.26301" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Learning to Manage Investment Portfolios beyond Simple Utility Functions <a href="https://arxiv.org/pdf/2510.26165" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks <a href="https://arxiv.org/pdf/2510.26098" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Multi-Agent Reinforcement Learning for Market Making: Competition without Collusion <a href="https://arxiv.org/pdf/2510.25929" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Do Not Step Into the Same River Twice: Learning to Reason from Trial and Error <a href="https://arxiv.org/pdf/2510.26109" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Kimi Linear: An Expressive, Efficient Attention Architecture <a href="https://arxiv.org/pdf/2510.26692" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle <a href="https://arxiv.org/pdf/2510.26347" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Action-Driven Processes for Continuous-Time Control <a href="https://arxiv.org/pdf/2510.26672" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Adaptive Context Length Optimization with Low-Frequency Truncation for Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2510.26389" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start <a href="https://arxiv.org/pdf/2510.25801" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Human-in-the-loop Online Rejection Sampling for Robotic Manipulation <a href="https://arxiv.org/pdf/2510.26406" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Data-Efficient RLVR via Off-Policy Influence Guidance <a href="https://arxiv.org/pdf/2510.26491" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math <a href="https://arxiv.org/pdf/2510.26143" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] The Era of Agentic Organization: Learning to Organize with Language Models <a href="https://arxiv.org/pdf/2510.26658" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning <a href="https://arxiv.org/pdf/2510.25992" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Non-myopic Matching and Rebalancing in Large-Scale On-Demand Ride-Pooling Systems Using Simulation-Informed Reinforcement Learning <a href="https://arxiv.org/pdf/2510.25796" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Graph-Enhanced Policy Optimization in LLM Agent Training <a href="https://arxiv.org/pdf/2510.26270" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] A General Incentives-Based Framework for Fairness in Multi-agent Resource Allocation <a href="https://arxiv.org/pdf/2510.26740" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning <a href="https://arxiv.org/pdf/2510.26167" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Defeating the Training-Inference Mismatch via FP16 <a href="https://arxiv.org/pdf/2510.26788" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 9</strong></p>
<ul>
<li class="">[arXiv251103] Polybasic Speculative Decoding Through a Theoretical Perspective <a href="https://arxiv.org/pdf/2510.26527" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation <a href="https://arxiv.org/pdf/2510.25904" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] PRESTO: Preimage-Informed Instruction Optimization for Prompting Black-Box LLMs <a href="https://arxiv.org/pdf/2510.25808" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] FlowQ-Net: A Generative Framework for Automated Quantum Circuit Design <a href="https://arxiv.org/pdf/2510.26688" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Risks and Opportunities in Human-Machine Teaming in Operationalizing Machine Learning Target Variables <a href="https://arxiv.org/pdf/2510.25974" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] Data-Efficient RLVR via Off-Policy Influence Guidance <a href="https://arxiv.org/pdf/2510.26491" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache <a href="https://arxiv.org/pdf/2510.25979" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] The Kinetics of Reasoning: How Chain-of-Thought Shapes Learning in Transformers? <a href="https://arxiv.org/pdf/2510.25791" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251103] The FM Agent <a href="https://arxiv.org/pdf/2510.26144" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-11-03T02:28:52.000Z" itemprop="dateModified">Nov 3, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20251027-20251102"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251027-20251102</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-11-03" class="table-of-contents__link toc-highlight">2025-11-03</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>