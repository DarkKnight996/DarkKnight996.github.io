<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20260302-20260308" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20260302-20260308 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20260302-20260308"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20260302-20260308 | DarkKnight Note"><meta data-rh="true" name="description" content="2026-03-02"><meta data-rh="true" property="og:description" content="2026-03-02"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20260302-20260308"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260302-20260308" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260302-20260308" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20260302-20260308","item":"https://darkknight996.github.io/daily/20260302-20260308"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.5e1fce07.js" defer="defer"></script>
<script src="/assets/js/main.138dced8.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260105-20260111"><span title="20260105-20260111" class="linkLabel_WmDU">20260105-20260111</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260112-20260118"><span title="20260112-20260118" class="linkLabel_WmDU">20260112-20260118</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260119-20260125"><span title="20260119-20260125" class="linkLabel_WmDU">20260119-20260125</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260126-20260201"><span title="20260126-20260201" class="linkLabel_WmDU">20260126-20260201</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260202-20260208"><span title="20260202-20260208" class="linkLabel_WmDU">20260202-20260208</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260209-20260215"><span title="20260209-20260215" class="linkLabel_WmDU">20260209-20260215</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260216-20260222"><span title="20260216-20260222" class="linkLabel_WmDU">20260216-20260222</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260223-20260301"><span title="20260223-20260301" class="linkLabel_WmDU">20260223-20260301</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20260302-20260308"><span title="20260302-20260308" class="linkLabel_WmDU">20260302-20260308</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20260302-20260308</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20260302-20260308</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-03-02">2026-03-02<a href="#2026-03-02" class="hash-link" aria-label="Direct link to 2026-03-02" title="Direct link to 2026-03-02" translate="no">​</a></h2>
<p><strong>cs.DC total: 12</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260302] QoSFlow: Ensuring Service Quality of Distributed Workflows Using Interpretable Sensitivity Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed workflow scheduling], [performance modeling, configuration space partitioning, statistical sensitivity, QoS-driven scheduling]</li>
<li class=""><strong>authors:</strong> Md Hasanur Rashid, Jesun Firoz, Nathan R. Tallent, Luanzheng Guo, Meng Tang, Dong Dai</li>
<li class=""><strong>institution:</strong> University of Delaware, Pacific Northwest National Laboratory, Illinois Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.23598" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.23598</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QoSFlow is a performance modeling method that partitions a workflow&#x27;s execution configuration space into regions with similar behavior to enable efficient QoS-driven scheduling. It outperforms the best-performing standard heuristic by 27.38% and its recommended configurations consistently match measured execution outcomes across different QoS constraints.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260302] Mixed Choice in Asynchronous Multiparty Session Types</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems], [multiparty session types, asynchronous communication, mixed choice, protocol verification, Erlang/OTP]</li>
<li class=""><strong>authors:</strong> Laura Bocchi, Raymond Hu, Adriana Laura Voinea, Simon Thompson</li>
<li class=""><strong>institution:</strong> University of Kent, Queen Mary University of London, University of Glasgow</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.23927" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.23927</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a multiparty session type framework that supports asynchronous mixed choice, allowing for transient state inconsistencies while guaranteeing eventual consistency among distributed participants. The authors prove the system&#x27;s correctness and implement a toolchain for specifying and validating such protocols, which they test by reimplementing part of the RabbitMQ broker&#x27;s client.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260302] nvidia-pcm: A D-Bus-Driven Platform Configuration Manager for OpenBMC Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [firmware management], [D-Bus, JSON configuration, environment variables, systemd, OpenBMC]</li>
<li class=""><strong>authors:</strong> Harinder Singh</li>
<li class=""><strong>institution:</strong> NVIDIA Corporation</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.24237" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.24237</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces nvidia-pcm, a D-Bus-driven platform configuration manager for OpenBMC environments that uses JSON files to declaratively define hardware variants. At boot, it queries hardware identity via D-Bus and exports platform-specific configurations as environment variables, enabling a single firmware image to serve multiple server platforms. This approach eliminates the need for separate firmware builds per variant, significantly reducing maintenance overhead.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260302] Green or Fast? Learning to Balance Cold Starts and Idle Carbon in Serverless Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [deep reinforcement learning, serverless computing, cold-start optimization, carbon-aware management, sequential decision problem]</li>
<li class=""><strong>authors:</strong> Bowen Sun, Christos D. Antonopoulos, Evgenia Smirni, Bin Ren, Nikolaos Bellas, Spyros Lalis</li>
<li class=""><strong>institution:</strong> William &amp; Mary, University of Thessaly</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.23935" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.23935</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes LACE-RL, a framework that uses deep reinforcement learning to dynamically manage serverless function instances, balancing cold-start latency and idle carbon emissions. It formulates pod retention as a sequential decision problem, jointly modeling cold-start probability, latency costs, and real-time carbon intensity. The method significantly reduces both cold starts and idle carbon emissions compared to static policies, achieving a superior latency-carbon trade-off.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260302] 2G2T: Constant-Size, Statistically Sound MSM Outsourcing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cryptography], [multi-scalar multiplication, outsourcing protocol, statistical soundness, Ristretto255, constant-size verification]</li>
<li class=""><strong>authors:</strong> Majid Khabbazian</li>
<li class=""><strong>institution:</strong> University of Alberta</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.23464" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.23464</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents 2G2T, a protocol for verifiably outsourcing multi-scalar multiplication (MSM) computations to an untrusted server. It uses a one-time setup to generate a public merged-bases vector, allowing verification with only a single inner product and constant group operations, while the server performs two MSMs. The method achieves statistical soundness with a constant-size server response, making verification up to ~300x faster than local computation for large inputs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260302] FedDAG: Clustered Federated Learning via Global Data and Gradient Integration for Heterogeneous Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [clustered federated learning, dual-encoder architecture, weighted class-wise similarity, gradient integration, cross-cluster feature transfer]</li>
<li class=""><strong>authors:</strong> Anik Pramanik, Murat Kantarcioglu, Vincent Oria, Shantanu Sharma</li>
<li class=""><strong>institution:</strong> New Jersey Institute of Technology, Virginia Tech</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.23504" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.23504</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FedDAG is a clustered federated learning framework that uses a weighted, class-wise similarity metric combining both data and gradient information for client clustering, and employs a dual-encoder architecture to enable cross-cluster knowledge transfer. This approach provides a more holistic client similarity assessment and allows cluster models to benefit from diverse data across clusters. Experiments show that FedDAG consistently outperforms existing clustered FL methods in accuracy under heterogeneous data settings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260302] Rudder: Steering Prefetching in Distributed GNN Training using LLM Agents</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [LLM agents, in-context learning, prefetching, distributed GNN training, DistDGL]</li>
<li class=""><strong>authors:</strong> Aishwarya Sarkar, Sayan Ghosh, Nathan Tallent, Aman Chadha, Tanya Roosta, Ali Jannesari</li>
<li class=""><strong>institution:</strong> Iowa State University, Pacific Northwest National Laboratory, University of California, Berkeley, Amazon GenAI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.23556" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.23556</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Rudder, a software module that uses LLM agents for adaptive prefetching in distributed Graph Neural Network (GNN) training to minimize communication stalls. It leverages the in-context learning and reasoning capabilities of LLMs to dynamically decide what and when to prefetch, outperforming static methods. Evaluations show up to 91% improvement in training performance over a baseline with no prefetching and an 82% improvement over static prefetching.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260302] Data Driven Optimization of GPU efficiency for Distributed LLM Adapter Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [digital twin, machine learning model, greedy placement algorithm]</li>
<li class=""><strong>authors:</strong> Ferran Agullo, Joan Oliveras, Chen Wang, Alberto Gutierrez-Torre, Olivier Tardieu, Alaa Youssef, Jordi Torres, Josep Ll. Berral</li>
<li class=""><strong>institution:</strong> Barcelona Supercomputing Center (BSC), Universitat Politècnica de Catalunya - BarcelonaTech (UPC), IBM Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.24044" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.24044</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a data-driven pipeline to optimize GPU efficiency for distributed LLM adapter serving. The method combines a high-fidelity Digital Twin for performance emulation, a distilled ML model for fast prediction, and a greedy placement algorithm to minimize the number of GPUs needed for a workload. The results show the pipeline significantly improves GPU efficiency and can be adapted for other objectives like latency minimization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260302] MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [machine unlearning, privacy-preserving, server-client framework, perturbed copies, reparameterization, harmonic denoising]</li>
<li class=""><strong>authors:</strong> Tiantong Wang, Xinyu Yan, Tiantong Wu, Yurong Hao, Yong Jiang, Fei Huang, Wei Yang Bryan Lim</li>
<li class=""><strong>institution:</strong> Nanyang Technological University, Alibaba-NTU Global e-Sustainability CorpLab, Tongyi Lab, Alibaba Group</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.23798" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.23798</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes MPU, a privacy-preserving framework for machine unlearning in large language models that addresses dual non-disclosure constraints by distributing perturbed model copies to clients for local unlearning and aggregating updates server-side with denoising. It demonstrates that MPU maintains comparable unlearning performance to noise-free baselines across multiple algorithms, with minimal performance degradation even under added noise.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260302] Hestia: Hyperthread-Level Scheduling for Cloud Microservices with Interference-Aware Attention</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [hyperthread-level scheduling, interference-aware scheduling, self-attention, simultaneous multithreading (SMT), sharing-core (SC), sharing-socket (SS)]</li>
<li class=""><strong>authors:</strong> Dingyu Yang, Fanyong Kong, Jie Dai, Shiyou Qian, Shuangwei Li, Jian Cao, Guangtao Xue, Gang Chen</li>
<li class=""><strong>institution:</strong> Zhejiang University, Shanghai Jiao Tong University, Alibaba Group, OKBL Technology Company Limited</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.23758" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.23758</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents Hestia, a scheduling framework that uses a self-attention-based predictor and an interference scoring model to perform hyperthread-level, interference-aware placement of cloud microservices. It identifies and models two key contention patterns (sharing-core and sharing-socket) to mitigate performance interference. The system significantly reduces service latency and CPU consumption, outperforming existing schedulers in production deployments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260302] The PLUTO Code on GPUs: Offloading Lagrangian Particle Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high-performance computing], [OpenACC, MPI, GPU offloading, Lagrangian Particles, weak scaling, strong scaling]</li>
<li class=""><strong>authors:</strong> Alessio Suriano, Stefano Truzzi, Agnese Costa, Marco Rossazza, Nitin Shukla, Andrea Mignone, Vittoria Berta, Claudio Zanni</li>
<li class=""><strong>institution:</strong> Università degli Studi di Torino, Istituto Nazionale di Astrofisica, Italian Research Center on High Performance Computing, Big Data and Quantum Computing, CINECA</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.23434" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.23434</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a GPU-compatible redesign of the Lagrangian Particles module in the PLUTO astrophysics code using OpenACC and MPI for high-performance computing. The implementation demonstrates efficient scaling on up to 1024 GPUs, achieving a 6x speedup compared to CPU nodes. The work verifies the code against analytical solutions and is part of developing gPLUTO, a GPU-ready version of the legacy code.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260302] Advanced Scheduling Strategies for Distributed Quantum Computing Jobs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed quantum computing], [job scheduling, makespan, QPU utilization, non-local gate density, reinforcement learning, proximal policy optimization, FIFO, LIST]</li>
<li class=""><strong>authors:</strong> Gongyu Ni, Davide Ferrari, Lester Ho, Michele Amoretti</li>
<li class=""><strong>institution:</strong> Tyndall National Institute, University of Parma</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.24152" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.24152</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes and evaluates several advanced scheduling strategies for distributed quantum computing, including heuristics for resource maximization and a reinforcement learning approach. These methods are benchmarked against traditional schedulers like FIFO and LIST under various network conditions. The study concludes that the proposed strategies can effectively manage novel quantum-specific constraints, such as QPU utilization and entanglement latency, to improve job allocation in quantum networks.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 26</strong></p>
<ul>
<li class="">[arXiv260302] The Auton Agentic AI Framework <a href="https://arxiv.org/pdf/2602.23720" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Pacing Opinion Polarization via Graph Reinforcement Learning <a href="https://arxiv.org/pdf/2602.23390" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Multi-Objective Reinforcement Learning for Large-Scale Tote Allocation in Human-Robot Collaborative Fulfillment Centers <a href="https://arxiv.org/pdf/2602.24182" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Foundation World Models for Agents that Learn, Verify, and Adapt Reliably Beyond Static Environments <a href="https://arxiv.org/pdf/2602.23997" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] EMO-R3: Reflective Reinforcement Learning for Emotional Reasoning in Multimodal Large Language Models <a href="https://arxiv.org/pdf/2602.23802" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Bridging Dynamics Gaps via Diffusion Schrödinger Bridge for Cross-Domain Reinforcement Learning <a href="https://arxiv.org/pdf/2602.23737" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Actor-Critic Pretraining for Proximal Policy Optimization <a href="https://arxiv.org/pdf/2602.23804" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] See, Act, Adapt: Active Perception for Unsupervised Cross-Domain Visual Adaptation via Personalized VLM-Guided Agent <a href="https://arxiv.org/pdf/2602.23806" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Human Supervision as an Information Bottleneck: A Unified Theory of Error Floors in Human-Guided Learning <a href="https://arxiv.org/pdf/2602.23446" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] SafeGen-LLM: Enhancing Safety Generalization in Task Planning for Robotic Systems <a href="https://arxiv.org/pdf/2602.24235" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Construct, Merge, Solve &amp; Adapt with Reinforcement Learning for the min-max Multiple Traveling Salesman Problem <a href="https://arxiv.org/pdf/2602.23579" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Task Complexity Matters: An Empirical Study of Reasoning in LLMs for Sentiment Analysis <a href="https://arxiv.org/pdf/2602.24060" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Adaptive Correlation-Weighted Intrinsic Rewards for Reinforcement Learning <a href="https://arxiv.org/pdf/2602.24081" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] MAGE: Multi-scale Autoregressive Generation for Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2602.23770" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] RUMAD: Reinforcement-Unifying Multi-Agent Debate <a href="https://arxiv.org/pdf/2602.23864" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Bi-level RL-Heuristic Optimization for Real-world Winter Road Maintenance <a href="https://arxiv.org/pdf/2602.24097" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Recycling Failures: Salvaging Exploration in RLVR via Fine-Grained Off-Policy Guidance <a href="https://arxiv.org/pdf/2602.24110" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Beyond State-Wise Mirror Descent: Offline Policy Optimization with Parameteric Policies <a href="https://arxiv.org/pdf/2602.23811" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Learning to Build: Autonomous Robotic Assembly of Stable Structures Without Predefined Plans <a href="https://arxiv.org/pdf/2602.23934" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Learning to maintain safety through expert demonstrations in settings with unknown constraints: A Q-learning perspective <a href="https://arxiv.org/pdf/2602.23816" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Learning to Generate Secure Code via Token-Level Rewards <a href="https://arxiv.org/pdf/2602.23407" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Learning Flexible Job Shop Scheduling under Limited Buffers and Material Kitting Constraints <a href="https://arxiv.org/pdf/2602.24180" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Component Centric Placement Using Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2602.23540" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Pessimistic Auxiliary Policy for Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2602.23974" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] CUDA Agent: Large-Scale Agentic RL for High-Performance CUDA Kernel Generation <a href="https://arxiv.org/pdf/2602.24286" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] DARE-bench: Evaluating Modeling and Instruction Fidelity of LLMs in Data Science <a href="https://arxiv.org/pdf/2602.24288" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 6</strong></p>
<ul>
<li class="">[arXiv260302] SenCache: Accelerating Diffusion Model Inference via Sensitivity-Aware Caching <a href="https://arxiv.org/pdf/2602.24208" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] BiKA: Kolmogorov-Arnold-Network-inspired Ultra Lightweight Neural Network Hardware Accelerator <a href="https://arxiv.org/pdf/2602.23455" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] LK Losses: Direct Acceptance Rate Optimization for Speculative Decoding <a href="https://arxiv.org/pdf/2602.23881" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] Task-Centric Acceleration of Small-Language Models <a href="https://arxiv.org/pdf/2602.24174" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] FedNSAM<!-- -->:Consistency<!-- --> of Local and Global Flatness for Federated Learning <a href="https://arxiv.org/pdf/2602.23827" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260302] A distributed semismooth Newton based augmented Lagrangian method for distributed optimization <a href="https://arxiv.org/pdf/2602.23854" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2026-03-02T03:24:49.000Z" itemprop="dateModified">Mar 2, 2026</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20260223-20260301"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20260223-20260301</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2026-03-02" class="table-of-contents__link toc-highlight">2026-03-02</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>