<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20260209-20260215" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20260209-20260215 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20260209-20260215"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20260209-20260215 | DarkKnight Note"><meta data-rh="true" name="description" content="2026-02-09"><meta data-rh="true" property="og:description" content="2026-02-09"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20260209-20260215"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260209-20260215" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260209-20260215" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20260209-20260215","item":"https://darkknight996.github.io/daily/20260209-20260215"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.a7269b84.js" defer="defer"></script>
<script src="/assets/js/main.ce07ced2.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260105-20260111"><span title="20260105-20260111" class="linkLabel_WmDU">20260105-20260111</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260112-20260118"><span title="20260112-20260118" class="linkLabel_WmDU">20260112-20260118</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260119-20260125"><span title="20260119-20260125" class="linkLabel_WmDU">20260119-20260125</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260126-20260201"><span title="20260126-20260201" class="linkLabel_WmDU">20260126-20260201</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260202-20260208"><span title="20260202-20260208" class="linkLabel_WmDU">20260202-20260208</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20260209-20260215"><span title="20260209-20260215" class="linkLabel_WmDU">20260209-20260215</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20260209-20260215</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20260209-20260215</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-09">2026-02-09<a href="#2026-02-09" class="hash-link" aria-label="Direct link to 2026-02-09" title="Direct link to 2026-02-09" translate="no">​</a></h2>
<p><strong>cs.DC total: 21</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260209] Computationally Efficient Laplacian CL-colME</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [decentralized learning, collaborative mean estimation, consensus algorithms, Laplacian-based consensus, graph-based methods]</li>
<li class=""><strong>authors:</strong> Nikola Stankovic</li>
<li class=""><strong>institution:</strong> IEEE</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06070" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06070</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes CL-colME, a Laplacian-based consensus variant of collaborative mean estimation that avoids computationally expensive normalization processes. The method maintains the convergence and accuracy of the previous C-colME framework while improving computational efficiency in decentralized, heterogeneous networks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Experimental Analysis of Server-Side Caching for Web Performance</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [web performance optimization], [server-side caching, in-memory cache, response time, time-to-live, performance evaluation]</li>
<li class=""><strong>authors:</strong> Mohammad Umar, Bharat Tripathi</li>
<li class=""><strong>institution:</strong> Allenhouse Business School</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06074" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06074</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper experimentally compares the performance of a web server with and without simple in-memory caching using a fixed time-to-live. The results show that server-side caching significantly reduces response times, demonstrating its effectiveness for small-scale applications and educational use cases.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] PackInfer: Compute- and I/O-Efficient Attention for Batched LLM Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [kernel-level optimization, load-balanced execution groups, I/O-aware grouping, KV cache reorganization, FlashAttention]</li>
<li class=""><strong>authors:</strong> Rui Ning, Wei Zhang, Fan Lai</li>
<li class=""><strong>institution:</strong> Nanjing University, University of Illinois Urbana-Champaign</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06072" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06072</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PackInfer is a kernel-level attention framework that improves batched LLM inference by packing heterogeneous requests into load-balanced execution groups and reorganizing KV caches into group-contiguous layouts. This approach reduces computation and I/O imbalance, leading to reduced latency and increased throughput compared to FlashAttention.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] iScheduler: Reinforcement Learning-Driven Continual Optimization for Large-Scale Resource Investment Problems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [reinforcement learning, iterative scheduling, Markov decision process, resource investment problem, decomposition, reconfiguration]</li>
<li class=""><strong>authors:</strong> Yi-Xiang Hu, Yuke Wang, Feng Wu, Zirui Huang, Shuli Zeng, Xiang-Yang Li</li>
<li class=""><strong>institution:</strong> University of Science and Technology of China</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06064" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06064</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces iScheduler, a framework that uses reinforcement learning to iteratively schedule tasks by decomposing large resource investment problems into subproblems modeled as a Markov decision process. It achieves fast schedule generation and supports efficient updates by reusing unaffected schedules. Experiments show it reduces time to feasibility by up to 43x while maintaining competitive resource costs compared to commercial solvers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] FlashSketch: Sketch-Kernel Co-Design for Fast Sparse Sketching on GPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [BlockPerm-SJLT, sketch-kernel co-design, sparse sketching, oblivious subspace embedding, CUDA kernel, memory bandwidth]</li>
<li class=""><strong>authors:</strong> Rajat Vadiraj Dwaraknath, Sungyoon Kim, Mert Pilanci</li>
<li class=""><strong>institution:</strong> Stanford University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06071" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06071</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces FlashSketch, a method that co-designs a new sparse sketch family (BlockPerm-SJLT) with an optimized CUDA kernel to improve GPU efficiency. This approach explicitly trades off sketching robustness with hardware performance. The result is a significant speedup (1.7x geomean) over prior state-of-the-art GPU sketches across various benchmarks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Quantifying Energy-Efficient Edge Intelligence: Inference-time Scaling Laws for Heterogeneous Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [scaling laws, heterogeneous orchestration, hardware-aware routing, progressive sample multiplexing, cost models, Intelligence Per Watt, Energy-Coverage Efficiency, Price-Power-Performance]</li>
<li class=""><strong>authors:</strong> Satyam Kumar, Saurabh Jha</li>
<li class=""><strong>institution:</strong> Not explicitly provided in the given text.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06057" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06057</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces QEIL, a framework that uses inference-time scaling laws and heterogeneous hardware orchestration (across CPU, GPU, NPU) to optimize LLM inference on edge devices. It demonstrates that this approach achieves significant improvements in coverage, energy efficiency, latency, and cost compared to homogeneous methods, establishing it as an optimal strategy for energy-constrained edge AI systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] HQP: Sensitivity-Aware Hybrid Quantization and Pruning for Ultra-Low-Latency Edge AI Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [hybrid quantization, structural pruning, Fisher Information Matrix, sensitivity-aware pruning, post-training quantization, model compression]</li>
<li class=""><strong>authors:</strong> Dinesh Gopalan, Ratul Ali</li>
<li class=""><strong>institution:</strong> AMD, Jahangirnagar University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06069" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06069</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces HQP, a sensitivity-aware hybrid framework that combines structural pruning using a dynamic weight sensitivity metric from an efficient Fisher Information Matrix approximation, followed by conditional 8-bit post-training quantization. It achieves up to 3.12× inference speedup and 55% model size reduction while limiting accuracy drop to under 1.5% on edge platforms like NVIDIA Jetson. The method outperforms single-objective compression techniques, providing a hardware-agnostic solution for ultra-low-latency edge AI inference.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Canzona: A Unified, Asynchronous, and Load-Balanced Framework for Distributed Matrix-based Optimizers</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [matrix-based optimizers, data parallelism, tensor parallelism, asynchronous compute, load balancing, Shampoo, Muon, SOAP, ZeRO]</li>
<li class=""><strong>authors:</strong> Liangyu Wang, Siqi Zhang, Junjie Wang, Yiming Dong, Bo Zheng, Zihan Qiu, Shengkun Tang, Di Wang, Rui Men, Dayiheng Liu</li>
<li class=""><strong>institution:</strong> KAUST, Alibaba Group, Peking University, MBZUAI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06079" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06079</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Canzona, a framework that decouples logical optimizer assignment from physical parameter distribution to efficiently run matrix-based optimizers (like Shampoo) in distributed LLM training. It introduces load-balanced partitioning for Data Parallelism and an asynchronous compute pipeline for Tensor Parallelism. Evaluations show it preserves parallel architecture efficiency, achieving a 1.57x end-to-end speedup and reducing optimizer step latency by 5.8x.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Mapping Gemma3 onto an Edge Dataflow Architecture</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [dequantization engine, tiled matrix multiplication, FlowQKV, FusedDQP, FlowKV, Q4NX quantization, dataflow architecture]</li>
<li class=""><strong>authors:</strong> Shouyu Du, Miaoxiang Yu, Zhiheng Ni, Jillian Cai, Qing Yang, Tao Wei, Zhenyu Xu</li>
<li class=""><strong>institution:</strong> Clemson University, University of Rhode Island</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06063" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06063</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents the first end-to-end deployment of the Gemma3 family of models on an AMD Ryzen AI NPU, introducing hardware-aware techniques like FlowQKV for prefill and FusedDQP for decoding, along with a custom 4-bit quantization format. The methods achieve significant speed and power efficiency improvements over iGPU and CPU baselines. The work demonstrates that modern NPUs can enable practical, low-power LLM and VLM inference at the edge and provides a blueprint for mapping transformers onto tiled dataflow accelerators.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] MemGUI-Bench: Benchmarking Memory of Mobile GUI Agents in Dynamic Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [memory-centric benchmark, mobile GUI agents, LLM-as-judge, pass@k, cross-session learning, cross-temporal retention, cross-spatial retention, Progressive Scrutiny]</li>
<li class=""><strong>authors:</strong> Guangyi Liu, Pengxiang Zhao, Yaozhen Liang, Qinyi Luo, Shunye Tang, Yuxiang Chai, Weifeng Lin, Han Xiao, WenHao Wang, Siheng Chen, Zhengxi Lu, Gao Wu, Hao Wang, Liang Liu, Yong Liu</li>
<li class=""><strong>institution:</strong> Zhejiang University, Nankai University, The Chinese University of Hong Kong, Shanghai Jiao Tong University, vivo AI Lab</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06075" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06075</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MemGUI-Bench, a comprehensive benchmark and evaluation pipeline designed to assess the memory capabilities of mobile GUI agents. The method includes a memory taxonomy, 128 memory-challenging tasks, and an automated evaluator (MemGUI-Eval) using staged LLM-as-judge and Progressive Scrutiny. The main conclusion is that current state-of-the-art agents exhibit significant memory deficits, with the benchmark identifying five distinct failure modes and synthesizing actionable design implications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] LAAFD: LLM-based Agents for Accelerated FPGA Design</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [high-level synthesis, FPGA, agentic workflow, pipelining, vectorization, dataflow partitioning, co-simulation]</li>
<li class=""><strong>authors:</strong> Maxim Moraru, Kamalavasan Kamalakkannan, Jered Dominguez-Trujillo, Patrick Diehl, Atanu Barai, Julien Loiseau, Zachary Kent Baker, Howard Pritchard, Galen M Shipman</li>
<li class=""><strong>institution:</strong> Los Alamos National Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06085" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06085</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces LAAFD, an agentic workflow that uses large language models to automatically translate general-purpose C++ code into optimized FPGA kernels for Vitis HLS. The system leverages HLS co-simulation and synthesis feedback to iteratively apply hardware optimizations like pipelining and dataflow. The results show that LAAFD achieves performance comparable to hand-tuned baselines, significantly lowering the expertise barrier for FPGA acceleration.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] BouquetFL: Emulating diverse participant hardware in Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, hardware emulation, resource restriction, GPU constraints, CPU throttling, memory constraints, heterogeneous clients]</li>
<li class=""><strong>authors:</strong> Arno Geimer</li>
<li class=""><strong>institution:</strong> Not specified (author email domain not provided)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06498" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06498</a></li>
<li class=""><strong>Simple LLM Summary:</strong> BouquetFL is a framework that simulates heterogeneous client hardware in federated learning by programmatically restricting CPU, memory, and GPU resources on a single machine. It enables controlled experimentation under realistic hardware diversity without requiring multiple physical devices. The tool addresses a methodological gap in FL research by providing an accessible way to study system heterogeneity, bringing experimental practice closer to practical deployment conditions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] AdFL: In-Browser Federated Learning for Online Advertisement</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, differential privacy, in-browser training, ad viewability prediction]</li>
<li class=""><strong>authors:</strong> Ahmad Alemari, Pritam Sen, Cristian Borcea</li>
<li class=""><strong>institution:</strong> New Jersey Institute of Technology, Jazan University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06336" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06336</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes AdFL, a federated learning framework that runs directly in users&#x27; web browsers to learn ad preferences without sharing raw data. It demonstrates the framework&#x27;s feasibility for real-time in-browser training and shows that an ad viewability prediction model built on it achieves high performance, which is maintained even when differential privacy is applied for enhanced security.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] FCDP: Fully Cached Data Parallel for Communication-Avoiding Large-Scale Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [ZeRO-3, host memory caching, parameter-efficient fine-tuning, all-gather, data parallel]</li>
<li class=""><strong>authors:</strong> Gyeongseo Park, Eungyeong Lee, Song-woo Sok, Myung-Hoon Cha, Kwangwon Koh, Baik-Song An, Hongyeon Kim, Ki-Dong Kang</li>
<li class=""><strong>institution:</strong> Electronics and Telecommunications Research Institute (ETRI)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06499" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06499</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FCDP, a method that caches forward-pass parameters in host memory to reuse them during the backward pass, eliminating redundant inter-node communication while preserving a minimal GPU memory footprint. It achieves up to 100x higher throughput than ZeRO-3 on commodity hardware by leveraging host memory as a fast cache layer instead of an overflow tier.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Degradation of Feature Space in Continual Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [continual learning], [isotropic regularization, contrastive learning, rehearsal strategies, catastrophic forgetting, feature space geometry]</li>
<li class=""><strong>authors:</strong> Chiara Lanza, Roberto Pereira, Marco Miozzo, Eduard Angelats, Paolo Dini</li>
<li class=""><strong>institution:</strong> CTTC (Centre Tecnològic de Telecomunicacions de Catalunya)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06586" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06586</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates whether enforcing isotropy in the feature space can improve continual learning by mitigating catastrophic forgetting. Using contrastive continual learning techniques with rehearsal on CIFAR datasets, the authors find that isotropic regularization actually degrades model performance. The conclusion is that isotropy, beneficial in centralized training, is not a suitable inductive bias for non-stationary continual learning scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Reinforcement Learning-Based Dynamic Management of Structured Parallel Farm Skeletons on Serverless Platforms</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [reinforcement learning, serverless computing, autoscaling, OpenFaaS, farm skeleton, Gymnasium]</li>
<li class=""><strong>authors:</strong> Lanpei Li, Massimo Coppola, Malio Li, Valerio Besozzi, Jack Bell, Vincenzo Lomonaco</li>
<li class=""><strong>institution:</strong> National Research Council of Italy (CNR), University of Pisa, LUISS University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06555" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06555</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a framework using Reinforcement Learning (RL) to dynamically manage the autoscaling of a parallel task farm skeleton on a serverless platform (OpenFaaS). It evaluates RL-based policies against a reactive baseline, finding that AI-driven management better handles platform-specific limitations, improving Quality of Service (QoS) while maintaining efficient resource usage.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] DualMap: Enabling Both Cache Affinity and Load Balancing for Distributed LLM Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [dual-mapping scheduling, cache-affinity scheduling, load-balancing scheduling, KV cache reuse, SLO-aware routing, hotspot-aware rebalancing, dual-hash-ring scaling]</li>
<li class=""><strong>authors:</strong> Ying Yuan, Pengfei Zuo, Bo Wang, Zhangyu Chen, Zhipeng Tan, Zhou Yu</li>
<li class=""><strong>institution:</strong> Huazhong University of Science and Technology, Huawei</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06502" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06502</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes DualMap, a dual-mapping scheduling strategy for distributed LLM serving that maps each request to two candidate instances using independent hash functions to intelligently balance KV cache reuse and load distribution. It incorporates SLO-aware routing, hotspot-aware rebalancing, and lightweight scaling to handle dynamic workloads. Experiments show DualMap improves effective request capacity by up to 2.25x under the same TTFT SLO constraints compared to state-of-the-art methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Wonderboom -- Efficient, and Censorship-Resilient Signature Aggregation for Million Scale Consensus</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain consensus], [signature aggregation, censorship-resilient, Byzantine Fault Tolerant, quorum attestation, validator set, simulation]</li>
<li class=""><strong>authors:</strong> Zeta Avarikioti, Ray Neiheiser, Krzysztof Pietrzak, Michelle X. Yeo</li>
<li class=""><strong>institution:</strong> TU Wien, Institute of Science and Technology Austria, Nanyang Technological University, Aarhus University, Common Prefix</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06655" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06655</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Wonderboom, a new protocol designed to efficiently aggregate signatures from millions of validators in Ethereum&#x27;s consensus mechanism. It achieves this up to 32 times faster than the current state-of-the-art while providing stronger security guarantees against censorship and stake-shifting attacks. The authors implement a simulation tool to demonstrate that Wonderboom can handle over 2 million signatures within a single Ethereum slot.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Same Engine, Multiple Gears: Parallelizing Fixpoint Iteration at Different Granularities (Extended Version)</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [static analysis], [fixpoint iteration, parallelization, top-down solver, task granularity, immediate approach, independent approach, publish/subscribe]</li>
<li class=""><strong>authors:</strong> Ali Rasim Kocal, Michael Schwarz, Simmo Saan, Helmut Seidl</li>
<li class=""><strong>institution:</strong> Technical University of Munich, National University of Singapore, University of Tartu</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06680" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06680</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a parallel fixpoint engine for static analysis that is parametric in task granularity, enabling it to operate at different levels of parallelism. It implements two parallelization philosophies—immediate and independent—within the Goblint framework. The results demonstrate the approach&#x27;s effectiveness in reducing analysis times for large real-world programs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Implementing Grassroots Logic Programs with Multiagent Transition Systems and AI</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [concurrent logic programming], [Grassroots Logic Programs, multiagent transition systems, operational semantics, peer-to-peer, deterministic semantics]</li>
<li class=""><strong>authors:</strong> Ehud Shapiro</li>
<li class=""><strong>institution:</strong> London School of Economics, Weizmann Institute of Science</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06934" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06934</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents deterministic operational semantics (dGLP and madGLP) to facilitate the implementation of Grassroots Logic Programs, a concurrent logic programming language for peer-to-peer systems. The semantics were used as formal specifications for an AI to generate implementations in Dart for workstations and smartphones. The main conclusion is that the developed mathematical specifications enabled correct, implementation-ready semantics, though the development process required iterative refinement across mathematical, informal, and code layers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Distributed Knowledge in Simplicial Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [simplicial complexes, epistemic logic, Kripke models, distributed knowledge, majority consensus]</li>
<li class=""><strong>authors:</strong> Éric Goubault, Jérémy Ledent, Sergio Rajsbaum</li>
<li class=""><strong>institution:</strong> LIX, CNRS, École Polytechnique, Institut Polytechnique de Paris; Université Paris Cité, CNRS, IRIF; Instituto de Matemáticas, UNAM</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06945" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06945</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces simplicial complexes as models for multi-agent epistemic logic, shifting the focus from possible worlds to agents&#x27; local views. It connects this topological approach to distributed computing, showing how distributed knowledge relates to solving the majority consensus task. The work describes the specific distributed knowledge used when the task is solvable and presents a logical obstruction when it is not.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 30</strong></p>
<ul>
<li class="">[arXiv260209] Transformer-Based Reinforcement Learning for Autonomous Orbital Collision Avoidance in Partially Observable Environments <a href="https://arxiv.org/pdf/2602.06088" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning <a href="https://arxiv.org/pdf/2602.06107" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Self-Improving World Modelling with Latent Actions <a href="https://arxiv.org/pdf/2602.06130" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Flow Matching for Offline Reinforcement Learning with Discrete Actions <a href="https://arxiv.org/pdf/2602.06138" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Learning Rate Scaling across LoRA Ranks and Transfer to Full Finetuning <a href="https://arxiv.org/pdf/2602.06204" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Online Adaptive Reinforcement Learning with Echo State Networks for Non-Stationary Dynamics <a href="https://arxiv.org/pdf/2602.06326" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Training Data Selection with Gradient Orthogonality for Efficient Domain Adaptation <a href="https://arxiv.org/pdf/2602.06359" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization <a href="https://arxiv.org/pdf/2602.06394" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] TrailBlazer: History-Guided Reinforcement Learning for Black-Box LLM Jailbreaking <a href="https://arxiv.org/pdf/2602.06440" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Prism: Spectral Parameter Sharing for Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.06476" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents <a href="https://arxiv.org/pdf/2602.06485" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Adaptive Uncertainty-Aware Tree Search for Robust Reasoning <a href="https://arxiv.org/pdf/2602.06493" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Progress Constraints for Reinforcement Learning in Behavior Trees <a href="https://arxiv.org/pdf/2602.06525" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Dynamics-Aligned Shared Hypernetworks for Zero-Shot Actuator Inversion <a href="https://arxiv.org/pdf/2602.06550" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees <a href="https://arxiv.org/pdf/2602.06554" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] SPARC: Separating Perception And Reasoning Circuits for Test-time Scaling of VLMs <a href="https://arxiv.org/pdf/2602.06566" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Sample-Efficient Policy Space Response Oracles with Joint Experience Best Response <a href="https://arxiv.org/pdf/2602.06599" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] The hidden risks of temporal resampling in clinical reinforcement learning <a href="https://arxiv.org/pdf/2602.06603" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Humanoid Manipulation Interface: Humanoid Whole-Body Manipulation from Robot-Free Demonstrations <a href="https://arxiv.org/pdf/2602.06643" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] compar:IA: The French Government&#x27;s LLM arena to collect French-language human prompts and preference data <a href="https://arxiv.org/pdf/2602.06669" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] F-GRPO: Don&#x27;t Let Your Policy Learn the Obvious and Forget the Rare <a href="https://arxiv.org/pdf/2602.06717" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Semantically Labelled Automata for Multi-Task Reinforcement Learning with LTL Instructions <a href="https://arxiv.org/pdf/2602.06746" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Soft Forward-Backward Representations for Zero-shot Reinforcement Learning with General Utilities <a href="https://arxiv.org/pdf/2602.06769" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Generating Data-Driven Reasoning Rubrics for Domain-Adaptive Reward Modeling <a href="https://arxiv.org/pdf/2602.06795" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] AEGPO: Adaptive Entropy-Guided Policy Optimization for Diffusion Models <a href="https://arxiv.org/pdf/2602.06825" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] A first realization of reinforcement learning-based closed-loop EEG-TMS <a href="https://arxiv.org/pdf/2602.06907" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Continuous-time reinforcement learning: ellipticity enables model-free value function approximation <a href="https://arxiv.org/pdf/2602.06930" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Cochain Perspectives on Temporal-Difference Signals for Learning Beyond Markov Dynamics <a href="https://arxiv.org/pdf/2602.06939" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Optimal Derivative Feedback Control for an Active Magnetic Levitation System: An Experimental Study on Data-Driven Approaches <a href="https://arxiv.org/pdf/2602.06944" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.06960" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 16</strong></p>
<ul>
<li class="">[arXiv260209] Analyzing Diffusion and Autoregressive Vision Language Models in Multimodal Embedding Space <a href="https://arxiv.org/pdf/2602.06056" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Compressing LLMs with MoP: Mixture of Pruners <a href="https://arxiv.org/pdf/2602.06127" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding <a href="https://arxiv.org/pdf/2602.06161" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] To 2:4 Sparsity and Beyond: Neuron-level Activation Function to Accelerate LLM Pre-Training <a href="https://arxiv.org/pdf/2602.06183" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Accelerating Vision Transformers on Brain Processing Unit <a href="https://arxiv.org/pdf/2602.06300" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Beyond Code Contributions: How Network Position, Temporal Bursts, and Code Review Activities Shape Contributor Influence in Large-Scale Open Source Ecosystems <a href="https://arxiv.org/pdf/2602.06426" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Principle-Evolvable Scientific Discovery via Uncertainty Minimization <a href="https://arxiv.org/pdf/2602.06448" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] SaDiT: Efficient Protein Backbone Design via Latent Structural Tokenization and Diffusion Transformers <a href="https://arxiv.org/pdf/2602.06706" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] GhostCite: A Large-Scale Analysis of Citation Validity in the Age of Large Language Models <a href="https://arxiv.org/pdf/2602.06718" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] AEGPO: Adaptive Entropy-Guided Policy Optimization for Diffusion Models <a href="https://arxiv.org/pdf/2602.06825" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Are Deep Learning Based Hybrid PDE Solvers Reliable? Why Training Paradigms and Update Strategies Matter <a href="https://arxiv.org/pdf/2602.06842" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Rethinking Multi-Condition DiTs: Eliminating Redundant Attention via Position-Alignment and Keyword-Scoping <a href="https://arxiv.org/pdf/2602.06850" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents <a href="https://arxiv.org/pdf/2602.06855" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] When RL Meets Adaptive Speculative Training: A Unified Training-Serving System <a href="https://arxiv.org/pdf/2602.06932" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos <a href="https://arxiv.org/pdf/2602.06949" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.06960" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-10">2026-02-10<a href="#2026-02-10" class="hash-link" aria-label="Direct link to 2026-02-10" title="Direct link to 2026-02-10" translate="no">​</a></h2>
<p><strong>cs.DC total: 18</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260210] Privacy-Preserving Coding Schemes for Multi-Access Distributed Computing Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [placement delivery arrays, coded MapReduce, privacy-preserving coding, multi-access distributed computing]</li>
<li class=""><strong>authors:</strong> Shanuja Sasi</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology Kanpur</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.07850" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.07850</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces privacy constraints into the multi-access distributed computing (MADC) model and develops private coded schemes using extended placement delivery arrays. The proposed coding schemes reduce communication bottlenecks without file replication while ensuring the privacy of each reducer&#x27;s assigned function.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] Parallel Track Transformers: Enabling Fast GPU Inference with Reduced Synchronization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [tensor parallelism, Parallel Track Transformer, multi-GPU synchronization, model architecture, serving efficiency]</li>
<li class=""><strong>authors:</strong> Chong Wang, Nan Du, Tom Gunter, Tao Lei, Kulin Seth, Senyu Tong, Jianyu Wang, Guoli Yin, Xiyou Zhou, Kelvin Zou, Ruoming Pang</li>
<li class=""><strong>institution:</strong> Apple</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.07306" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.07306</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes the Parallel Track (PT) Transformer, a novel model architecture that uses multiple independent transformer &quot;tracks&quot; to minimize inter-GPU synchronization during inference. It achieves significant reductions in synchronization operations and improves serving efficiency, including faster token generation and higher throughput, when integrated into existing LLM serving frameworks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] Knowledge Graphs-Driven Intelligence for Distributed Decision Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Knowledge Graphs, Graph Embeddings, GraphSAGE, Knowledge Sharing, Distributed Decision Systems]</li>
<li class=""><strong>authors:</strong> Rosario Napoli, Gabriele Morabito, Antonio Celesti, Massimo Villari, Maria Fazio</li>
<li class=""><strong>institution:</strong> University of Messina</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.07614" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.07614</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a distributed knowledge-sharing architecture that uses Knowledge Graphs and Graph Embeddings, aggregated locally via GraphSAGE, to create a global semantic abstraction called a Knowledge Map for decentralized coordination. The method was validated in a resource orchestration use case, showing it effectively maintains semantic coherence and adaptability in dynamic environments like Edge Computing and IoT.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] Wireless Streamlet: A Spectrum-Aware and Cognitive Consensus Protocol for Edge IoT</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain consensus], [Channel-Aware Leader Election (CALE), coded dual-chain architecture, TDMA voting schedule, erasure coding, spectrum-aware consensus]</li>
<li class=""><strong>authors:</strong> Taotao Wang, Long Shi, Fang Liu, Qing Yang, Shengli Zhang</li>
<li class=""><strong>institution:</strong> Shenzhen University, Nanjing University of Science and Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.07630" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.07630</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Wireless Streamlet, a blockchain consensus protocol for edge IoT that uses a Channel-Aware Leader Election mechanism and a coded dual-chain architecture to improve reliability and efficiency in wireless networks. It demonstrates higher throughput and lower latency in lossy environments while reducing storage requirements.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] Multi-Agentic AI for Fairness-Aware and Accelerated Multi-modal Large Model Inference in Real-world Mobile Edge Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [multi-agentic AI, natural language reasoning, containerized deployment, runtime telemetry, prompt scheduling, resource management]</li>
<li class=""><strong>authors:</strong> Haiyuan Li, Hari Madhukumar, Shuangyi Yan, Yulei Wu, Dimitra Simeonidou</li>
<li class=""><strong>institution:</strong> University of Bristol</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.07215" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.07215</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a multi-agentic AI framework, powered by foundation language models, to optimize latency and fairness for multi-modal large model inference in mobile edge networks. The agents cooperatively manage prompt routing and model deployment using natural language reasoning over system telemetry. Experiments on a city-wide testbed show the solution reduces average latency by over 80% and improves fairness without requiring fine-tuning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] ZipFlow: a Compiler-based Framework to Unleash Compressed Data Movement for Modern GPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [data compression, GPU decompression, compiler-based framework, parallel patterns, scheduling strategies, PCIe bandwidth optimization]</li>
<li class=""><strong>authors:</strong> Gwangoo Yeo, Zhiyang Shen, Wei Cui, Matteo Interlandi, Rathijit Sen, Bailu Ding, Qi Chen, Minsoo Rhu</li>
<li class=""><strong>institution:</strong> KAIST, Tsinghua University, Microsoft Research Asia, Microsoft Gray Systems Lab</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.08190" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.08190</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ZipFlow is a compiler-based framework that optimizes compressed data transfer for GPU-accelerated data analytics by classifying compression algorithms into parallel patterns and applying tailored scheduling strategies. It achieves significant speedups over state-of-the-art GPU compression libraries and CPU-based query engines, enhancing end-to-end performance in data-intensive workloads.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] Don&#x27;t Always Pick the Highest-Performing Model: An Information Theoretic View of LLM Ensemble Selection</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [ensemble selection, mutual information, greedy algorithm, Gaussian-copula, correlated errors, budgeted selection]</li>
<li class=""><strong>authors:</strong> Yigit Turkmen, Baturalp Buyukates, Melih Bastopcu</li>
<li class=""><strong>institution:</strong> Bilkent University, University of Birmingham</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.08003" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.08003</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a greedy mutual-information selection algorithm for forming LLM ensembles under a query budget, aiming to maximize the information about the true label rather than just picking the highest-performing models. It shows that due to correlated errors among models, performance can saturate, and its method consistently outperforms baselines like selecting top-k models by accuracy on question answering and sentiment classification datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] Accuracy-Delay Trade-Off in LLM Offloading via Token-Level Uncertainty</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [mobile edge computing, offloading, token-level uncertainty, greedy offloading algorithm, accuracy-delay trade-off]</li>
<li class=""><strong>authors:</strong> Yumin Kim, Hyeonsu Lyu, Minjae Lee, Hyun Jong Yang</li>
<li class=""><strong>institution:</strong> Seoul National University, POSTECH</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.07958" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.07958</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes an uncertainty-aware offloading framework for LLM inference in mobile edge computing, using a token-level uncertainty metric to dynamically decide between local and server-side processing. It introduces a greedy offloading algorithm (GOA) that prioritizes offloading high-uncertainty queries to minimize delay while maintaining accuracy. The experiments show GOA achieves a favorable accuracy-delay trade-off, outperforming baseline strategies across varying user densities.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] Fork, Explore, Commit: OS Primitives for Agentic Exploration</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [branch context, copy-on-write, FUSE, atomic commit, process isolation, first-commit-wins]</li>
<li class=""><strong>authors:</strong> Cong Wang, Yusheng Zheng</li>
<li class=""><strong>institution:</strong> Multikernel Technologies, Inc., University of California, Santa Cruz</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.08199" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.08199</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a new OS abstraction called a &quot;branch context&quot; to support AI agentic exploration, providing isolated copy-on-write workspaces and process groups with atomic commit/rollback. It is realized through BranchFS, a FUSE-based filesystem, and a proposed branch() syscall for Linux. Preliminary evaluation shows efficient branch creation and commit overhead, addressing the need for reliable state isolation in parallel AI agent workflows.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] The CAPSARII Approach to Cyber-Secure Wearable, Ultra-Low-Power Networked Sensors for Soldier Health Monitoring</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [wearable sensors, Internet of Battlefield Things (IoBT), edge AI, cloud-based analytics, smart textile integration, ultra-low-power optimization, encryption, authentication]</li>
<li class=""><strong>authors:</strong> Luciano Bozzi, Christian Celidonio, Umberto Nuzzi, Massimo Biagini, Stefano Cherubin, Asbjørn Djupdal, Tor Andre Haugdahl, Andrea Aliverti, Alessandra Angelucci, Giovanni Agosta, Gerardo Pelosi, Paolo Belluco, Samuele Polistina, Riccardo Volpi, Luigi Malagò, Michael Schneider, Florian Wieczorek, Xabier Eguiluz</li>
<li class=""><strong>institution:</strong> Sea Sky Technologies, NTNU, Politecnico di Milano, LWT3, QUAESTA AI, BORN GmbH, IKERLAN</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.08080" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.08080</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The CAPSARII project proposes a wearable sensor system and IoBT framework to monitor soldiers&#x27; health using edge AI for real-time decision support and cloud analytics. It focuses on ultra-low-power optimization, smart textile integration, and cybersecurity. The approach aims to enhance soldier protection and operational effectiveness through data-driven insights.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] HEAL: Online Incremental Recovery for Leaderless Distributed Systems Across Persistency Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems], [leaderless systems, incremental recovery, linearizable consistency, memory persistency models, fault tolerance]</li>
<li class=""><strong>authors:</strong> Antonis Psistakis, Burak Ocalan, Fabien Chaix, Ramnatthan Alagappan, Josep Torrellas</li>
<li class=""><strong>institution:</strong> University of Illinois Urbana-Champaign, Foundation for Research and Technology-Hellas</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.08257" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.08257</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes HEAL, a low-overhead online incremental recovery scheme for non-transactional leaderless distributed systems. It presents algorithms for linearizable consistency across different memory persistency models. Experimental results show HEAL significantly reduces recovery latency and throughput degradation compared to conventional and leader-based recovery schemes.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] PARD: Enhancing Goodput for Inference Pipeline via Proactive Request Dropping</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [proactive request dropping, adaptive request priority, inference pipeline optimization]</li>
<li class=""><strong>authors:</strong> Zhixin Zhao, Yitao Hu, Simin Chen, Mingfang Ji, Wei Yang, Yuhao Zhang, Laiping Zhao, Wenxin Li, Xiulong Liu, Wenyu Qu, Hao Wang</li>
<li class=""><strong>institution:</strong> Tianjin University, University of Texas at Dallas, Stevens Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.08747" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.08747</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PARD introduces a proactive request dropping system for DNN inference pipelines, combining timely dropping decisions based on runtime information and an adaptive priority mechanism to select which requests to drop. It achieves higher goodput and reduces wasted resources compared to reactive dropping methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] Equilibria: Fair Multi-Tenant CXL Memory Tiering At Scale</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [memory tiering], [CXL, multi-tenancy, fairness policies, promotion and demotion, thrashing suppression, TPP, service level objectives]</li>
<li class=""><strong>authors:</strong> Kaiyang Zhao, Neha Gholkar, Hasan Maruf, Abhishek Dhanotia, Johannes Weiner, Gregory Price, Ning Sun, Bhavya Dwivedi, Stuart Clark, Dimitrios Skarlatos</li>
<li class=""><strong>institution:</strong> Carnegie Mellon University, Meta</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.08800" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.08800</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Equilibria is an OS framework for fair, multi-tenant memory tiering using CXL memory. It provides per-container controls, enforces fairness policies, and suppresses thrashing to mitigate interference. The system improves performance over the state-of-the-art Linux solution by up to 52% for production workloads.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] Modalities, a PyTorch-native Framework For Large-scale LLM Training and Research</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [PyTorch-native, distributed pretraining, modular design, declarative configuration, parallelization strategies, ablation studies]</li>
<li class=""><strong>authors:</strong> Max Lübbering, Timm Ruland, Richard Rutmann, Felix Stollenwerk, David Fitzek, Michael Fromm, Alexander Weber, Rafet Sifa, Nicolas Flores-Herr, Joachim Köhler, Mehdi Ali</li>
<li class=""><strong>institution:</strong> Fraunhofer IAIS, AI Sweden, University of Bonn, Lamarr Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.08387" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.08387</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Modalities, a PyTorch-native framework designed for large-scale LLM training and research. It integrates advanced parallelization strategies to enable efficient pretraining and systematic ablation studies at scale, and uses a modular, declarative configuration to improve reproducibility and extensibility compared to existing frameworks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] Recursive QAOA for Interference-Aware Resource Allocation in Wireless Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [quantum optimization], [RQAOA, QAOA, QUBO, Ising model, variable elimination, channel assignment]</li>
<li class=""><strong>authors:</strong> Kuan-Cheng Chen, Hiromichi Matsuyama, Wei-hao Huang, Yu Yamashiro</li>
<li class=""><strong>institution:</strong> J-ij Europe Ltd, Jij Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.07483" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.07483</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using the Recursive Quantum Approximate Optimization Algorithm (RQAOA) for interference-aware wireless resource allocation, formulating the problem as a QUBO/Ising model. The method recursively eliminates variables to reduce problem size and stabilize training. The results show that RQAOA can find feasible, optimal solutions and mitigate scalability issues present in standard QAOA.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] RIFLE: Robust Distillation-based FL for Deep Model Deployment on Resource-Constrained IoT Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [knowledge distillation, federated learning, Kullback-Leibler divergence, logit-based knowledge transfer, robust aggregation]</li>
<li class=""><strong>authors:</strong> Pouria Arefijamal, Mahdi Ahmadlou, Bardia Safaei, Jörg Henkel</li>
<li class=""><strong>institution:</strong> Sharif University of Technology, Karlsruhe Institute of Technology (KIT)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.08446" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.08446</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces RIFLE, a robust federated learning framework that replaces gradient sharing with logit-based knowledge distillation to train deep models on resource-constrained IoT devices. It uses a KL divergence-based mechanism to validate client updates for security and privacy. The method significantly reduces training time and improves accuracy and robustness against attacks compared to conventional FL baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] DynamiQ: Accelerating Gradient Synchronization using Compressed Multi-hop All-reduce</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [gradient compression, multi-hop all-reduce, quantization, fused kernel, NCCL, PyTorch DDP]</li>
<li class=""><strong>authors:</strong> Wenchen Han, Shay Vargaftik, Michael Mitzenmacher, Ran Ben Basat</li>
<li class=""><strong>institution:</strong> University College London, Broadcom, Harvard University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.08923" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.08923</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DynamiQ is a quantization framework designed to accelerate gradient synchronization in multi-hop all-reduce for large model training by better representing partial sums and using a fused decompress-accumulate-recompress kernel. It demonstrates consistent performance improvements over state-of-the-art methods while maintaining near-baseline model accuracy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260210] Towards CXL Resilience to CPU Failures</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [fault-tolerance], [CXL, cache coherence, hardware logging, data replication, recovery protocol]</li>
<li class=""><strong>authors:</strong> Antonis Psistakis, Burak Ocalan, Chloe Alverti, Fabien Chaix, Ramnatthan Alagappan, Josep Torrellas</li>
<li class=""><strong>institution:</strong> University of Illinois Urbana-Champaign, National Technical University of Athens, Foundation for Research and Technology-Hellas</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.08271" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.08271</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes ReCXL, a system that extends the CXL specification to handle compute node failures by replicating cache line updates to other nodes via a hardware Logging Unit. The method ensures fault tolerance by logging writes and using these logs to recover directory and memory state after a failure. The evaluation shows that ReCXL achieves fault-tolerant execution with only a 30% performance slowdown compared to a non-fault-tolerant platform.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 68</strong></p>
<ul>
<li class="">[arXiv260210] Regret Analysis of Unichain Average Reward Constrained MDPs with General Parameterization <a href="https://arxiv.org/pdf/2602.08000" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Direct Soft-Policy Sampling via Langevin Dynamics <a href="https://arxiv.org/pdf/2602.07873" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Objective Decoupling in Social Reinforcement Learning: Recovering Ground Truth from Sycophantic Majorities <a href="https://arxiv.org/pdf/2602.08092" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] ToolSelf: Unifying Task Execution and Self-Reconfiguration via Tool-Driven Intrinsic Adaptation <a href="https://arxiv.org/pdf/2602.07883" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Joint Reward Modeling: Internalizing Chain-of-Thought for Efficient Visual Reward Models <a href="https://arxiv.org/pdf/2602.07533" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Do We Need Adam? Surprisingly Strong and Sparse Reinforcement Learning with SGD in LLMs <a href="https://arxiv.org/pdf/2602.07729" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Interpretable Failure Analysis in Multi-Agent Reinforcement Learning Systems <a href="https://arxiv.org/pdf/2602.08104" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] TeleBoost: A Systematic Alignment Framework for High-Fidelity, Controllable, and Robust Video Generation <a href="https://arxiv.org/pdf/2602.07595" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Scalable Dexterous Robot Learning with AR-based Remote Human-Robot Interactions <a href="https://arxiv.org/pdf/2602.07341" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Horizon Imagination: Efficient On-Policy Training in Diffusion World Models <a href="https://arxiv.org/pdf/2602.08032" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Time Series Reasoning via Process-Verifiable Thinking Data Synthesis and Scheduling for Tailored LLM Reasoning <a href="https://arxiv.org/pdf/2602.07830" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] The Laplacian Keyboard: Beyond the Linear Span <a href="https://arxiv.org/pdf/2602.07730" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] High Fidelity Textual User Representation over Heterogeneous Sources via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.07333" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] VideoTemp-o3: Harmonizing Temporal Grounding and Video Understanding in Agentic Thinking-with-Videos <a href="https://arxiv.org/pdf/2602.07801" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Unified Biomolecular Trajectory Generation via Pretrained Variational Bridge <a href="https://arxiv.org/pdf/2602.07588" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] The Optimal Token Baseline: Variance Reduction for Long-Horizon LLM-RL <a href="https://arxiv.org/pdf/2602.07078" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Efficient Anti-exploration via VQVAE and Fuzzy Clustering in Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2602.07889" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Learning to Self-Verify Makes Language Models Better Reasoners <a href="https://arxiv.org/pdf/2602.07594" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System <a href="https://arxiv.org/pdf/2602.07308" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] FIRE: Frobenius-Isometry Reinitialization for Balancing the Stability-Plasticity Tradeoff <a href="https://arxiv.org/pdf/2602.08040" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] rePIRL: Learn PRM with Inverse RL for LLM Reasoning <a href="https://arxiv.org/pdf/2602.07832" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] AceGRPO: Adaptive Curriculum Enhanced Group Relative Policy Optimization for Autonomous Machine Learning Engineering <a href="https://arxiv.org/pdf/2602.07906" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Generative Reasoning Re-ranker <a href="https://arxiv.org/pdf/2602.07774" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling <a href="https://arxiv.org/pdf/2602.08052" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Preference Conditioned Multi-Objective Reinforcement Learning: Decomposed, Diversity-Driven Policy Optimization <a href="https://arxiv.org/pdf/2602.07764" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] TodoEvolve: Learning to Architect Agent Planning Systems <a href="https://arxiv.org/pdf/2602.07839" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Epigraph-Guided Flow Matching for Safe and Performant Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2602.08054" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] CoMI-IRL: Contrastive Multi-Intention Inverse Reinforcement Learning <a href="https://arxiv.org/pdf/2602.07496" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model <a href="https://arxiv.org/pdf/2602.07422" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Risk-Sensitive Exponential Actor Critic <a href="https://arxiv.org/pdf/2602.07202" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Proximal Action Replacement for Behavior Cloning Actor-Critic in Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2602.07441" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Cerebellar-Inspired Residual Control for Fault Recovery: From Inference-Time Adaptation to Structural Consolidation <a href="https://arxiv.org/pdf/2602.07227" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] When Is Compositional Reasoning Learnable from Verifiable Rewards? <a href="https://arxiv.org/pdf/2602.07992" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Efficient Planning in Reinforcement Learning via Model Introspection <a href="https://arxiv.org/pdf/2602.07719" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] MARTI-MARS<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>: Scaling Multi-Agent Self-Search via Reinforcement Learning for Code Generation <a href="https://arxiv.org/pdf/2602.07848" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] CADO: From Imitation to Cost Minimization for Heatmap-based Solvers in Combinatorial Optimization <a href="https://arxiv.org/pdf/2602.08210" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] DrugR: Optimizing Molecular Drugs through LLM-based Explicit Reasoning <a href="https://arxiv.org/pdf/2602.08213" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning <a href="https://arxiv.org/pdf/2602.08234" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs <a href="https://arxiv.org/pdf/2602.08241" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Learning in Context, Guided by Choice: A Reward-Free Paradigm for Reinforcement Learning with Transformers <a href="https://arxiv.org/pdf/2602.08244" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] When Do Multi-Agent Systems Outperform? Analysing the Learning Efficiency of Agentic Systems <a href="https://arxiv.org/pdf/2602.08272" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Towards Efficient Large Language Reasoning Models via Extreme-Ratio Chain-of-Thought Compression <a href="https://arxiv.org/pdf/2602.08324" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System <a href="https://arxiv.org/pdf/2602.08335" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration <a href="https://arxiv.org/pdf/2602.08344" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Does Your Reasoning Model Implicitly Know When to Stop Thinking? <a href="https://arxiv.org/pdf/2602.08354" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Learning Human-Like Badminton Skills for Humanoid Robots <a href="https://arxiv.org/pdf/2602.08370" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Reinforcement Learning with Backtracking Feedback <a href="https://arxiv.org/pdf/2602.08377" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning <a href="https://arxiv.org/pdf/2602.08382" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Intelligent support for Human Oversight: Integrating Reinforcement Learning with Gaze Simulation to Personalize Highlighting <a href="https://arxiv.org/pdf/2602.08403" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Beyond Correctness: Learning Robust Reasoning via Transfer <a href="https://arxiv.org/pdf/2602.08489" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Contextual Rollout Bandits for Reinforcement Learning with Verifiable Rewards <a href="https://arxiv.org/pdf/2602.08499" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Learning Self-Correction in Vision-Language Models via Rollout Augmentation <a href="https://arxiv.org/pdf/2602.08503" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Dialogue Model Optimization via Agent Game and Adaptive Tree-based GRPO <a href="https://arxiv.org/pdf/2602.08533" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Conditional Sequence Modeling for Safe Reinforcement Learning <a href="https://arxiv.org/pdf/2602.08584" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Breaking the Grid: Distance-Guided Reinforcement Learning in Large Discrete and Hybrid Action Spaces <a href="https://arxiv.org/pdf/2602.08616" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] From Robotics to Sepsis Treatment: Offline RL via Geometric Pessimism <a href="https://arxiv.org/pdf/2602.08655" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] LLaDA2.1: Speeding Up Text Diffusion via Token Editing <a href="https://arxiv.org/pdf/2602.08676" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Learning To Sample From Diffusion Models Via Inverse Reinforcement Learning <a href="https://arxiv.org/pdf/2602.08689" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] SoK: The Pitfalls of Deep Reinforcement Learning for Cybersecurity <a href="https://arxiv.org/pdf/2602.08690" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Finite-State Controllers for (Hidden-Model) POMDPs using Deep Reinforcement Learning <a href="https://arxiv.org/pdf/2602.08734" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Bayesian Preference Learning for Test-Time Steerable Reward Models <a href="https://arxiv.org/pdf/2602.08819" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning <a href="https://arxiv.org/pdf/2602.08835" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems <a href="https://arxiv.org/pdf/2602.08847" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] AnomSeer: Reinforcing Multimodal LLMs to Reason for Time-Series Anomaly Detection <a href="https://arxiv.org/pdf/2602.08868" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Efficient and Stable Reinforcement Learning for Diffusion Language Models <a href="https://arxiv.org/pdf/2602.08905" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors <a href="https://arxiv.org/pdf/2602.08934" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Learning to Coordinate via Quantum Entanglement in Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.08965" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] iGRPO: Self-Feedback-Driven LLM Reasoning <a href="https://arxiv.org/pdf/2602.09000" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 30</strong></p>
<ul>
<li class="">[arXiv260210] When Excellence Stops Producing Knowledge: A Practitioner&#x27;s Observation on Research Funding <a href="https://arxiv.org/pdf/2602.07039" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents <a href="https://arxiv.org/pdf/2602.07035" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] FlashVID: Efficient Video Large Language Models via Training-free Tree-based Spatiotemporal Token Merging <a href="https://arxiv.org/pdf/2602.08024" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] &quot;Death&quot; of a Chatbot: Investigating and Designing Toward Psychologically Safe Endings for Human-AI Relationships <a href="https://arxiv.org/pdf/2602.07193" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning <a href="https://arxiv.org/pdf/2602.07543" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Scalable Dexterous Robot Learning with AR-based Remote Human-Robot Interactions <a href="https://arxiv.org/pdf/2602.07341" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Systematic Performance Assessment of Deep Material Networks for Multiscale Material Modeling <a href="https://arxiv.org/pdf/2602.07192" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] GRAFT: Decoupling Ranking and Calibration for Survival Analysis <a href="https://arxiv.org/pdf/2602.07884" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] MaD-Mix: Multi-Modal Data Mixtures via Latent Space Coupling for Vision-Language Model Training <a href="https://arxiv.org/pdf/2602.07790" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Optimizing Few-Step Generation with Adaptive Matching Distillation <a href="https://arxiv.org/pdf/2602.07345" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Interpreting Physics in Video World Models <a href="https://arxiv.org/pdf/2602.07050" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] PipeMFL-240K: A Large-scale Dataset and Benchmark for Object Detection in Pipeline Magnetic Flux Leakage Imaging <a href="https://arxiv.org/pdf/2602.07044" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Accelerating Social Science Research via Agentic Hypothesization and Experimentation <a href="https://arxiv.org/pdf/2602.07983" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] aerial-autonomy-stack -- a Faster-than-real-time, Autopilot-agnostic, ROS2 Framework to Simulate and Deploy Perception-based Drones <a href="https://arxiv.org/pdf/2602.07264" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design <a href="https://arxiv.org/pdf/2602.07491" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] STEP: Warm-Started Visuomotor Policies with Spatiotemporal Consistency Prediction <a href="https://arxiv.org/pdf/2602.08245" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Noise Stability of Transformer Models <a href="https://arxiv.org/pdf/2602.08287" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Fast Flow Matching based Conditional Independence Tests for Causal Discovery <a href="https://arxiv.org/pdf/2602.08315" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Prism: Spectral-Aware Block-Sparse Attention <a href="https://arxiv.org/pdf/2602.08426" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] GISA: A Benchmark for General Information-Seeking Assistant <a href="https://arxiv.org/pdf/2602.08543" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Predicting Future Utility: Global Combinatorial Optimization for Task-Agnostic KV Cache Eviction <a href="https://arxiv.org/pdf/2602.08585" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] QUOKA: Query-Oriented KV Selection For Efficient LLM Prefill <a href="https://arxiv.org/pdf/2602.08722" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Default Machine Learning Hyperparameters Do Not Provide Informative Initialization for Bayesian Optimization <a href="https://arxiv.org/pdf/2602.08774" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Multimodal Learning for Arcing Detection in Pantograph-Catenary Systems <a href="https://arxiv.org/pdf/2602.08792" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] FlattenGPT: Depth Compression for Transformer with Layer Flattening <a href="https://arxiv.org/pdf/2602.08858" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] ARO: A New Lens On Matrix Optimization For Large Models <a href="https://arxiv.org/pdf/2602.09006" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] ANCRe: Adaptive Neural Connection Reassignment for Efficient Depth Scaling <a href="https://arxiv.org/pdf/2602.09009" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Electron-Informed Coarse-Graining Molecular Representation Learning for Real-World Molecular Physics <a href="https://arxiv.org/pdf/2602.07087" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Fast and Robust Likelihood-Guided Diffusion Posterior Sampling with Amortized Variational Inference <a href="https://arxiv.org/pdf/2602.07102" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260210] Optimizing Spectral Prediction in MXene-Based Metasurfaces Through Multi-Channel Spectral Refinement and Savitzky-Golay Smoothing <a href="https://arxiv.org/pdf/2602.08406" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2026-02-10T05:22:45.000Z" itemprop="dateModified">Feb 10, 2026</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20260202-20260208"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20260202-20260208</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2026-02-09" class="table-of-contents__link toc-highlight">2026-02-09</a></li><li><a href="#2026-02-10" class="table-of-contents__link toc-highlight">2026-02-10</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>