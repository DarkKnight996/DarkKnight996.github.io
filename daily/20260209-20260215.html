<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20260209-20260215" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20260209-20260215 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20260209-20260215"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20260209-20260215 | DarkKnight Note"><meta data-rh="true" name="description" content="2026-02-09"><meta data-rh="true" property="og:description" content="2026-02-09"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20260209-20260215"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260209-20260215" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260209-20260215" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20260209-20260215","item":"https://darkknight996.github.io/daily/20260209-20260215"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.6ec850d2.js" defer="defer"></script>
<script src="/assets/js/main.497dafe5.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260105-20260111"><span title="20260105-20260111" class="linkLabel_WmDU">20260105-20260111</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260112-20260118"><span title="20260112-20260118" class="linkLabel_WmDU">20260112-20260118</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260119-20260125"><span title="20260119-20260125" class="linkLabel_WmDU">20260119-20260125</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260126-20260201"><span title="20260126-20260201" class="linkLabel_WmDU">20260126-20260201</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260202-20260208"><span title="20260202-20260208" class="linkLabel_WmDU">20260202-20260208</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20260209-20260215"><span title="20260209-20260215" class="linkLabel_WmDU">20260209-20260215</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20260209-20260215</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20260209-20260215</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-09">2026-02-09<a href="#2026-02-09" class="hash-link" aria-label="Direct link to 2026-02-09" title="Direct link to 2026-02-09" translate="no">​</a></h2>
<p><strong>cs.DC total: 21</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260209] Computationally Efficient Laplacian CL-colME</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [decentralized learning, collaborative mean estimation, consensus algorithms, Laplacian-based consensus, graph-based methods]</li>
<li class=""><strong>authors:</strong> Nikola Stankovic</li>
<li class=""><strong>institution:</strong> IEEE</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06070" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06070</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes CL-colME, a Laplacian-based consensus variant of collaborative mean estimation that avoids computationally expensive normalization processes. The method maintains the convergence and accuracy of the previous C-colME framework while improving computational efficiency in decentralized, heterogeneous networks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Experimental Analysis of Server-Side Caching for Web Performance</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [web performance optimization], [server-side caching, in-memory cache, response time, time-to-live, performance evaluation]</li>
<li class=""><strong>authors:</strong> Mohammad Umar, Bharat Tripathi</li>
<li class=""><strong>institution:</strong> Allenhouse Business School</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06074" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06074</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper experimentally compares the performance of a web server with and without simple in-memory caching using a fixed time-to-live. The results show that server-side caching significantly reduces response times, demonstrating its effectiveness for small-scale applications and educational use cases.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] PackInfer: Compute- and I/O-Efficient Attention for Batched LLM Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [kernel-level optimization, load-balanced execution groups, I/O-aware grouping, KV cache reorganization, FlashAttention]</li>
<li class=""><strong>authors:</strong> Rui Ning, Wei Zhang, Fan Lai</li>
<li class=""><strong>institution:</strong> Nanjing University, University of Illinois Urbana-Champaign</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06072" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06072</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PackInfer is a kernel-level attention framework that improves batched LLM inference by packing heterogeneous requests into load-balanced execution groups and reorganizing KV caches into group-contiguous layouts. This approach reduces computation and I/O imbalance, leading to reduced latency and increased throughput compared to FlashAttention.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] iScheduler: Reinforcement Learning-Driven Continual Optimization for Large-Scale Resource Investment Problems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [reinforcement learning, iterative scheduling, Markov decision process, resource investment problem, decomposition, reconfiguration]</li>
<li class=""><strong>authors:</strong> Yi-Xiang Hu, Yuke Wang, Feng Wu, Zirui Huang, Shuli Zeng, Xiang-Yang Li</li>
<li class=""><strong>institution:</strong> University of Science and Technology of China</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06064" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06064</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces iScheduler, a framework that uses reinforcement learning to iteratively schedule tasks by decomposing large resource investment problems into subproblems modeled as a Markov decision process. It achieves fast schedule generation and supports efficient updates by reusing unaffected schedules. Experiments show it reduces time to feasibility by up to 43x while maintaining competitive resource costs compared to commercial solvers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] FlashSketch: Sketch-Kernel Co-Design for Fast Sparse Sketching on GPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [BlockPerm-SJLT, sketch-kernel co-design, sparse sketching, oblivious subspace embedding, CUDA kernel, memory bandwidth]</li>
<li class=""><strong>authors:</strong> Rajat Vadiraj Dwaraknath, Sungyoon Kim, Mert Pilanci</li>
<li class=""><strong>institution:</strong> Stanford University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06071" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06071</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces FlashSketch, a method that co-designs a new sparse sketch family (BlockPerm-SJLT) with an optimized CUDA kernel to improve GPU efficiency. This approach explicitly trades off sketching robustness with hardware performance. The result is a significant speedup (1.7x geomean) over prior state-of-the-art GPU sketches across various benchmarks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Quantifying Energy-Efficient Edge Intelligence: Inference-time Scaling Laws for Heterogeneous Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [scaling laws, heterogeneous orchestration, hardware-aware routing, progressive sample multiplexing, cost models, Intelligence Per Watt, Energy-Coverage Efficiency, Price-Power-Performance]</li>
<li class=""><strong>authors:</strong> Satyam Kumar, Saurabh Jha</li>
<li class=""><strong>institution:</strong> Not explicitly provided in the given text.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06057" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06057</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces QEIL, a framework that uses inference-time scaling laws and heterogeneous hardware orchestration (across CPU, GPU, NPU) to optimize LLM inference on edge devices. It demonstrates that this approach achieves significant improvements in coverage, energy efficiency, latency, and cost compared to homogeneous methods, establishing it as an optimal strategy for energy-constrained edge AI systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] HQP: Sensitivity-Aware Hybrid Quantization and Pruning for Ultra-Low-Latency Edge AI Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [hybrid quantization, structural pruning, Fisher Information Matrix, sensitivity-aware pruning, post-training quantization, model compression]</li>
<li class=""><strong>authors:</strong> Dinesh Gopalan, Ratul Ali</li>
<li class=""><strong>institution:</strong> AMD, Jahangirnagar University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06069" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06069</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces HQP, a sensitivity-aware hybrid framework that combines structural pruning using a dynamic weight sensitivity metric from an efficient Fisher Information Matrix approximation, followed by conditional 8-bit post-training quantization. It achieves up to 3.12× inference speedup and 55% model size reduction while limiting accuracy drop to under 1.5% on edge platforms like NVIDIA Jetson. The method outperforms single-objective compression techniques, providing a hardware-agnostic solution for ultra-low-latency edge AI inference.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Canzona: A Unified, Asynchronous, and Load-Balanced Framework for Distributed Matrix-based Optimizers</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [matrix-based optimizers, data parallelism, tensor parallelism, asynchronous compute, load balancing, Shampoo, Muon, SOAP, ZeRO]</li>
<li class=""><strong>authors:</strong> Liangyu Wang, Siqi Zhang, Junjie Wang, Yiming Dong, Bo Zheng, Zihan Qiu, Shengkun Tang, Di Wang, Rui Men, Dayiheng Liu</li>
<li class=""><strong>institution:</strong> KAUST, Alibaba Group, Peking University, MBZUAI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06079" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06079</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Canzona, a framework that decouples logical optimizer assignment from physical parameter distribution to efficiently run matrix-based optimizers (like Shampoo) in distributed LLM training. It introduces load-balanced partitioning for Data Parallelism and an asynchronous compute pipeline for Tensor Parallelism. Evaluations show it preserves parallel architecture efficiency, achieving a 1.57x end-to-end speedup and reducing optimizer step latency by 5.8x.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Mapping Gemma3 onto an Edge Dataflow Architecture</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [dequantization engine, tiled matrix multiplication, FlowQKV, FusedDQP, FlowKV, Q4NX quantization, dataflow architecture]</li>
<li class=""><strong>authors:</strong> Shouyu Du, Miaoxiang Yu, Zhiheng Ni, Jillian Cai, Qing Yang, Tao Wei, Zhenyu Xu</li>
<li class=""><strong>institution:</strong> Clemson University, University of Rhode Island</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06063" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06063</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents the first end-to-end deployment of the Gemma3 family of models on an AMD Ryzen AI NPU, introducing hardware-aware techniques like FlowQKV for prefill and FusedDQP for decoding, along with a custom 4-bit quantization format. The methods achieve significant speed and power efficiency improvements over iGPU and CPU baselines. The work demonstrates that modern NPUs can enable practical, low-power LLM and VLM inference at the edge and provides a blueprint for mapping transformers onto tiled dataflow accelerators.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] MemGUI-Bench: Benchmarking Memory of Mobile GUI Agents in Dynamic Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [memory-centric benchmark, mobile GUI agents, LLM-as-judge, pass@k, cross-session learning, cross-temporal retention, cross-spatial retention, Progressive Scrutiny]</li>
<li class=""><strong>authors:</strong> Guangyi Liu, Pengxiang Zhao, Yaozhen Liang, Qinyi Luo, Shunye Tang, Yuxiang Chai, Weifeng Lin, Han Xiao, WenHao Wang, Siheng Chen, Zhengxi Lu, Gao Wu, Hao Wang, Liang Liu, Yong Liu</li>
<li class=""><strong>institution:</strong> Zhejiang University, Nankai University, The Chinese University of Hong Kong, Shanghai Jiao Tong University, vivo AI Lab</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06075" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06075</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MemGUI-Bench, a comprehensive benchmark and evaluation pipeline designed to assess the memory capabilities of mobile GUI agents. The method includes a memory taxonomy, 128 memory-challenging tasks, and an automated evaluator (MemGUI-Eval) using staged LLM-as-judge and Progressive Scrutiny. The main conclusion is that current state-of-the-art agents exhibit significant memory deficits, with the benchmark identifying five distinct failure modes and synthesizing actionable design implications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] LAAFD: LLM-based Agents for Accelerated FPGA Design</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [high-level synthesis, FPGA, agentic workflow, pipelining, vectorization, dataflow partitioning, co-simulation]</li>
<li class=""><strong>authors:</strong> Maxim Moraru, Kamalavasan Kamalakkannan, Jered Dominguez-Trujillo, Patrick Diehl, Atanu Barai, Julien Loiseau, Zachary Kent Baker, Howard Pritchard, Galen M Shipman</li>
<li class=""><strong>institution:</strong> Los Alamos National Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06085" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06085</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces LAAFD, an agentic workflow that uses large language models to automatically translate general-purpose C++ code into optimized FPGA kernels for Vitis HLS. The system leverages HLS co-simulation and synthesis feedback to iteratively apply hardware optimizations like pipelining and dataflow. The results show that LAAFD achieves performance comparable to hand-tuned baselines, significantly lowering the expertise barrier for FPGA acceleration.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] BouquetFL: Emulating diverse participant hardware in Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, hardware emulation, resource restriction, GPU constraints, CPU throttling, memory constraints, heterogeneous clients]</li>
<li class=""><strong>authors:</strong> Arno Geimer</li>
<li class=""><strong>institution:</strong> Not specified (author email domain not provided)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06498" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06498</a></li>
<li class=""><strong>Simple LLM Summary:</strong> BouquetFL is a framework that simulates heterogeneous client hardware in federated learning by programmatically restricting CPU, memory, and GPU resources on a single machine. It enables controlled experimentation under realistic hardware diversity without requiring multiple physical devices. The tool addresses a methodological gap in FL research by providing an accessible way to study system heterogeneity, bringing experimental practice closer to practical deployment conditions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] AdFL: In-Browser Federated Learning for Online Advertisement</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, differential privacy, in-browser training, ad viewability prediction]</li>
<li class=""><strong>authors:</strong> Ahmad Alemari, Pritam Sen, Cristian Borcea</li>
<li class=""><strong>institution:</strong> New Jersey Institute of Technology, Jazan University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06336" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06336</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes AdFL, a federated learning framework that runs directly in users&#x27; web browsers to learn ad preferences without sharing raw data. It demonstrates the framework&#x27;s feasibility for real-time in-browser training and shows that an ad viewability prediction model built on it achieves high performance, which is maintained even when differential privacy is applied for enhanced security.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] FCDP: Fully Cached Data Parallel for Communication-Avoiding Large-Scale Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [ZeRO-3, host memory caching, parameter-efficient fine-tuning, all-gather, data parallel]</li>
<li class=""><strong>authors:</strong> Gyeongseo Park, Eungyeong Lee, Song-woo Sok, Myung-Hoon Cha, Kwangwon Koh, Baik-Song An, Hongyeon Kim, Ki-Dong Kang</li>
<li class=""><strong>institution:</strong> Electronics and Telecommunications Research Institute (ETRI)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06499" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06499</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FCDP, a method that caches forward-pass parameters in host memory to reuse them during the backward pass, eliminating redundant inter-node communication while preserving a minimal GPU memory footprint. It achieves up to 100x higher throughput than ZeRO-3 on commodity hardware by leveraging host memory as a fast cache layer instead of an overflow tier.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Degradation of Feature Space in Continual Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [continual learning], [isotropic regularization, contrastive learning, rehearsal strategies, catastrophic forgetting, feature space geometry]</li>
<li class=""><strong>authors:</strong> Chiara Lanza, Roberto Pereira, Marco Miozzo, Eduard Angelats, Paolo Dini</li>
<li class=""><strong>institution:</strong> CTTC (Centre Tecnològic de Telecomunicacions de Catalunya)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06586" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06586</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates whether enforcing isotropy in the feature space can improve continual learning by mitigating catastrophic forgetting. Using contrastive continual learning techniques with rehearsal on CIFAR datasets, the authors find that isotropic regularization actually degrades model performance. The conclusion is that isotropy, beneficial in centralized training, is not a suitable inductive bias for non-stationary continual learning scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Reinforcement Learning-Based Dynamic Management of Structured Parallel Farm Skeletons on Serverless Platforms</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [reinforcement learning, serverless computing, autoscaling, OpenFaaS, farm skeleton, Gymnasium]</li>
<li class=""><strong>authors:</strong> Lanpei Li, Massimo Coppola, Malio Li, Valerio Besozzi, Jack Bell, Vincenzo Lomonaco</li>
<li class=""><strong>institution:</strong> National Research Council of Italy (CNR), University of Pisa, LUISS University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06555" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06555</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a framework using Reinforcement Learning (RL) to dynamically manage the autoscaling of a parallel task farm skeleton on a serverless platform (OpenFaaS). It evaluates RL-based policies against a reactive baseline, finding that AI-driven management better handles platform-specific limitations, improving Quality of Service (QoS) while maintaining efficient resource usage.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] DualMap: Enabling Both Cache Affinity and Load Balancing for Distributed LLM Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [dual-mapping scheduling, cache-affinity scheduling, load-balancing scheduling, KV cache reuse, SLO-aware routing, hotspot-aware rebalancing, dual-hash-ring scaling]</li>
<li class=""><strong>authors:</strong> Ying Yuan, Pengfei Zuo, Bo Wang, Zhangyu Chen, Zhipeng Tan, Zhou Yu</li>
<li class=""><strong>institution:</strong> Huazhong University of Science and Technology, Huawei</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06502" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06502</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes DualMap, a dual-mapping scheduling strategy for distributed LLM serving that maps each request to two candidate instances using independent hash functions to intelligently balance KV cache reuse and load distribution. It incorporates SLO-aware routing, hotspot-aware rebalancing, and lightweight scaling to handle dynamic workloads. Experiments show DualMap improves effective request capacity by up to 2.25x under the same TTFT SLO constraints compared to state-of-the-art methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Wonderboom -- Efficient, and Censorship-Resilient Signature Aggregation for Million Scale Consensus</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain consensus], [signature aggregation, censorship-resilient, Byzantine Fault Tolerant, quorum attestation, validator set, simulation]</li>
<li class=""><strong>authors:</strong> Zeta Avarikioti, Ray Neiheiser, Krzysztof Pietrzak, Michelle X. Yeo</li>
<li class=""><strong>institution:</strong> TU Wien, Institute of Science and Technology Austria, Nanyang Technological University, Aarhus University, Common Prefix</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06655" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06655</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Wonderboom, a new protocol designed to efficiently aggregate signatures from millions of validators in Ethereum&#x27;s consensus mechanism. It achieves this up to 32 times faster than the current state-of-the-art while providing stronger security guarantees against censorship and stake-shifting attacks. The authors implement a simulation tool to demonstrate that Wonderboom can handle over 2 million signatures within a single Ethereum slot.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Same Engine, Multiple Gears: Parallelizing Fixpoint Iteration at Different Granularities (Extended Version)</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [static analysis], [fixpoint iteration, parallelization, top-down solver, task granularity, immediate approach, independent approach, publish/subscribe]</li>
<li class=""><strong>authors:</strong> Ali Rasim Kocal, Michael Schwarz, Simmo Saan, Helmut Seidl</li>
<li class=""><strong>institution:</strong> Technical University of Munich, National University of Singapore, University of Tartu</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06680" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06680</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a parallel fixpoint engine for static analysis that is parametric in task granularity, enabling it to operate at different levels of parallelism. It implements two parallelization philosophies—immediate and independent—within the Goblint framework. The results demonstrate the approach&#x27;s effectiveness in reducing analysis times for large real-world programs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Implementing Grassroots Logic Programs with Multiagent Transition Systems and AI</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [concurrent logic programming], [Grassroots Logic Programs, multiagent transition systems, operational semantics, peer-to-peer, deterministic semantics]</li>
<li class=""><strong>authors:</strong> Ehud Shapiro</li>
<li class=""><strong>institution:</strong> London School of Economics, Weizmann Institute of Science</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06934" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06934</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents deterministic operational semantics (dGLP and madGLP) to facilitate the implementation of Grassroots Logic Programs, a concurrent logic programming language for peer-to-peer systems. The semantics were used as formal specifications for an AI to generate implementations in Dart for workstations and smartphones. The main conclusion is that the developed mathematical specifications enabled correct, implementation-ready semantics, though the development process required iterative refinement across mathematical, informal, and code layers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260209] Distributed Knowledge in Simplicial Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [simplicial complexes, epistemic logic, Kripke models, distributed knowledge, majority consensus]</li>
<li class=""><strong>authors:</strong> Éric Goubault, Jérémy Ledent, Sergio Rajsbaum</li>
<li class=""><strong>institution:</strong> LIX, CNRS, École Polytechnique, Institut Polytechnique de Paris; Université Paris Cité, CNRS, IRIF; Instituto de Matemáticas, UNAM</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.06945" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.06945</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces simplicial complexes as models for multi-agent epistemic logic, shifting the focus from possible worlds to agents&#x27; local views. It connects this topological approach to distributed computing, showing how distributed knowledge relates to solving the majority consensus task. The work describes the specific distributed knowledge used when the task is solvable and presents a logical obstruction when it is not.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 30</strong></p>
<ul>
<li class="">[arXiv260209] Transformer-Based Reinforcement Learning for Autonomous Orbital Collision Avoidance in Partially Observable Environments <a href="https://arxiv.org/pdf/2602.06088" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning <a href="https://arxiv.org/pdf/2602.06107" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Self-Improving World Modelling with Latent Actions <a href="https://arxiv.org/pdf/2602.06130" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Flow Matching for Offline Reinforcement Learning with Discrete Actions <a href="https://arxiv.org/pdf/2602.06138" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Learning Rate Scaling across LoRA Ranks and Transfer to Full Finetuning <a href="https://arxiv.org/pdf/2602.06204" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Online Adaptive Reinforcement Learning with Echo State Networks for Non-Stationary Dynamics <a href="https://arxiv.org/pdf/2602.06326" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Training Data Selection with Gradient Orthogonality for Efficient Domain Adaptation <a href="https://arxiv.org/pdf/2602.06359" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization <a href="https://arxiv.org/pdf/2602.06394" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] TrailBlazer: History-Guided Reinforcement Learning for Black-Box LLM Jailbreaking <a href="https://arxiv.org/pdf/2602.06440" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Prism: Spectral Parameter Sharing for Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.06476" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents <a href="https://arxiv.org/pdf/2602.06485" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Adaptive Uncertainty-Aware Tree Search for Robust Reasoning <a href="https://arxiv.org/pdf/2602.06493" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Progress Constraints for Reinforcement Learning in Behavior Trees <a href="https://arxiv.org/pdf/2602.06525" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Dynamics-Aligned Shared Hypernetworks for Zero-Shot Actuator Inversion <a href="https://arxiv.org/pdf/2602.06550" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees <a href="https://arxiv.org/pdf/2602.06554" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] SPARC: Separating Perception And Reasoning Circuits for Test-time Scaling of VLMs <a href="https://arxiv.org/pdf/2602.06566" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Sample-Efficient Policy Space Response Oracles with Joint Experience Best Response <a href="https://arxiv.org/pdf/2602.06599" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] The hidden risks of temporal resampling in clinical reinforcement learning <a href="https://arxiv.org/pdf/2602.06603" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Humanoid Manipulation Interface: Humanoid Whole-Body Manipulation from Robot-Free Demonstrations <a href="https://arxiv.org/pdf/2602.06643" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] compar:IA: The French Government&#x27;s LLM arena to collect French-language human prompts and preference data <a href="https://arxiv.org/pdf/2602.06669" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] F-GRPO: Don&#x27;t Let Your Policy Learn the Obvious and Forget the Rare <a href="https://arxiv.org/pdf/2602.06717" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Semantically Labelled Automata for Multi-Task Reinforcement Learning with LTL Instructions <a href="https://arxiv.org/pdf/2602.06746" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Soft Forward-Backward Representations for Zero-shot Reinforcement Learning with General Utilities <a href="https://arxiv.org/pdf/2602.06769" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Generating Data-Driven Reasoning Rubrics for Domain-Adaptive Reward Modeling <a href="https://arxiv.org/pdf/2602.06795" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] AEGPO: Adaptive Entropy-Guided Policy Optimization for Diffusion Models <a href="https://arxiv.org/pdf/2602.06825" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] A first realization of reinforcement learning-based closed-loop EEG-TMS <a href="https://arxiv.org/pdf/2602.06907" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Continuous-time reinforcement learning: ellipticity enables model-free value function approximation <a href="https://arxiv.org/pdf/2602.06930" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Cochain Perspectives on Temporal-Difference Signals for Learning Beyond Markov Dynamics <a href="https://arxiv.org/pdf/2602.06939" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Optimal Derivative Feedback Control for an Active Magnetic Levitation System: An Experimental Study on Data-Driven Approaches <a href="https://arxiv.org/pdf/2602.06944" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.06960" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 16</strong></p>
<ul>
<li class="">[arXiv260209] Analyzing Diffusion and Autoregressive Vision Language Models in Multimodal Embedding Space <a href="https://arxiv.org/pdf/2602.06056" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Compressing LLMs with MoP: Mixture of Pruners <a href="https://arxiv.org/pdf/2602.06127" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding <a href="https://arxiv.org/pdf/2602.06161" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] To 2:4 Sparsity and Beyond: Neuron-level Activation Function to Accelerate LLM Pre-Training <a href="https://arxiv.org/pdf/2602.06183" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Accelerating Vision Transformers on Brain Processing Unit <a href="https://arxiv.org/pdf/2602.06300" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Beyond Code Contributions: How Network Position, Temporal Bursts, and Code Review Activities Shape Contributor Influence in Large-Scale Open Source Ecosystems <a href="https://arxiv.org/pdf/2602.06426" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Principle-Evolvable Scientific Discovery via Uncertainty Minimization <a href="https://arxiv.org/pdf/2602.06448" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] SaDiT: Efficient Protein Backbone Design via Latent Structural Tokenization and Diffusion Transformers <a href="https://arxiv.org/pdf/2602.06706" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] GhostCite: A Large-Scale Analysis of Citation Validity in the Age of Large Language Models <a href="https://arxiv.org/pdf/2602.06718" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] AEGPO: Adaptive Entropy-Guided Policy Optimization for Diffusion Models <a href="https://arxiv.org/pdf/2602.06825" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Are Deep Learning Based Hybrid PDE Solvers Reliable? Why Training Paradigms and Update Strategies Matter <a href="https://arxiv.org/pdf/2602.06842" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] Rethinking Multi-Condition DiTs: Eliminating Redundant Attention via Position-Alignment and Keyword-Scoping <a href="https://arxiv.org/pdf/2602.06850" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents <a href="https://arxiv.org/pdf/2602.06855" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] When RL Meets Adaptive Speculative Training: A Unified Training-Serving System <a href="https://arxiv.org/pdf/2602.06932" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos <a href="https://arxiv.org/pdf/2602.06949" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260209] InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.06960" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2026-02-09T03:36:34.000Z" itemprop="dateModified">Feb 9, 2026</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20260202-20260208"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20260202-20260208</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2026-02-09" class="table-of-contents__link toc-highlight">2026-02-09</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>