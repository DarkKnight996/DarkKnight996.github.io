<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20260202-20260208" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20260202-20260208 | DarkKnight Note</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://darkknight996.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://darkknight996.github.io/daily/20260202-20260208"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20260202-20260208 | DarkKnight Note"><meta data-rh="true" name="description" content="2026-02-02"><meta data-rh="true" property="og:description" content="2026-02-02"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://darkknight996.github.io/daily/20260202-20260208"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260202-20260208" hreflang="en"><link data-rh="true" rel="alternate" href="https://darkknight996.github.io/daily/20260202-20260208" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://darkknight996.github.io/category/daily"},{"@type":"ListItem","position":2,"name":"20260202-20260208","item":"https://darkknight996.github.io/daily/20260202-20260208"}]}</script><link rel="stylesheet" href="/assets/css/styles.2a9d613c.css">
<script src="/assets/js/runtime~main.6cdbb34f.js" defer="defer"></script>
<script src="/assets/js/main.c7401d40.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.ico"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="DarkKnight Note" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Dark Knight Note</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/DarkKnight996" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260105-20260111"><span title="20260105-20260111" class="linkLabel_WmDU">20260105-20260111</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260112-20260118"><span title="20260112-20260118" class="linkLabel_WmDU">20260112-20260118</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260119-20260125"><span title="20260119-20260125" class="linkLabel_WmDU">20260119-20260125</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260126-20260201"><span title="20260126-20260201" class="linkLabel_WmDU">20260126-20260201</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/daily/20260202-20260208"><span title="20260202-20260208" class="linkLabel_WmDU">20260202-20260208</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260209-20260215"><span title="20260209-20260215" class="linkLabel_WmDU">20260209-20260215</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260216-20260222"><span title="20260216-20260222" class="linkLabel_WmDU">20260216-20260222</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/daily/20260223-20260301"><span title="20260223-20260301" class="linkLabel_WmDU">20260223-20260301</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20260202-20260208</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20260202-20260208</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-02">2026-02-02<a href="#2026-02-02" class="hash-link" aria-label="Direct link to 2026-02-02" title="Direct link to 2026-02-02" translate="no">​</a></h2>
<p><strong>cs.DC total: 12</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260202] Towards Resiliency in Large Language Model Serving with KevlarFlow</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [decoupled model parallelism initialization, dynamic traffic rerouting, background KV cache replication, model parallelism, tensor parallelism, pipeline parallelism]</li>
<li class=""><strong>authors:</strong> Shangshu Qian, Kipling Liu, P. C. Sruthi, Lin Tan, Yongle Zhang</li>
<li class=""><strong>institution:</strong> Purdue University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.22438" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.22438</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces KevlarFlow, a fault-tolerant LLM serving architecture that uses decoupled model parallelism initialization, dynamic traffic rerouting, and background KV cache replication to handle hardware failures. It significantly reduces recovery time and improves latency and time-to-first-token metrics during failures compared to existing systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260202] Coordinating Power Grid Frequency Regulation Service with Data Center Load Flexibility</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [Exogenous Carbon, EcoCenter, frequency regulation, GPU data centers, load flexibility]</li>
<li class=""><strong>authors:</strong> Ali Jahanshahi, Sara Rashidi Golrouye, Osten Anderson, Nanpeng Yu, Daniel Wong</li>
<li class=""><strong>institution:</strong> University of California, Riverside</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.22487" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.22487</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a framework called EcoCenter and a metric called Exogenous Carbon to enable GPU data centers to provide frequency regulation services to the power grid. It concludes that data center participation in this service can reduce the need for fossil-fueled reserves, and the resulting carbon savings often exceed the data centers&#x27; own operational emissions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260202] AsyncMesh: Fully Asynchronous Optimization for Data and Pipeline Parallelism</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [asynchronous optimization, sparse averaging, weight look-ahead, pipeline parallelism, data parallelism]</li>
<li class=""><strong>authors:</strong> Thalaiyasingam Ajanthan, Sameera Ramasinghe, Gil Avraham, Hadi Mohaghegh Dolatabadi, Chamin P Hewa Koneputugodage, Violetta Shevchenko, Yan Zuo, Alexander Long</li>
<li class=""><strong>institution:</strong> Pluralis Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.22442" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.22442</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces AsyncMesh, a method that uses fully asynchronous updates for both data and pipeline parallelism to reduce communication overhead in distributed training. It employs weight look-ahead for pipeline stages and asynchronous sparse averaging with an EMA correction for data replicas to mitigate staleness. Experiments on large language models show it matches synchronous baseline performance while significantly cutting communication costs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260202] SAIR: Cost-Efficient Multi-Stage ML Pipeline Autoscaling via In-Context Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [in-context reinforcement learning, Pareto-dominance reward shaping, surprisal-guided experience retrieval, GPU rate control, CUDA interception]</li>
<li class=""><strong>authors:</strong> Jianchang Su, Yifan Zhang, Shengkai Lin, Shizhen Zhao, Yusheng Zheng, Yiwei Yang, Wei Zhang</li>
<li class=""><strong>institution:</strong> University of Connecticut, Shanghai Jiao Tong University, University of California, Santa Cruz</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.22397" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.22397</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SAIR is an autoscaling framework for multi-stage ML inference pipelines that uses a Large Language Model as an in-context reinforcement learning controller to learn scaling policies online without gradient updates. It achieves improved latency and reduces resource cost significantly compared to existing baselines, demonstrating effective bottleneck detection without requiring offline training.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260202] Learning Provably Correct Distributed Protocols Without Human Knowledge</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [Monte Carlo Tree Search, transformer-based action encoder, global depth-first search, model checking, Satisfiability Modulo Theories (SMT)]</li>
<li class=""><strong>authors:</strong> Yujie Hui, Xiaoyi Lu, Andrew Perrault, Yang Wang</li>
<li class=""><strong>institution:</strong> The Ohio State University, University of Florida</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.22369" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.22369</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes GGMS, a learning framework that combines a specialized Monte Carlo Tree Search with a transformer-based action encoder, global depth-first search, and model checker feedback to automatically design provably correct distributed protocols. It proves the search process is complete and demonstrates that GGMS can learn correct protocols for larger settings than existing methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260202] CONCUR: High-Throughput Agentic Batch Inference of LLM via Congestion-Based Concurrency Control</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [KV cache management, admission control, congestion control, batch inference, agentic workloads, middle-phase thrashing]</li>
<li class=""><strong>authors:</strong> Qiaoling Chen, Zhisheng Ye, Tian Tang, Peng Sun, Boyu Tian, Guoteng Wang, Shenggui Li, Yonggang Wen, Zhenhua Han, Tianwei Zhang</li>
<li class=""><strong>institution:</strong> Nanyang Technological University, Shanghai Qiji Zhifeng Co., Ltd.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.22705" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.22705</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces CONCUR, a proactive agent-level admission control system that prevents KV cache thrashing in LLM batch inference by dynamically regulating the number of active agents based on runtime cache pressure. It improves throughput significantly, up to 4.09x on Qwen3-32B, by maintaining cache efficiency for long-lived, asynchronous agentic workloads.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260202] FedAdaVR: Adaptive Variance Reduction for Robust Federated Learning under Limited Client Participation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, variance reduction, adaptive optimizer, quantization, partial client participation]</li>
<li class=""><strong>authors:</strong> S M Ruhul Kabir Howlader, Xiao Chen, Yifei Xie, Lu Liu</li>
<li class=""><strong>institution:</strong> University of Leicester, University of Edinburgh, University of Exeter</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.22204" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.22204</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FedAdaVR, a federated learning algorithm that combines an adaptive optimizer with variance reduction to mitigate errors from sporadic client participation by using stored client updates. It also introduces a quantized version, FedAdaVR-Quant, to reduce memory overhead. The method is proven to eliminate partial participation error and outperforms state-of-the-art baselines in experiments under IID and non-IID data settings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260202] HetCCL: Accelerating LLM Training with Heterogeneous GPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [collective communication, RDMA, NCCL, RCCL, All-Reduce, All-Gather, Reduce-Scatter, data parallelism, model parallelism]</li>
<li class=""><strong>authors:</strong> Heehoon Kim, Jaehwan Lee, Taejeoung Kim, Jongwon Park, Jinpyo Kim, Pyongwon Suh, Ryan H. Choi, Sangwoo Lee, Jaejin Lee</li>
<li class=""><strong>institution:</strong> Seoul National University, Moreh Inc., Samsung Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.22585" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.22585</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces HetCCL, a collective communication library that enables high-performance communication across heterogeneous GPUs (e.g., NVIDIA and AMD) by unifying vendor-specific backends like NCCL and RCCL without requiring driver modifications. It matches the performance of vendor libraries in homogeneous setups and uniquely scales in heterogeneous environments, allowing efficient large language model training on mixed GPU clusters without changes to existing deep learning applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260202] ZK-HybridFL: Zero-Knowledge Proof-Enhanced Hybrid Ledger for Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, directed acyclic graph (DAG) ledger, sidechains, zero-knowledge proofs (ZKPs), event-driven smart contracts, oracle-assisted sidechain, challenge mechanism]</li>
<li class=""><strong>authors:</strong> Amirhossein Taherpour, Xiaodong Wang</li>
<li class=""><strong>institution:</strong> Columbia University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.22302" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.22302</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes ZK-HybridFL, a secure decentralized federated learning framework that integrates a DAG ledger with sidechains and zero-knowledge proofs for privacy-preserving model validation. The method uses event-driven smart contracts and an oracle-assisted sidechain to verify local updates without exposing data, and includes a challenge mechanism to detect adversarial behavior. Experiments show it achieves faster convergence, higher accuracy, and robust security compared to prior frameworks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260202] SQUAD: Scalable Quorum Adaptive Decisions via ensemble of early exit neural networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [early-exit neural networks, ensemble learning, neural architecture search, quorum-based stopping, dynamic inference]</li>
<li class=""><strong>authors:</strong> Matteo Gambella, Fabrizio Pittorino, Giuliano Casale, Manuel Roveri</li>
<li class=""><strong>institution:</strong> Politecnico di Milano, Imperial College London</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.22711" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.22711</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SQUAD, an inference scheme that combines early-exit neural networks with distributed ensemble learning, using a quorum-based voting mechanism to decide when to stop computation. It also proposes QUEST, a neural architecture search method to optimize the diversity of the ensemble learners. The method improves test accuracy by up to 5.95% over state-of-the-art dynamic solutions and reduces inference latency by up to 70.60% compared to static ensembles.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260202] AscendCraft: Automatic Ascend NPU Kernel Generation via DSL-Guided Transcompilation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [DSL-guided transcompilation, LLM lowering passes, AscendC, kernel generation]</li>
<li class=""><strong>authors:</strong> Zhongzhen Wen, Shudi Shao, Zhong Li, Yu Ge, Tongtong Xu, Yuanyi Lin, Tian Zhang</li>
<li class=""><strong>institution:</strong> Nanjing University, Huawei</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.22760" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.22760</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces AscendCraft, a method that uses a domain-specific language (DSL) and LLM-guided transcompilation to automatically generate correct and performant kernels for Ascend NPUs. The approach achieves high compilation success and functional correctness, with many generated kernels matching or exceeding PyTorch eager execution performance, demonstrating the effectiveness of DSL abstraction for NPU kernel generation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260202] ERA: Epoch-Resolved Arbitration for Duelling Admins in Group Management CRDTs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems], [CRDTs, Byzantine fault tolerance, epoch events, finality, arbitration]</li>
<li class=""><strong>authors:</strong> Kegan Dougal</li>
<li class=""><strong>institution:</strong> Element Creations Ltd</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.22963" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.22963</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ERA (Epoch-Resolved Arbitration), a method using asynchronous &quot;epoch events&quot; to introduce a bounded total order and arbitrate concurrent events in group management CRDTs. It concludes that this approach prevents Byzantine admins from exploiting concurrency in the &quot;Duelling Admins&quot; problem, improving consistency and providing finality while preserving availability.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 39</strong></p>
<ul>
<li class="">[arXiv260202] Continual Policy Distillation from Distributed Reinforcement Learning Teachers <a href="https://arxiv.org/pdf/2601.22475" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] ShellForge: Adversarial Co-Evolution of Webshell Generation and Multi-View Detection for Robust Webshell Defense <a href="https://arxiv.org/pdf/2601.22182" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Real-Time Aligned Reward Model beyond Semantics <a href="https://arxiv.org/pdf/2601.22664" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Unrewarded Exploration in Large Language Models Reveals Latent Learning from Psychology <a href="https://arxiv.org/pdf/2601.22474" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Action-Sufficient Goal Representations <a href="https://arxiv.org/pdf/2601.22496" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Learn More with Less: Uncertainty Consistency Guided Query Selection for RLVR <a href="https://arxiv.org/pdf/2601.22595" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Aligning Microscopic Vehicle and Macroscopic Traffic Statistics: Reconstructing Driving Behavior from Partial Data <a href="https://arxiv.org/pdf/2601.22242" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Models Under SCOPE: Scalable and Controllable Routing via Pre-hoc Reasoning <a href="https://arxiv.org/pdf/2601.22323" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Latent Spherical Flow Policy for Reinforcement Learning with Combinatorial Actions <a href="https://arxiv.org/pdf/2601.22211" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Quantum-Inspired Reinforcement Learning for Secure and Sustainable AIoT-Driven Supply Chain Systems <a href="https://arxiv.org/pdf/2601.22339" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Exo-Plore: Exploring Exoskeleton Control Space through Human-aligned Simulation <a href="https://arxiv.org/pdf/2601.22550" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Detect and Act: Automated Dynamic Optimizer through Meta-Black-Box Optimization <a href="https://arxiv.org/pdf/2601.22542" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] From Self-Evolving Synthetic Data to Verifiable-Reward RL: Post-Training Multi-turn Interactive Tool-Using Agents <a href="https://arxiv.org/pdf/2601.22607" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] RulePlanner: All-in-One Reinforcement Learner for Unifying Design Rules in 3D Floorplanning <a href="https://arxiv.org/pdf/2601.22476" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios <a href="https://arxiv.org/pdf/2601.22545" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Learning Reward Functions for Cooperative Resilience in Multi-Agent Systems <a href="https://arxiv.org/pdf/2601.22292" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] A Step Back: Prefix Importance Ratio Stabilizes Policy Optimization <a href="https://arxiv.org/pdf/2601.22718" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] TSPO: Breaking the Double Homogenization Dilemma in Multi-turn Search Policy Optimization <a href="https://arxiv.org/pdf/2601.22776" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Clipping-Free Policy Optimization for Large Language Models <a href="https://arxiv.org/pdf/2601.22801" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] CVeDRL: An Efficient Code Verifier via Difficulty-aware Reinforcement Learning <a href="https://arxiv.org/pdf/2601.22803" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Offline Reinforcement Learning of High-Quality Behaviors Under Robust Style Alignment <a href="https://arxiv.org/pdf/2601.22823" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Degradation-Aware Frequency Regulation of a Heterogeneous Battery Fleet via Reinforcement Learning <a href="https://arxiv.org/pdf/2601.22865" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Reinforcement Learning-Based Co-Design and Operation of Chiller and Thermal Energy Storage for Cost-Optimal HVAC Systems <a href="https://arxiv.org/pdf/2601.22880" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] PlatoLTL: Learning to Generalize Across Symbols in LTL Instructions for Multi-Task RL <a href="https://arxiv.org/pdf/2601.22891" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] MulFeRL: Enhancing Reinforcement Learning with Verbal Feedback in a Multi-turn Loop <a href="https://arxiv.org/pdf/2601.22900" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] MTDrive: Multi-turn Interactive Reinforcement Learning for Autonomous Driving <a href="https://arxiv.org/pdf/2601.22930" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Golden Goose: A Simple Trick to Synthesize Unlimited RLVR Tasks from Unverifiable Internet Text <a href="https://arxiv.org/pdf/2601.22975" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Automatic Constraint Policy Optimization based on Continuous Constraint Interpolation Framework for Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2601.23010" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Mem-T: Densifying Rewards for Long-Horizon Memory Agents <a href="https://arxiv.org/pdf/2601.23014" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Guided by Trajectories: Repairing and Rewarding Tool-Use Trajectories for Tool-Integrated Reasoning <a href="https://arxiv.org/pdf/2601.23032" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] From Absolute to Relative: Rethinking Reward Shaping in Group-Based Reinforcement Learning <a href="https://arxiv.org/pdf/2601.23058" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] RN-D: Discretized Categorical Actors with Regularized Networks for On-Policy Reinforcement Learning <a href="https://arxiv.org/pdf/2601.23075" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Why GRPO Needs Normalization: A Local-Curvature Perspective on Adaptive Gradients <a href="https://arxiv.org/pdf/2601.23135" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] THINKSAFE: Self-Generated Safety Alignment for Reasoning Models <a href="https://arxiv.org/pdf/2601.23143" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] On Safer Reinforcement Learning Policies for Sedation and Analgesia in Intensive Care <a href="https://arxiv.org/pdf/2601.23154" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Unsupervised Hierarchical Skill Discovery <a href="https://arxiv.org/pdf/2601.23156" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Med-Scout: Curing MLLMs&#x27; Geometric Blindness in Medical Perception via Geometry-Aware RL Post-Training <a href="https://arxiv.org/pdf/2601.23220" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Agile Reinforcement Learning through Separable Neural Architecture <a href="https://arxiv.org/pdf/2601.23225" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models <a href="https://arxiv.org/pdf/2601.23266" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 10</strong></p>
<ul>
<li class="">[arXiv260202] Predicting Intermittent Job Failure Categories for Diagnosis Using Few-Shot Fine-Tuned Language Models <a href="https://arxiv.org/pdf/2601.22264" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Scalable Topology-Preserving Graph Coarsening with Graph Collapse <a href="https://arxiv.org/pdf/2601.22943" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Why GRPO Needs Normalization: A Local-Curvature Perspective on Adaptive Gradients <a href="https://arxiv.org/pdf/2601.23135" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Unsupervised Hierarchical Skill Discovery <a href="https://arxiv.org/pdf/2601.23156" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification <a href="https://arxiv.org/pdf/2601.23180" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] YuriiFormer: A Suite of Nesterov-Accelerated Transformers <a href="https://arxiv.org/pdf/2601.23236" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Spectral Gradient Descent Mitigates Anisotropy-Driven Misalignment: A Case Study in Phase Retrieval <a href="https://arxiv.org/pdf/2601.22652" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] A Cross-Domain Graph Learning Protocol for Single-Step Molecular Geometry Refinement <a href="https://arxiv.org/pdf/2601.22723" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Disentangling multispecific antibody function with graph neural networks <a href="https://arxiv.org/pdf/2601.23212" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260202] Nested Slice Sampling: Vectorized Nested Sampling for GPU-Accelerated Inference <a href="https://arxiv.org/pdf/2601.23252" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-03">2026-02-03<a href="#2026-02-03" class="hash-link" aria-label="Direct link to 2026-02-03" title="Direct link to 2026-02-03" translate="no">​</a></h2>
<p><strong>cs.DC total: 31</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260203] Stabilizing Decentralized Federated Fine-Tuning via Topology-Aware Alternating LoRA</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [decentralized federated learning, low-rank adaptation, parameter-efficient fine-tuning, alternating optimization, topology-aware]</li>
<li class=""><strong>authors:</strong> Xiaoyu Wang, Xiaotian Li, Zhixiang Zhou, Chen Li, Yong Liu</li>
<li class=""><strong>institution:</strong> New York University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00451" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00451</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes TAD-LoRA, a topology-aware decentralized framework that coordinates the alternating updates and mixing of LoRA factors to stabilize federated fine-tuning under dynamic communication graphs. It theoretically proves convergence and shows the method achieves robust performance, especially under moderately and weakly connected network topologies.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Self-Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [self-attention, Taylor approximation, symmetric tensor products, polynomial-kernel feature basis, constant cost per token]</li>
<li class=""><strong>authors:</strong> Franz A. Heinsen, Leo Kozachkov</li>
<li class=""><strong>institution:</strong> GlassRoom Software LLC, Brown University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00294" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00294</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a method to compute self-attention with constant cost per token by using a symmetry-aware Taylor approximation, decomposing the expansion into symmetric tensor product chains. This enables unbounded token generation with fixed memory and compute, drastically reducing the infrastructure and energy demands of large Transformer models.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] VoxServe: Streaming-Centric Serving System for Speech Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [model-execution abstraction, streaming-aware scheduling, asynchronous inference pipeline]</li>
<li class=""><strong>authors:</strong> Keisuke Kamahori, Wei-Tzu Lee, Atindra Jha, Rohan Kadekodi, Stephanie Wang, Arvind Krishnamurthy, Baris Kasikci</li>
<li class=""><strong>institution:</strong> University of Washington, Stanford University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00269" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00269</a></li>
<li class=""><strong>Simple LLM Summary:</strong> VoxServe is a serving system for Speech Language Models that introduces a model-execution abstraction to decouple architecture from system optimizations, enabling support for diverse models. It uses streaming-aware scheduling and an asynchronous inference pipeline to improve efficiency. The system achieves 10-20x higher throughput than existing implementations at comparable latency while maintaining high streaming viability.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] A Fault-Tolerant Version of Safra&#x27;s Termination Detection Algorithm</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed algorithms], [Safra&#x27;s algorithm, token ring, fault tolerance, model checking, termination detection]</li>
<li class=""><strong>authors:</strong> Wan Fokkink, Georgios Karlos, Andy Tatman</li>
<li class=""><strong>institution:</strong> Vrije Universiteit Amsterdam, Paderborn University, University of Groningen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00272" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00272</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper adapts Safra&#x27;s classic termination detection algorithm to be fault-tolerant by splitting the global token counter into per-node counters and using a decentralized mechanism to restore the token ring after crashes. The proposed variant imposes no additional message overhead and can tolerate any number of simultaneous crashes. Correctness is proven and supported by model checking analysis.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Standardized Methods and Recommendations for Green Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, carbon accounting, NVFlare, CodeCarbon, energy model, communication emissions]</li>
<li class=""><strong>authors:</strong> Austin Tapp, Holger R. Roth, Ziyue Xu, Abhijeet Parida, Hareem Nisar, Marius George Linguraru</li>
<li class=""><strong>institution:</strong> Children&#x27;s National Hospital, NVIDIA, George Washington University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00343" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00343</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a standardized carbon-accounting methodology for Federated Learning (FL) using NVIDIA NVFlare and CodeCarbon to track CO2e emissions across different training phases and network communication. It demonstrates that system-level inefficiencies and hardware heterogeneity can drastically increase the carbon footprint, highlighting the need for per-site and per-round reporting. The main conclusion is that this standardized method is a prerequisite for reproducible and comparable &quot;green&quot; FL evaluation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] What Artificial Intelligence can do for High-Performance Computing systems?</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [reinforcement learning, graph neural networks, time-series models, language models, surrogate modeling, performance estimation, scheduling, fault detection]</li>
<li class=""><strong>authors:</strong> Pierrick Pochelu, Hyacinthe Cartiaux, Julien Schleich</li>
<li class=""><strong>institution:</strong> LuxProvide S.A., University of Luxembourg</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00014" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00014</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This review paper surveys how AI and machine learning techniques can improve the operational efficiency of High-Performance Computing systems. It analyzes 74 publications, identifying key application areas like scheduling, performance optimization, and fault detection. The main conclusion is that AI integration, including specialized language models and hybrid ML-heuristic approaches, offers significant opportunities for HPC efficiency but requires advances in MLOps and standardization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] FedMOA: Federated GRPO for Personalized Reasoning LLMs under Heterogeneous Rewards</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [federated learning, group relative policy optimization, hypergradient descent, multi-objective alignment, personalized reasoning]</li>
<li class=""><strong>authors:</strong> Ziyao Wang, Daeun Jung, Yexiao He, Guoheng Sun, Zheyu Shen, Myungjin Lee, Ang Li</li>
<li class=""><strong>institution:</strong> University of Maryland, College Park, Cisco Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00453" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00453</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FedMOA, a federated learning framework that adapts Group Relative Policy Optimization (GRPO) for personalized reasoning in large language models under heterogeneous client rewards. It introduces an online adaptive weighting mechanism for local training and a task-aware aggregation strategy on the server. Experiments show FedMOA outperforms standard federated averaging, improving accuracy, personalization, and multi-objective balance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Asynchronous MultiAgent Reinforcement Learning for 5G Routing under Side Constraints</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-agent reinforcement learning, asynchronous learning, PPO, routing, O-RAN]</li>
<li class=""><strong>authors:</strong> Sebastian Racedo, Brigitte Jaumard, Oscar Delgado, Meysam Masoudi</li>
<li class=""><strong>institution:</strong> Concordia University, Ecole de Technologie Supérieure (ETS), Ericsson</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00035" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00035</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an asynchronous multi-agent reinforcement learning (AMARL) framework for 5G routing, where independent PPO agents per service plan routes in parallel and coordinate via a shared global resource environment. The method achieves similar performance to a centralized baseline in terms of Grade of Service and latency, while offering reduced training time and improved robustness to demand shifts, demonstrating a scalable approach for distributed network optimization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] PROBE: Co-Balancing Computation and Communication in MoE Inference via Real-Time Predictive Prefetching</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [mixture-of-experts, expert parallelism, continuous lookahead pipelining, predictive prefetching, gate-initialized lookahead predictor, hardware-aware balance planning, phase-locked co-scheduling]</li>
<li class=""><strong>authors:</strong> Qianchao Zhu, Xucheng Ye, Yuliang Liu, Haodong Ouyang, Chengru Song</li>
<li class=""><strong>institution:</strong> Kling Infra, Kuaishou Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00509" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00509</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces PROBE, an inference system for Mixture-of-Experts models that uses real-time predictive prefetching to balance computation and communication. Its core method involves predicting upcoming expert activations and proactively planning token assignments and expert transfers to hide network latency behind computation. The system reduces prefill latency and improves decoding throughput under dynamic workloads compared to state-of-the-art baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Training LLMs with Fault Tolerant HSDP on 100,000 GPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [Fault Tolerant Hybrid-Shared Data Parallelism (FT-HSDP), Fault Tolerant All Reduce (FTAR), non-blocking catch-up protocol, data parallel replicas]</li>
<li class=""><strong>authors:</strong> Omkar Salpekar, Rohan Varma, Kenny Yu, Vladimir Ivanov, Yang Wang, Ahmed Sharif, Min Si, Shawn Xu, Feng Tian, Shengbao Zheng, Tristan Rice, Ankush Garg, Shangfu Peng, Shreyas Siravara, Wenyin Fu, Rodrigo de Castro, Adithya Gangidi, Andrey Obraztsov, Sharan Narang, Sergey Edunov, Maxim Naumov, Chunqiang Tang, Mathew Oldham</li>
<li class=""><strong>institution:</strong> Meta Platforms, Thinking Machines Labs, The Ohio State University, Genesis Molecular AI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00277" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00277</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Fault Tolerant Hybrid-Shared Data Parallelism (FT-HSDP), a novel training paradigm that uses data parallel replicas as fault tolerance units to minimize stall time during GPU failures. It introduces techniques like a Fault Tolerant All Reduce protocol and a non-blocking catch-up protocol. The method reduces recovery stall time from 10 to 3 minutes at O(100K) GPU scale, boosting effective training time from 44% to 80% without degrading model accuracy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Forecasting Energy Availability in Local Energy Communities via LSTM Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Federated Learning, LSTM, forecasting, privacy-preserving]</li>
<li class=""><strong>authors:</strong> Fabio Turazza, Marcello Pietri, Natalia Selini Hadjidimitriou, Marco Mamei</li>
<li class=""><strong>institution:</strong> University of Modena and Reggio Emilia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00694" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00694</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using Federated Learning combined with Long Short-Term Memory (LSTM) networks to forecast energy availability in Local Energy Communities while preserving user data privacy. It demonstrates that this approach can create an accurate forecasting model without sharing sensitive consumption data among users, highlighting a trade-off between data sharing and prediction accuracy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] HyperOffload: Graph-Driven Hierarchical Memory Management for Large Language Models on SuperNode Architectures</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [graph-driven memory management, compiler-assisted offloading, static scheduling, remote memory access, hierarchical supernode architecture]</li>
<li class=""><strong>authors:</strong> Fangxin Liu, Qinghua Zhang, Hanjing Shen, Qinghua Zhang, Zhibo Liang, Li Jiang, Haibing Guan, Chong Bao, Xuefeng Jin</li>
<li class=""><strong>institution:</strong> Shanghai Jiao Tong University, Huawei Technologies Co., Ltd.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00748" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00748</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes HyperOffload, a compiler-assisted framework that uses graph-driven memory management to explicitly treat remote memory access as operations in the computation graph. This enables static scheduling of data transfers to hide latency, reducing peak device memory usage by up to 26% for LLM inference while maintaining performance. The work demonstrates that integrating memory-augmented hardware into compiler optimization is key for scaling next-generation AI workloads.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] System-Level Performance Modeling of Photonic In-Memory Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [photonic computing], [photonic SRAM, system-level modeling, algorithm-to-hardware mapping, opto-electronic conversion, silicon photonics]</li>
<li class=""><strong>authors:</strong> Jebacyril Arockiaraj, Sasindu Wijeratne, Sugeet Sunder, Md Abdullah-Al Kaiser, Akhilesh Jaiswal, Ajey P. Jacob, Viktor Prasanna</li>
<li class=""><strong>institution:</strong> University of Southern California, University of Wisconsin-Madison</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00892" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00892</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper develops a system-level performance model for photonic in-memory computing, accounting for latencies like external memory access. It maps high-performance computing workloads to a photonic SRAM hardware model. The model shows the fabricated photonic SRAM array can sustain up to 1.5 TOPS with an average energy efficiency of 2.5 TOPS/W on the evaluated workloads.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] FUPareto: Bridging the Forgetting-Utility Gap in Federated Unlearning via Pareto Augmented Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zeyan Wang, Zhengmao Liu, Yongxin Cai, Chi Li, Xiaoying Tang, Jingchao Chen, Zibin Pan, Jing Qiu</li>
<li class=""><strong>institution:</strong></li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.01852" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.01852</a></li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Low-latency Federated LLM Fine-tuning Over Wireless Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [federated learning, client-specific pruning, bandwidth allocation, block coordinate descent, LoRA, model compression]</li>
<li class=""><strong>authors:</strong> Zhiwen Pang, Kang Wei, Long Shi, Zhe Wang, Jun Li, Feng Shu</li>
<li class=""><strong>institution:</strong> Nanjing University of Science and Technology, Southeast University, Hainan University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.01024" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.01024</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a joint client-specific pruning and bandwidth allocation (JCPBA) framework to reduce the latency of federated fine-tuning for large language models over wireless networks. The method formulates and solves a latency minimization problem by optimizing pruning rates and bandwidth allocations for heterogeneous clients. Experiments show the framework significantly reduces fine-tuning time and achieves comparable or lower test loss with lower overhead compared to baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] FedBGS: A Blockchain Approach to Segment Gossip Learning in Decentralized Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [blockchain, gossip learning, federated analytics, differential privacy, homomorphic encryption, secure multi-party computation]</li>
<li class=""><strong>authors:</strong> Fabio Turazza, Marcello Pietri, Marco Picone, Marco Mamei</li>
<li class=""><strong>institution:</strong> University of Modena and Reggio Emilia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.01185" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.01185</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes FedBGS, a fully decentralized framework that combines blockchain and segmented gossip learning to enhance federated learning. It aims to eliminate the central server as a single point of failure, thereby improving security, scalability, and handling of non-IID data. The main conclusion is that this approach provides comprehensive protection against various attacks while optimizing blockchain usage in federated environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] MedBeads: An Agent-Native, Immutable Data Substrate for Trustworthy Medical AI</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [Merkle DAG, Immutable Data, Breadth-First Search (BFS), FHIR-to-DAG conversion, Cryptographic Chain, Tamper-evidence]</li>
<li class=""><strong>authors:</strong> Takahito Nakajima</li>
<li class=""><strong>institution:</strong> University of Tsukuba</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.01086" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.01086</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes MedBeads, an agent-native data infrastructure that structures clinical events as immutable nodes in a Merkle DAG to provide deterministic, tamper-evident context for LLMs. This addresses the &quot;Context Mismatch&quot; in medical AI by replacing probabilistic data retrieval with deterministic graph traversal, aiming to reduce hallucinations and improve auditability for trustworthy clinical agents.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Privocracy: Online Democracy through Private Voting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [access control], [private voting, verifiable secret sharing, k-anonymity, asynchronous multiparty-computation, vote delegation]</li>
<li class=""><strong>authors:</strong> Pedro Camponês, Hugo Pereira, Adrian Persaud, Kevin Gallagher, Santiago Torres-Arias</li>
<li class=""><strong>institution:</strong> NOVA LINCS, NOVA School of Science and Technology, Purdue University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.01341" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.01341</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Privocracy, an access control mechanism that replaces unilateral administrative privileges with a secure, private e-voting procedure to authorize sensitive commands. The system achieves everlasting vote privacy and incorporates features like delegation and rapid voting. The authors conclude that Privocracy efficiently distributes trust to minimize single points of failure and can be deployed on commodity hardware.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Mean field optimal Core Allocation across Malleable jobs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [scheduling theory], [mean field analysis, Whittle policy, concave speedup functions, core allocation]</li>
<li class=""><strong>authors:</strong> Zhouzi Li, Mor Harchol-Balter, Benjamin Berg</li>
<li class=""><strong>institution:</strong> Carnegie Mellon University, UNC Chapel Hill</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.01411" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.01411</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper solves the Core Allocation to Malleable jobs (CAM) problem by analyzing it in the mean field asymptotic regime, deriving two optimal policies: FW-CAM and WHAM. The main conclusion is that WHAM is asymptotically optimal and serves as a good heuristic, and that in the mean field regime, job sizes are not relevant for finding an optimal policy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Fast Sparse Matrix Permutation for Mesh-Based Direct Solvers</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [sparse linear algebra], [nested dissection, sparse matrix permutation, sparse Cholesky factorization, elimination-tree, quotient-graph ordering]</li>
<li class=""><strong>authors:</strong> Behrooz Zarebavami, Ahmed H. Mahmoud, Ana Dodik, Changcheng Yuan, Serban D. Porumbescu, John D. Owens, Maryam Mehri Dehnavi, Justin Solomon</li>
<li class=""><strong>institution:</strong> University of Toronto, Massachusetts Institute of Technology, Texas A&amp;M University, University of California, Davis, NVIDIA Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.00898" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.00898</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a fast sparse matrix permutation algorithm designed for linear systems from triangle meshes. It relaxes strict balance and separator optimality to achieve faster partitioning and elimination-tree construction, decomposing the permutation into patch-level local orderings and a compact separator ordering. The method reduces permutation time and improves sparse Cholesky solve performance by up to 6.27x when integrated into vendor solvers on CPUs and GPUs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] BOA Constrictor: Squeezing Performance out of GPUs in the Cloud via Budget-Optimal Allocation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [budget-optimal allocation, scheduling, job completion time, GPU allocation, cost-performance tradeoff]</li>
<li class=""><strong>authors:</strong> Zhouzi Li, Cindy Zhu, Arpan Mukhopadhyay, Mor Harchol-Balter, Benjamin Berg</li>
<li class=""><strong>institution:</strong> Carnegie Mellon University, University of Warwick, UNC Chapel Hill</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.01404" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.01404</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces BOA Constrictor, a scheduler that uses a Budget-Optimal Allocation (BOA) policy to optimize the allocation of rented cloud GPUs for ML training jobs under a fixed budget constraint. It formulates the problem as a budget-constrained scheduling problem to minimize average job completion time. The method demonstrates significant performance improvements, reducing average JCT by up to 2x and cutting the required budget for a target JCT by up to 2x compared to heuristic schedulers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Developing a Portable Solution for Post-Event Analysis Pipelines</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Science Gateway, Apache Airflow, Photogrammetry, Machine Learning, Data Visualization, Directed Acyclic Graphs (DAGs)]</li>
<li class=""><strong>authors:</strong> Leonardo Pelonero, Fabio Vitello, Eva Sciacca, Mauro Imbrosciano, Salvatore Scavo, Ugo Becciani</li>
<li class=""><strong>institution:</strong> INAF Astrophysical Observatory of Catania</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.01798" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.01798</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a Science Gateway framework for creating portable, automated post-event analysis pipelines that integrate photogrammetry, data visualization, and AI technologies on aerial images. The core method involves migrating standalone workflows into a single orchestrated pipeline using Apache Airflow and DAGs within a Science Gateway platform. The main conclusion is that this framework enables efficient assessment of extreme natural events and their impact on at-risk assets, supporting timely hazard management and decision-making.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] TriCloudEdge: A multi-layer Cloud Continuum</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [cloud continuum, edge computing, federated learning, WebSocket, MQTT, Zenoh, model adaptation]</li>
<li class=""><strong>authors:</strong> George Violettas, Lefteris Mamatas</li>
<li class=""><strong>institution:</strong> University of Macedonia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02121" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02121</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes TriCloudEdge, a three-tier cloud continuum architecture that integrates far-edge devices, intermediate edge nodes, and central cloud services to distribute computational tasks. It compares a multi-protocol approach (WebSocket, MQTT, HTTP) with a versatile protocol (Zenoh) for data transfer, demonstrating trade-offs in resource utilization and communication efficiency. The results show that this architecture can effectively address latency and privacy concerns by distributing AI workloads across the continuum.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Grappa: Gradient-Only Communication for Scalable Graph Neural Network Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [gradient-only communication, coverage-corrected gradient aggregation, periodic repartitioning]</li>
<li class=""><strong>authors:</strong> Chongyang Xu, Christoph Siebenbrunner, Laurent Bindschaedler</li>
<li class=""><strong>institution:</strong> Max Planck Institute for Software Systems (MPI-SWS), Vienna University of Economics and Business (WU)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.01872" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.01872</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Grappa is a distributed GNN training framework that eliminates per-iteration cross-partition data fetching by having partitions train in isolation and only exchange gradients. It recovers accuracy through periodic graph repartitioning and a coverage-corrected gradient aggregation technique. The paper shows that Grappa trains GNNs significantly faster than state-of-the-art systems while achieving better accuracy, especially for deeper models, and scales to trillion-edge graphs on commodity hardware.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] vLLM-Omni: Fully Disaggregated Serving for Any-to-Any Multimodal Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [stage abstraction, disaggregated serving, request batching, GPU allocation, inter-stage connectors]</li>
<li class=""><strong>authors:</strong> Peiqi Yin, Jiangyun Zhu, Han Gao, Chenguang Zheng, Yongxiang Huang, Taichang Zhou, Ruirui Yang, Weizhi Liu, Weiqing Chen, Canlin Guo, Didan Deng, Zifeng Mo, Cong Wang, James Cheng, Roger Wang, Hongsheng Liu</li>
<li class=""><strong>institution:</strong> Huawei, The Chinese University of Hong Kong, Institute of Software Chinese Academy of Sciences, Sun Yat-sen University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02204" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02204</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces vLLM-Omni, a serving system that decomposes complex any-to-any multimodal models into interconnected stages for disaggregated execution. It optimizes resource use with per-stage batching and flexible GPU allocation. Experiments show it reduces job completion time by up to 91.4% compared to baseline methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] ECHO-2: A Large Scale Distributed Rollout Framework for Cost-efficient Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [distributed reinforcement learning, policy staleness, peer-assisted pipelined broadcast, cost-aware activation, GRPO]</li>
<li class=""><strong>authors:</strong> Jie Xiao, Meng Chen, Qingnan Ren, Song Jingwei, Jiaqi Huang, Yangshen Deng, Chris Tong, Wanyi Chen, Suli Wang, Ziqian Bi, Shuo Lu, Yiqun Duan, Lynn Ai, Eric Yang, Bill Shi</li>
<li class=""><strong>institution:</strong> Gradient, Fudan University, The University of Hong Kong, University of Edinburgh, Technical University of Darmstadt</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02192" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02192</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces ECHO-2, a distributed framework for cost-efficient reinforcement learning (RL) post-training of large language models. It enables overlapping rollout generation, policy dissemination, and centralized learning by treating policy staleness as a controllable parameter and uses techniques like peer-assisted broadcast and cost-aware worker activation. Experiments show that ECHO-2 significantly improves cost efficiency while maintaining reward performance comparable to strong baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Enabling AI Deep Potentials for Ab Initio-quality Molecular Dynamics Simulations in GROMACS</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [deep potentials, molecular dynamics, GROMACS, DeePMD-kit, attention mechanism, GNN, CUDA, kernel-launch overhead, domain-decomposed inference]</li>
<li class=""><strong>authors:</strong> Andong Hu, Luca Pennati, Stefano Markidis, Ivy Peng</li>
<li class=""><strong>institution:</strong> KTH Royal Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02234" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02234</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper integrates AI deep potentials into the GROMACS molecular dynamics simulation software by coupling it with the DeePMD-kit backend, enabling ab initio-quality simulations. It evaluates two neural network architectures (DPA2 and DPA3) on protein benchmarks, finding that the attention-based DPA2 significantly outperforms the GNN-based DPA3 in throughput on GPUs. The study identifies kernel-launch overhead and domain-decomposed inference as key optimization targets for production MD simulations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Hierarchical Federated Learning with SignSGD: A Highly Communication-Efficient Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [hierarchical federated learning, SignSGD, majority-vote aggregation, gradient compression, quantization, communication-efficient]</li>
<li class=""><strong>authors:</strong> Amirreza Kazemi, Seyed Mohammad Azimi-Abarghouyi, Gabor Fodor, Carlo Fischione</li>
<li class=""><strong>institution:</strong> KTH Royal Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02355" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02355</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes HierSignSGD, a hierarchical federated learning framework that uses one-bit gradient compression (SignSGD) and majority-vote aggregation at edge servers to drastically reduce communication costs. The method achieves accuracy comparable to full-precision SGD while being robust to aggressive downlink sparsification, making it highly efficient for large-scale IoT and wireless systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] sVIRGO: A Scalable Virtual Tree Hierarchical Framework for Distributed Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems], [virtual hierarchical tree, multi-region coordination, layer-scoped command execution, dynamic role mapping, fault tolerance]</li>
<li class=""><strong>authors:</strong> Lican Huang</li>
<li class=""><strong>institution:</strong> Hangzhou Domain Zones Technology Co., Ltd.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02438" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02438</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes sVIRGO, a framework that constructs a scalable virtual tree hierarchy directly on physical nodes without overlay networks, enabling dynamic role assignment and locality-preserving coordination. It achieves robust, large-scale coordination across thousands of regions with near-zero recovery latency and bounded communication overhead, ensuring safety and liveness under dynamic or adversarial conditions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] Building a Correct-by-Design Lakehouse. Data Contracts, Versioning, and Transactional Pipelines for Humans and Agents</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [data contracts, Git-like versioning, transactional pipelines, verification, lakehouse]</li>
<li class=""><strong>authors:</strong> Weiming Sheng, Jinlang Wang, Manuel Barros, Aldrin Montana, Jacopo Tagliabue, Luca Bigon</li>
<li class=""><strong>institution:</strong> Columbia University, University of Wisconsin-Madison, Carnegie Mellon University, Bauplan Labs</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02335" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02335</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents Bauplan, a code-first lakehouse designed to ensure correctness through three integrated axes: typed table contracts for static checking, Git-like data versioning for collaboration, and transactional pipeline runs for atomicity. It aims to make illegal data states unrepresentable, providing safety for concurrent operations by humans and AI agents. Early results from a formal transaction model are reported, with future work motivated by identified counterexamples.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260203] LCLs Beyond Bounded Degrees</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [Locally Checkable Labelings, Locally Finite Labelings, LOCAL model, gap results, polynomial regime, trees, unbounded degree]</li>
<li class=""><strong>authors:</strong> Gustav Schmid</li>
<li class=""><strong>institution:</strong> University of Freiburg</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02340" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02340</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper investigates the complexity of distributed graph labeling problems (LCLs) on trees with unbounded node degrees. It introduces Locally Finite Labelings (LFLs), a restricted class of problems where nodes have only finitely many local configurations. The main conclusion is that for LFLs, the deterministic LOCAL complexity on trees is either polylogarithmic or exactly polynomial (Θ(n^{1/k})), restoring the strong gap results that disappear for general LCLs in the unbounded-degree setting.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 101</strong></p>
<ul>
<li class="">[arXiv260203] Search Inspired Exploration in Reinforcement Learning <a href="https://arxiv.org/pdf/2602.00460" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] AdaFuse: Adaptive Multimodal Fusion for Lung Cancer Risk Prediction via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.00347" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Joint Continual Learning of Local Language Models and Cloud Offloading Decisions with Budget Constraints <a href="https://arxiv.org/pdf/2602.00166" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Distributional Reinforcement Learning for Condition-Based Maintenance of Multi-Pump Equipment <a href="https://arxiv.org/pdf/2602.00051" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] LLMs as High-Dimensional Nonlinear Autoregressive Models with Attention: Training, Alignment and Inference <a href="https://arxiv.org/pdf/2602.00426" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] ZEST: Zero-shot Embodied Skill Transfer for Athletic Robot Control <a href="https://arxiv.org/pdf/2602.00401" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Open Materials Generation with Inference-Time Reinforcement Learning <a href="https://arxiv.org/pdf/2602.00424" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models <a href="https://arxiv.org/pdf/2602.00190" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Variational Approach for Job Shop Scheduling <a href="https://arxiv.org/pdf/2602.00408" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Sample Complexity Analysis for Constrained Bilevel Reinforcement Learning <a href="https://arxiv.org/pdf/2602.00282" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] KEPO: Knowledge-Enhanced Preference Optimization for Reinforcement Learning with Reasoning <a href="https://arxiv.org/pdf/2602.00400" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] CamReasoner: Reinforcing Camera Movement Understanding via Structured Spatial Reasoning <a href="https://arxiv.org/pdf/2602.00181" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Representation Learning Enhanced Deep Reinforcement Learning for Optimal Operation of Hydrogen-based Multi-Energy Systems <a href="https://arxiv.org/pdf/2602.00027" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Learning Robust Reasoning through Guided Adversarial Self-Play <a href="https://arxiv.org/pdf/2602.00173" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] AREAL-DTA: Dynamic Tree Attention for Efficient Reinforcement Learning of Large Language Models <a href="https://arxiv.org/pdf/2602.00482" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] DROGO: Default Representation Objective via Graph Optimization in Reinforcement Learning <a href="https://arxiv.org/pdf/2602.00403" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Minerva: Reinforcement Learning with Verifiable Rewards for Cyber Threat Intelligence LLMs <a href="https://arxiv.org/pdf/2602.00513" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] How Far Are LLMs from Professional Poker Players? Revisiting Game-Theoretic Reasoning with Agentic Tool Use <a href="https://arxiv.org/pdf/2602.00528" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Reinforcement Learning-assisted Constraint Relaxation for Constrained Expensive Optimization <a href="https://arxiv.org/pdf/2602.00532" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Surrogate Ensemble in Expensive Multi-Objective Optimization via Deep Q-Learning <a href="https://arxiv.org/pdf/2602.00540" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Learning to Decode Against Compositional Hallucination in Video Multimodal Large Language Models <a href="https://arxiv.org/pdf/2602.00559" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Learning Modal-Mixed Chain-of-Thought Reasoning with Latent Embeddings <a href="https://arxiv.org/pdf/2602.00574" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Safe Langevin Soft Actor Critic <a href="https://arxiv.org/pdf/2602.00587" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Equilibrium of Feasible Zone and Uncertain Model in Safe Exploration <a href="https://arxiv.org/pdf/2602.00636" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] SA-VLA: Spatially-Aware Flow-Matching for Vision-Language-Action Reinforcement Learning <a href="https://arxiv.org/pdf/2602.00743" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning <a href="https://arxiv.org/pdf/2602.00759" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Communications-Incentivized Collaborative Reasoning in NetGPT through Agentic Reinforcement Learning <a href="https://arxiv.org/pdf/2602.00766" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Fast Non-Episodic Finite-Horizon RL with K-Step Lookahead Thresholding <a href="https://arxiv.org/pdf/2602.00781" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] World Models as an Intermediary between Agents and the Real World <a href="https://arxiv.org/pdf/2602.00785" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Resource-Efficient Reinforcement for Reasoning Large Language Models via Dynamic One-Shot Policy Refinement <a href="https://arxiv.org/pdf/2602.00815" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Learning Abstractions for Hierarchical Planning in Program-Synthesis Agents <a href="https://arxiv.org/pdf/2602.00929" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning <a href="https://arxiv.org/pdf/2602.00983" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Reasoning and Tool-use Compete in Agentic RL<!-- -->:From<!-- --> Quantifying Interference to Disentangled Tuning <a href="https://arxiv.org/pdf/2602.00994" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] ESSAM: A Novel Competitive Evolution Strategies Approach to Reinforcement Learning for Memory Efficient LLMs Fine-Tuning <a href="https://arxiv.org/pdf/2602.01003" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Discovering Process-Outcome Credit in Multi-Step LLM Reasoning <a href="https://arxiv.org/pdf/2602.01034" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Good SFT Optimizes for SFT, Better SFT Prepares for Reinforcement Learning <a href="https://arxiv.org/pdf/2602.01058" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] SetPO: Set-Level Policy Optimization for Diversity-Preserving LLM Reasoning <a href="https://arxiv.org/pdf/2602.01062" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Probing RLVR training instability through the lens of objective-level hacking <a href="https://arxiv.org/pdf/2602.01103" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Lyapunov Stability-Aware Stackelberg Game for Low-Altitude Economy: A Control-Oriented Pruning-Based DRL Approach <a href="https://arxiv.org/pdf/2602.01131" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Self-Generative Adversarial Fine-Tuning for Large Language Models <a href="https://arxiv.org/pdf/2602.01137" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] PolicyFlow: Policy Optimization with Continuous Normalizing Flow in Reinforcement Learning <a href="https://arxiv.org/pdf/2602.01156" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Sample Efficient Active Algorithms for Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2602.01260" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Mixture-of-World Models: Scaling Multi-Task Reinforcement Learning with Modular Latent Dynamics <a href="https://arxiv.org/pdf/2602.01270" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] From Intents to Actions: Agentic AI in Autonomous Networks <a href="https://arxiv.org/pdf/2602.01271" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Adaptive Quantum-Safe Cryptography for 6G Vehicular Networks via Context-Aware Optimization <a href="https://arxiv.org/pdf/2602.01342" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] CRAFT: Calibrated Reasoning with Answer-Faithful Traces via Reinforcement Learning for Multi-Hop Question Answering <a href="https://arxiv.org/pdf/2602.01348" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] PromptRL: Prompt Matters in RL for Flow-Based Image Generation <a href="https://arxiv.org/pdf/2602.01382" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] The Enhanced Physics-Informed Kolmogorov-Arnold Networks: Applications of Newton&#x27;s Laws in Financial Deep Reinforcement Learning (RL) Algorithms <a href="https://arxiv.org/pdf/2602.01388" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] TQL: Scaling Q-Functions with Transformers by Preventing Attention Collapse <a href="https://arxiv.org/pdf/2602.01439" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Provable Cooperative Multi-Agent Exploration for Reward-Free MDPs <a href="https://arxiv.org/pdf/2602.01453" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training <a href="https://arxiv.org/pdf/2602.01511" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] A Relative-Budget Theory for Reinforcement Learning with Verifiable Rewards in Large Language Model Reasoning <a href="https://arxiv.org/pdf/2602.01523" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Making Bias Non-Predictive: Training Robust LLM Judges via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.01528" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] MAGIC: A Co-Evolving Attacker-Defender Adversarial Game for Robust LLM Safety <a href="https://arxiv.org/pdf/2602.01539" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Toward Cognitive Supersensing in Multimodal Large Language Model <a href="https://arxiv.org/pdf/2602.01541" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] The Multiple Ticket Hypothesis: Random Sparse Subnetworks Suffice for RLVR <a href="https://arxiv.org/pdf/2602.01599" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Adaptive Rollout Allocation for Online Reinforcement Learning with Verifiable Rewards <a href="https://arxiv.org/pdf/2602.01601" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Boosting Maximum Entropy Reinforcement Learning via One-Step Flow Matching <a href="https://arxiv.org/pdf/2602.01606" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] SUSD: Structured Unsupervised Skill Discovery through State Factorization <a href="https://arxiv.org/pdf/2602.01619" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.01649" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning <a href="https://arxiv.org/pdf/2602.01664" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] TABX: A High-Throughput Sandbox Battle Simulator for Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.01665" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios <a href="https://arxiv.org/pdf/2602.01675" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Semantic-aware Wasserstein Policy Regularization for Large Language Model Alignment <a href="https://arxiv.org/pdf/2602.01685" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Restoring Exploration after Post-Training: Latent Exploration Decoding for Large Reasoning Models <a href="https://arxiv.org/pdf/2602.01698" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Mitigating loss of control in advanced AI systems through instrumental goal trajectories <a href="https://arxiv.org/pdf/2602.01699" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner <a href="https://arxiv.org/pdf/2602.01705" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Adversarial Reward Auditing for Active Detection and Mitigation of Reward Hacking <a href="https://arxiv.org/pdf/2602.01750" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting <a href="https://arxiv.org/pdf/2602.01776" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Grad2Reward: From Sparse Judgment to Dense Rewards for Improving Open-Ended LLM Reasoning <a href="https://arxiv.org/pdf/2602.01791" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Beyond Precision: Training-Inference Mismatch is an Optimization Problem and Simple LR Scheduling Fixes It <a href="https://arxiv.org/pdf/2602.01826" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Designing Time Series Experiments in A/B Testing with Transformer Reinforcement Learning <a href="https://arxiv.org/pdf/2602.01853" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] VLM-Guided Experience Replay <a href="https://arxiv.org/pdf/2602.01915" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Zero-Shot Off-Policy Learning <a href="https://arxiv.org/pdf/2602.01962" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models <a href="https://arxiv.org/pdf/2602.01970" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization <a href="https://arxiv.org/pdf/2602.02035" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] FORLER: Federated Offline Reinforcement Learning with Q-Ensemble and Actor Rectification <a href="https://arxiv.org/pdf/2602.02055" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Probabilistic Performance Guarantees for Multi-Task Reinforcement Learning <a href="https://arxiv.org/pdf/2602.02098" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Think Dense, Not Long: Dynamic Decoupled Conditional Advantage for Efficient Reasoning <a href="https://arxiv.org/pdf/2602.02099" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations <a href="https://arxiv.org/pdf/2602.02137" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Learning Generative Selection for Best-of-N <a href="https://arxiv.org/pdf/2602.02143" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] ECHO: Entropy-Confidence Hybrid Optimization for Test-Time Reinforcement Learning <a href="https://arxiv.org/pdf/2602.02150" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Online Fine-Tuning of Pretrained Controllers for Autonomous Driving via Real-Time Recurrent RL <a href="https://arxiv.org/pdf/2602.02236" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Learning While Staying Curious: Entropy-Preserving Supervised Fine-Tuning via Adaptive Self-Distillation for Large Reasoning Models <a href="https://arxiv.org/pdf/2602.02244" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Segment to Focus: Guiding Latent Action Models in the Presence of Distractors <a href="https://arxiv.org/pdf/2602.02259" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Learning Markov Decision Processes under Fully Bandit Feedback <a href="https://arxiv.org/pdf/2602.02260" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Choice-Model-Assisted Q-learning for Delayed-Feedback Revenue Management <a href="https://arxiv.org/pdf/2602.02283" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Advancing General-Purpose Reasoning Models with Modular Gradient Surgery <a href="https://arxiv.org/pdf/2602.02301" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Position: Explaining Behavioral Shifts in Large Language Models Requires a Comparative Approach <a href="https://arxiv.org/pdf/2602.02304" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] SWE-Universe: Scale Real-World Verifiable Environments to Millions <a href="https://arxiv.org/pdf/2602.02361" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] SLIME: Stabilized Likelihood Implicit Margin Enforcement for Preference Optimization <a href="https://arxiv.org/pdf/2602.02383" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.02395" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] World-Gymnast: Training Robots with Reinforcement Learning in a World Model <a href="https://arxiv.org/pdf/2602.02454" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Conflict-Aware Client Selection for Multi-Server Federated Learning <a href="https://arxiv.org/pdf/2602.02458" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System <a href="https://arxiv.org/pdf/2602.02488" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Design and Empirical Study of a Large Language Model-Based Multi-Agent Investment System for Chinese Public REITs <a href="https://arxiv.org/pdf/2602.00082" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Reinforcement Learning for Control Systems with Time Delays: A Comprehensive Survey <a href="https://arxiv.org/pdf/2602.00399" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Stabilizing Fixed-Point Iteration for Markov Chain Poisson Equations <a href="https://arxiv.org/pdf/2602.00474" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] FinEvo: From Isolated Backtests to Ecological Market Games for Multi-Agent Financial Strategy Evolution <a href="https://arxiv.org/pdf/2602.00948" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Non-Uniform Noise-to-Signal Ratio in the REINFORCE Policy-Gradient Estimator <a href="https://arxiv.org/pdf/2602.01460" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Well-Posed KL-Regularized Control via Wasserstein and Kalman-Wasserstein KL Divergences <a href="https://arxiv.org/pdf/2602.02250" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 39</strong></p>
<ul>
<li class="">[arXiv260203] Harvest: Opportunistic Peer-to-Peer GPU Caching for LLM Inference <a href="https://arxiv.org/pdf/2602.00328" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Autonomous Data Processing using Meta-Agents <a href="https://arxiv.org/pdf/2602.00307" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Fast Forward: Accelerating LLM Prefill with Predictive FFN Sparsity <a href="https://arxiv.org/pdf/2602.00397" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Agentic Framework for Epidemiological Modeling <a href="https://arxiv.org/pdf/2602.00299" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Generation Order and Parallel Decoding in Masked Diffusion Models: An Information-Theoretic Perspective <a href="https://arxiv.org/pdf/2602.00286" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] 3DGS<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>-TR: Scalable Second-Order Trust-Region Method for 3D Gaussian Splatting <a href="https://arxiv.org/pdf/2602.00395" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Representation Learning Enhanced Deep Reinforcement Learning for Optimal Operation of Hydrogen-based Multi-Energy Systems <a href="https://arxiv.org/pdf/2602.00027" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Scalable Generative Game Engine: Breaking the Resolution Wall via Hardware-Algorithm Co-Design <a href="https://arxiv.org/pdf/2602.00608" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Environment-Aware Adaptive Pruning with Interleaved Inference Orchestration for Vision-Language-Action Models <a href="https://arxiv.org/pdf/2602.00780" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Multi-Objective Multi-Fidelity Bayesian Optimization with Causal Priors <a href="https://arxiv.org/pdf/2602.00788" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Exploration of Unary Arithmetic-Based Matrix Multiply Units for Low Precision DL Accelerators <a href="https://arxiv.org/pdf/2602.00838" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] LASS-ODE: Scaling ODE Computations to Connect Foundation Models with Dynamical Physical Systems <a href="https://arxiv.org/pdf/2602.01009" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Superposition unifies power-law training dynamics <a href="https://arxiv.org/pdf/2602.01045" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Not All Preferences Are Created Equal: Stability-Aware and Gradient-Efficient Alignment for Reasoning Models <a href="https://arxiv.org/pdf/2602.01207" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Sample Efficient Active Algorithms for Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2602.01260" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length <a href="https://arxiv.org/pdf/2602.01274" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] LLM-Driven Ontology Construction for Enterprise Knowledge Graphs <a href="https://arxiv.org/pdf/2602.01276" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Gradient-Aligned Calibration for Post-Training Quantization of Diffusion Models <a href="https://arxiv.org/pdf/2602.01289" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Improve the Trade-off Between Watermark Strength and Speculative Sampling Efficiency for Language Models <a href="https://arxiv.org/pdf/2602.01428" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.01649" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] TABX: A High-Throughput Sandbox Battle Simulator for Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.01665" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Real-Time Loop Closure Detection in Visual SLAM via NetVLAD and Faiss <a href="https://arxiv.org/pdf/2602.01673" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Physics Informed Generative AI Enabling Labour Free Segmentation For Microscopy Analysis <a href="https://arxiv.org/pdf/2602.01710" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] PRISM: Parametrically Refactoring Inference for Speculative Sampling Draft Models <a href="https://arxiv.org/pdf/2602.01762" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention <a href="https://arxiv.org/pdf/2602.01801" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] IntraSlice: Towards High-Performance Structural Pruning with Block-Intra PCA for LLMs <a href="https://arxiv.org/pdf/2602.01975" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Position: The Need for Ultrafast Training <a href="https://arxiv.org/pdf/2602.02005" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] BAPS: A Fine-Grained Low-Precision Scheme for Softmax in Attention via Block-Aware Precision reScaling <a href="https://arxiv.org/pdf/2602.02071" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Toxicity Assessment in Preclinical Histopathology via Class-Aware Mahalanobis Distance for Known and Novel Anomalies <a href="https://arxiv.org/pdf/2602.02124" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Scalable Spatio-Temporal SE(3) Diffusion for Long-Horizon Protein Dynamics <a href="https://arxiv.org/pdf/2602.02128" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Generalized Optimal Classification Trees: A Mixed-Integer Programming Approach <a href="https://arxiv.org/pdf/2602.02173" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Models <a href="https://arxiv.org/pdf/2602.02197" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Spark: Modular Spiking Neural Networks <a href="https://arxiv.org/pdf/2602.02306" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Towards Agentic Intelligence for Materials Science <a href="https://arxiv.org/pdf/2602.00169" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Action-Free Offline-to-Online RL via Discretised State Policies <a href="https://arxiv.org/pdf/2602.00629" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] A New Workflow for Materials Discovery Bridging the Gap Between Experimental Databases and Graph Neural Networks <a href="https://arxiv.org/pdf/2602.00756" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] WAKESET: A Large-Scale, High-Reynolds Number Flow Dataset for Machine Learning of Turbulent Wake Dynamics <a href="https://arxiv.org/pdf/2602.01379" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] FluxNet: Learning Capacity-Constrained Local Transport Operators for Conservative and Bounded PDE Surrogates <a href="https://arxiv.org/pdf/2602.01941" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260203] Training-free score-based diffusion for parameter-dependent stochastic dynamical systems <a href="https://arxiv.org/pdf/2602.02113" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-04">2026-02-04<a href="#2026-02-04" class="hash-link" aria-label="Direct link to 2026-02-04" title="Direct link to 2026-02-04" translate="no">​</a></h2>
<p><strong>cs.DC total: 15</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260204] Joint Network-and-Server Congestion in Multi-Source Traffic Allocation: A Convex Formulation and Price-Based Decentralization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [network optimization], [convex optimization, marginal cost pricing, Wardrop condition, distributed algorithm, queueing delay]</li>
<li class=""><strong>authors:</strong> Tamoghna Sarkar, Bhaskar Krishnamachari</li>
<li class=""><strong>institution:</strong> University of Southern California</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.03246" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.03246</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper formulates a multi-source traffic allocation problem with joint network and server congestion as a convex program and develops a distributed pricing-based algorithm. The method uses congestion prices broadcast by service nodes to allow sources to locally optimize traffic splits, converging to a system-optimal solution characterized by total marginal cost equalization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] StreamShield: A Production-Proven Resiliency Solution for Apache Flink at ByteDance</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed stream processing], [runtime optimization, fine-grained fault-tolerance, hybrid replication strategy, high availability]</li>
<li class=""><strong>authors:</strong> Yong Fang, Yuxing Han, Meng Wang, Yifan Zhang, Yue Ma, Chi Zhang</li>
<li class=""><strong>institution:</strong> ByteDance Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.03189" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.03189</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents StreamShield, a resiliency solution for Apache Flink clusters, which introduces techniques like runtime optimization and hybrid replication to enhance fault tolerance and stability. The system was extensively evaluated on a large-scale production cluster at ByteDance, demonstrating its effectiveness in meeting strict service level objectives.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] Large-Scale LLM Inference with Heterogeneous Workloads: Prefill-Decode Contention and Asymptotically Optimal Control</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [stochastic control, queueing network, fluid approximation, linear programming, gate-and-route policy]</li>
<li class=""><strong>authors:</strong> Ruihan Lin, Zezhen Ding, Zean Han, Jiheng Zhang</li>
<li class=""><strong>institution:</strong> The Hong Kong University of Science and Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02987" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02987</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper develops a stochastic control and queueing network framework to schedule heterogeneous LLM inference workloads, addressing contention between prefill and decode phases. It designs and proves the asymptotic optimality of gate-and-route policies for resource allocation in large GPU clusters. Numerical experiments show these policies outperform standard serving heuristics.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] Error Analysis of Matrix Multiplication Emulation Using Ozaki-II Scheme</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [Ozaki-II scheme, Chinese Remainder Theorem, error analysis, matrix multiplication emulation, low-precision arithmetic, INT8, INT32]</li>
<li class=""><strong>authors:</strong> Yuki Uchino, Katsuhisa Ozaki, Toshiyuki Imamura</li>
<li class=""><strong>institution:</strong> RIKEN Center for Computational Science, Shibaura Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02549" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02549</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a rigorous error analysis for the Ozaki-II scheme, a method that emulates high-precision matrix multiplication using multiple low-precision operations via the Chinese Remainder Theorem. The analysis clarifies the scheme&#x27;s accuracy behavior and enables estimation of the number of low-precision multiplications needed to achieve a desired numerical precision.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] Studying the Effect of Schedule Preemption on Dynamic Task Graph Scheduling</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [task scheduling], [dynamic scheduling, preemptive scheduling, Last-K Preemption, DAG scheduling, makespan]</li>
<li class=""><strong>authors:</strong> Mohammadali Khodabandehlou, Jared Coleman, Niranjan Suri, Bhaskar Krishnamachari</li>
<li class=""><strong>institution:</strong> University of Southern California, Loyola Marymount University, US Army Research Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.03081" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.03081</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces the Last-K Preemption model for dynamic task graph scheduling, which selectively reschedules only the most recent K task graphs to balance adaptability and stability. The results show that moderate preemption can achieve near-optimal makespan and utilization gains similar to full preemption while maintaining fairness and low overhead.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] Controlled disagreement improves generalization in decentralized training</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [decentralized SGD, adaptive consensus, Hessian subspace, structured perturbations, flat minima]</li>
<li class=""><strong>authors:</strong> Zesen Wang, Mikael Johansson</li>
<li class=""><strong>institution:</strong> KTH Royal Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02899" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02899</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Decentralized SGD with Adaptive Consensus (DSGD-AC), a method that intentionally preserves controlled consensus errors between workers through a time-dependent scaling mechanism. It proves these errors act as structured perturbations aligned with the Hessian&#x27;s dominant subspace, guiding optimization toward flatter minima. The main conclusion is that these consensus errors serve as a useful implicit regularizer, allowing DSGD-AC to consistently outperform both standard DSGD and centralized SGD in test accuracy and generalization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] Dynamic Topology Optimization for Non-IID Data in Decentralized Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [decentralized learning, topology optimization, gossip-based peer discovery, diversity-driven neighbor selection, non-IID data]</li>
<li class=""><strong>authors:</strong> Bart Cox, Antreas Ioannou, Jérémie Decouchant</li>
<li class=""><strong>institution:</strong> Delft University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.03383" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.03383</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Morph, a dynamic topology optimization algorithm for decentralized learning that adaptively reshapes the communication graph by having nodes select peers based on maximum model dissimilarity. This approach improves robustness to non-IID data distributions. Experiments show Morph achieves higher accuracy, faster convergence, and lower variance compared to static and epidemic baselines, closely matching the performance of a fully connected network.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] Exploiting Multi-Core Parallelism in Blockchain Validation and Construction</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain validation], [multi-core parallelism, conflict-aware scheduling, Mixed-Integer Linear Programming (MILP), heuristics, deterministic execution]</li>
<li class=""><strong>authors:</strong> Arivarasan Karmegam, Lucianna Kiffer, Antonio Fernández Anta</li>
<li class=""><strong>institution:</strong> IMDEA Networks Institute, Universidad Carlos III de Madrid, IMDEA Software Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.03444" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.03444</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes methods to exploit multi-core parallelism for blockchain block validation and construction, using MILP formulations and fast heuristics for scheduling under conflict and order constraints. The heuristics achieve near-optimal performance with millisecond runtimes, enabling significant speedups (up to 7.9x with 8 cores) while preserving deterministic blockchain semantics.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] Kino-PAX<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7713em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span>: Near-Optimal Massively Parallel Kinodynamic Sampling-based Motion Planner</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [motion planning], [sampling-based motion planning, kinodynamic constraints, parallelization, GPU, asymptotic near-optimality, δ-robust completeness]</li>
<li class=""><strong>authors:</strong> Nicolas Perrault, Qi Heng Ho, Morteza Lahijanian</li>
<li class=""><strong>institution:</strong> University of Colorado Boulder, Virginia Tech</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02846" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02846</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Kino-PAX+, a massively parallel kinodynamic sampling-based motion planner that decomposes serial operations into three parallel subroutines on GPU-like devices to build a sparse tree of trajectories. It focuses computation on promising nodes for rapid cost improvement and provides asymptotic near-optimality guarantees. The method achieves solutions up to three orders of magnitude faster than serial planners and lower costs than a state-of-the-art GPU-based planner.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] Prefix Consensus For Censorship Resistant BFT</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed consensus], [prefix consensus, strong prefix consensus, leaderless BFT, censorship resistance, state machine replication, graded consensus, binary consensus, validated consensus]</li>
<li class=""><strong>authors:</strong> Zhuolun Xiang, Andrei Tonkikh, Alexander Spiegelman</li>
<li class=""><strong>institution:</strong> Aptos Labs</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.02892" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.02892</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a new consensus primitive called Prefix Consensus and its stronger variant to build a leaderless, censorship-resistant BFT protocol. The core method uses multiple proposers per slot and a deterministic ranking/demotion rule to guarantee inclusion of honest transactions. The main conclusion is that this approach provides strong censorship resistance, committing honest proposals in four rounds while tolerating up to f-1 Byzantine faults and adversarial suspensions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] Recursive Energy Efficient Agreement</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [agreement, energy efficiency, crash faults, recursive algorithm, active rounds]</li>
<li class=""><strong>authors:</strong> Shachar Meir, David Peleg</li>
<li class=""><strong>institution:</strong> Weizmann Institute of Science</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.03474" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.03474</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a recursive algorithm for solving the Agreement problem in distributed systems with crash faults. Its core method focuses on minimizing the number of rounds each participant must be active, thereby reducing energy consumption. The main conclusion is that the algorithm achieves O(log f) active rounds per participant, where f is the maximum number of faults.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] DALI: A Workload-Aware Offloading Framework for Efficient MoE Inference on Local PCs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [mixture of experts, offloading, workload-aware, dynamic assignment, residual-based prefetching, cache replacement, greedy assignment]</li>
<li class=""><strong>authors:</strong> Zeyu Zhu, Gang Li, Peisong Wang, Zitao Mo, Minnan Pei, Zhuoran Song, Xiaoyao Liang, Jian Cheng</li>
<li class=""><strong>institution:</strong> Institute of Automation, Chinese Academy of Sciences; Shanghai Jiao Tong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.03495" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.03495</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes DALI, a workload-aware offloading framework for efficient Mixture of Experts inference on local PCs. It introduces dynamic expert assignment, residual-based prefetching, and a workload-aware cache replacement policy to address load imbalance and improve resource utilization. The evaluation shows DALI achieves significant speedups over state-of-the-art offloading frameworks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] Mitigating Staleness in Asynchronous Pipeline Parallelism via Basis Rotation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [asynchronous pipeline parallelism, gradient staleness, basis rotation, Hessian eigenbasis, Adam optimizer]</li>
<li class=""><strong>authors:</strong> Hyunji Jung, Sungbin Shin, Namhoon Lee</li>
<li class=""><strong>institution:</strong> POSTECH</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.03515" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.03515</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using basis rotation to mitigate the gradient staleness problem in asynchronous pipeline parallelism for large language model training. The method addresses the misalignment between the Hessian eigenbasis and the coordinate basis, which exacerbates the noise from delayed gradients. The authors demonstrate that this approach significantly accelerates convergence, achieving the same training loss in 76.8% fewer iterations for a 1B-parameter LLM compared to the baseline.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] Do We Need Asynchronous SGD? On the Near-Optimality of Synchronous Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [Synchronous SGD, Asynchronous SGD, m-Synchronous SGD, distributed optimization, heterogeneous computation]</li>
<li class=""><strong>authors:</strong> Grigory Begunov, Alexander Tyurin</li>
<li class=""><strong>institution:</strong> AXXX, Lomonosov Moscow State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.03802" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.03802</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper revisits Synchronous SGD and its robust variant m-Synchronous SGD, analyzing them under random computation times and adversarial partial worker participation. It theoretically shows that these synchronous methods are nearly optimal in many heterogeneous computation scenarios, up to logarithmic factors, and are sufficient for many modern distributed training tasks despite the common perception of their inefficiency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260204] Improved Analysis of the Accelerated Noisy Power Method with Applications to Decentralized PCA</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [optimization algorithms], [accelerated noisy power method, decentralized PCA, inexact matrix-vector products, principal component analysis, convergence analysis]</li>
<li class=""><strong>authors:</strong> Pierre Aguié, Mathieu Even, Laurent Massoulié</li>
<li class=""><strong>institution:</strong> Inria, DI-ENS, PSL Research University, Université de Montpellier, INSERM</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.03682" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.03682</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper provides an improved analysis of the Accelerated Noisy Power Method for PCA, showing it maintains accelerated convergence under much milder noise conditions than previous work. The authors prove their analysis is worst-case optimal and apply it to derive the first provably accelerated decentralized PCA algorithm with similar communication costs to non-accelerated methods.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 60</strong></p>
<ul>
<li class="">[arXiv260204] medR: Reward Engineering for Clinical Offline Reinforcement Learning via Tri-Drive Potential Functions <a href="https://arxiv.org/pdf/2602.03305" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] IMAGINE: Intelligent Multi-Agent Godot-based Indoor Networked Exploration <a href="https://arxiv.org/pdf/2602.02858" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Learning Fast Monomial Orders for Gröbner Basis Computations <a href="https://arxiv.org/pdf/2602.02972" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Reinforcement Learning with Promising Tokens for Large Language Models <a href="https://arxiv.org/pdf/2602.03195" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Self-Hinting Language Models Enhance Reinforcement Learning <a href="https://arxiv.org/pdf/2602.03143" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Entropy-Gated Selective Policy Optimization<!-- -->:Token-Level<!-- --> Gradient Allocation for Hybrid Training of Large Language Models <a href="https://arxiv.org/pdf/2602.03309" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Co2PO: Coordinated Constrained Policy Optimization for Multi-Agent RL <a href="https://arxiv.org/pdf/2602.02970" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] From Scalar Rewards to Potential Trends: Shaping Potential Landscapes for Model-Based Reinforcement Learning <a href="https://arxiv.org/pdf/2602.03201" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Intelligent Front-End Personalization: AI-Driven UI Adaptation <a href="https://arxiv.org/pdf/2602.03154" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] CoBA-RL: Capability-Oriented Budget Allocation for Reinforcement Learning in LLMs <a href="https://arxiv.org/pdf/2602.03048" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] CADENT: Gated Hybrid Distillation for Sample-Efficient Transfer in Reinforcement Learning <a href="https://arxiv.org/pdf/2602.02532" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning <a href="https://arxiv.org/pdf/2602.03320" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Hypersonic Flow Control: Generalized Deep Reinforcement Learning for Hypersonic Intake Unstart Control under Uncertainty <a href="https://arxiv.org/pdf/2602.02531" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] ForesightKV: Optimizing KV Cache Eviction for Reasoning Models by Learning Long-Term Contribution <a href="https://arxiv.org/pdf/2602.03203" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] StepScorer: Accelerating Reinforcement Learning with Step-wise Scoring and Psychological Regret Modeling <a href="https://arxiv.org/pdf/2602.03171" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] TMS: Trajectory-Mixed Supervision for Reward-Free, On-Policy SFT <a href="https://arxiv.org/pdf/2602.03073" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Hierarchical Entity-centric Reinforcement Learning with Factored Subgoal Diffusion <a href="https://arxiv.org/pdf/2602.02722" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] MentalSeek-Dx: Towards Progressive Hypothetico-Deductive Reasoning for Real-world Psychiatric Diagnosis <a href="https://arxiv.org/pdf/2602.03340" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] BatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation <a href="https://arxiv.org/pdf/2602.02554" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Beyond Alignment: Expanding Reasoning Capacity via Manifold-Reshaping Policy Optimization <a href="https://arxiv.org/pdf/2602.02545" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Neural Predictor-Corrector: Solving Homotopy Problems with Reinforcement Learning <a href="https://arxiv.org/pdf/2602.03086" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] BinaryPPO: Efficient Policy Optimization for Binary Classification <a href="https://arxiv.org/pdf/2602.02708" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Learning to Explore with Parameter-Space Noise: A Deep Dive into Parameter-Space Noise for Reinforcement Learning with Verifiable Rewards <a href="https://arxiv.org/pdf/2602.02555" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Maximum Likelihood Reinforcement Learning <a href="https://arxiv.org/pdf/2602.02710" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Training and Simulation of Quadrupedal Robot in Adaptive Stair Climbing for Indoor Firefighting: An End-to-End Reinforcement Learning Approach <a href="https://arxiv.org/pdf/2602.03087" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Formulating Reinforcement Learning for Human-Robot Collaboration through Off-Policy Evaluation <a href="https://arxiv.org/pdf/2602.02530" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] GraphDancer: Training LLMs to Explore and Reason over Graphs via Curriculum Reinforcement Learning <a href="https://arxiv.org/pdf/2602.02518" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Accordion-Thinking: Self-Regulated Step Summaries for Efficient and Readable LLM Reasoning <a href="https://arxiv.org/pdf/2602.03249" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] QuantLRM: Quantization of Large Reasoning Models via Fine-Tuning Signals <a href="https://arxiv.org/pdf/2602.02581" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] ContextEvolve: Multi-Agent Context Compression for Systems Code Optimization <a href="https://arxiv.org/pdf/2602.02597" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Prompt Augmentation Scales up GRPO Training on Mathematical Reasoning <a href="https://arxiv.org/pdf/2602.03190" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] How Does the Lagrangian Guide Safe Reinforcement Learning through Diffusion Models? <a href="https://arxiv.org/pdf/2602.02924" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Notes on the Reward Representation of Posterior Updates <a href="https://arxiv.org/pdf/2602.02912" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] An Approximate Ascent Approach To Prove Convergence of PPO <a href="https://arxiv.org/pdf/2602.03386" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Embodiment-Aware Generalist Specialist Distillation for Unified Humanoid Whole-Body Control <a href="https://arxiv.org/pdf/2602.02960" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Quantized Evolution Strategies: High-precision Fine-tuning of Quantized LLMs at Low-precision Cost <a href="https://arxiv.org/pdf/2602.03120" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Manifold-Constrained Energy-Based Transition Models for Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2602.02900" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] From Tokens to Numbers: Continuous Number Modeling for SVG Generation <a href="https://arxiv.org/pdf/2602.02820" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Periodic Regularized Q-Learning <a href="https://arxiv.org/pdf/2602.03301" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Causal Flow Q-Learning for Robust Offline Reinforcement Learning <a href="https://arxiv.org/pdf/2602.02847" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Chain-of-Goals Hierarchical Policy for Long-Horizon Offline Goal-Conditioned RL <a href="https://arxiv.org/pdf/2602.03389" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Structuring Value Representations via Geometric Coherence in Markov Decision Processes <a href="https://arxiv.org/pdf/2602.02978" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Human-Centric Traffic Signal Control for Equity: A Multi-Agent Action Branching Deep Reinforcement Learning Approach <a href="https://arxiv.org/pdf/2602.02959" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Spatiotemporal Decision Transformer for Traffic Coordination <a href="https://arxiv.org/pdf/2602.02903" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] CRL-VLA: Continual Vision-Language-Action Learning <a href="https://arxiv.org/pdf/2602.03445" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Beyond Variance: Prompt-Efficient RLVR via Rare-Event Amplification and Bidirectional Pairing <a href="https://arxiv.org/pdf/2602.03452" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] IntentRL: Training Proactive User-intent Agents for Open-ended Deep Research via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.03468" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Reparameterization Flow Policy Optimization <a href="https://arxiv.org/pdf/2602.03501" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] CMR: Contractive Mapping Embeddings for Robust Humanoid Locomotion on Unstructured Terrains <a href="https://arxiv.org/pdf/2602.03511" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Not All Negative Samples Are Equal: LLMs Learn Better from Plausible Reasoning <a href="https://arxiv.org/pdf/2602.03516" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] TRE: Encouraging Exploration in the Trust Region <a href="https://arxiv.org/pdf/2602.03635" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Reinforcement Fine-Tuning for History-Aware Dense Retriever in RAG <a href="https://arxiv.org/pdf/2602.03645" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration <a href="https://arxiv.org/pdf/2602.03647" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Rethinking the Reranker: Boundary-Aware Evidence Selection for Robust Retrieval-Augmented Generation <a href="https://arxiv.org/pdf/2602.03689" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL <a href="https://arxiv.org/pdf/2602.03773" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Efficient Estimation of Kernel Surrogate Models for Task Attribution <a href="https://arxiv.org/pdf/2602.03783" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation <a href="https://arxiv.org/pdf/2602.03806" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] SymPlex: A Structure-Aware Transformer for Symbolic PDE Solving <a href="https://arxiv.org/pdf/2602.03816" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL <a href="https://arxiv.org/pdf/2602.03839" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Relaxed Triangle Inequality for Kullback-Leibler Divergence Between Multivariate Gaussian Distributions <a href="https://arxiv.org/pdf/2602.02577" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 25</strong></p>
<ul>
<li class="">[arXiv260204] FIRE-Bench: Evaluating Agents on the Rediscovery of Scientific Insights <a href="https://arxiv.org/pdf/2602.02905" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Learning-Infused Formal Reasoning: From Contract Synthesis to Artifact Reuse and Formal Semantics <a href="https://arxiv.org/pdf/2602.02881" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Nüwa: Mending the Spatial Integrity Torn by VLM Token Pruning <a href="https://arxiv.org/pdf/2602.02951" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Consistency Deep Equilibrium Models <a href="https://arxiv.org/pdf/2602.03024" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Aligning Language Model Benchmarks with Pairwise Preferences <a href="https://arxiv.org/pdf/2602.02898" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] StepScorer: Accelerating Reinforcement Learning with Step-wise Scoring and Psychological Regret Modeling <a href="https://arxiv.org/pdf/2602.03171" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] A Semi-Supervised Pipeline for Generalized Behavior Discovery from Animal-Borne Motion Time Series <a href="https://arxiv.org/pdf/2602.02618" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] From Inexact Gradients to Byzantine Robustness: Acceleration and Optimization under Similarity <a href="https://arxiv.org/pdf/2602.03329" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Token Sparse Attention: Efficient Long-Context Inference with Interleaved Token Selection <a href="https://arxiv.org/pdf/2602.03216" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Probe-then-Commit Multi-Objective Bandits: Theoretical Benefits of Limited Multi-Arm Feedback <a href="https://arxiv.org/pdf/2602.03175" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Every Bit Counts: A Theoretical Study of Precision-Expressivity Tradeoffs in Quantized Transformers <a href="https://arxiv.org/pdf/2602.02707" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Privasis: Synthesizing the Largest &quot;Public&quot; Private Dataset from Scratch <a href="https://arxiv.org/pdf/2602.03183" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Rethinking Benign Relearning: Syntax as the Hidden Driver of Unlearning Failures <a href="https://arxiv.org/pdf/2602.03379" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Digital Lifelong Learning in the Age of AI: Trends and Insights <a href="https://arxiv.org/pdf/2602.03114" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] GraDE: A Graph Diffusion Estimator for Frequent Subgraph Discovery in Neural Architectures <a href="https://arxiv.org/pdf/2602.03257" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Understanding Multi-Agent LLM Frameworks: A Unified Benchmark and Experimental Analysis <a href="https://arxiv.org/pdf/2602.03128" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Koopman Autoencoders with Continuous-Time Latent Dynamics for Fluid Dynamics Forecasting <a href="https://arxiv.org/pdf/2602.02832" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] NLI<!-- -->:Non-uniform<!-- --> Linear Interpolation Approximation of Nonlinear Operations for Efficient LLMs Inference <a href="https://arxiv.org/pdf/2602.02988" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Fast-MWEM: Private Data Release in Sublinear Time <a href="https://arxiv.org/pdf/2602.03732" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Zero-shot large vision-language model prompting for automated bone identification in paleoradiology x-ray archives <a href="https://arxiv.org/pdf/2602.03750" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Fast-Slow Efficient Training for Multimodal Large Language Models via Visual Token Pruning <a href="https://arxiv.org/pdf/2602.03815" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Accelerating Scientific Research with Gemini: Case Studies and Common Techniques <a href="https://arxiv.org/pdf/2602.03837" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] PrevizWhiz: Combining Rough 3D Scenes and 2D Video to Guide Generative Video Previsualization <a href="https://arxiv.org/pdf/2602.03838" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] CryoLVM: Self-supervised Learning from Cryo-EM Density Maps with Large Vision Models <a href="https://arxiv.org/pdf/2602.02620" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260204] Multiparameter Uncertainty Mapping in Quantitative Molecular MRI using a Physics-Structured Variational Autoencoder (PS-VAE) <a href="https://arxiv.org/pdf/2602.03317" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-05">2026-02-05<a href="#2026-02-05" class="hash-link" aria-label="Direct link to 2026-02-05" title="Direct link to 2026-02-05" translate="no">​</a></h2>
<p><strong>cs.DC total: 9</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260205] SPEAR: An Engineering Case Study of Multi-Agent Coordination for Smart Contract Auditing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [multi-agent systems], [contract net protocol, AGM belief revision, programmatic-first repair, risk-aware heuristics]</li>
<li class=""><strong>authors:</strong> Arnab Mallick, Indraveni Chebolu, Harmesh Rana</li>
<li class=""><strong>institution:</strong> Center for Development of Advanced Computing, Hyderabad</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.04418" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.04418</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents SPEAR, a multi-agent coordination framework for smart contract auditing that uses specialized agents for planning, execution, and repair. An empirical study shows this multi-agent design offers better coordination, recovery, and resource use compared to centralized or pipeline-based alternatives.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260205] Scalable Explainability-as-a-Service (XaaS) for Edge AI Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [distributed explanation cache, semantic similarity retrieval, lightweight verification protocol, adaptive explanation engine]</li>
<li class=""><strong>authors:</strong> Samaresh Kumar Singh, Joyjit Roy</li>
<li class=""><strong>institution:</strong> IEEE</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.04120" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.04120</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Explainability-as-a-Service (XaaS), a distributed system architecture that decouples AI inference from explanation generation to improve efficiency on edge devices. It introduces a caching mechanism, a verification protocol, and an adaptive engine to reduce latency and computational redundancy. The evaluation shows XaaS reduces latency by 38% while maintaining explanation quality across real-world use cases.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260205] Pending Conflicts Make Progress Impossible</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [conflict-obstruction-freedom, linearizability, universal construction, read-write shared memory, obstruction-freedom]</li>
<li class=""><strong>authors:</strong> Petr Kuznetsov, Pierre Sutra, Guillermo Toyos-Marfurt</li>
<li class=""><strong>institution:</strong> Télécom Paris, Institut Polytechnique de Paris, SAMOVAR, Télécom SudParis</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.04013" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.04013</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces conflict-obstruction-freedom, a progress condition for shared objects that allows parallel execution of commuting operations. It proves that implementing conflict-obstruction-free universal constructions is impossible in asynchronous read-write shared memory, showing that the invocation of conflicting operations inherently imposes a synchronization cost.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260205] Entanglement improves coordination in distributed systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [quantum distributed systems], [entanglement, non-local correlations, queueing theory, Pareto optimization, distributed scheduling]</li>
<li class=""><strong>authors:</strong> Francisco Ferreira da Silva, Stephanie Wehner</li>
<li class=""><strong>institution:</strong> Delft University of Technology, QuTech, Delft Networks, Kavli Institute of Nanoscience</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.04588" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.04588</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using quantum entanglement to coordinate two servers in a distributed system without communication latency. It demonstrates, through queueing-theoretic analysis and non-local game formulation, that entanglement-assisted strategies achieve superior performance trade-offs (Pareto-superior) compared to classical strategies for a specific dual-work optimization problem. The main conclusion is that distributed scheduling is a novel application domain for near-term quantum networks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260205] Six Times to Spare: LDPC Acceleration on DGX Spark for AI-Native Open RAN</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [LDPC decoding, GPU acceleration, NVIDIA Sionna, Blackwell GB10, DGX Spark, 5G NR, belief-propagation]</li>
<li class=""><strong>authors:</strong> Ryan Barker, Fatemeh Afghah</li>
<li class=""><strong>institution:</strong> Clemson University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.04652" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.04652</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper evaluates offloading 5G LDPC decoding from a Grace CPU to an integrated Blackwell GB10 GPU on an NVIDIA DGX Spark platform using the NVIDIA Sionna library. The results show the GPU achieves an average 6x throughput speedup over the CPU, meets the strict 0.5 ms latency deadline, and consumes significantly less power, freeing CPU resources for other tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260205] GPU Acceleration and Portability of the TRIMEG Code for Gyrokinetic Plasma Simulations using OpenMP</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [high performance computing], [GPU offloading, OpenMP, particle-in-cell, finite element, MPI-OpenMP, scalability]</li>
<li class=""><strong>authors:</strong> Giorgio Daneri</li>
<li class=""><strong>institution:</strong> Politecnico di Milano</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.14301" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.14301</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents the GPU acceleration of the TRIMEG gyrokinetic plasma simulation code using OpenMP for portability across AMD and NVIDIA architectures. The core method involves offloading particle pushing and grid-to-particle operations to GPUs, with performance evaluated through grid size exploration and scalability studies. The main conclusion is that the GPU-accelerated version achieves significant speedup compared to the CPU version while maintaining correctness, as verified by simulating the Ion Temperature Gradient mode.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260205] A TEE-based Approach for Preserving Data Secrecy in Process Mining with Decentralized Sources</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [confidential computing], [Trusted Execution Environments (TEEs), segmentation-based strategy, formal verification, security analysis]</li>
<li class=""><strong>authors:</strong> Davide Basile, Valerio Goretti, Luca Barbaro, Hajo A. Reijers, Claudio Di Ciccio</li>
<li class=""><strong>institution:</strong> Sapienza University of Rome, Utrecht University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.04697" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.04697</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes CONFINE, a method for secrecy-preserving inter-organizational process mining that uses Trusted Execution Environments (TEEs) and a four-stage protocol to securely process decentralized event logs. The approach employs a segmentation strategy to manage memory constraints within TEEs. The evaluation shows the prototype handles real-world workloads with logarithmic memory growth relative to log size and identifies linear growth with the number of organizations, confirming its feasibility and scalability.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260205] Trust The Typical</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [out-of-distribution detection, semantic space, guardrails, adversarial prompts, typical set]</li>
<li class=""><strong>authors:</strong> Debargha Ganguly, Sreehari Sankar, Biyao Zhang, Vikash Singh, Kanan Gupta, Harshini Kavuru, Alan Luo, Weicong Chen, Warren Morningstar, Raghu Machiraju, Vipin Chaudhary</li>
<li class=""><strong>institution:</strong> Case Western Reserve University, University of Pittsburgh, The Ohio State University, Google Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.04581" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.04581</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Trust The Typical (T3), a framework that treats LLM safety as an out-of-distribution detection problem by learning the distribution of acceptable prompts in a semantic space and flagging deviations. It achieves state-of-the-art performance across multiple safety benchmarks without training on harmful examples and integrates efficiently into inference systems like vLLM with minimal overhead. The main conclusion is that robust safety comes from understanding what is typical and safe, rather than reactively enumerating harmful patterns.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260205] Horizon-LM: A RAM-Centric Architecture for LLM Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [CPU-master GPU-template execution, explicit recomputation, manual gradient propagation, pipelined double-buffered execution, host memory offloading]</li>
<li class=""><strong>authors:</strong> Zhengqing Yuan, Lichao Sun, Yanfang</li>
<li class=""><strong>institution:</strong> University of Notre Dame, Lehigh University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.04816" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.04816</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Horizon-LM is a memory-centric training system that treats host RAM as the primary parameter store and uses GPUs only as transient compute engines, eliminating persistent GPU-resident modules and autograd graphs. It decouples model scale from GPU count, enabling training of up to 120B parameter models on a single GPU with large host memory. The system achieves significantly higher throughput than existing offloading methods while maintaining predictable memory usage, demonstrating that host memory defines the feasibility boundary for node-scale LLM training.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 31</strong></p>
<ul>
<li class="">[arXiv260205] Rationality Measurement and Theory for Reinforcement Learning Agents <a href="https://arxiv.org/pdf/2602.04737" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning <a href="https://arxiv.org/pdf/2602.03978" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning <a href="https://arxiv.org/pdf/2602.04284" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Steering LLMs via Scalable Interactive Oversight <a href="https://arxiv.org/pdf/2602.04210" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] When Silence Is Golden: Can LLMs Learn to Abstain in Temporal QA and Beyond? <a href="https://arxiv.org/pdf/2602.04755" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Thickening-to-Thinning: Reward Shaping via Human-Inspired Learning Dynamics for LLM Reasoning <a href="https://arxiv.org/pdf/2602.04265" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Skin Tokens: A Learned Compact Representation for Unified Autoregressive Rigging <a href="https://arxiv.org/pdf/2602.04805" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] QUATRO: Query-Adaptive Trust Region Policy Optimization for LLM Fine-tuning <a href="https://arxiv.org/pdf/2602.04620" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] The Missing Half: Unveiling Training-time Implicit Safety Risks Beyond Deployment <a href="https://arxiv.org/pdf/2602.04196" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.04634" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Dual Mind World Model Inspired Network Digital Twin for Access Scheduling <a href="https://arxiv.org/pdf/2602.04566" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Autonomous AI Agents for Real-Time Affordable Housing Site Selection: Multi-Objective Reinforcement Learning Under Regulatory Constraints <a href="https://arxiv.org/pdf/2602.03940" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] From Ambiguity to Action: A POMDP Perspective on Partial Multi-Label Ambiguity and Its Horizon-One Resolution <a href="https://arxiv.org/pdf/2602.04255" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Decoupling Time and Risk: Risk-Sensitive Reinforcement Learning with General Discounting <a href="https://arxiv.org/pdf/2602.04131" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation <a href="https://arxiv.org/pdf/2602.04868" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] GOPO: Policy Optimization using Ranked Rewards <a href="https://arxiv.org/pdf/2602.03876" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Evolving Afferent Architectures: Biologically-inspired Models for Damage-Avoidance Learning <a href="https://arxiv.org/pdf/2602.04807" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Lyapunov Constrained Soft Actor-Critic (LC-SAC) using Koopman Operator Theory for Quadrotor Trajectory Tracking <a href="https://arxiv.org/pdf/2602.04132" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL <a href="https://arxiv.org/pdf/2602.04089" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Beyond Rewards in Reinforcement Learning for Cyber Defence <a href="https://arxiv.org/pdf/2602.04809" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Topology-Aware Revival for Efficient Sparse Training <a href="https://arxiv.org/pdf/2602.04166" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Rethinking the Trust Region in LLM Reinforcement Learning <a href="https://arxiv.org/pdf/2602.04879" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Learning to Reason in 13 Parameters <a href="https://arxiv.org/pdf/2602.04118" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Piece of CAKE: Adaptive Execution Engines via Microsecond-Scale Learning <a href="https://arxiv.org/pdf/2602.04181" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Mixture of Masters: Sparse Chess Language Models with Player Routing <a href="https://arxiv.org/pdf/2602.04447" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Reinforced Attention Learning <a href="https://arxiv.org/pdf/2602.04884" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Learning the Value Systems of Agents with Preference-based and Inverse Reinforcement Learning <a href="https://arxiv.org/pdf/2602.04518" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Stochastic Decision Horizons for Constrained Reinforcement Learning <a href="https://arxiv.org/pdf/2602.04599" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] EMA Policy Gradient: Taming Reinforcement Learning for LLMs with EMA Anchor and Top-k KL <a href="https://arxiv.org/pdf/2602.04417" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Rethinking the Design Space of Reinforcement Learning for Diffusion Models: On the Importance of Likelihood Estimation Beyond Loss Design <a href="https://arxiv.org/pdf/2602.04663" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] HoRD: Robust Humanoid Control via History-Conditioned Reinforcement Learning and Online Distillation <a href="https://arxiv.org/pdf/2602.04412" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 5</strong></p>
<ul>
<li class="">[arXiv260205] Machine Learning-Driven Crystal System Prediction for Perovskites Using Augmented X-ray Diffraction Data <a href="https://arxiv.org/pdf/2602.04435" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Multi-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism <a href="https://arxiv.org/pdf/2602.04870" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] SparVAR: Exploring Sparsity in Visual AutoRegressive Modeling for Training-Free Acceleration <a href="https://arxiv.org/pdf/2602.04361" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] HybridQuestion: Human-AI Collaboration for Identifying High-Impact Research Questions <a href="https://arxiv.org/pdf/2602.03849" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260205] Digital Twins &amp; ZeroConf AI: Structuring Automated Intelligent Pipelines for Industrial Applications <a href="https://arxiv.org/pdf/2602.04385" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-02-06">2026-02-06<a href="#2026-02-06" class="hash-link" aria-label="Direct link to 2026-02-06" title="Direct link to 2026-02-06" translate="no">​</a></h2>
<p><strong>cs.DC total: 15</strong></p>
<ul>
<li class="">
<p><strong>[arXiv260206] Proteus: Append-Only Ledgers for (Mostly) Trusted Execution Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed consensus], [trusted execution environments, crash-fault-tolerant consensus, byzantine fault-tolerant consensus, append-only ledger]</li>
<li class=""><strong>authors:</strong> Shubham Mishra, João Gonçalves, Chawinphat Tankuranand, Neil Giridharan, Natacha Crooks, Heidi Howard, Chris Jensen</li>
<li class=""><strong>institution:</strong> UC Berkeley, Microsoft, IST U. Lisboa &amp; INESC-ID</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05346" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05346</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents Proteus, a distributed consensus protocol that embeds a Byzantine fault-tolerant (BFT) protocol inside a crash-fault-tolerant (CFT) protocol without extra messages, by aligning their structures. It cautiously trusts hardware TEEs to maintain performance while guaranteeing integrity even if TEEs are compromised.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] FedRandom: Sampling Consistent and Accurate Contribution Values in Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [FedRandom, contribution valuation, statistical estimation, client sampling, federated aggregation]</li>
<li class=""><strong>authors:</strong> Arno Geimer, Beltran Fiz Pontiveros, Radu State</li>
<li class=""><strong>institution:</strong> University of Luxembourg</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05693" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05693</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces FedRandom, a method that treats contribution instability in Federated Learning as a statistical estimation problem, allowing for the generation of more samples than regular FL strategies. It demonstrates that these additional samples lead to more consistent and reliable evaluations of participant contributions. The approach is shown to reduce the distance to ground truth in many scenarios and improves stability in over 90% of cases.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] Sovereign-by-Design A Reference Architecture for AI and Blockchain Enabled Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [blockchain, self-sovereign identity, reference architecture, generative AI, data governance, auditability]</li>
<li class=""><strong>authors:</strong> Matteo Esposito, Lodovica Marchesi, Roberto Tonelli, Valentina Lenarduzzi</li>
<li class=""><strong>institution:</strong> University of Oulu, University of Cagliari, University of Southern Denmark</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05486" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05486</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a Sovereign Reference Architecture that integrates self-sovereign identity, blockchain, and controlled Generative AI to operationalize digital sovereignty as a core architectural property. It concludes that this approach provides a foundation for building auditable, evolvable, and jurisdiction-aware AI systems by bridging regulatory intent with concrete system design.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] Emergence-as-Code for Self-Governing Reliable Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [reliability engineering], [SLO-as-code, microservices, GitOps, service level objectives, control-flow operators, burn-rate alerts]</li>
<li class=""><strong>authors:</strong> Anatoly A. Krasnovsky</li>
<li class=""><strong>institution:</strong> Innopolis University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05458" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05458</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Emergence-as-Code (EmaC), a method to make the reliability of user journeys in microservices computable by combining declarative intent with runtime evidence from telemetry and configuration. It concludes that this approach allows journey SLOs to be derived as compiled artifacts, making system reliability auditable and actionable within a Git-based workflow.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] Smoothed aggregation algebraic multigrid for problems with heterogeneous and anisotropic materials</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [numerical methods], [smoothed aggregation algebraic multigrid, strength-of-connection measure, material tensor, coarsening process]</li>
<li class=""><strong>authors:</strong> Max Firmbach, Malachi Phillips, Christian Glusa, Alexander Popp, Christopher M. Siefert, Matthias Mayr</li>
<li class=""><strong>institution:</strong> Universität der Bundeswehr München, Sandia National Laboratories</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05686" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05686</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a new material-aware strength-of-connection measure for smoothed aggregation algebraic multigrid methods to improve robustness for PDEs with heterogeneous and anisotropic materials. The method incorporates material tensor information directly into the coarsening process to better detect weak connections and preserve the problem&#x27;s structure. The approach demonstrates robust performance across high material contrasts and anisotropies in both academic tests and real-world applications like battery and solar cell simulations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] ORACL: Optimized Reasoning for Autoscaling via Chain of Thought with LLMs for Microservices</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [chain-of-thought reasoning, instruction tuning, supervised fine-tuning, reinforcement learning, root cause analysis, resource allocation]</li>
<li class=""><strong>authors:</strong> Haoyu Bai, Muhammed Tawfiqul Islam, Minxian Xu, Rajkumar Buyya</li>
<li class=""><strong>institution:</strong> The University of Melbourne, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05292" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05292</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ORACL, a framework that uses large language models (LLMs) with chain-of-thought reasoning to diagnose performance issues and allocate resources for microservice autoscaling. It transforms runtime telemetry into natural language descriptions for the LLM to produce interpretable reasoning traces and safe allocation decisions. Experiments show the approach improves root-cause identification accuracy, accelerates training, and enhances quality of service without requiring deployment-specific retraining.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] Evaluating Kubernetes Performance for GenAI Inference: From Automatic Speech Recognition to LLM Summarization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [Kubernetes, Kueue, Dynamic Accelerator Slicer (DAS), Gateway API Inference Extension (GAIE), batch inference, online inference]</li>
<li class=""><strong>authors:</strong> Sai Sindhur Malleni, Raúl Sevilla, Aleksei Vasilevskii, José Castillo Lema, André Bauer</li>
<li class=""><strong>institution:</strong> Red Hat, Illinois Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.04900" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.04900</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper evaluates a Kubernetes-native platform for managing multi-stage Generative AI inference workflows, combining Kueue for batch job orchestration, Dynamic Accelerator Slicer for parallel execution, and the Gateway API Inference Extension for optimized online request routing. The study demonstrates that this integrated approach significantly improves performance metrics for tasks like speech recognition and summarization. The main conclusion is that Kubernetes, enhanced with these components, forms a cohesive and high-performance foundation for demanding GenAI workloads.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] Reaching Univalency with Subquadratic Communication</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing], [Byzantine Agreement, Dolev-Reischuk bound, univalency, deterministic protocol, communication complexity, dissemination, epsilon-BA, Extractable BA]</li>
<li class=""><strong>authors:</strong> Andrew Lewis-Pye</li>
<li class=""><strong>institution:</strong> Not explicitly provided; author affiliation inferred from email domain is not present in the given text.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05356" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05356</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a relaxed Byzantine Agreement problem called epsilon-BA, which allows a small fraction of correct processors to output incorrectly, and shows it can be solved deterministically with O(n log n) communication. This demonstrates that the quadratic cost of the classic Dolev-Reischuk lower bound stems from disseminating the outcome to all processors, not from reaching the point of univalency where the outcome is determined.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] Towards Advancing Research with Workflows: A perspective from the Workflows Community Summit -- Amsterdam, 2025</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [scientific workflows], [scientific workflows, reproducibility, workflow patterns, community benchmarks, sustainability, standardization]</li>
<li class=""><strong>authors:</strong> Irene Bonati, Silvina Caino-Lores, Tainã Coleman, Sagar Dolas, Sandro Fiore, Venkatesh Kannan, Marco Verdicchio, Sean R. Wilkinson, Rafael Ferreira da Silva</li>
<li class=""><strong>institution:</strong> SURF Cooperation, University of Rennes, San Diego Computing Center, University of Trento, Irish Centre for High-End Computing, Oak Ridge National Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05131" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05131</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents the findings of the 2025 Workflows Community Summit, which examined challenges and opportunities in scientific workflows. The method involves community discussion to identify barriers like sustainability and lack of recognition, and proposes action lines including shifting metrics to scientific impact and formalizing workflow patterns. The main conclusion is that advancing research requires a paradigm shift towards measuring scientific utility, building a cohesive international community, and investing in human capital to enhance workflow adoption and impact.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] A novel scalable high performance diffusion solver for multiscale cell simulations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [computational biology], [Finite Volume Method, High Performance Computing, Parallel algorithms, Tridiagonal solver, Distributed computing, BioFVM]</li>
<li class=""><strong>authors:</strong> Jose-Luis Estragues-Muñoz, Carlos Alvarez, Arnau Montagud, Daniel Jimenez-Gonzalez, Alfonso Valencia</li>
<li class=""><strong>institution:</strong> Barcelona Supercomputing Center (BSC), Universitat Politecnica de Catalunya (UPC), Institute for Integrative Systems Biology (I2SysBio), CSIC-UV, ICREA</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05017" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05017</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a scalable high-performance computing solution for molecular diffusion in cell simulations, based on an efficient implementation of the Finite Volume Method (BioFVM). The proposed method achieves nearly a 200x speedup and up to 36% reduction in memory usage compared to state-of-the-art solutions, enabling efficient large-scale biological simulations like digital twin models.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] TimelyFreeze: Adaptive Parameter Freezing Mechanism for Pipeline Parallelism</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [pipeline parallelism, parameter freezing, linear programming, directed acyclic graph, 1F1B, GPipe]</li>
<li class=""><strong>authors:</strong> Seonghye Cho, Jaemin Han, Hyunjin Kim, Euisoo Jung, Jae-Gil Lee</li>
<li class=""><strong>institution:</strong> KAIST</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05754" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05754</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes TimelyFreeze, an adaptive parameter freezing mechanism that models the pipeline schedule as a DAG and uses linear programming to compute optimal freeze ratios, minimizing batch execution time under accuracy constraints. It achieves up to 40% training throughput improvement on models like LLaMA-8B while maintaining comparable accuracy, enabling faster large-scale model training without compromising convergence.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] Location-Aware Dispersion on Anonymous Graphs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed robotics], [deterministic algorithms, lower bound, impossibility result, anonymous graphs, mobile robots]</li>
<li class=""><strong>authors:</strong> Himani, Supantha Pandit, Gokarna Sharma</li>
<li class=""><strong>institution:</strong> Dhirubhai Ambani University, Kent State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05948" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05948</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Location-Aware Dispersion, a generalization of the classic Dispersion problem where robots must relocate to distinct nodes matching their assigned colors in an anonymous graph. It presents several deterministic algorithms with bounds on time and memory, along with impossibility results and lower bounds. The results establish the algorithmic feasibility of the problem while highlighting its increased complexity compared to standard Dispersion.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] Distributed Quantum Error Mitigation: Global and Local ZNE encodings</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [quantum computing], [Zero Noise Extrapolation, distributed quantum computing, circuit partitioning, teleportation-based communication]</li>
<li class=""><strong>authors:</strong> Maria Gragera Garces</li>
<li class=""><strong>institution:</strong> University of Edinburgh</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.04981" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.04981</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates Zero Noise Extrapolation (ZNE) for error mitigation in distributed quantum computing, comparing a Global approach (applied before circuit partitioning) against a Local approach (applied to each sub-circuit). The results show that Global ZNE scales better, achieving up to 48% error reduction across six quantum processors, and reveals that increasing the number of processors can paradoxically improve mitigation despite higher communication noise.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] The Quantum Message Complexity of Distributed Wake-Up with Advice</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed computing, quantum algorithms], [quantum routing model, distributed advising scheme, message complexity, lower bound, wake-up problem]</li>
<li class=""><strong>authors:</strong> Peter Robinson, Ming Ming Tan</li>
<li class=""><strong>institution:</strong> Augusta University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05801" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05801</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents the first quantum upper and lower bounds for the distributed wake-up problem with advice. It introduces a quantum advising scheme that achieves a message complexity of O(√(n³/2^max{⌊(α-1)/2⌋,0})·log n) with α bits of advice per node, breaking a known classical barrier, and proves an Ω(n^{3/2}) lower bound on quantum message complexity without advice.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260206] From Sequential to Parallel: Reformulating Dynamic Programming as GPU Kernels for Large-Scale Stochastic Combinatorial Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [dynamic programming, GPU kernels, scenario-batched parallelism, Bellman updates, stochastic programming, Sample Average Approximation]</li>
<li class=""><strong>authors:</strong> Jingyi Zhao, Linxin Yang, Haohua Zhang, Tian Ding</li>
<li class=""><strong>institution:</strong> Shenzhen Research Institute of Big Data, The Chinese University of Hongkong (Shenzhen), Shenzhen International Center for Industrial and Applied Mathematics, AutoKernel</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2602.05179" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2602.05179</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper develops a GPU-based framework that reformulates dynamic programming as parallel, scenario-batched kernels to solve large-scale stochastic combinatorial optimization problems. This enables massive parallelization across scenarios and DP layers, achieving orders-of-magnitude speedups. The results demonstrate that full-fidelity integer second-stage models become tractable at previously impossible scales, improving decision quality in stochastic programming.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 37</strong></p>
<ul>
<li class="">[arXiv260206] ReFORM: Reflected Flows for On-support Offline RL via Noise Manipulation <a href="https://arxiv.org/pdf/2602.05051" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] GAS: Enhancing Reward-Cost Balance of Generative Model-assisted Offline Safe RL <a href="https://arxiv.org/pdf/2602.05323" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] EBPO: Empirical Bayes Shrinkage for Stabilizing Group-Relative Policy Optimization <a href="https://arxiv.org/pdf/2602.05165" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Unveiling Implicit Advantage Symmetry: Why GRPO Struggles with Exploration and Difficulty Adaptation <a href="https://arxiv.org/pdf/2602.05548" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Formal Synthesis of Certifiably Robust Neural Lyapunov-Barrier Certificates <a href="https://arxiv.org/pdf/2602.05311" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Data-Centric Interpretability for LLM-based Multi-Agent Reinforcement Learning <a href="https://arxiv.org/pdf/2602.05183" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] ALIVE: Awakening LLM Reasoning via Adversarial Learning and Instructive Verbal Evaluation <a href="https://arxiv.org/pdf/2602.05472" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Mode-Dependent Rectification for Stable PPO Training <a href="https://arxiv.org/pdf/2602.05619" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Back to Basics: Revisiting Exploration in Reinforcement Learning for LLM Reasoning via Generative Probabilities <a href="https://arxiv.org/pdf/2602.05281" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Rewards as Labels: Revisiting RLVR from a Classification Perspective <a href="https://arxiv.org/pdf/2602.05630" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Optimizing Mission Planning for Multi-Debris Rendezvous Using Reinforcement Learning with Refueling and Adaptive Collision Avoidance <a href="https://arxiv.org/pdf/2602.05075" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] UAV Trajectory Optimization via Improved Noisy Deep Q-Network <a href="https://arxiv.org/pdf/2602.05644" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Reinforcement Learning Enhancement Using Vector Semantic Representation and Symbolic Reasoning for Human-Centered Autonomous Emergency Braking <a href="https://arxiv.org/pdf/2602.05079" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Privileged Information Distillation for Language Models <a href="https://arxiv.org/pdf/2602.04942" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Euphonium: Steering Video Flow Matching via Process Reward Gradient Guided Stochastic Dynamics <a href="https://arxiv.org/pdf/2602.04928" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] When Are RL Hyperparameters Benign? A Study in Offline Goal-Conditioned RL <a href="https://arxiv.org/pdf/2602.05459" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] A Unified Framework for Rethinking Policy Divergence Measures in GRPO <a href="https://arxiv.org/pdf/2602.05494" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Beware Untrusted Simulators -- Reward-Free Backdoor Attacks in Reinforcement Learning <a href="https://arxiv.org/pdf/2602.05089" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Laplacian Representations for Decision-Time Planning <a href="https://arxiv.org/pdf/2602.05031" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Gradually Compacting Large Language Models for Reasoning Like a Boiling Frog <a href="https://arxiv.org/pdf/2602.04919" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Anchored Policy Optimization: Mitigating Exploration Collapse Via Support-Constrained Rectification <a href="https://arxiv.org/pdf/2602.05717" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Mitigating Hallucination in Financial Retrieval-Augmented Generation via Fine-Grained Knowledge Verification <a href="https://arxiv.org/pdf/2602.05723" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Learning to Inject: Automated Prompt Injection via Reinforcement Learning <a href="https://arxiv.org/pdf/2602.05746" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] RL-VLA<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>: Reinforcement Learning VLA Accelerating via Full Asynchronism <a href="https://arxiv.org/pdf/2602.05765" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Cross-Domain Offline Policy Adaptation via Selective Transition Correction <a href="https://arxiv.org/pdf/2602.05776" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Distributional Reinforcement Learning with Diffusion Bridge Critics <a href="https://arxiv.org/pdf/2602.05783" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning <a href="https://arxiv.org/pdf/2602.05818" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations <a href="https://arxiv.org/pdf/2602.05885" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] DFPO: Scaling Value Modeling via Distributional Flow towards Robust and Generalizable LLM Post-Training <a href="https://arxiv.org/pdf/2602.05890" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem <a href="https://arxiv.org/pdf/2602.05920" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training <a href="https://arxiv.org/pdf/2602.05933" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span></span></span></span>-GRPO and Beyond: Divergence-Based Reinforcement Learning Algorithms for General LLM Alignment <a href="https://arxiv.org/pdf/2602.05946" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Learning to Share: Selective Memory for Efficient Parallel Agentic Systems <a href="https://arxiv.org/pdf/2602.05965" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] On Computation and Reinforcement Learning <a href="https://arxiv.org/pdf/2602.05999" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory <a href="https://arxiv.org/pdf/2602.06025" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Can vision language models learn intuitive physics from interaction? <a href="https://arxiv.org/pdf/2602.06033" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Variance Reduction Based Experience Replay for Policy Optimization <a href="https://arxiv.org/pdf/2602.05379" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 16</strong></p>
<ul>
<li class="">[arXiv260206] Accelerated Sequential Flow Matching: A Bayesian Filtering Perspective <a href="https://arxiv.org/pdf/2602.05319" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] TurboBoA: Faster and Exact Attention-aware Quantization without Backpropagation <a href="https://arxiv.org/pdf/2602.04929" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Autodiscover: A reinforcement learning recommendation system for the cold-start imbalance challenge in active learning, powered by graph-aware thompson sampling <a href="https://arxiv.org/pdf/2602.05087" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] E-Globe: Scalable <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ε</mi></mrow><annotation encoding="application/x-tex">ε</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ε</span></span></span></span>-Global Verification of Neural Networks via Tight Upper Bounds and Pattern-Aware Branching <a href="https://arxiv.org/pdf/2602.05068" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better <a href="https://arxiv.org/pdf/2602.05393" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] M<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>-Miner: Multi-Agent Enhanced MCTS for Mobile GUI Agent Data Mining <a href="https://arxiv.org/pdf/2602.05429" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Euphonium: Steering Video Flow Matching via Process Reward Gradient Guided Stochastic Dynamics <a href="https://arxiv.org/pdf/2602.04928" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] DisCa: Accelerating Video Diffusion Transformers with Distillation-Compatible Learnable Feature Caching <a href="https://arxiv.org/pdf/2602.05449" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] TIDE: Temporal Incremental Draft Engine for Self-Improving LLM Inference <a href="https://arxiv.org/pdf/2602.05145" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Gradually Compacting Large Language Models for Reasoning Like a Boiling Frog <a href="https://arxiv.org/pdf/2602.04919" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Variational Speculative Decoding: Rethinking Draft Training from Token Likelihood to Sequence Acceptance <a href="https://arxiv.org/pdf/2602.05774" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] STProtein: predicting spatial protein expression from multi-omics data <a href="https://arxiv.org/pdf/2602.05811" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Characterizing Human Semantic Navigation in Concept Production as Trajectories in Embedding Space <a href="https://arxiv.org/pdf/2602.05971" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Multi-Token Prediction via Self-Distillation <a href="https://arxiv.org/pdf/2602.06019" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] ARCHI-TTS: A flow-matching-based Text-to-Speech Model with Self-supervised Semantic Aligner and Accelerated Inference <a href="https://arxiv.org/pdf/2602.05207" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv260206] Variance Reduction Based Experience Replay for Policy Optimization <a href="https://arxiv.org/pdf/2602.05379" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2026-02-26T03:26:47.000Z" itemprop="dateModified">Feb 26, 2026</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/daily/20260126-20260201"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20260126-20260201</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/daily/20260209-20260215"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">20260209-20260215</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2026-02-02" class="table-of-contents__link toc-highlight">2026-02-02</a></li><li><a href="#2026-02-03" class="table-of-contents__link toc-highlight">2026-02-03</a></li><li><a href="#2026-02-04" class="table-of-contents__link toc-highlight">2026-02-04</a></li><li><a href="#2026-02-05" class="table-of-contents__link toc-highlight">2026-02-05</a></li><li><a href="#2026-02-06" class="table-of-contents__link toc-highlight">2026-02-06</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 DarkKnight996, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>